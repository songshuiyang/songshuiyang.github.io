{"meta":{"title":"宋水阳个人博客","subtitle":null,"description":null,"author":"songshuiyang","url":"http://www.songshuiyang.com"},"pages":[{"title":"关于","date":"2017-09-09T16:35:25.000Z","updated":"2017-09-09T16:55:32.269Z","comments":true,"path":"about/index.html","permalink":"http://www.songshuiyang.com/about/index.html","excerpt":"","text":"logo 姓名:宋水阳 学校:东华理工大学 专业:软件工程 籍贯:江西省赣州市 与其纠结无法改变的过去，不如微笑着，珍惜未来。"},{"title":"","date":"2018-07-25T07:21:50.657Z","updated":"2018-07-25T07:21:50.594Z","comments":false,"path":"categories/index.html","permalink":"http://www.songshuiyang.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-25T07:20:10.686Z","updated":"2018-07-25T07:20:10.622Z","comments":false,"path":"tags/index.html","permalink":"http://www.songshuiyang.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringCloud(Feign)工作原理及源码分析","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Feign)工作原理及源码分析","date":"2019-08-06T16:06:01.000Z","updated":"2019-09-16T13:11:05.893Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Feign)工作原理及源码分析/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Feign)工作原理及源码分析/","excerpt":"","text":"前言 上一章节我们知道SpringCloudFeign基于接口来实现调用，那我们要知道它是怎么实现的，我们可以通过断点来一步步跟进，因为接口是不能具体执行任务，所以我们可以猜测是采用动态代理来实现的，应该和Mybatis的Mapper接口的工作原理差不多 解析 我们先在AuthenticationFilter的下面这行打好断点 12// 调用sso服务鉴权resModel = ssoClient.checkToken(new TokenMO(token)); 然后进入方法体feign.ReflectiveFeign.FeignInvocationHandler#invoke()，果不其然，看见FeignInvocationHandler这个类实现了InvocationHandler接口就可以知道是使用了JDK的动态代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static class FeignInvocationHandler implements InvocationHandler &#123;private final Target target;private final Map&lt;Method, MethodHandler&gt; dispatch;FeignInvocationHandler(Target target, Map&lt;Method, MethodHandler&gt; dispatch) &#123; this.target = checkNotNull(target, \"target\"); this.dispatch = checkNotNull(dispatch, \"dispatch for %s\", target);&#125;@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 执行equals()方法 if (\"equals\".equals(method.getName())) &#123; try &#123; Object otherHandler = args.length &gt; 0 &amp;&amp; args[0] != null ? Proxy.getInvocationHandler(args[0]) : null; return equals(otherHandler); &#125; catch (IllegalArgumentException e) &#123; return false; &#125; &#125; else if (\"hashCode\".equals(method.getName())) &#123; // 执行hashCode()方法 return hashCode(); &#125; else if (\"toString\".equals(method.getName())) &#123; // 执行toString()方法 return toString(); &#125; return dispatch.get(method).invoke(args);&#125;@Overridepublic boolean equals(Object obj) &#123; if (obj instanceof FeignInvocationHandler) &#123; FeignInvocationHandler other = (FeignInvocationHandler) obj; return target.equals(other.target); &#125; return false;&#125;@Overridepublic int hashCode() &#123; return target.hashCode();&#125;@Overridepublic String toString() &#123; return target.toString();&#125;&#125; 可以看到实际上调用了dispatch.get(method).invoke(args);方法，dispatch是个Map里面存的两个MethodHandler就是对应我们上一章节定义的SsoClient的两个方法 1private final Map&lt;Method, MethodHandler&gt; dispatch; 继续跳入，我们来到feign.SynchronousMethodHandler#invoke()方法，可以看到根据方法参数构造了一个RequestTemplate对象 12345678910111213141516@Overridepublic Object invoke(Object[] argv) throws Throwable &#123; RequestTemplate template = buildTemplateFromArgs.create(argv); Retryer retryer = this.retryer.clone(); while (true) &#123; try &#123; return executeAndDecode(template); &#125; catch (RetryableException e) &#123; retryer.continueOrPropagate(e); if (logLevel != Logger.Level.NONE) &#123; logger.logRetry(metadata.configKey(), logLevel); &#125; continue; &#125; &#125;&#125; 继续跳入executeAndDecode(template); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566Object executeAndDecode(RequestTemplate template) throws Throwable &#123; // 请求Request对象 Request request = targetRequest(template); if (logLevel != Logger.Level.NONE) &#123; logger.logRequest(metadata.configKey(), logLevel, request); &#125; // 结果Response对象 Response response; long start = System.nanoTime(); try &#123; // 执行请求 response = client.execute(request, options); // ensure the request is set. TODO: remove in Feign 10 response.toBuilder().request(request).build(); &#125; catch (IOException e) &#123; if (logLevel != Logger.Level.NONE) &#123; logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime(start)); &#125; throw errorExecuting(request, e); &#125; long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start); boolean shouldClose = true; try &#123; if (logLevel != Logger.Level.NONE) &#123; response = logger.logAndRebufferResponse(metadata.configKey(), logLevel, response, elapsedTime); // ensure the request is set. TODO: remove in Feign 10 response.toBuilder().request(request).build(); &#125; if (Response.class == metadata.returnType()) &#123; if (response.body() == null) &#123; return response; &#125; if (response.body().length() == null || response.body().length() &gt; MAX_RESPONSE_BUFFER_SIZE) &#123; shouldClose = false; return response; &#125; // Ensure the response body is disconnected byte[] bodyData = Util.toByteArray(response.body().asInputStream()); return response.toBuilder().body(bodyData).build(); &#125; if (response.status() &gt;= 200 &amp;&amp; response.status() &lt; 300) &#123; if (void.class == metadata.returnType()) &#123; return null; &#125; else &#123; return decode(response); &#125; &#125; else if (decode404 &amp;&amp; response.status() == 404 &amp;&amp; void.class != metadata.returnType()) &#123; return decode(response); &#125; else &#123; throw errorDecoder.decode(metadata.configKey(), response); &#125; &#125; catch (IOException e) &#123; if (logLevel != Logger.Level.NONE) &#123; logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime); &#125; throw errorReading(request, response, e); &#125; finally &#123; if (shouldClose) &#123; ensureClosed(response.body()); &#125; &#125;&#125; 我们关注response = client.execute(request, options);方法，这里client我们由上一张图可以看到是LoadBalancerFeignClient，这里的设计和之前的Ribbon的IClient类似 这个方法位于org.springframework.cloud.netflix.feign.ribbon.LoadBalancerFeignClient，见方法名可以知道是要实现负载均衡 下面的方法我们可以知道主体逻辑是调用com.netflix.client.AbstractLoadBalancerAwareClient#executeWithLoadBalancer(S, com.netflix.client.config.IClientConfig)，这个类及方法是不是有点熟悉，没错和我们之前分析Ribbon实现负载均衡的执行的方法是一样的 12345678910111213141516171819202122@Override public Response execute(Request request, Request.Options options) throws IOException &#123; try &#123; URI asUri = URI.create(request.url()); String clientName = asUri.getHost(); URI uriWithoutHost = cleanUrl(request.url(), clientName); FeignLoadBalancer.RibbonRequest ribbonRequest = new FeignLoadBalancer.RibbonRequest( this.delegate, request, uriWithoutHost); IClientConfig requestConfig = getClientConfig(options, clientName); // 开始负载均衡处理了 return lbClient(clientName).executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse(); &#125; catch (ClientException e) &#123; IOException io = findIOException(e); if (io != null) &#123; throw io; &#125; throw new RuntimeException(e); &#125;&#125; 我们这里关注lbClient(clientName)方法，这个方法是构造FeignLoadBalancer， 123private FeignLoadBalancer lbClient(String clientName) &#123; return this.lbClientFactory.create(clientName);&#125; FeignLoadBalancer 类成员变量及主要方法 1234567891011121314151617181920212223242526272829303132333435363738public class FeignLoadBalancer extends AbstractLoadBalancerAwareClient&lt;FeignLoadBalancer.RibbonRequest, FeignLoadBalancer.RibbonResponse&gt; &#123; protected int connectTimeout; protected int readTimeout; protected IClientConfig clientConfig; protected ServerIntrospector serverIntrospector; public FeignLoadBalancer(ILoadBalancer lb, IClientConfig clientConfig, ServerIntrospector serverIntrospector) &#123; super(lb, clientConfig); this.setRetryHandler(RetryHandler.DEFAULT); this.clientConfig = clientConfig; this.connectTimeout = clientConfig.get(CommonClientConfigKey.ConnectTimeout); this.readTimeout = clientConfig.get(CommonClientConfigKey.ReadTimeout); this.serverIntrospector = serverIntrospector; &#125; @Override public RibbonResponse execute(RibbonRequest request, IClientConfig configOverride) throws IOException &#123; Request.Options options; if (configOverride != null) &#123; options = new Request.Options( configOverride.get(CommonClientConfigKey.ConnectTimeout, this.connectTimeout), (configOverride.get(CommonClientConfigKey.ReadTimeout, this.readTimeout))); &#125; else &#123; options = new Request.Options(this.connectTimeout, this.readTimeout); &#125; // 执行请求 Response response = request.client().execute(request.toRequest(), options); return new RibbonResponse(request.getUri(), response); &#125; ... 类继承关系图 由上图我们看到FeignLoadBalancer继承了Ribbon的AbstractLoadBalancerAwareClient， 这个类是Ribbon执行请求客户端 我们现在来看是怎么构建FeignLoadBalancer的 12345678910111213public FeignLoadBalancer create(String clientName) &#123; // 这里做了缓存处理 if (this.cache.containsKey(clientName)) &#123; return this.cache.get(clientName); &#125; IClientConfig config = this.factory.getClientConfig(clientName); ILoadBalancer lb = this.factory.getLoadBalancer(clientName); ServerIntrospector serverIntrospector = this.factory.getInstance(clientName, ServerIntrospector.class); FeignLoadBalancer client = enableRetry ? new RetryableFeignLoadBalancer(lb, config, serverIntrospector, loadBalancedRetryPolicyFactory, loadBalancedBackOffPolicyFactory, loadBalancedRetryListenerFactory) : new FeignLoadBalancer(lb, config, serverIntrospector); this.cache.put(clientName, client); return client;&#125; 由上图我们可以看到之前设置的连接超时时间及读取超时时间及重试参数，同时还构造了Ribbon的IClientConfig客户端配置及ILoadBalancer负载均衡器对象，I字母开头 继续跳入executeWithLoadBalancer方法，进入到com.netflix.client.AbstractLoadBalancerAwareClient类中，到这里Feign就把负载均衡及重试工作给Ribbon了 123456789101112131415161718192021222324252627282930public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException &#123; LoadBalancerCommand&lt;T&gt; command = buildLoadBalancerCommand(request, requestConfig); try &#123; return command.submit( new ServerOperation&lt;T&gt;() &#123; @Override public Observable&lt;T&gt; call(Server server) &#123; URI finalUri = reconstructURIWithServer(server, request.getUri()); S requestForServer = (S) request.replaceUri(finalUri); try &#123; return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig)); &#125; catch (Exception e) &#123; return Observable.error(e); &#125; &#125; &#125;) .toBlocking() .single(); &#125; catch (Exception e) &#123; Throwable t = e.getCause(); if (t instanceof ClientException) &#123; throw (ClientException) t; &#125; else &#123; throw new ClientException(e); &#125; &#125; &#125; 上面的return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));会调用我们的FeignLoadBalancer的execute()方法，这里完成请求处理 123456789101112131415161718@Overridepublic RibbonResponse execute(RibbonRequest request, IClientConfig configOverride) throws IOException &#123; Request.Options options; if (configOverride != null) &#123; options = new Request.Options( configOverride.get(CommonClientConfigKey.ConnectTimeout, this.connectTimeout), (configOverride.get(CommonClientConfigKey.ReadTimeout, this.readTimeout))); &#125; else &#123; options = new Request.Options(this.connectTimeout, this.readTimeout); &#125; // 执行请求 Response response = request.client().execute(request.toRequest(), options); return new RibbonResponse(request.getUri(), response);&#125; 进入feign.Client.Default#execute()方法，可以看到使用了java.net.HttpURLConnection发送请求 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Overridepublic Response execute(Request request, Options options) throws IOException &#123; // 包装参数及发送请求 HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection).toBuilder().request(request).build();&#125;HttpURLConnection convertAndSend(Request request, Options options) throws IOException &#123; final HttpURLConnection connection = (HttpURLConnection) new URL(request.url()).openConnection(); if (connection instanceof HttpsURLConnection) &#123; HttpsURLConnection sslCon = (HttpsURLConnection) connection; if (sslContextFactory != null) &#123; sslCon.setSSLSocketFactory(sslContextFactory); &#125; if (hostnameVerifier != null) &#123; sslCon.setHostnameVerifier(hostnameVerifier); &#125; &#125; connection.setConnectTimeout(options.connectTimeoutMillis()); connection.setReadTimeout(options.readTimeoutMillis()); connection.setAllowUserInteraction(false); connection.setInstanceFollowRedirects(true); connection.setRequestMethod(request.method()); Collection&lt;String&gt; contentEncodingValues = request.headers().get(CONTENT_ENCODING); boolean gzipEncodedRequest = contentEncodingValues != null &amp;&amp; contentEncodingValues.contains(ENCODING_GZIP); boolean deflateEncodedRequest = contentEncodingValues != null &amp;&amp; contentEncodingValues.contains(ENCODING_DEFLATE); boolean hasAcceptHeader = false; Integer contentLength = null; for (String field : request.headers().keySet()) &#123; if (field.equalsIgnoreCase(\"Accept\")) &#123; hasAcceptHeader = true; &#125; for (String value : request.headers().get(field)) &#123; if (field.equals(CONTENT_LENGTH)) &#123; if (!gzipEncodedRequest &amp;&amp; !deflateEncodedRequest) &#123; contentLength = Integer.valueOf(value); connection.addRequestProperty(field, value); &#125; &#125; else &#123; connection.addRequestProperty(field, value); &#125; &#125; &#125; // Some servers choke on the default accept string. if (!hasAcceptHeader) &#123; connection.addRequestProperty(\"Accept\", \"*/*\"); &#125; if (request.body() != null) &#123; if (contentLength != null) &#123; connection.setFixedLengthStreamingMode(contentLength); &#125; else &#123; connection.setChunkedStreamingMode(8196); &#125; connection.setDoOutput(true); OutputStream out = connection.getOutputStream(); if (gzipEncodedRequest) &#123; out = new GZIPOutputStream(out); &#125; else if (deflateEncodedRequest) &#123; out = new DeflaterOutputStream(out); &#125; try &#123; out.write(request.body()); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException suppressed) &#123; // NOPMD &#125; &#125; &#125; return connection;&#125; 由上面convertAndSend(request, options)方法只看到了组装参数，但是发现并没有执行发送请求，而且responseCode = -1，那么是在哪里调用的，查看网上资料发现HttpURLConnection的使用有点特殊 关于要不要显示调用connect()方法的问题： 1、不需要显示调用connect方法 2、必须调用getResponseCode()方法 试了一下在不调用getResponseCode()方法的时候，无论是否调用connect()方法，请求都是不能成功的，调用connect()方法只是建立连接，并不会向服务器传递数据 只有调用getRespconseCode()方法时，才会向服务器传递数据(有博文说是getInputStream()才会向服务器传递数据，getResponseCode中会调用getInputStream方法)。跟着getResponseCode()源码发现里面调用了getInputStream()方法，在getInputStream()方法中会判断当前是否连接，如果没有连接，则调用connect()方法建立连接。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public int getResponseCode() throws IOException &#123; /* * We're got the response code already */ if (responseCode != -1) &#123; return responseCode; &#125; /* * Ensure that we have connected to the server. Record * exception as we need to re-throw it if there isn't * a status line. */ Exception exc = null; try &#123; // 这里面会建立连接并发送请求 getInputStream(); &#125; catch (Exception e) &#123; exc = e; &#125; /* * If we can't a status-line then re-throw any exception * that getInputStream threw. */ String statusLine = getHeaderField(0); if (statusLine == null) &#123; if (exc != null) &#123; if (exc instanceof RuntimeException) throw (RuntimeException)exc; else throw (IOException)exc; &#125; return -1; &#125; /* * Examine the status-line - should be formatted as per * section 6.1 of RFC 2616 :- * * Status-Line = HTTP-Version SP Status-Code SP Reason-Phrase * * If status line can't be parsed return -1. */ if (statusLine.startsWith(\"HTTP/1.\")) &#123; int codePos = statusLine.indexOf(' '); if (codePos &gt; 0) &#123; int phrasePos = statusLine.indexOf(' ', codePos+1); if (phrasePos &gt; 0 &amp;&amp; phrasePos &lt; statusLine.length()) &#123; responseMessage = statusLine.substring(phrasePos+1); &#125; // deviation from RFC 2616 - don't reject status line // if SP Reason-Phrase is not included. if (phrasePos &lt; 0) phrasePos = statusLine.length(); try &#123; responseCode = Integer.parseInt (statusLine.substring(codePos+1, phrasePos)); return responseCode; &#125; catch (NumberFormatException e) &#123; &#125; &#125; &#125; return -1;&#125; 执行完成convertAndSend(request, options)方法之后进入convertResponse(connection)方法，可以看到这里调用了connection.getResponseCode();方法，执行完成之后就得到了200的返回码 1234567891011121314151617181920212223242526272829303132333435Response convertResponse(HttpURLConnection connection) throws IOException &#123; // 这里会触发请求 int status = connection.getResponseCode(); String reason = connection.getResponseMessage(); if (status &lt; 0) &#123; throw new IOException(format(\"Invalid status(%s) executing %s %s\", status, connection.getRequestMethod(), connection.getURL())); &#125; Map&lt;String, Collection&lt;String&gt;&gt; headers = new LinkedHashMap&lt;String, Collection&lt;String&gt;&gt;(); for (Map.Entry&lt;String, List&lt;String&gt;&gt; field : connection.getHeaderFields().entrySet()) &#123; // response message if (field.getKey() != null) &#123; headers.put(field.getKey(), field.getValue()); &#125; &#125; Integer length = connection.getContentLength(); if (length == -1) &#123; length = null; &#125; InputStream stream; if (status &gt;= 400) &#123; stream = connection.getErrorStream(); &#125; else &#123; stream = connection.getInputStream(); &#125; return Response.builder() .status(status) .reason(reason) .headers(headers) .body(stream, length) .build();&#125; 执行完请求之后就是根据 status、reason、headers、InputStream请求构造了Response对象，这里使用了建造者设计模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public Builder toBuilder()&#123; return new Builder(this);&#125;public static Builder builder()&#123; return new Builder();&#125;public static final class Builder &#123; int status; String reason; Map&lt;String, Collection&lt;String&gt;&gt; headers; Body body; Request request; Builder() &#123; &#125; Builder(Response source) &#123; this.status = source.status; this.reason = source.reason; this.headers = source.headers; this.body = source.body; this.request = source.request; &#125; /** @see Response#status*/ public Builder status(int status) &#123; this.status = status; return this; &#125; /** @see Response#reason */ public Builder reason(String reason) &#123; this.reason = reason; return this; &#125; /** @see Response#headers */ public Builder headers(Map&lt;String, Collection&lt;String&gt;&gt; headers) &#123; this.headers = headers; return this; &#125; /** @see Response#body */ public Builder body(Body body) &#123; this.body = body; return this; &#125; /** @see Response#body */ public Builder body(InputStream inputStream, Integer length) &#123; this.body = InputStreamBody.orNull(inputStream, length); return this; &#125; /** @see Response#body */ public Builder body(byte[] data) &#123; this.body = ByteArrayBody.orNull(data); return this; &#125; /** @see Response#body */ public Builder body(String text, Charset charset) &#123; this.body = ByteArrayBody.orNull(text, charset); return this; &#125; /** @see Response#request * * NOTE: will add null check in version 10 which may require changes * to custom feign.Client or loggers */ public Builder request(Request request) &#123; this.request = request; return this; &#125; public Response build() &#123; return new Response(this); &#125;&#125; 现在我们得到了Response对象，现在回到feign.SynchronousMethodHandler#executeAndDecode()方法，得到结果之后就是要将Http的响应流转化成实体类对象了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667Object executeAndDecode(RequestTemplate template) throws Throwable &#123; // 请求Request对象 Request request = targetRequest(template); if (logLevel != Logger.Level.NONE) &#123; logger.logRequest(metadata.configKey(), logLevel, request); &#125; // 结果Response对象 Response response; long start = System.nanoTime(); try &#123; // 执行请求 response = client.execute(request, options); // ensure the request is set. TODO: remove in Feign 10 response.toBuilder().request(request).build(); &#125; catch (IOException e) &#123; if (logLevel != Logger.Level.NONE) &#123; logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime(start)); &#125; throw errorExecuting(request, e); &#125; long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start); boolean shouldClose = true; try &#123; if (logLevel != Logger.Level.NONE) &#123; response = logger.logAndRebufferResponse(metadata.configKey(), logLevel, response, elapsedTime); // ensure the request is set. TODO: remove in Feign 10 response.toBuilder().request(request).build(); &#125; if (Response.class == metadata.returnType()) &#123; if (response.body() == null) &#123; return response; &#125; if (response.body().length() == null || response.body().length() &gt; MAX_RESPONSE_BUFFER_SIZE) &#123; shouldClose = false; return response; &#125; // Ensure the response body is disconnected byte[] bodyData = Util.toByteArray(response.body().asInputStream()); return response.toBuilder().body(bodyData).build(); &#125; if (response.status() &gt;= 200 &amp;&amp; response.status() &lt; 300) &#123; if (void.class == metadata.returnType()) &#123; return null; &#125; else &#123; // 解析结果 return decode(response); &#125; &#125; else if (decode404 &amp;&amp; response.status() == 404 &amp;&amp; void.class != metadata.returnType()) &#123; return decode(response); &#125; else &#123; throw errorDecoder.decode(metadata.configKey(), response); &#125; &#125; catch (IOException e) &#123; if (logLevel != Logger.Level.NONE) &#123; logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime); &#125; throw errorReading(request, response, e); &#125; finally &#123; if (shouldClose) &#123; ensureClosed(response.body()); &#125; &#125;&#125; 关注下面这块代码可以看到是对返回码200-300进行了处理 12345678if (response.status() &gt;= 200 &amp;&amp; response.status() &lt; 300) &#123; if (void.class == metadata.returnType()) &#123; return null; &#125; else &#123; // 解析结果 return decode(response); &#125; &#125; 继续跳入 decode(response)方法直到进入org.springframework.cloud.netflix.feign.support.SpringDecoder#decode(final Response response, Type type)方法，可以看到和Spring MVC解析输入参数及输出结果一样使用了HttpMessageConverter进行转化 1234567891011121314@Overridepublic Object decode(final Response response, Type type) throws IOException, FeignException &#123; if (type instanceof Class || type instanceof ParameterizedType || type instanceof WildcardType) &#123; @SuppressWarnings(&#123; \"unchecked\", \"rawtypes\" &#125;) HttpMessageConverterExtractor&lt;?&gt; extractor = new HttpMessageConverterExtractor( type, this.messageConverters.getObject().getConverters()); return extractor.extractData(new FeignResponseAdapter(response)); &#125; throw new DecodeException( \"type is not an instance of Class or ParameterizedType: \" + type);&#125; 到这里Feign请求就执行完成了 总结 SpringCloudFeign采用JDK动态代理基于接口来实现调用，SpringCloudFeign主要做的就是解析@FeignClient注解及其方法定义信息，一个方法封装成一个MethodHandler，由此对象来完成方法执行逻辑 ，同时集成了Ribbon来实现负载均衡处理，专人做专事，具体发送请求是由自身FeignLoadBalancer的execute()方法来执行的，这里涉及到请求参数及响应参数的解析","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Feign)声明式服务调用介绍","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Feign)声明式服务调用介绍","date":"2019-08-06T16:06:00.000Z","updated":"2019-09-16T13:11:05.881Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Feign)声明式服务调用介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Feign)声明式服务调用介绍/","excerpt":"","text":"Feign 简介是什么 Feign是一个声明式的Web Service客户端，它的出现让微服务之间的调用变得更简单了 SpringCloudFeign在Netfix Feign的基础上扩展了对SpringMVC的注解支持，所以通过这些注解可以很方便的定义一些服务接口，服务调服务通过接口来调用十分方便，同时SpringCloudFeign整合了Spring Cloud Ribbon与Spring Cloud Hystrix，具有负载均衡及服务容错保护功能 为什么要使用 只需创建一个接口并用注解的方式来配置它，即可完成服务提供方的接口绑定 在使用过程中与Spring MVC完美衔接 整合了Spring Cloud Ribbon，可实现负载均衡，实现服务高可用 整合了Spring Cloud Hystrix，可实现服务断路及服务降级 简单例子 下面通过一个简单示例来展示SpringCloudFeign在服务客户端定义上所带来的便利 1、pom.xml 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; 2、启动类添加开关注解 @EnableFeignClients 12345678910@EnableFeignClients@EnableZuulProxy@SpringCloudApplicationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 3、新增cloudSso服务接口类，下面可以看到使用了Spring MVC的注解，@FeignClient(value = &quot;cloudSso&quot;)的value是具体调用服务的服务名 12345678910111213141516171819@FeignClient(value = \"cloudSso\")public interface SsoClient &#123; @PostMapping(\"/sso/createToken\") ResponseMO createToken(); @PostMapping(\"/sso/checkToken\") ResponseMO checkToken(@RequestBody TokenMO tokenMO);&#125;// 也可以这么使用，通过url来访问接口@FeignClient(value = \"cloudOther\", url = \"https://www.baidu.com\")public interface BaiduClient &#123; @PostMapping(\"/baidu\") ResponseMO baidu(); &#125; SsoController.java 是cloudSso服务下的接口 1234567891011121314@RestController@RequestMapping(\"/sso\")public class SsoController extends BaseController &#123; @PostMapping(\"/createToken\") public ResponseMO createToken() &#123; return ResponseUtil.successWithData(\"EADF89QWJ0IFJWEJFQHWEFU9QEWH9FH0Q9EW\"); &#125; @PostMapping(\"/checkToken\") public ResponseMO checkToken(@RequestBody TokenMO tokenMO) &#123; return ResponseUtil.successWithData(tokenMO); &#125;&#125; 4、有了上面的准备之后就可以使用SsoClient的接口了，前面学习Zuul的文章有介绍，如果要对网关服务进行鉴权校验，我们这里添加了一个鉴权Filter,通过调用SsoClient接口的checkToken()方法来校验Token是否有效 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105@Slf4j@Componentpublic class AuthenticationFilter extends ZuulFilter &#123; @Autowired private SsoClient ssoClient; private Pattern p = Pattern.compile(\"/*/pub/*\"); @Override public Object run() &#123; ResponseMO resMO = new ResponseMO(); RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String relativeURL = extractRelativePath(request); String token = request.getHeader(WebConstants.TOKEN_HEADER); if (p.matcher(relativeURL).find()) &#123; return null; &#125; log.info(\"&gt;&gt; 鉴权开始[&#123;&#125;]\",relativeURL); ResponseMO resModel = null; if (relativeURL.startsWith(ApplicationConstants.APPLICATION_ZUUL) || relativeURL.startsWith(ApplicationConstants.APPLICATION_USER) || relativeURL.startsWith(ApplicationConstants.APPLICATION_SSO)) &#123; // 调用sso服务鉴权 resModel = ssoClient.checkToken(new TokenMO(token)); &#125; else &#123; // 其他服务不对其进行路由 authorizationFailed(relativeURL, ctx, resMO); return null; &#125; if (resModel.getCode() != ResponseMO.RESPONSE_CODE_SUCCESS) &#123; // 鉴权失败不对其进行路由 authorizationFailed(relativeURL, ctx, resMO); return null; &#125; // 从jwt解析后的userId ctx.addZuulRequestHeader(\"userId\", \"reUserId\"); log.info(\"&lt;&lt; 鉴权通过[&#123;&#125;]] \", relativeURL); return null; &#125; /** * 返回一个boolean值来判断该过滤器是否要执行，true表示执行，false表示不执行 * @return */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * gives the order in which this filter will be executed, relative to other * filters * @return */ @Override public int filterOrder() &#123; // TODO Auto-generated method stub return 0; &#125; @Override public String filterType() &#123; return \"pre\"; &#125; /** * 鉴权失败 * @param relativeURL * @param ctx * @param resMO */ private void authorizationFailed (String relativeURL, RequestContext ctx, ResponseMO resMO) &#123; ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); resMO.setAnonymous(); String resBody = convertToString(resMO); ctx.setResponseBody(resBody); log.info(\"&lt;&lt; 鉴权失败[&#123;&#125;]\",relativeURL); &#125; private String convertToString(ResponseMO resMO) &#123; String result = \"\"; ObjectMapper mapper = new ObjectMapper(); try &#123; result = mapper.writeValueAsString(resMO); &#125; catch (JsonProcessingException e) &#123; log.error(e.getMessage()); &#125; return result; &#125; /** * 获取相对访问路径 * @param request * @return */ private String extractRelativePath(HttpServletRequest request) &#123; String requestURI = request.getRequestURI(); return requestURI; &#125;&#125; 总结 SpringCloudFeign基于接口来实现调用，Spring Cloud 给Feign 添加了支持 Spring MVC 注解，这对应我们平常开发来说是很容易上手的","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Zuul)服务路由转发RibbonRoutingFilter","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)服务路由转发RibbonRoutingFilter","date":"2019-08-06T16:05:03.000Z","updated":"2019-09-16T13:11:06.070Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)服务路由转发RibbonRoutingFilter/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)服务路由转发RibbonRoutingFilter/","excerpt":"","text":"前言 当我们为Spring Cloud Zuul构建的API网关服务引入Spring Cloud Consul之后，它会为Consul中的每个服务都自动创建一个默认路由规则，这些默认规则的path会使用ServiceId配置的服务名作为请求前缀 比如上图我们在consul注册了cloudZuul，cloudSso，cloudUser三个服务，那么就可以通过服务名作为请求前缀将请求转发到不同服务上，这里我们cloudZuul服务地址为http://127.0.0.1:2000 访问cloudUser服务接口，举例:http://127.0.0.1:2000/cloudUser/user/getById/1 访问cloudSso服务接口，举例:http://127.0.0.1:2000/cloudSso/sso/createToken 上面这个服务路由转发是怎么实现的呢，通过上面几章我们可以知道zuul内部工作是通过一系列的ZuulFilter来实现的，通过调试断点可以定位到这个RibbonRoutingFilter，这个ZuulFilter的filterType是route 解析 查看RibbonRoutingFilter.java，查看注释可以看到是使用了Ribbon及Hystrix 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184/** * Route &#123;@link ZuulFilter&#125; that uses Ribbon, Hystrix and pluggable http clients to send requests. * ServiceIds are found in the &#123;@link RequestContext&#125; attribute &#123;@link org.springframework.cloud.netflix.zuul.filters.support.FilterConstants#SERVICE_ID_KEY&#125;. * * @author Spencer Gibb * @author Dave Syer * @author Ryan Baxter */public class RibbonRoutingFilter extends ZuulFilter &#123; private static final Log log = LogFactory.getLog(RibbonRoutingFilter.class); protected ProxyRequestHelper helper; protected RibbonCommandFactory&lt;?&gt; ribbonCommandFactory; protected List&lt;RibbonRequestCustomizer&gt; requestCustomizers; private boolean useServlet31 = true; public RibbonRoutingFilter(ProxyRequestHelper helper, RibbonCommandFactory&lt;?&gt; ribbonCommandFactory, List&lt;RibbonRequestCustomizer&gt; requestCustomizers) &#123; this.helper = helper; this.ribbonCommandFactory = ribbonCommandFactory; this.requestCustomizers = requestCustomizers; // To support Servlet API 3.1 we need to check if getContentLengthLong exists try &#123; //TODO: remove in 2.0 HttpServletRequest.class.getMethod(\"getContentLengthLong\"); &#125; catch(NoSuchMethodException e) &#123; useServlet31 = false; &#125; &#125; public RibbonRoutingFilter(RibbonCommandFactory&lt;?&gt; ribbonCommandFactory) &#123; this(new ProxyRequestHelper(), ribbonCommandFactory, null); &#125; /* for testing */ boolean isUseServlet31() &#123; return useServlet31; &#125; @Override public String filterType() &#123; return ROUTE_TYPE; &#125; @Override public int filterOrder() &#123; return RIBBON_ROUTING_FILTER_ORDER; &#125; @Override public boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); return (ctx.getRouteHost() == null &amp;&amp; ctx.get(SERVICE_ID_KEY) != null &amp;&amp; ctx.sendZuulResponse()); &#125; @Override public Object run() &#123; RequestContext context = RequestContext.getCurrentContext(); this.helper.addIgnoredHeaders(); try &#123; RibbonCommandContext commandContext = buildCommandContext(context); ClientHttpResponse response = forward(commandContext); setResponse(response); return response; &#125; catch (ZuulException ex) &#123; throw new ZuulRuntimeException(ex); &#125; catch (Exception ex) &#123; throw new ZuulRuntimeException(ex); &#125; &#125; protected RibbonCommandContext buildCommandContext(RequestContext context) &#123; HttpServletRequest request = context.getRequest(); MultiValueMap&lt;String, String&gt; headers = this.helper .buildZuulRequestHeaders(request); MultiValueMap&lt;String, String&gt; params = this.helper .buildZuulRequestQueryParams(request); String verb = getVerb(request); InputStream requestEntity = getRequestBody(request); if (request.getContentLength() &lt; 0 &amp;&amp; !verb.equalsIgnoreCase(\"GET\")) &#123; context.setChunkedRequestBody(); &#125; String serviceId = (String) context.get(SERVICE_ID_KEY); Boolean retryable = (Boolean) context.get(RETRYABLE_KEY); Object loadBalancerKey = context.get(LOAD_BALANCER_KEY); String uri = this.helper.buildZuulRequestURI(request); // remove double slashes uri = uri.replace(\"//\", \"/\"); long contentLength = useServlet31 ? request.getContentLengthLong(): request.getContentLength(); return new RibbonCommandContext(serviceId, verb, uri, retryable, headers, params, requestEntity, this.requestCustomizers, contentLength, loadBalancerKey); &#125; protected ClientHttpResponse forward(RibbonCommandContext context) throws Exception &#123; Map&lt;String, Object&gt; info = this.helper.debug(context.getMethod(), context.getUri(), context.getHeaders(), context.getParams(), context.getRequestEntity()); RibbonCommand command = this.ribbonCommandFactory.create(context); try &#123; ClientHttpResponse response = command.execute(); this.helper.appendDebug(info, response.getRawStatusCode(), response.getHeaders()); return response; &#125; catch (HystrixRuntimeException ex) &#123; return handleException(info, ex); &#125; &#125; protected ClientHttpResponse handleException(Map&lt;String, Object&gt; info, HystrixRuntimeException ex) throws ZuulException &#123; int statusCode = HttpStatus.INTERNAL_SERVER_ERROR.value(); Throwable cause = ex; String message = ex.getFailureType().toString(); ClientException clientException = findClientException(ex); if (clientException == null) &#123; clientException = findClientException(ex.getFallbackException()); &#125; if (clientException != null) &#123; if (clientException .getErrorType() == ClientException.ErrorType.SERVER_THROTTLED) &#123; statusCode = HttpStatus.SERVICE_UNAVAILABLE.value(); &#125; cause = clientException; message = clientException.getErrorType().toString(); &#125; info.put(\"status\", String.valueOf(statusCode)); throw new ZuulException(cause, \"Forwarding error\", statusCode, message); &#125; protected ClientException findClientException(Throwable t) &#123; if (t == null) &#123; return null; &#125; if (t instanceof ClientException) &#123; return (ClientException) t; &#125; return findClientException(t.getCause()); &#125; protected InputStream getRequestBody(HttpServletRequest request) &#123; InputStream requestEntity = null; try &#123; requestEntity = (InputStream) RequestContext.getCurrentContext() .get(REQUEST_ENTITY_KEY); if (requestEntity == null) &#123; requestEntity = request.getInputStream(); &#125; &#125; catch (IOException ex) &#123; log.error(\"Error during getRequestBody\", ex); &#125; return requestEntity; &#125; protected String getVerb(HttpServletRequest request) &#123; String method = request.getMethod(); if (method == null) &#123; return \"GET\"; &#125; return method; &#125; protected void setResponse(ClientHttpResponse resp) throws ClientException, IOException &#123; RequestContext.getCurrentContext().set(\"zuulResponse\", resp); this.helper.setResponse(resp.getRawStatusCode(), resp.getBody() == null ? null : resp.getBody(), resp.getHeaders()); &#125;&#125; 我们关注run()方法，可以发现可以划分为三个步骤 123456789101112131415161718192021@Overridepublic Object run() &#123; // 获取RequestContext RequestContext context = RequestContext.getCurrentContext(); this.helper.addIgnoredHeaders(); try &#123; // 构建执行Ribbon命令的参数 RibbonCommandContext commandContext = buildCommandContext(context); // 执行请求(核心) ClientHttpResponse response = forward(commandContext); // 设置返回体 setResponse(response); return response; &#125; catch (ZuulException ex) &#123; throw new ZuulRuntimeException(ex); &#125; catch (Exception ex) &#123; throw new ZuulRuntimeException(ex); &#125;&#125; 1、构建执行Ribbon命令的参数 下图是http://127.0.0.1:2000/cloudSso/sso/createToken链接构造的RibbonCommandContext，可以看到获取到了serviceId、请求链接及方式、请求头的一些信息 buildCommandContext()方法就是通过RequestContext来构造RibbonCommandContext，RequestContext通过之前的ZuulFilter已经设置了一些属性，那么buildCommandContext()方法就可以很方便的获取一些参数信息 1234567891011121314151617181920212223242526272829protected RibbonCommandContext buildCommandContext(RequestContext context) &#123; HttpServletRequest request = context.getRequest(); MultiValueMap&lt;String, String&gt; headers = this.helper .buildZuulRequestHeaders(request); MultiValueMap&lt;String, String&gt; params = this.helper .buildZuulRequestQueryParams(request); String verb = getVerb(request); InputStream requestEntity = getRequestBody(request); if (request.getContentLength() &lt; 0 &amp;&amp; !verb.equalsIgnoreCase(\"GET\")) &#123; context.setChunkedRequestBody(); &#125; // 获取serviceId String serviceId = (String) context.get(SERVICE_ID_KEY); // 是否重试 Boolean retryable = (Boolean) context.get(RETRYABLE_KEY); // 负载均衡key Object loadBalancerKey = context.get(LOAD_BALANCER_KEY); String uri = this.helper.buildZuulRequestURI(request); // remove double slashes uri = uri.replace(\"//\", \"/\"); long contentLength = useServlet31 ? request.getContentLengthLong(): request.getContentLength(); return new RibbonCommandContext(serviceId, verb, uri, retryable, headers, params, requestEntity, this.requestCustomizers, contentLength, loadBalancerKey);&#125; 2、执行请求(核心) forward()方法是执行的主体逻辑，可以看到主要逻辑是构建RibbonCommand然后执行command.execute()方法，由RibbonCommand完成HTTP请求的发送并的得到响应结果ClientHttpResponse 123456789101112131415protected ClientHttpResponse forward(RibbonCommandContext context) throws Exception &#123; Map&lt;String, Object&gt; info = this.helper.debug(context.getMethod(), context.getUri(), context.getHeaders(), context.getParams(), context.getRequestEntity()); RibbonCommand command = this.ribbonCommandFactory.create(context); try &#123; ClientHttpResponse response = command.execute(); this.helper.appendDebug(info, response.getRawStatusCode(), response.getHeaders()); return response; &#125; catch (HystrixRuntimeException ex) &#123; return handleException(info, ex); &#125;&#125; 进入command.execute(); 方法，可以看到注释这个方法是同步执行方法，但里面又调用了queue().get()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132/** * Used for synchronous execution of command. * * @return R * Result of &#123;@link #run()&#125; execution or a fallback from &#123;@link #getFallback()&#125; if the command fails for any reason. * @throws HystrixRuntimeException * if a failure occurs and a fallback cannot be retrieved * @throws HystrixBadRequestException * if invalid arguments or state were used representing a user failure, not a system failure * @throws IllegalStateException * if invoked more than once */public R execute() &#123; try &#123; return queue().get(); &#125; catch (Exception e) &#123; throw Exceptions.sneakyThrow(decomposeException(e)); &#125;&#125;/** * Used for asynchronous execution of command. * &lt;p&gt; * This will queue up the command on the thread pool and return an &#123;@link Future&#125; to get the result once it completes. * &lt;p&gt; * NOTE: If configured to not run in a separate thread, this will have the same effect as &#123;@link #execute()&#125; and will block. * &lt;p&gt; * We don't throw an exception but just flip to synchronous execution so code doesn't need to change in order to switch a command from running on a separate thread to the calling thread. * * @return &#123;@code Future&lt;R&gt;&#125; Result of &#123;@link #run()&#125; execution or a fallback from &#123;@link #getFallback()&#125; if the command fails for any reason. * @throws HystrixRuntimeException * if a fallback does not exist * &lt;p&gt; * &lt;ul&gt; * &lt;li&gt;via &#123;@code Future.get()&#125; in &#123;@link ExecutionException#getCause()&#125; if a failure occurs&lt;/li&gt; * &lt;li&gt;or immediately if the command can not be queued (such as short-circuited, thread-pool/semaphore rejected)&lt;/li&gt; * &lt;/ul&gt; * @throws HystrixBadRequestException * via &#123;@code Future.get()&#125; in &#123;@link ExecutionException#getCause()&#125; if invalid arguments or state were used representing a user failure, not a system failure * @throws IllegalStateException * if invoked more than once */public Future&lt;R&gt; queue() &#123; /* * The Future returned by Observable.toBlocking().toFuture() does not implement the * interruption of the execution thread when the \"mayInterrupt\" flag of Future.cancel(boolean) is set to true; * thus, to comply with the contract of Future, we must wrap around it. */ final Future&lt;R&gt; delegate = toObservable().toBlocking().toFuture(); final Future&lt;R&gt; f = new Future&lt;R&gt;() &#123; @Override public boolean cancel(boolean mayInterruptIfRunning) &#123; if (delegate.isCancelled()) &#123; return false; &#125; if (HystrixCommand.this.getProperties().executionIsolationThreadInterruptOnFutureCancel().get()) &#123; /* * The only valid transition here is false -&gt; true. If there are two futures, say f1 and f2, created by this command * (which is super-weird, but has never been prohibited), and calls to f1.cancel(true) and to f2.cancel(false) are * issued by different threads, it's unclear about what value would be used by the time mayInterruptOnCancel is checked. * The most consistent way to deal with this scenario is to say that if *any* cancellation is invoked with interruption, * than that interruption request cannot be taken back. */ interruptOnFutureCancel.compareAndSet(false, mayInterruptIfRunning); &#125; final boolean res = delegate.cancel(interruptOnFutureCancel.get()); if (!isExecutionComplete() &amp;&amp; interruptOnFutureCancel.get()) &#123; final Thread t = executionThread.get(); if (t != null &amp;&amp; !t.equals(Thread.currentThread())) &#123; t.interrupt(); &#125; &#125; return res; &#125; @Override public boolean isCancelled() &#123; return delegate.isCancelled(); &#125; @Override public boolean isDone() &#123; return delegate.isDone(); &#125; @Override public R get() throws InterruptedException, ExecutionException &#123; return delegate.get(); &#125; @Override public R get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return delegate.get(timeout, unit); &#125; &#125;; // 特殊处理立即抛出的错误状态 /* special handling of error states that throw immediately */ if (f.isDone()) &#123; try &#123; f.get(); return f; &#125; catch (Exception e) &#123; Throwable t = decomposeException(e); if (t instanceof HystrixBadRequestException) &#123; return f; &#125; else if (t instanceof HystrixRuntimeException) &#123; HystrixRuntimeException hre = (HystrixRuntimeException) t; switch (hre.getFailureType()) &#123; case COMMAND_EXCEPTION: case TIMEOUT: // we don't throw these types from queue() only from queue().get() as they are execution errors return f; default: // these are errors we throw from queue() as they as rejection type errors throw hre; &#125; &#125; else &#123; throw Exceptions.sneakyThrow(t); &#125; &#125; &#125; return f;&#125; 这个queue()方法 查看注释可以知道这里采用了异步执行命令，这将在线程池上排队命令并返回{@link Future}以在结果完成后获得结果。 可以看到final Future&lt;R&gt; delegate = toObservable().toBlocking().toFuture();，这里使用了Future来执行处理，这个在多线程中可以经常看见，使用这个类可以得到线程的执行结果、什么Observable 观察者模式、toBlocking 队列形式 toObservable()方法，这里使用了ReactiveX，这块感觉比较复杂，加个TODO ReactiveX这里简单百度了下 RxJava是 ReactiveX 在JVM上的一个实现，ReactiveX使用Observable序列组合异步和基于事件的程序。 相关链接:官网 中文文档 经过上面异步和基于事件的处理，我们可以来到下面这个方法 进入com.netflix.loadbalancer.reactive.LoadBalancerCommand#selectServer()方法，这个方法是根据负载均衡器返回一个Server 123456789101112131415161718/** * Return an Observable that either emits only the single requested server * or queries the load balancer for the next server on each subscription */private Observable&lt;Server&gt; selectServer() &#123; return Observable.create(new OnSubscribe&lt;Server&gt;() &#123; @Override public void call(Subscriber&lt;? super Server&gt; next) &#123; try &#123; Server server = loadBalancerContext.getServerFromLoadBalancer(loadBalancerURI, loadBalancerKey); next.onNext(server); next.onCompleted(); &#125; catch (Exception e) &#123; next.onError(e); &#125; &#125; &#125;);&#125; 进入com.netflix.loadbalancer.LoadBalancerContext#getServerFromLoadBalancer()方法，可以看到主要逻辑是从请求中的部分URI计算最终URI，下面有好几种情况 如果主机丢失并且有负载均衡器，那么是从负载均衡器中选择的服务器获取主机/端口 如果主机丢失且没有负载均衡器，请尝试从客户端设置的虚拟地址派生主机/端口 如果主机存在并且URI的权限部分是为客户端设置的虚拟地址，并且存在负载均衡器，则从负载均衡器中选择的服务器获取主机/端口 如果主机存在但上述情况均不适用，则将主机解释为实际物理地址 如果主机丢失但以上都不适用，则抛出ClientException 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/** * Compute the final URI from a partial URI in the request. The following steps are performed: * &lt;ul&gt; * &lt;li&gt; if host is missing and there is a load balancer, get the host/port from server chosen from load balancer * &lt;li&gt; if host is missing and there is no load balancer, try to derive host/port from virtual address set with the client * &lt;li&gt; if host is present and the authority part of the URI is a virtual address set for the client, * and there is a load balancer, get the host/port from server chosen from load balancer * &lt;li&gt; if host is present but none of the above applies, interpret the host as the actual physical address * &lt;li&gt; if host is missing but none of the above applies, throws ClientException * &lt;/ul&gt; * * @param original Original URI passed from caller */public Server getServerFromLoadBalancer(@Nullable URI original, @Nullable Object loadBalancerKey) throws ClientException &#123; String host = null; int port = -1; if (original != null) &#123; host = original.getHost(); &#125; if (original != null) &#123; Pair&lt;String, Integer&gt; schemeAndPort = deriveSchemeAndPortFromPartialUri(original); port = schemeAndPort.second(); &#125; // Various Supported Cases // The loadbalancer to use and the instances it has is based on how it was registered // In each of these cases, the client might come in using Full Url or Partial URL ILoadBalancer lb = getLoadBalancer(); if (host == null) &#123; // Partial URI or no URI Case // well we have to just get the right instances from lb - or we fall back if (lb != null)&#123; // 选择服务实例 Server svc = lb.chooseServer(loadBalancerKey); if (svc == null)&#123; throw new ClientException(ClientException.ErrorType.GENERAL, \"Load balancer does not have available server for client: \" + clientName); &#125; host = svc.getHost(); if (host == null)&#123; throw new ClientException(ClientException.ErrorType.GENERAL, \"Invalid Server for :\" + svc); &#125; logger.debug(\"&#123;&#125; using LB returned Server: &#123;&#125; for request &#123;&#125;\", new Object[]&#123;clientName, svc, original&#125;); return svc; &#125; else &#123; // No Full URL - and we dont have a LoadBalancer registered to // obtain a server // if we have a vipAddress that came with the registration, we // can use that else we // bail out if (vipAddresses != null &amp;&amp; vipAddresses.contains(\",\")) &#123; throw new ClientException( ClientException.ErrorType.GENERAL, \"Method is invoked for client \" + clientName + \" with partial URI of (\" + original + \") with no load balancer configured.\" + \" Also, there are multiple vipAddresses and hence no vip address can be chosen\" + \" to complete this partial uri\"); &#125; else if (vipAddresses != null) &#123; try &#123; Pair&lt;String,Integer&gt; hostAndPort = deriveHostAndPortFromVipAddress(vipAddresses); host = hostAndPort.first(); port = hostAndPort.second(); &#125; catch (URISyntaxException e) &#123; throw new ClientException( ClientException.ErrorType.GENERAL, \"Method is invoked for client \" + clientName + \" with partial URI of (\" + original + \") with no load balancer configured. \" + \" Also, the configured/registered vipAddress is unparseable (to determine host and port)\"); &#125; &#125; else &#123; throw new ClientException( ClientException.ErrorType.GENERAL, this.clientName + \" has no LoadBalancer registered and passed in a partial URL request (with no host:port).\" + \" Also has no vipAddress registered\"); &#125; &#125; &#125; else &#123; // Full URL Case // This could either be a vipAddress or a hostAndPort or a real DNS // if vipAddress or hostAndPort, we just have to consult the loadbalancer // but if it does not return a server, we should just proceed anyways // and assume its a DNS // For restClients registered using a vipAddress AND executing a request // by passing in the full URL (including host and port), we should only // consult lb IFF the URL passed is registered as vipAddress in Discovery boolean shouldInterpretAsVip = false; if (lb != null) &#123; shouldInterpretAsVip = isVipRecognized(original.getAuthority()); &#125; if (shouldInterpretAsVip) &#123; Server svc = lb.chooseServer(loadBalancerKey); if (svc != null)&#123; host = svc.getHost(); if (host == null)&#123; throw new ClientException(ClientException.ErrorType.GENERAL, \"Invalid Server for :\" + svc); &#125; logger.debug(\"using LB returned Server: &#123;&#125; for request: &#123;&#125;\", svc, original); return svc; &#125; else &#123; // just fall back as real DNS logger.debug(\"&#123;&#125;:&#123;&#125; assumed to be a valid VIP address or exists in the DNS\", host, port); &#125; &#125; else &#123; // consult LB to obtain vipAddress backed instance given full URL //Full URL execute request - where url!=vipAddress logger.debug(\"Using full URL passed in by caller (not using load balancer): &#123;&#125;\", original); &#125; &#125; // end of creating final URL if (host == null)&#123; throw new ClientException(ClientException.ErrorType.GENERAL,\"Request contains no HOST to talk to\"); &#125; // just verify that at this point we have a full URL return new Server(host, port);&#125; 我们这里进入Server svc = lb.chooseServer(loadBalancerKey);方法 进入com.netflix.loadbalancer.AbstractServerPredicate#chooseRoundRobinAfterFiltering()方法，我这里可以看到是有两个服务实例，那么就是需要从这两个中选择一个 1234567891011121314151617181920212223242526/** * Choose a server in a round robin fashion after the predicate filters a given list of servers and load balancer key. */public Optional&lt;Server&gt; chooseRoundRobinAfterFiltering(List&lt;Server&gt; servers, Object loadBalancerKey) &#123; // 从服务实例列表中筛选一下符合条件的服务 List&lt;Server&gt; eligible = getEligibleServers(servers, loadBalancerKey); if (eligible.size() == 0) &#123; return Optional.absent(); &#125; return Optional.of(eligible.get(incrementAndGetModulo(eligible.size())));&#125;/** * Referenced from RoundRobinRule * Inspired by the implementation of &#123;@link AtomicInteger#incrementAndGet()&#125;. * * @param modulo The modulo to bound the value of the counter. * @return The next value. */private int incrementAndGetModulo(int modulo) &#123; for (;;) &#123; int current = nextIndex.get(); int next = (current + 1) % modulo; if (nextIndex.compareAndSet(current, next)) return current; &#125;&#125; incrementAndGetModulo()这里默认是采用了简单轮询负载均衡（RoundRobin）策略，看注释这里是copy了JDK里的{@link AtomicInteger#incrementAndGet()} 我们可以测试下这个方法 测试代码： 123456789101112131415161718192021222324252627282930public class IncrementAndGetModuloTest &#123; private final AtomicInteger nextIndex = new AtomicInteger(); public static void main(String[] args) &#123; IncrementAndGetModuloTest incrementAndGetModuloTest = new IncrementAndGetModuloTest(); List&lt;String&gt; eligible = new ArrayList&lt;String&gt;(); eligible.add(\"服务1\"); eligible.add(\"服务2\"); eligible.add(\"服务3\"); eligible.add(\"服务4\"); eligible.add(\"服务5\"); for (int i = 0; i &lt; 20; i++) &#123; System.out.println(incrementAndGetModuloTest.getServer(eligible)); &#125; &#125; private String getServer(List&lt;String&gt; eligible) &#123; return eligible.get(incrementAndGetModulo(eligible.size())); &#125; private int incrementAndGetModulo(int modulo) &#123; for (; ; ) &#123; int current = nextIndex.get(); int next = (current + 1) % modulo; if (nextIndex.compareAndSet(current, next)) return current; &#125; &#125;&#125; 测试结果： 1234567891011121314151617181920服务1服务2服务3服务4服务5服务1服务2服务3服务4服务5服务1服务2服务3服务4服务5服务1服务2服务3服务4服务5 3、设置返回体 执行完请求之后的得到结果， 可以看到是直接将ClientHttpResponse赋值到了RequestContext中 123456protected void setResponse(ClientHttpResponse resp) throws ClientException, IOException &#123; RequestContext.getCurrentContext().set(\"zuulResponse\", resp); this.helper.setResponse(resp.getRawStatusCode(), resp.getBody() == null ? null : resp.getBody(), resp.getHeaders());&#125; 总结 RibbonRoutingFilter这个类会为Consul中的每个服务都自动创建一个默认路由规则，然后根据这个规则将请求转发到不同的服务实例上，这些默认规则的path会使用ServiceId配置的服务名作为请求前缀 RibbonRoutingFilter的类的主要功能 1、先要挑选出具体调那个服务实例，如果是有多个服务具体选用的是哪种负载均衡策略，默认采用的是简单轮询负载均衡（RoundRobin）策略 2、获取到实例之后就是就是拼接HTTP请求，涉及请求host及port，组装完成之后就是执行请求了 3、执行请求之后就是把结果赋值到了RequestContext中，然后执行下一步ZuulFilter 参考","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Zuul)工作原理及源码分析之执行流程","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)工作原理及源码分析之执行流程","date":"2019-08-06T16:05:02.000Z","updated":"2019-09-16T13:11:06.057Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)工作原理及源码分析之执行流程/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)工作原理及源码分析之执行流程/","excerpt":"","text":"前言 上一章节已经介绍了使用@EnableZuulServer注解会开启 ZuulProxyAutoConfiguration自动注册功能，这个类会自动注册Zuul服务启动所需要的Bean，因为我们这里是网关服务，所以是需要接受外部应用的Http请求的 回顾ZuulProxyAutoConfiguration 的父类ZuulServerAutoConfiguration，从下面可以看到是注册了ZuulController，ZuulHandlerMapping，ZuulServlet三个Bean，所以我们可以猜测入口应该是Spring MVC DispatcherServlet 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * @author Spencer Gibb * @author Dave Syer * @author Biju Kunjummen */@Configuration // 声明是配置类@EnableConfigurationProperties(&#123; ZuulProperties.class &#125;) // 激活 zuul配置@ConditionalOnClass(ZuulServlet.class) // 条件1 存在ZuulServlet.class@ConditionalOnBean(ZuulServerMarkerConfiguration.Marker.class) // 条件2 存在ZuulServerMarkerConfiguration.Marker.class bean, 即应用使用@EnableZuulServer注解// Make sure to get the ServerProperties from the same place as a normal web app would@Import(ServerPropertiesAutoConfiguration.class) // 配置ServerProperties实例public class ZuulServerAutoConfiguration &#123; @Autowired protected ZuulProperties zuulProperties; @Autowired protected ServerProperties server; @Autowired(required = false) private ErrorController errorController; @Bean public HasFeatures zuulFeature() &#123; return HasFeatures.namedFeature(\"Zuul (Simple)\", ZuulServerAutoConfiguration.class); &#125; @Bean @Primary public CompositeRouteLocator primaryRouteLocator( Collection&lt;RouteLocator&gt; routeLocators) &#123; return new CompositeRouteLocator(routeLocators); &#125; @Bean @ConditionalOnMissingBean(SimpleRouteLocator.class) public SimpleRouteLocator simpleRouteLocator() &#123; return new SimpleRouteLocator(this.server.getServletPrefix(), this.zuulProperties); &#125; /** * zuulController, 包装了一个ZuulServlet类型的servlet, 实现对ZuulServlet类型的servlet的初始化. * * @return */ @Bean public ZuulController zuulController() &#123; return new ZuulController(); &#125; @Bean public ZuulHandlerMapping zuulHandlerMapping(RouteLocator routes) &#123; ZuulHandlerMapping mapping = new ZuulHandlerMapping(routes, zuulController()); mapping.setErrorController(this.errorController); return mapping; &#125; @Bean public ApplicationListener&lt;ApplicationEvent&gt; zuulRefreshRoutesListener() &#123; return new ZuulRefreshListener(); &#125; @Bean @ConditionalOnMissingBean(name = \"zuulServlet\") public ServletRegistrationBean zuulServlet() &#123; ServletRegistrationBean servlet = new ServletRegistrationBean(new ZuulServlet(), this.zuulProperties.getServletPattern()); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. servlet.addInitParameter(\"buffer-requests\", \"false\"); return servlet; &#125; ... 解析 查看源码是怎样执行调用的可以在代码里打好断点，观察其执行链，第六章节已经介绍了Zuul的一个简单例子，我们可以在自己定义的Filter的run()方法里打好断点，只要没配置错误，这里是一定会执行的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105@Slf4j@Componentpublic class AuthenticationFilter extends ZuulFilter &#123; @Autowired private SsoClient ssoClient; private Pattern p = Pattern.compile(\"/*/pub/*\"); @Override public Object run() &#123; ResponseMO resMO = new ResponseMO(); RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String relativeURL = extractRelativePath(request); String token = request.getHeader(WebConstants.TOKEN_HEADER); if (p.matcher(relativeURL).find()) &#123; return null; &#125; log.info(\"&gt;&gt; 鉴权开始[&#123;&#125;]\",relativeURL); ResponseMO resModel = null; if (relativeURL.startsWith(ApplicationConstants.APPLICATION_ZUUL) || relativeURL.startsWith(ApplicationConstants.APPLICATION_USER) || relativeURL.startsWith(ApplicationConstants.APPLICATION_SSO)) &#123; // 调用sso服务鉴权 resModel = ssoClient.checkToken(new TokenMO(token)); &#125; else &#123; // 其他服务不对其进行路由 authorizationFailed(relativeURL, ctx, resMO); return null; &#125; if (resModel.getCode() != ResponseMO.RESPONSE_CODE_SUCCESS) &#123; // 鉴权失败不对其进行路由 authorizationFailed(relativeURL, ctx, resMO); return null; &#125; // 从jwt解析后的userId ctx.addZuulRequestHeader(\"userId\", \"reUserId\"); log.info(\"&lt;&lt; 鉴权通过[&#123;&#125;]] \", relativeURL); return null; &#125; /** * 返回一个boolean值来判断该过滤器是否要执行，true表示执行，false表示不执行 * @return */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * gives the order in which this filter will be executed, relative to other * filters * @return */ @Override public int filterOrder() &#123; // TODO Auto-generated method stub return 0; &#125; @Override public String filterType() &#123; return \"pre\"; &#125; /** * 鉴权失败 * @param relativeURL * @param ctx * @param resMO */ private void authorizationFailed (String relativeURL, RequestContext ctx, ResponseMO resMO) &#123; ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); resMO.setAnonymous(); String resBody = convertToString(resMO); ctx.setResponseBody(resBody); log.info(\"&lt;&lt; 鉴权失败[&#123;&#125;]\",relativeURL); &#125; private String convertToString(ResponseMO resMO) &#123; String result = \"\"; ObjectMapper mapper = new ObjectMapper(); try &#123; result = mapper.writeValueAsString(resMO); &#125; catch (JsonProcessingException e) &#123; log.error(e.getMessage()); &#125; return result; &#125; /** * 获取相对访问路径 * @param request * @return */ private String extractRelativePath(HttpServletRequest request) &#123; String requestURI = request.getRequestURI(); return requestURI; &#125;&#125; 下图是其方法调用链路图，可以看到入口是Spring MVC的DispatcherServlet，然后就是doDispatch到了ZuulController上，ZuulController又转发到了ZuulServlet的service方法 根据上图可以梳理出大致的执行流程 1、内置tomcat容器接受Http请求 2、进入DispatcherServlet进行doDispatch请求转发 3、转发到ZuulController上，执行其handleRequest()方法 4、然后转发到ZuulServlet上的service()方法上，这个是个HttpServlet，这里会执行一系列的拦截器 1、ZuulController 我们平常开发使用 Spring MVC一般都是通过@Controller注解的形式来定义其执行方法，Spring也提供通过实现接口的形式来定义其执行方法，下面的ZuulController就是这个例子，可以看到这个类十分简单，就只有主体方法handleRequest()，此方法是定义在Controller接口上 那是DispatcherServlet是怎样找到ZuulController这个执行类的呢，可以看到ZuulServerAutoConfiguration是注册了ZuulController及ZuulHandlerMapping这两个bean，ZuulHandlerMapping和我们平常使用的RequestMappingHandlerMapping都是继承HandlerMapping接口，这个接口是定义请求与具体执行者的映射关系，所以DispatcherServlet就能发现ZuulController这个执行类 12345678910111213141516/** * zuulController, 包装了一个ZuulServlet类型的servlet, 实现对ZuulServlet类型的servlet的初始化. * * @return */@Beanpublic ZuulController zuulController() &#123; return new ZuulController();&#125;@Beanpublic ZuulHandlerMapping zuulHandlerMapping(RouteLocator routes) &#123; ZuulHandlerMapping mapping = new ZuulHandlerMapping(routes, zuulController()); mapping.setErrorController(this.errorController); return mapping;&#125; org.springframework.web.servlet.mvc.Controller#handleRequest 123456789101112131415public interface Controller &#123; /** * Process the request and return a ModelAndView object which the DispatcherServlet * will render. A &#123;@code null&#125; return value is not an error: it indicates that * this object completed request processing itself and that there is therefore no * ModelAndView to render. * @param request current HTTP request * @param response current HTTP response * @return a ModelAndView to render, or &#123;@code null&#125; if handled directly * @throws Exception in case of errors */ ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception;&#125; org.springframework.cloud.netflix.zuul.web.ZuulController#handleRequest 12345678910111213141516171819202122232425/** * @author Spencer Gibb */public class ZuulController extends ServletWrappingController &#123; public ZuulController() &#123; setServletClass(ZuulServlet.class); setServletName(\"zuul\"); setSupportedMethods((String[]) null); // Allow all &#125; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; try &#123; // We don't care about the other features of the base class, just want to // handle the request return super.handleRequestInternal(request, response); &#125; finally &#123; // @see com.netflix.zuul.context.ContextLifecycleFilter.doFilter RequestContext.getCurrentContext().unset(); &#125; &#125;&#125; 查看ZuulController的构造函数里面setServletClass(ZuulServlet.class)可以看到是设置了父类ServletWrappingController的servletClass为ZuulServlet.class 看看父类ServletWrappingController 代码如下，可以看到成员变量是记录了Servlet的name及Class对象，Servlet servletInstance是在afterPropertiesSet()赋值的，这个函数是Spring的钩子函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class ServletWrappingController extends AbstractController implements BeanNameAware, InitializingBean, DisposableBean &#123; private Class&lt;? extends Servlet&gt; servletClass; private String servletName; private Properties initParameters = new Properties(); private String beanName; private Servlet servletInstance; public ServletWrappingController() &#123; super(false); &#125; /** * Set the class of the servlet to wrap. * Needs to implement &#123;@code javax.servlet.Servlet&#125;. * @see javax.servlet.Servlet */ public void setServletClass(Class&lt;? extends Servlet&gt; servletClass) &#123; this.servletClass = servletClass; &#125; /** * Set the name of the servlet to wrap. * Default is the bean name of this controller. */ public void setServletName(String servletName) &#123; this.servletName = servletName; &#125; /** * Specify init parameters for the servlet to wrap, * as name-value pairs. */ public void setInitParameters(Properties initParameters) &#123; this.initParameters = initParameters; &#125; @Override public void setBeanName(String name) &#123; this.beanName = name; &#125; /** * Initialize the wrapped Servlet instance. * @see javax.servlet.Servlet#init(javax.servlet.ServletConfig) */ @Override public void afterPropertiesSet() throws Exception &#123; if (this.servletClass == null) &#123; throw new IllegalArgumentException(\"'servletClass' is required\"); &#125; if (this.servletName == null) &#123; this.servletName = this.beanName; &#125; this.servletInstance = this.servletClass.newInstance(); this.servletInstance.init(new DelegatingServletConfig()); &#125; /** * Invoke the wrapped Servlet instance. * @see javax.servlet.Servlet#service(javax.servlet.ServletRequest, javax.servlet.ServletResponse) */ @Override protected ModelAndView handleRequestInternal(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; this.servletInstance.service(request, response); return null; &#125;... 进入ZuulController的handleRequest()方法，可以看到就一个入口super.handleRequestInternal(request, response);，进入此方法，可以看到实际上就是执行了ZuulServlet的service()方法，Spring将一个Servlet包裹在一个Controller里面了 12345678910111213/** * 执行被包裹的Servlet * * Invoke the wrapped Servlet instance. * @see javax.servlet.Servlet#service(javax.servlet.ServletRequest, javax.servlet.ServletResponse) */@Overrideprotected ModelAndView handleRequestInternal(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; this.servletInstance.service(request, response); return null;&#125; 2、ZuulServlet 先看代码，可以看到ZuulServlet就是个Servlet，所以我们关心他的service()方法，注意这个类是属于com.netflix.zuul包下的，不是Spring的类， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162/** * Core Zuul servlet which intializes and orchestrates zuulFilter execution * * @author Mikey Cohen * Date: 12/23/11 * Time: 10:44 AM */public class ZuulServlet extends HttpServlet &#123; private static final long serialVersionUID = -3374242278843351500L; private ZuulRunner zuulRunner; @Override public void init(ServletConfig config) throws ServletException &#123; super.init(config); String bufferReqsStr = config.getInitParameter(\"buffer-requests\"); boolean bufferReqs = bufferReqsStr != null &amp;&amp; bufferReqsStr.equals(\"true\") ? true : false; zuulRunner = new ZuulRunner(bufferReqs); &#125; @Override public void service(javax.servlet.ServletRequest servletRequest, javax.servlet.ServletResponse servletResponse) throws ServletException, IOException &#123; try &#123; init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); // Marks this request as having passed through the \"Zuul engine\", as opposed to servlets // explicitly bound in web.xml, for which requests will not have the same data attached RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try &#123; preRoute(); &#125; catch (ZuulException e) &#123; error(e); postRoute(); return; &#125; try &#123; route(); &#125; catch (ZuulException e) &#123; error(e); postRoute(); return; &#125; try &#123; postRoute(); &#125; catch (ZuulException e) &#123; error(e); return; &#125; &#125; catch (Throwable e) &#123; error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); &#125; finally &#123; RequestContext.getCurrentContext().unset(); &#125; &#125; /** * executes \"post\" ZuulFilters * * @throws ZuulException */ void postRoute() throws ZuulException &#123; zuulRunner.postRoute(); &#125; /** * executes \"route\" filters * * @throws ZuulException */ void route() throws ZuulException &#123; zuulRunner.route(); &#125; /** * executes \"pre\" filters * * @throws ZuulException */ void preRoute() throws ZuulException &#123; zuulRunner.preRoute(); &#125; /** * initializes request * * @param servletRequest * @param servletResponse */ void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) &#123; zuulRunner.init(servletRequest, servletResponse); &#125; /** * sets error context info and executes \"error\" filters * * @param e */ void error(ZuulException e) &#123; RequestContext.getCurrentContext().setThrowable(e); zuulRunner.error(); &#125; @RunWith(MockitoJUnitRunner.class) public static class UnitTest &#123; @Mock HttpServletRequest servletRequest; @Mock HttpServletResponseWrapper servletResponse; @Mock FilterProcessor processor; @Mock PrintWriter writer; @Before public void before() &#123; MockitoAnnotations.initMocks(this); &#125; @Test public void testProcessZuulFilter() &#123; ZuulServlet zuulServlet = new ZuulServlet(); zuulServlet = spy(zuulServlet); RequestContext context = spy(RequestContext.getCurrentContext()); try &#123; FilterProcessor.setProcessor(processor); RequestContext.testSetCurrentContext(context); when(servletResponse.getWriter()).thenReturn(writer); zuulServlet.init(servletRequest, servletResponse); verify(zuulServlet, times(1)).init(servletRequest, servletResponse); assertTrue(RequestContext.getCurrentContext().getRequest() instanceof HttpServletRequestWrapper); assertTrue(RequestContext.getCurrentContext().getResponse() instanceof HttpServletResponseWrapper); zuulServlet.preRoute(); verify(processor, times(1)).preRoute(); zuulServlet.postRoute(); verify(processor, times(1)).postRoute();// verify(context, times(1)).unset(); zuulServlet.route(); verify(processor, times(1)).route(); RequestContext.testSetCurrentContext(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 关注service()方法，可以说这里是zuul的核心方法，看到这里的代码再来理解之前章节截的图就十分形象了，可以看到这里主要逻辑就是执行filter了，可以发现preRoute()及route()都是跳转到ZuulRunner zuulRunner里对应的方法执行 1234567891011121314151617181920212223242526272829303132333435363738public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException &#123; try &#123; this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse); RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try &#123; // 执行 pre filter this.preRoute(); &#125; catch (ZuulException var12) &#123; // 发生异常 执行error 及 post filter this.error(var12); this.postRoute(); return; &#125; try &#123; // 执行 routing filter this.route(); &#125; catch (ZuulException var13) &#123; // 发生异常 执行error 及 post filter this.error(var13); this.postRoute(); return; &#125; try &#123; // 执行 post filter this.postRoute(); &#125; catch (ZuulException var11) &#123; this.error(var11); &#125; &#125; catch (Throwable var14) &#123; this.error(new ZuulException(var14, 500, \"UNHANDLED_EXCEPTION_\" + var14.getClass().getName())); &#125; finally &#123; RequestContext.getCurrentContext().unset(); &#125;&#125; 我们现在来调试service()方法 先来看第一行this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse); 代码 123void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) &#123; zuulRunner.init(servletRequest, servletResponse);&#125; 跳转到zuulRunner.init（）方法，可以看到下面使用了构造了一个RequestContext，并设置HttpServlet request and HttpResponse，不出所外这个类就是ThreadLocal来实现的 1234567891011121314151617/** * sets HttpServlet request and HttpResponse * * @param servletRequest * @param servletResponse */public void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) &#123; RequestContext ctx = RequestContext.getCurrentContext(); if (bufferRequests) &#123; ctx.setRequest(new HttpServletRequestWrapper(servletRequest)); &#125; else &#123; ctx.setRequest(servletRequest); &#125; ctx.setResponse(new HttpServletResponseWrapper(servletResponse));&#125; 查看RequestContext类，查看本地变量可以发现ThreadLocal&lt;? extends RequestContext&gt; threadLocal，而且这个类继承了ConcurrentHashMap所以这个类应该是存放每次请求的各种参数的，使用ThreadLocal变量来达到线程隔离的效果 123456789101112131415161718192021222324252627282930313233/** * The Request Context holds request, response, state information and data for ZuulFilters to access and share. * The RequestContext lives for the duration of the request and is ThreadLocal. * extensions of RequestContext can be substituted by setting the contextClass. * Most methods here are convenience wrapper methods; the RequestContext is an extension of a ConcurrentHashMap * * @author Mikey Cohen * Date: 10/13/11 * Time: 10:21 AM */public class RequestContext extends ConcurrentHashMap&lt;String, Object&gt; &#123; private static final Logger LOG = LoggerFactory.getLogger(RequestContext.class); protected static Class&lt;? extends RequestContext&gt; contextClass = RequestContext.class; private static RequestContext testContext = null; protected static final ThreadLocal&lt;? extends RequestContext&gt; threadLocal = new ThreadLocal&lt;RequestContext&gt;() &#123; @Override protected RequestContext initialValue() &#123; try &#123; return contextClass.newInstance(); &#125; catch (Throwable e) &#123; throw new RuntimeException(e); &#125; &#125; &#125;; public RequestContext() &#123; super(); &#125; 看完第一行我们知道构造了一个RequestContext，再来回去看第二三行代码 可以看到重新获取了一下RequestContext,context.setZuulEngineRan();用于标记这个请求是Zuul engine1234// Marks this request as having passed through the \"Zuul engine\", as opposed to servlets// explicitly bound in web.xml, for which requests will not have the same data attachedRequestContext context = RequestContext.getCurrentContext();context.setZuulEngineRan(); 下面就是执行各种Route了 2.1、preRoute() 先来看preRoute()，这个filters是最先执行的 123void preRoute() throws ZuulException &#123; zuulRunner.preRoute();&#125; 进入com.netflix.zuul.ZuulRunner#preRoute()，可以看到又包装了一个FilterProcessor 123public void preRoute() throws ZuulException &#123; FilterProcessor.getInstance().preRoute();&#125; 查看FilterProcessor类，这个类是执行filters的核心类，可以看到这个类的使用是用了单例模式 代码12345678910111213141516171819202122232425262728293031323334/** * This the the core class to execute filters. * * @author Mikey Cohen * Date: 10/24/11 * Time: 12:47 PM */public class FilterProcessor &#123; static FilterProcessor INSTANCE = new FilterProcessor(); protected static final Logger logger = LoggerFactory.getLogger(FilterProcessor.class); private FilterUsageNotifier usageNotifier; public FilterProcessor() &#123; usageNotifier = new BasicFilterUsageNotifier(); &#125; /** * @return the singleton FilterProcessor */ public static FilterProcessor getInstance() &#123; return INSTANCE; &#125; /** * sets a singleton processor in case of a need to override default behavior * * @param processor */ public static void setProcessor(FilterProcessor processor) &#123; INSTANCE = processor; &#125; 进入com.netflix.zuul.FilterProcessor#preRoute()，看注释可以看到本方法是在请求路由之前执行所有的&quot;pre&quot; filters，可以看到得到List&lt;ZuulFilter&gt; list然后for循环执行 123456789101112131415161718192021222324252627282930313233343536373839/** * runs all \"pre\" filters. These filters are run before routing to the orgin. * * @throws ZuulException */public void preRoute() throws ZuulException &#123; try &#123; runFilters(\"pre\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_PRE_FILTER_\" + e.getClass().getName()); &#125;&#125;/** * runs all filters of the filterType sType/ Use this method within filters to run custom filters by type * * @param sType the filterType. * @return * @throws Throwable throws up an arbitrary exception */public Object runFilters(String sType) throws Throwable &#123; if (RequestContext.getCurrentContext().debugRouting()) &#123; Debug.addRoutingDebug(\"Invoking &#123;\" + sType + \"&#125; type filters\"); &#125; boolean bResult = false; List&lt;ZuulFilter&gt; list = FilterLoader.getInstance().getFiltersByType(sType); if (list != null) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; ZuulFilter zuulFilter = list.get(i); // 执行ZuulFilter Object result = processZuulFilter(zuulFilter); if (result != null &amp;&amp; result instanceof Boolean) &#123; bResult |= ((Boolean) result); &#125; &#125; &#125; return bResult;&#125; List list 结果 上面代码可以看到已经筛选出上图这些&quot;pre&quot; filters 这些&quot;pre&quot; filters 也有我们自己定义的AuthenticationFilter 可以看到ServletDetectionFilter是最先执行的filter，因为filterOrder()是最小，这个filter用于标识请求是否是DispatcherServletRequest12345678910111213141516171819202122232425262728293031323334353637383940414243public class ServletDetectionFilter extends ZuulFilter &#123; public ServletDetectionFilter() &#123; &#125; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * Must run before other filters that rely on the difference between * DispatcherServlet and ZuulServlet. */ @Override public int filterOrder() &#123; return SERVLET_DETECTION_FILTER_ORDER; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); if (!(request instanceof HttpServletRequestWrapper) &amp;&amp; isDispatcherServletRequest(request)) &#123; ctx.set(IS_DISPATCHER_SERVLET_REQUEST_KEY, true); &#125; else &#123; ctx.set(IS_DISPATCHER_SERVLET_REQUEST_KEY, false); &#125; return null; &#125; private boolean isDispatcherServletRequest(HttpServletRequest request) &#123; return request.getAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null; &#125; &#125; 进入Object result = processZuulFilter(zuulFilter) 查看ZuulFilter执行逻辑 com.netflix.zuul.FilterProcessor#processZuulFilter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Processes an individual ZuulFilter. This method adds Debug information. Any uncaught Thowables are caught by this method and converted to a ZuulException with a 500 status code. * * @param filter * @return the return value for that filter * @throws ZuulException */public Object processZuulFilter(ZuulFilter filter) throws ZuulException &#123; RequestContext ctx = RequestContext.getCurrentContext(); boolean bDebug = ctx.debugRouting(); final String metricPrefix = \"zuul.filter-\"; long execTime = 0; String filterName = \"\"; try &#123; long ltime = System.currentTimeMillis(); filterName = filter.getClass().getSimpleName(); RequestContext copy = null; Object o = null; Throwable t = null; if (bDebug) &#123; Debug.addRoutingDebug(\"Filter \" + filter.filterType() + \" \" + filter.filterOrder() + \" \" + filterName); copy = ctx.copy(); &#125; // 执行方法 ZuulFilterResult result = filter.runFilter(); ExecutionStatus s = result.getStatus(); execTime = System.currentTimeMillis() - ltime; switch (s) &#123; case FAILED: t = result.getException(); ctx.addFilterExecutionSummary(filterName, ExecutionStatus.FAILED.name(), execTime); break; case SUCCESS: o = result.getResult(); ctx.addFilterExecutionSummary(filterName, ExecutionStatus.SUCCESS.name(), execTime); if (bDebug) &#123; Debug.addRoutingDebug(\"Filter &#123;\" + filterName + \" TYPE:\" + filter.filterType() + \" ORDER:\" + filter.filterOrder() + \"&#125; Execution time = \" + execTime + \"ms\"); Debug.compareContextState(filterName, copy); &#125; break; default: break; &#125; if (t != null) throw t; usageNotifier.notify(filter, s); return o; &#125; catch (Throwable e) &#123; if (bDebug) &#123; Debug.addRoutingDebug(\"Running Filter failed \" + filterName + \" type:\" + filter.filterType() + \" order:\" + filter.filterOrder() + \" \" + e.getMessage()); &#125; usageNotifier.notify(filter, ExecutionStatus.FAILED); if (e instanceof ZuulException) &#123; throw (ZuulException) e; &#125; else &#123; ZuulException ex = new ZuulException(e, \"Filter threw Exception\", 500, filter.filterType() + \":\" + filterName); ctx.addFilterExecutionSummary(filterName, ExecutionStatus.FAILED.name(), execTime); throw ex; &#125; &#125;&#125; 进入ZuulFilterResult result = filter.runFilter();可以看到是直接调用了run()方法 12345678910111213141516171819202122public ZuulFilterResult runFilter() &#123; ZuulFilterResult zr = new ZuulFilterResult(); if (!isFilterDisabled()) &#123; if (shouldFilter()) &#123; Tracer t = TracerFactory.instance().startMicroTracer(\"ZUUL::\" + this.getClass().getSimpleName()); try &#123; // 执行run方法 Object res = run(); zr = new ZuulFilterResult(res, ExecutionStatus.SUCCESS); &#125; catch (Throwable e) &#123; t.setName(\"ZUUL::\" + this.getClass().getSimpleName() + \" failed\"); zr = new ZuulFilterResult(ExecutionStatus.FAILED); zr.setException(e); &#125; finally &#123; t.stopAndLog(); &#125; &#125; else &#123; zr = new ZuulFilterResult(ExecutionStatus.SKIPPED); &#125; &#125; return zr;&#125; 2.2、route() preRoute()执行完成之后就是执行route()了，我们进入com.netflix.zuul.ZuulRunner#route()，可以看到这里和preRoute()方法执行一样也是执行了runFilters()方法，只不过是用参数进行区分 12345678910111213141516171819/** * executes \"route\" filterType ZuulFilters * * @throws ZuulException */public void route() throws ZuulException &#123; FilterProcessor.getInstance().route();&#125;// com.netflix.zuul.FilterProcessor#route public void route() throws ZuulException &#123; try &#123; runFilters(\"route\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_ROUTE_FILTER_\" + e.getClass().getName()); &#125;&#125; List list 查看上图可以发现默认是有三个routing filter，我们这里关注的是RibbonRoutingFilter，这里是进行负载均衡路由转发的操作 进入processZuulFilter(ZuulFilter filter)方法，查看RequestContext变量已经发现有一些关键信息了，这些信息是pre filter添加上去的，为路由转发为准备 进入RibbonRoutingFilter的run()方法，可以看到是封装了一个Ribbon请求，执行请求，设置请求结果 1234567891011121314151617181920@Overridepublic Object run() &#123; RequestContext context = RequestContext.getCurrentContext(); this.helper.addIgnoredHeaders(); try &#123; // 根据RequestContext封装为一个Ribbon请求命名对象，里面有请求链接及请求参数 RibbonCommandContext commandContext = buildCommandContext(context); // 执行请求 ClientHttpResponse response = forward(commandContext); // 设置请求结果 setResponse(response); return response; &#125; catch (ZuulException ex) &#123; throw new ZuulRuntimeException(ex); &#125; catch (Exception ex) &#123; throw new ZuulRuntimeException(ex); &#125;&#125; 进入forward(commandContext)方法，command.execute();就是通过服务名来找出具体可以接受服务的ip及port，然后请求执行，这里涉及到从注册中心获取服务ip及port，负载均衡处理，断路器处理 最终结果会放在ClientHttpResponse中 12345678910111213141516protected ClientHttpResponse forward(RibbonCommandContext context) throws Exception &#123; Map&lt;String, Object&gt; info = this.helper.debug(context.getMethod(), context.getUri(), context.getHeaders(), context.getParams(), context.getRequestEntity()); // 创建请求 RibbonCommand command = this.ribbonCommandFactory.create(context); try &#123; // 执行请求 ClientHttpResponse response = command.execute(); this.helper.appendDebug(info, response.getRawStatusCode(), response.getHeaders()); return response; &#125; catch (HystrixRuntimeException ex) &#123; return handleException(info, ex); &#125;&#125; 进入this.ribbonCommandFactory.create(context);，下图是获取了RibbonLoadBalancingHttpClient，查看参数可以看到一些关键信息，比如链接超时时间 2.3、postRoute() 进入com.netflix.zuul.ZuulRunner#postRoute() 与上面同理 1234567891011121314public void postRoute() throws ZuulException &#123; FilterProcessor.getInstance().postRoute();&#125;// com.netflix.zuul.FilterProcessor#postRoute public void postRoute() throws ZuulException &#123; try &#123; runFilters(\"post\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_POST_FILTER_\" + e.getClass().getName()); &#125;&#125; 2.4、error()12345678910111213141516public void error() &#123; try &#123; runFilters(\"error\"); &#125; catch (Throwable e) &#123; logger.error(e.getMessage(), e); &#125;&#125;// com.netflix.zuul.FilterProcessor#error public void error() &#123; try &#123; runFilters(\"error\"); &#125; catch (Throwable e) &#123; logger.error(e.getMessage(), e); &#125;&#125; 其他总结 ZuulController是SpringCloud Zuul的统一入口，因为要和Spring联系起来，所以这里遵循的Spring MVC DispatcherServlet的模式，这个ZuulController将com.netflix.zuul包下的ZuulServlet整合起来，实际请求是跳转到ZuulServlet来处理的 Zuul组件的核心是一系列的过滤器filters，通过一系列的filters流式处理，按照阶段分为pre、routing 、post、error四种类型的filter，在流式处理过程中使用RequestContext保存整个请求需要的参数及结果 参考","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Zuul)工作原理及源码分析之初始化","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)工作原理及源码分析之初始化","date":"2019-08-06T16:05:01.000Z","updated":"2019-09-16T13:11:06.030Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)工作原理及源码分析之初始化/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)工作原理及源码分析之初始化/","excerpt":"","text":"前言 由上一章节可以知道要创建一个zuul应用，只需添加spring-cloud-starter-zuul maven依赖及启动类上添加@EnableZuulProxy就可创建一个zuul应用，那么要知道Zuul工作原理就需从这个两个地方作为入口进行研究 zuul版本: 1.4.3.RELEASE 解析Zuul 初始化spring-cloud-starter-zuul starter 我们先查看spring-cloud-starter-zuul starter包下有什么，这里的重点就是pom.xml文件，ZuulDeprecationWarningAutoConfiguration.java此类已经被@Deprecated 打开org.springframework.cloud/spring-cloud-starter-zuul/pom.xml ，可以看到是依赖了spring-cloud-starter-netflix-zuul 12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;relativePath&gt;..&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;name&gt;spring-cloud-starter-zuul&lt;/name&gt; &lt;description&gt;Spring Cloud Starter Zuul (deprecated, please use spring-cloud-starter-netflix-zuul)&lt;/description&gt; &lt;url&gt;https://projects.spring.io/spring-cloud&lt;/url&gt; &lt;organization&gt; &lt;name&gt;Pivotal Software, Inc.&lt;/name&gt; &lt;url&gt;https://www.spring.io&lt;/url&gt; &lt;/organization&gt; &lt;properties&gt; &lt;main.basedir&gt;$&#123;basedir&#125;/../..&lt;/main.basedir&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 我们查看spring-cloud-starter-netflix-zuul包 这里关注spring-cloud-starter-netflix-zuul/pom.xml及spring-cloud-starter-netflix-zuul-1.4.3.RELEASE.jar!/META-INF/spring.provides 打开/pom.xml可以看到依赖了com.netflix.zuul，所以说Spring Cloud Zuul是基于netflix公司的zuul实现的，除此之外还添加了hystrix及ribbon依赖，所以zuul是自带这两个功能的，spring-boot-starter-web依赖可以使应用成为web应用，spring-boot-starter-actuator是监控依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;name&gt;Spring Cloud Starter Netflix Zuul&lt;/name&gt; &lt;description&gt;Spring Cloud Starter Netflix Zuul&lt;/description&gt; &lt;url&gt;https://projects.spring.io/spring-cloud&lt;/url&gt; &lt;organization&gt; &lt;name&gt;Pivotal Software, Inc.&lt;/name&gt; &lt;url&gt;https://www.spring.io&lt;/url&gt; &lt;/organization&gt; &lt;properties&gt; &lt;main.basedir&gt;$&#123;basedir&#125;/../../..&lt;/main.basedir&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-archaius&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.zuul&lt;/groupId&gt; &lt;artifactId&gt;zuul-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; /META-INF/spring.provides 依赖spring-platform-netflix-core模块及zuul-core模块 1provides: spring-platform-netflix-core, zuul-core 现在我们进入spring-platform-netflix-core，看看Spring是怎样集成Netflix的一系列框架了，下面是代码框架图 可以看到这个炸包也包含了spring.factories文件，所以SpringBoot项目启动的时候会检索此配置文件，此文件是zuul实现自动注册配置的关键，下面可以看到熟悉的zuul,hystrix,feign,ribbon的自动配置类 12345678910111213141516171819org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.netflix.archaius.ArchaiusAutoConfiguration,\\org.springframework.cloud.netflix.feign.ribbon.FeignRibbonClientAutoConfiguration,\\org.springframework.cloud.netflix.feign.FeignAutoConfiguration,\\org.springframework.cloud.netflix.feign.encoding.FeignAcceptGzipEncodingAutoConfiguration,\\org.springframework.cloud.netflix.feign.encoding.FeignContentGzipEncodingAutoConfiguration,\\org.springframework.cloud.netflix.hystrix.HystrixAutoConfiguration,\\org.springframework.cloud.netflix.hystrix.security.HystrixSecurityAutoConfiguration,\\org.springframework.cloud.netflix.ribbon.RibbonAutoConfiguration,\\org.springframework.cloud.netflix.rx.RxJavaAutoConfiguration,\\org.springframework.cloud.netflix.metrics.servo.ServoMetricsAutoConfiguration,\\org.springframework.cloud.netflix.zuul.ZuulServerAutoConfiguration,\\org.springframework.cloud.netflix.zuul.ZuulProxyAutoConfigurationorg.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker=\\org.springframework.cloud.netflix.hystrix.HystrixCircuitBreakerConfigurationorg.springframework.boot.env.EnvironmentPostProcessor=\\org.springframework.cloud.netflix.metrics.ServoEnvironmentPostProcessor 我们现在关心Zuul的自动配置类，从上面spring.factories文件可以看到和Zuul相关的是自动配置了两个类，下图可以看到这两个有继承关系，ZuulProxyAutoConfiguration功能最为完全 ZuulServerAutoConfiguration 与 ZuulProxyAutoConfiguration ZuulServerAutoConfiguration自动配置类，启动类上如果有@EnableZuulServer则此类生效 下面代码可以看到大量使用了@Conditional作为条件判断，注意这个ZuulController这个Bean，它是我们Zuul的请求入口，这个类实现了Controller了，说明这里也使用了Spring MVC DispatcherServlet， 同时此类注册了大量的ZuulFilter 代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190/** * @author Spencer Gibb * @author Dave Syer * @author Biju Kunjummen */@Configuration // 声明是配置类@EnableConfigurationProperties(&#123; ZuulProperties.class &#125;) // 激活 zuul配置@ConditionalOnClass(ZuulServlet.class) // 条件1 存在ZuulServlet.class@ConditionalOnBean(ZuulServerMarkerConfiguration.Marker.class) // 条件2 存在ZuulServerMarkerConfiguration.Marker.class bean, 即应用使用@EnableZuulServer注解// Make sure to get the ServerProperties from the same place as a normal web app would@Import(ServerPropertiesAutoConfiguration.class) // 配置ServerProperties实例public class ZuulServerAutoConfiguration &#123; @Autowired protected ZuulProperties zuulProperties; @Autowired protected ServerProperties server; @Autowired(required = false) private ErrorController errorController; @Bean public HasFeatures zuulFeature() &#123; return HasFeatures.namedFeature(\"Zuul (Simple)\", ZuulServerAutoConfiguration.class); &#125; @Bean @Primary public CompositeRouteLocator primaryRouteLocator( Collection&lt;RouteLocator&gt; routeLocators) &#123; return new CompositeRouteLocator(routeLocators); &#125; @Bean @ConditionalOnMissingBean(SimpleRouteLocator.class) public SimpleRouteLocator simpleRouteLocator() &#123; return new SimpleRouteLocator(this.server.getServletPrefix(), this.zuulProperties); &#125; /** * zuulController, 包装了一个ZuulServlet类型的servlet, 实现对ZuulServlet类型的servlet的初始化. * * @return */ @Bean public ZuulController zuulController() &#123; return new ZuulController(); &#125; @Bean public ZuulHandlerMapping zuulHandlerMapping(RouteLocator routes) &#123; ZuulHandlerMapping mapping = new ZuulHandlerMapping(routes, zuulController()); mapping.setErrorController(this.errorController); return mapping; &#125; @Bean public ApplicationListener&lt;ApplicationEvent&gt; zuulRefreshRoutesListener() &#123; return new ZuulRefreshListener(); &#125; @Bean @ConditionalOnMissingBean(name = \"zuulServlet\") public ServletRegistrationBean zuulServlet() &#123; ServletRegistrationBean servlet = new ServletRegistrationBean(new ZuulServlet(), this.zuulProperties.getServletPattern()); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. servlet.addInitParameter(\"buffer-requests\", \"false\"); return servlet; &#125; // pre filters @Bean public ServletDetectionFilter servletDetectionFilter() &#123; return new ServletDetectionFilter(); &#125; @Bean public FormBodyWrapperFilter formBodyWrapperFilter() &#123; return new FormBodyWrapperFilter(); &#125; @Bean public DebugFilter debugFilter() &#123; return new DebugFilter(); &#125; @Bean public Servlet30WrapperFilter servlet30WrapperFilter() &#123; return new Servlet30WrapperFilter(); &#125; // post filters @Bean public SendResponseFilter sendResponseFilter() &#123; return new SendResponseFilter(); &#125; @Bean public SendErrorFilter sendErrorFilter() &#123; return new SendErrorFilter(); &#125; @Bean public SendForwardFilter sendForwardFilter() &#123; return new SendForwardFilter(); &#125; @Bean @ConditionalOnProperty(value = \"zuul.ribbon.eager-load.enabled\", matchIfMissing = false) public ZuulRouteApplicationContextInitializer zuulRoutesApplicationContextInitiazer( SpringClientFactory springClientFactory) &#123; return new ZuulRouteApplicationContextInitializer(springClientFactory, zuulProperties); &#125; @Configuration protected static class ZuulFilterConfiguration &#123; @Autowired private Map&lt;String, ZuulFilter&gt; filters; @Bean public ZuulFilterInitializer zuulFilterInitializer( CounterFactory counterFactory, TracerFactory tracerFactory) &#123; FilterLoader filterLoader = FilterLoader.getInstance(); FilterRegistry filterRegistry = FilterRegistry.instance(); return new ZuulFilterInitializer(this.filters, counterFactory, tracerFactory, filterLoader, filterRegistry); &#125; &#125; @Configuration @ConditionalOnClass(CounterService.class) protected static class ZuulCounterFactoryConfiguration &#123; @Bean @ConditionalOnBean(CounterService.class) public CounterFactory counterFactory(CounterService counterService) &#123; return new DefaultCounterFactory(counterService); &#125; &#125; @Configuration protected static class ZuulMetricsConfiguration &#123; @Bean @ConditionalOnMissingBean(CounterFactory.class) public CounterFactory counterFactory() &#123; return new EmptyCounterFactory(); &#125; @ConditionalOnMissingBean(TracerFactory.class) @Bean public TracerFactory tracerFactory() &#123; return new EmptyTracerFactory(); &#125; &#125; private static class ZuulRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; @Autowired private ZuulHandlerMapping zuulHandlerMapping; private HeartbeatMonitor heartbeatMonitor = new HeartbeatMonitor(); @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextRefreshedEvent || event instanceof RefreshScopeRefreshedEvent || event instanceof RoutesRefreshedEvent) &#123; this.zuulHandlerMapping.setDirty(true); &#125; else if (event instanceof HeartbeatEvent) &#123; if (this.heartbeatMonitor.update(((HeartbeatEvent) event).getValue())) &#123; this.zuulHandlerMapping.setDirty(true); &#125; &#125; &#125; &#125;&#125; ZuulProxyAutoConfiguration自动配置类，启动类上如果有对应@EnableZuulProxy则此类生效 由上面此类的继承图可以发现这个类继承了ZuulServerAutoConfiguration，所以此类拥有ZuulServerAutoConfiguration的所有功能，并在此基础上添加了使用了服务发现作为路由寻址功能 代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192/** * @author Spencer Gibb * @author Dave Syer * @author Biju Kunjummen */@Configuration // 声明是配置类@Import(&#123; RibbonCommandFactoryConfiguration.RestClientRibbonConfiguration.class, // 引入RibbonCommandFactory配置 RibbonCommandFactoryConfiguration.OkHttpRibbonConfiguration.class, RibbonCommandFactoryConfiguration.HttpClientRibbonConfiguration.class, HttpClientConfiguration.class &#125;)@ConditionalOnBean(ZuulProxyMarkerConfiguration.Marker.class) // 条件2 存在ZuulProxyMarkerConfiguration.Marker.class bean, 即应用使用@EnableZuulProxy注解public class ZuulProxyAutoConfiguration extends ZuulServerAutoConfiguration &#123; @SuppressWarnings(\"rawtypes\") @Autowired(required = false) private List&lt;RibbonRequestCustomizer&gt; requestCustomizers = Collections.emptyList(); /** * 网关服务注册实例信息 */ @Autowired(required = false) private Registration registration; /** * 服务发现客户端 */ @Autowired private DiscoveryClient discovery; /** * serviceId和路由的映射逻辑 */ @Autowired private ServiceRouteMapper serviceRouteMapper; @Override public HasFeatures zuulFeature() &#123; return HasFeatures.namedFeature(\"Zuul (Discovery)\", ZuulProxyAutoConfiguration.class); &#125; /** * 静态和动态路由寻址: 静态从配置文件获取, 动态通过服务发现客户端完成. 后者优先级更高 * @return */ @Bean @ConditionalOnMissingBean(DiscoveryClientRouteLocator.class) public DiscoveryClientRouteLocator discoveryRouteLocator() &#123; return new DiscoveryClientRouteLocator(this.server.getServletPrefix(), this.discovery, this.zuulProperties, this.serviceRouteMapper, this.registration); &#125; // pre filters @Bean public PreDecorationFilter preDecorationFilter(RouteLocator routeLocator, ProxyRequestHelper proxyRequestHelper) &#123; return new PreDecorationFilter(routeLocator, this.server.getServletPrefix(), this.zuulProperties, proxyRequestHelper); &#125; // route filters @Bean public RibbonRoutingFilter ribbonRoutingFilter(ProxyRequestHelper helper, RibbonCommandFactory&lt;?&gt; ribbonCommandFactory) &#123; RibbonRoutingFilter filter = new RibbonRoutingFilter(helper, ribbonCommandFactory, this.requestCustomizers); return filter; &#125; @Bean @ConditionalOnMissingBean(&#123;SimpleHostRoutingFilter.class, CloseableHttpClient.class&#125;) public SimpleHostRoutingFilter simpleHostRoutingFilter(ProxyRequestHelper helper, ZuulProperties zuulProperties, ApacheHttpClientConnectionManagerFactory connectionManagerFactory, ApacheHttpClientFactory httpClientFactory) &#123; return new SimpleHostRoutingFilter(helper, zuulProperties, connectionManagerFactory, httpClientFactory); &#125; @Bean @ConditionalOnMissingBean(&#123;SimpleHostRoutingFilter.class&#125;) public SimpleHostRoutingFilter simpleHostRoutingFilter2(ProxyRequestHelper helper, ZuulProperties zuulProperties, CloseableHttpClient httpClient) &#123; return new SimpleHostRoutingFilter(helper, zuulProperties, httpClient); &#125; @Bean public ApplicationListener&lt;ApplicationEvent&gt; zuulDiscoveryRefreshRoutesListener() &#123; return new ZuulDiscoveryRefreshListener(); &#125; @Bean @ConditionalOnMissingBean(ServiceRouteMapper.class) public ServiceRouteMapper serviceRouteMapper() &#123; return new SimpleServiceRouteMapper(); &#125; @Configuration @ConditionalOnMissingClass(\"org.springframework.boot.actuate.endpoint.Endpoint\") protected static class NoActuatorConfiguration &#123; @Bean public ProxyRequestHelper proxyRequestHelper(ZuulProperties zuulProperties) &#123; ProxyRequestHelper helper = new ProxyRequestHelper(); helper.setIgnoredHeaders(zuulProperties.getIgnoredHeaders()); helper.setTraceRequestBody(zuulProperties.isTraceRequestBody()); return helper; &#125; &#125; /** * 添加 Endpoint */ @Configuration @ConditionalOnClass(Endpoint.class) protected static class EndpointConfiguration &#123; @Autowired(required = false) private TraceRepository traces; @ConditionalOnEnabledEndpoint(\"routes\") @Bean public RoutesEndpoint routesEndpoint(RouteLocator routeLocator) &#123; return new RoutesEndpoint(routeLocator); &#125; @ConditionalOnEnabledEndpoint(\"routes\") @Bean public RoutesMvcEndpoint routesMvcEndpoint(RouteLocator routeLocator, RoutesEndpoint endpoint) &#123; return new RoutesMvcEndpoint(endpoint, routeLocator); &#125; @ConditionalOnEnabledEndpoint(\"filters\") @Bean public FiltersEndpoint filtersEndpoint() &#123; FilterRegistry filterRegistry = FilterRegistry.instance(); return new FiltersEndpoint(filterRegistry); &#125; @Bean public ProxyRequestHelper proxyRequestHelper(ZuulProperties zuulProperties) &#123; TraceProxyRequestHelper helper = new TraceProxyRequestHelper(); if (this.traces != null) &#123; helper.setTraces(this.traces); &#125; helper.setIgnoredHeaders(zuulProperties.getIgnoredHeaders()); helper.setTraceRequestBody(zuulProperties.isTraceRequestBody()); return helper; &#125; &#125; private static class ZuulDiscoveryRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; private HeartbeatMonitor monitor = new HeartbeatMonitor(); @Autowired private ZuulHandlerMapping zuulHandlerMapping; @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof InstanceRegisteredEvent) &#123; reset(); &#125; else if (event instanceof ParentHeartbeatEvent) &#123; ParentHeartbeatEvent e = (ParentHeartbeatEvent) event; resetIfNeeded(e.getValue()); &#125; else if (event instanceof HeartbeatEvent) &#123; HeartbeatEvent e = (HeartbeatEvent) event; resetIfNeeded(e.getValue()); &#125; &#125; private void resetIfNeeded(Object value) &#123; if (this.monitor.update(value)) &#123; reset(); &#125; &#125; private void reset() &#123; this.zuulHandlerMapping.setDirty(true); &#125; &#125;&#125; ZuulServerAutoConfiguration 与 ZuulProxyAutoConfiguration具体使用哪种模式，是分别通过@EnableZuulServer 和@EnableZuulProxy注解来区别的 前者使用了ZuulProperties进行配置路由寻址; 后者在原来的基础上添加了使用了服务发现作为路由寻址功能, 并使用Ribbon做客户端的负载均衡，这个最为常用; @EnableZuulProxy @EnableZuulProxy注解 1234567891011121314151617/** * Sets up a Zuul server endpoint and installs some reverse proxy filters in it, so it can * forward requests to backend servers. The backends can be registered manually through * configuration or via DiscoveryClient. * * @see EnableZuulServer for how to get a Zuul server without any proxying * * @author Spencer Gibb * @author Dave Syer * @author Biju Kunjummen */@EnableCircuitBreaker@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(ZuulProxyMarkerConfiguration.class)public @interface EnableZuulProxy &#123;&#125; @EnableZuulProxy分析 @EnableCircuitBreaker注解用于开启短路器功能 12345678910111213/** * Annotation to enable a CircuitBreaker implementation. * http://martinfowler.com/bliki/CircuitBreaker.html * @author Spencer Gibb */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(EnableCircuitBreakerImportSelector.class)public @interface EnableCircuitBreaker &#123;&#125; @Import(ZuulProxyMarkerConfiguration.class)注解用于注册ZuulProxyMarkerConfiguration.Marker.class这个Bean，这个Bean与上面的ZuulProxyAutoConfiguration的条件注解相对应@ConditionalOnBean(ZuulProxyMarkerConfiguration.Marker.class)，所以说如果启动类带了这个@EnableZuulProxy注解将会开启ZuulProxyMarkerConfiguration自动注册的功能，Spring这个可配置化对使用者来说十分方便 12345678910@Configurationpublic class ZuulProxyMarkerConfiguration &#123; @Bean public Marker zuulProxyMarkerBean() &#123; return new Marker(); &#125; class Marker &#123; &#125;&#125; 使用Consul作为注册中心 @EnableZuulProxy模式下的zuul需要注册中心的支持，因为eureka已经被抛弃了，我们这里选用的是Consul 添加Maven依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 启动类上加上@EnableDiscoveryClient注解 12345678910@EnableZuulProxy@EnableDiscoveryClient@SpringBootApplicationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 这样Zuul应用就可以发挥作用了 总结 本章节对Zuul的初始化进行了一次梳理，可以发现Zuul的初始化就是注册各种需要的Bean,粮草备好之后就是要发挥作用了，下一章节将介绍其具体是怎样发挥作用的 Spring Cloud对Netflix Zuul做了封装集成, 使得在Spring Cloud环境中使用Zuul更方便，只需添加spring-cloud-starter-zuul maven依赖及启动类上添加@EnableZuulProxy就可创建一个zuul应用 Spring Cloud Zuul 实际上就是在Servlet的基础上添加了一些ZuulFilter去完成一些额外事情，封装了就成框架了 参考 https://www.cnblogs.com/lexiaofei/p/7080257.html","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Zuul)网关服务Zuul","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)网关服务Zuul","date":"2019-08-06T16:05:00.000Z","updated":"2019-09-16T13:11:06.074Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)网关服务Zuul/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Zuul)网关服务Zuul/","excerpt":"","text":"Zuul 简介Zuul是什么 Zuul 是Netflix开源的一个API Gateway 服务器, 本质上是一个Web servlet应用，他可以和Eureka,Ribbon,Hystrix等组件配合使用。 Zuul组件的核心是一系列的过滤器filters，其作用可以类比Servlet框架的Filter，或者AOP。 为什么要用Zuul 在分布式架构中，对外提供的服务，在无网关的情况下，API接口直接暴露给服务调用方，当调用方增多，不同业务调用方各不相同，势必需要添加定制化访问权限、校验等逻辑。当添加API网关后，再第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发给后台服务端。Zuul就是提供负载均衡、反向代理、权限认证的这么一个API gateway。 微服务网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过微服务网关 logo Zuul 提供什么功能 Zuul组件的核心是一系列的过滤器，这些过滤器可以完成以下功能： 身份认证和安全: 识别每一个资源的验证要求，并拒绝那些不符的请求 审查与监控： 动态路由：动态将请求路由到不同后端集群 压力测试：逐渐增加指向集群的流量，以了解性能 负载分配：为每一种负载类型分配对应容量，并弃用超出限定值的请求 静态响应处理：边缘位置进行响应，避免转发到内部集群 多区域弹性：跨域AWS Region进行请求路由，旨在实现ELB(ElasticLoad Balancing)使用多样化 Spring Cloud对Zuul进行了整合和增强。目前Zuul使用的默认是Apache的HTTP Client，也可以使用Rest Client，可以设置ribbon.restclient.enabled=true. 简单示例 添加Maven依赖配置 12345678&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 添加配置文件application.yml 12345678910111213141516171819202122server: port: 9001spring: application: name: zuul-gatewayeureka: instance: hostname: localhost client: service-url: defaultZone: http://localhost:9010/eureka/,http://localhost:9011/eureka/zuul: routes: baidu-url: #传统路由方式 path: /baidu/** url: http://www.baidu.com/ provider: #面向服务的路由 path: /provider/** serviceId: eureka-provider consumer: #面向服务的路由 path: /consumer/** serviceId: eureka-consumer 启动类加上@EnableZuulProxy注解 12345678@EnableZuulProxy@SpringBootApplicationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 添加一个过滤器 AccessFilter.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class AccessFilter extends ZuulFilter&#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 定义过滤器的类型，决定过滤器在请求的那个生命周期中执行 * pre 请求被路由之前 * routing 在路由请求时被调用 * post 在routing和error过滤器之后被调用 * error 处理请求时发生错误时被调用 * @return */ @Override public String filterType() &#123; // 代表会在请求被路由之前被执行 return \"pre\"; &#125; /** * 定义过滤器的顺序，当请求在一个阶段中存在多个过滤器时，可以根据该值来决定执行顺序 * @return */ @Override public int filterOrder() &#123; return 0; &#125; /** * 判断过滤器是否需要被执行 * @return */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 过滤器的具体实现 * @return */ @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); logger.info(\"send &#123;&#125; request to &#123;&#125;\", request.getMethod(), request.getRequestURL().toString()); Object accessToken = request.getParameter(\"accessToken\"); if (accessToken == null) &#123; logger.error(\"access check failed\"); ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(401); return null; &#125; logger.error(\"access check passs\"); return null; &#125;&#125; 解析zuul默认支持hystrix和ribbon123456789101112hystrix: command: default: execution: timeout: enabled: true isolation: thread: timeoutInMilliseconds: 60000 // 设置API网关中路由转发请求的HystrixCommand执行超时时间，就是整个路由转发请求的执行时间ribbon: ConnectTimeout: 60000 // 设置创建请求连接的超时时间，如果该值小于上面的HystrixCommand执行超时时间，会自动进行重试路由请求 ReadTimeout: 60000 // 设置请求连接建立之后执行处理的超时时间，如果该值小于上面的HystrixCommand执行超时时间，会自动进行重试路由请求 Zuul的过滤器之间没有直接的相互通信，他们之间通过一个RequestContext的静态类来进行数据传递的。RequestContext类中有ThreadLocal变量来记录每个Request所需要传递的数据。 Zuul的过滤器是由Groovy写成，这些过滤器文件被放在Zuul Server上的特定目录下面，Zuul会定期轮询这些目录，修改过的过滤器会动态的加载到Zuul Server中以便过滤请求使用。 过滤器机制 Zuul大部分功能都是通过过滤器来实现的。Zuul中定义了四种标准过滤器类型，这些过滤器类型对应于请求的典型生命周期，下面有几种标准的过滤器类型： (1) PRE：这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 (2) ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。 (3) POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 (4) ERROR：在其他阶段发生错误时执行该过滤器。 过滤器的生命周期 各种不同类型的过滤器流转流程 当客户端请求过来首先会到 pre filters 这样的一个前置过滤器做一些处理，然后调用自定义的过滤器 前置过滤器执行完了之后会调用 routing filters 过滤器 ，看名字都知道这是做路由分发的过滤器 在路由的过程中出现了异常，那么会走 error filters过滤器，然后再走 post filters 过滤器 ，或者正常路由完成也会走到post filters post filters过滤器负责处理响应 ，最后把结果响应给客户端 内置的特殊过滤器 下面是zuul默认实现的过滤器 其他 当我们为Spring Cloud Zuul构建的API网关服务引入Spring Cloud Eureka之后，它会为Eureka中的每个服务都自动创建一个默认路由规则，这些默认规则的path会使用ServiceId配置的服务名作为请求前缀 Spring Cloud Zuul还特别提供了/routes端点来返回当前的所有路由规则 总结参考 https://www.cnblogs.com/lexiaofei/p/7080257.html https://www.jianshu.com/p/fd0d8a0019d6","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Hystrix)服务容错保护介绍","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Hystrix)服务容错保护介绍","date":"2019-08-06T16:04:00.000Z","updated":"2019-09-16T13:11:05.898Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Hystrix)服务容错保护介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Hystrix)服务容错保护介绍/","excerpt":"","text":"前言Hystrix是什么 Hystrix对应的中文名字是“豪猪”，豪猪周身长满了刺，能保护自己不受天敌的伤害，代表了一种防御机制，这与Hystrix本身的功能不谋而合，因此Netflix团队将该框架命名为Hystrix，并使用了对应的卡通形象做作为logo 为什么要使用 在一个分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，如何能够保证在一个依赖出问题的情况下，不会导致整体服务失败（比如生活中的电路的保险丝用途），这个就是Hystrix需做的事情。 提供哪些功能Hystrix提供了熔断、隔离、Fallback、cache、监控等功能，能够在一个、或多个依赖同时出现问题时保证系统依然可用。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Ribbon)常用配置","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)常用配置","date":"2019-08-06T16:03:05.000Z","updated":"2019-09-16T13:11:05.983Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)常用配置/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)常用配置/","excerpt":"","text":"Ribbon的重试机制 设置 1234567ribbon: // 同一台实例最大重试次数,不包括首次调用 MaxAutoRetries: 1 // 重试负载均衡其他的实例最大重试次数,不包括首次server MaxAutoRetriesNextServer: 1 // 是否所有操作都重试 OkToRetryOnAllOperations: false 根据上面的参数计算重试的次数：MaxAutoRetries + MaxAutoRetriesNextServer + (MaxAutoRetries * MaxAutoRetriesNextServer)即重试3次，加上本次重试 则一共产生4次调用 如果在重试期间，时间超过了hystrix的超时时间，便会立即执行熔断，fallback。所以要根据上面配置的参数计算hystrix的超时时间，使得在重试期间不能达到hystrix的超时时间，不然重试机制就会没有意义 hystrix超时时间的计算 不要用下面这种公式来配置hystrix的超时时间，不要，不要，重要的事情说3次：(1 + MaxAutoRetries + MaxAutoRetriesNextServer) * ReadTimeout = (1+1+1) * 3 = 9秒 正确的计算公式：ReadTimeout+（MaxAutoRetries * ReadTimeout），如果配置的有：MaxAutoRetriesNextServer这个属性，看下面例子： 先算出所有Ribbon的超时时间+重试时间的总和，那么hystrix的超时时间大于总和，就可以保证Ribbon在重试过程中不会被hystrix熔断。1234567891011121314151617181920ribbon: MaxAutoRetries: 1 #最大重试次数，当Eureka中可以找到服务，但是服务连不上时将会重试 MaxAutoRetriesNextServer: 1 #切换实例的重试次数 OkToRetryOnAllOperations: true # 对所有的操作请求都进行重试，如果是get则可以，如果是post,put等操作没有实现幂等的情况下是很危险的 ConnectTimeout: 250 #请求连接的超时时间 ReadTimeout: 1000 #请求处理的超时时间 这个hystrix的超时时间怎么配置：ReadTimeout+（MaxAutoRetries * ReadTimeout）+ ReadTimeout+（MaxAutoRetries * ReadTimeout）= 4000ms那么hystrix的超时时间为：&gt;4000ms如果MaxAutoRetriesNextServer=1，就加1个：ReadTimeout+（MaxAutoRetries * ReadTimeout）+ ReadTimeout+（MaxAutoRetries * ReadTimeout）= 4000ms如果MaxAutoRetriesNextServer=2，就加2个：ReadTimeout+（MaxAutoRetries * ReadTimeout）+ ReadTimeout+（MaxAutoRetries * ReadTimeout）+ ReadTimeout+（MaxAutoRetries * ReadTimeout）= 6000ms 正确配置 12345678910111213141516# hystrix的超时时间hystrix: command: default: execution: timeout: enabled: true isolation: thread: timeoutInMilliseconds: 9000ribbon: ReadTimeout: 3000 ConnectTimeout: 3000 MaxAutoRetries: 1 #同一台实例最大重试次数,不包括首次调用 MaxAutoRetriesNextServer: 1 #重试负载均衡其他的实例最大重试次数,不包括首次调用 OkToRetryOnAllOperations: false #是否所有操作都重试 默认情况下,GET方式请求无论是连接异常还是读取异常，都会进行重试，非GET方式请求,只有连接异常时,才会进行重试 当OkToRetryOnAllOperations设置为false时，只会对get请求进行重试。如果设置为true，便会对所有的请求进行重试，如果是put或post等写操作，如果服务器接口没做幂等性，会产生不好的结果，所以OkToRetryOnAllOperations慎用。 如果不配置ribbon的重试次数，默认会重试一次 默认值在com.netflix.client.config.DefaultClientConfigImpl有定义 12public static final int DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER = 1;public static final int DEFAULT_MAX_AUTO_RETRIES = 0; 因为Ribbon的重试机制和Feign的重试机制有冲突，所以源码中是默认关闭Feign的重试机制 超时时间设置 设置 12345ribbon: // http建立socket超时时间,毫秒 ReadTimeout: 60000 // http读取响应socket超时时间,毫秒 ConnectTimeout: 60000 默认值在 12public static final int DEFAULT_CONNECT_TIMEOUT = 1000;public static final int DEFAULT_READ_TIMEOUT = 1000; 支持对不同Ribbon clients进行属性配置 之前配置的参数都是全局配置，但在微服务环境下不是对所有服务都适用 12345ribbon: ReadTimeout: 60000 ConnectTimeout: 60000 MaxAutoRetries: 0 MaxAutoRetriesNextServer: 1 从1.2.0版本开始，Spring Cloud Netflix支持对不同Ribbon clients进行属性配置，按照&lt;clientName&gt;.ribbon.格式进行配置 比如我们有个服务是users，那么我们就针对这个服务这么配置：123456users: ribbon: ReadTimeout: 60000 ConnectTimeout: 60000 MaxAutoRetries: 0 MaxAutoRetriesNextServer: 1 参考 https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/1.4.7.RELEASE/multi/multi_spring-cloud-ribbon.html https://blog.csdn.net/east123321/article/details/82385816 https://blog.csdn.net/l848168/article/details/85090124","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Ribbon)工作原理及源码分析三","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析三","date":"2019-08-06T16:03:04.000Z","updated":"2019-09-16T13:11:05.922Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析三/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析三/","excerpt":"","text":"回顾 由前面章节我们知道Ribbon功能主要是将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，那么如果要实现负载均衡，具体是要做哪些事呢？ 1、第一步是要维护哪些服务实例可用，需要处理临时新增了服务或者某个服务不可用了情况 2、有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例 3、然后就是将执行请求，响应处理 4、如果调用失败是不是要重试 下面将从Ribbon的源码来按照上面的步骤来分析其具体实现, 源码版本： 1234567&lt;!-- https://mvnrepository.com/artifact/com.netflix.ribbon/ribbon-core --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-core&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 下面将继续接上一章节的内容 解析1、第一步是要维护哪些服务实例可用，需要处理临时新增了服务或者某个服务不可用了情况1、1 定义服务实例Server1、2 定义服务器列表ServerList2、有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例2、1 负责选取Server的接口ILoadBalancer2、2 负债均衡策略IRule3、然后就是将执行请求，响应处理3.1 执行请求客户端AbstractLoadBalancerAwareClient3.2 执行命令 LoadBalancerCommand 4、如果调用失败是不是要重试 这个构造的LoadBalancerCommand是一个RxJava风格的，从下面可以看到具体执行流程就是通过选取Server的接口ILoadBalancer来获取Server，然后就是执行请求了，它包含了重试和异常处理机制、同时还记录了执行状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public Observable&lt;T&gt; submit(final ServerOperation&lt;T&gt; operation) &#123; final ExecutionInfoContext context = new ExecutionInfoContext(); if (listenerInvoker != null) &#123; try &#123; listenerInvoker.onExecutionStart(); &#125; catch (AbortExecutionException e) &#123; return Observable.error(e); &#125; &#125; // 获取在每个服务实例重试的的次数 final int maxRetrysSame = retryHandler.getMaxRetriesOnSameServer(); // 最多尝试几个服务实例 final int maxRetrysNext = retryHandler.getMaxRetriesOnNextServer(); // 对于每个服务实例的调用逻辑 // 默认field server是null，通过selectServer()方法获取一个Server Observable&lt;T&gt; o = (server == null ? selectServer() : Observable.just(server)) .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() &#123; @Override // 对于每个Server，按顺序映射为对于每个Server包含重试逻辑的请求调用 public Observable&lt;T&gt; call(Server server) &#123; // 设置上下文 context.setServer(server); final ServerStats stats = loadBalancerContext.getServerStats(server); // 每个Server包含重试逻辑的请求调用 Observable&lt;T&gt; o = Observable .just(server) .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() &#123; @Override public Observable&lt;T&gt; call(final Server server) &#123; context.incAttemptCount(); // 增加Server正在处理的请求计数 loadBalancerContext.noteOpenConnection(stats); // 监听器 if (listenerInvoker != null) &#123; try &#123; listenerInvoker.onStartWithServer(context.toExecutionInfo()); &#125; catch (AbortExecutionException e) &#123; return Observable.error(e); &#125; &#125; // 计时器 final Stopwatch tracer = loadBalancerContext.getExecuteTracer().start(); // operation.call(server)就是刚刚分析的AbstractLoadBalancerAwareClient传过来的ServerOperation，就是直接对这个Server调用请求 // doOnEach的操作就是记录请求前后的一些数据用于负载均衡数据统计 return operation.call(server).doOnEach(new Observer&lt;T&gt;() &#123; private T entity; @Override public void onCompleted() &#123; // 记录请求完成 recordStats(tracer, stats, entity, null); &#125; @Override public void onError(Throwable e) &#123; // 记录请求结束 recordStats(tracer, stats, null, e); logger.debug(\"Got error &#123;&#125; when executed on server &#123;&#125;\", e, server); // 发生了错误，通知listener if (listenerInvoker != null) &#123; listenerInvoker.onExceptionWithServer(e, context.toExecutionInfo()); &#125; &#125; @Override public void onNext(T entity) &#123; // 因为只有调用请求成功只有一个结果（只有一个请求）， 这里的entity就是结果，只要收到结果就代表请求成功 this.entity = entity; if (listenerInvoker != null) &#123; listenerInvoker.onExecutionSuccess(entity, context.toExecutionInfo()); &#125; &#125; private void recordStats(Stopwatch tracer, ServerStats stats, Object entity, Throwable exception) &#123; tracer.stop(); loadBalancerContext.noteRequestCompletion(stats, entity, exception, tracer.getDuration(TimeUnit.MILLISECONDS), retryHandler); &#125; &#125;); &#125; &#125;); if (maxRetrysSame &gt; 0) // 是否retry o = o.retry(retryPolicy(maxRetrysSame, true)); return o; &#125; &#125;); if (maxRetrysNext &gt; 0 &amp;&amp; server == null) // 是否retry，如果retry回调用selectServer()返回下一个Server o = o.retry(retryPolicy(maxRetrysNext, false)); // 异常处理 return o.onErrorResumeNext(new Func1&lt;Throwable, Observable&lt;T&gt;&gt;() &#123; @Override public Observable&lt;T&gt; call(Throwable e) &#123; if (context.getAttemptCount() &gt; 0) &#123; // 如果超过重试次数，则抛异常 if (maxRetrysNext &gt; 0 &amp;&amp; context.getServerAttemptCount() == (maxRetrysNext + 1)) &#123; e = new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_NEXTSERVER_EXCEEDED, \"Number of retries on next server exceeded max \" + maxRetrysNext + \" retries, while making a call for: \" + context.getServer(), e); &#125; else if (maxRetrysSame &gt; 0 &amp;&amp; context.getAttemptCount() == (maxRetrysSame + 1)) &#123; e = new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_EXEEDED, \"Number of retries exceeded max \" + maxRetrysSame + \" retries, while making a call for: \" + context.getServer(), e); &#125; &#125; if (listenerInvoker != null) &#123; listenerInvoker.onExecutionFailed(e, context.toFinalExecutionInfo()); &#125; return Observable.error(e); &#125; &#125;);&#125; 下面来拆解 4.1 获取重试设置参数 RetryHandler1234// 获取在每个服务实例重试的的次数final int maxRetrysSame = retryHandler.getMaxRetriesOnSameServer();// 最多尝试几个服务实例final int maxRetrysNext = retryHandler.getMaxRetriesOnNextServer(); 这个参数可以在配置文件中配置 12345ribbon: ReadTimeout: 60000 ConnectTimeout: 60000 MaxAutoRetries: 1 MaxAutoRetriesNextServer: 1 上面配置的参数获取到的结果如下 4.1 通过选取Server的接口ILoadBalancer来获取Server123456789101112131415// 返回一个只包含一个Server的Observable，但是每次从负载均衡器中获取一个private Observable&lt;Server&gt; selectServer() &#123; return Observable.create(new OnSubscribe&lt;Server&gt;() &#123; @Override public void call(Subscriber&lt;? super Server&gt; next) &#123; try &#123; Server server = loadBalancerContext.getServerFromLoadBalancer(loadBalancerURI, loadBalancerKey); next.onNext(server); next.onCompleted(); &#125; catch (Exception e) &#123; next.onError(e); &#125; &#125; &#125;);&#125; 4.2 重试机制看代码是采用了RxJava重试方法 一开始默认进入到下面这行判断，这里 server == null 12if (maxRetrysNext &gt; 0 &amp;&amp; server == null) o = o.retry(retryPolicy(maxRetrysNext, false)); 然后就是进入到下面这执行体方法，可以得到以下信息 第一个可以看到主体逻辑就是执行operation.call(server)方法，这个就是刚刚分析的AbstractLoadBalancerAwareClient传过来的ServerOperation，就是直接对这个Server调用请求 第二个就是使用ServerStats来记录服务执行状态，这个是负载均衡选择策略时计算需要 第三个就是使用if (maxRetrysSame &gt; 0) {o = o.retry(retryPolicy(maxRetrysSame, true)); } 来控制是否重试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 设置上下文context.setServer(server);// 记录服务请求执行状态final ServerStats stats = loadBalancerContext.getServerStats(server);// 每个Server包含重试逻辑的请求调用Observable&lt;T&gt; o = Observable .just(server) .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() &#123; @Override public Observable&lt;T&gt; call(final Server server) &#123; context.incAttemptCount(); // 增加Server正在处理的请求计数 loadBalancerContext.noteOpenConnection(stats); // 监听器 if (listenerInvoker != null) &#123; try &#123; listenerInvoker.onStartWithServer(context.toExecutionInfo()); &#125; catch (AbortExecutionException e) &#123; return Observable.error(e); &#125; &#125; // 计时器 final Stopwatch tracer = loadBalancerContext.getExecuteTracer().start(); // operation.call(server)就是刚刚分析的AbstractLoadBalancerAwareClient传过来的ServerOperation，就是直接对这个Server调用请求 // doOnEach的操作就是记录请求前后的一些数据用于负载均衡数据统计 return operation.call(server).doOnEach(new Observer&lt;T&gt;() &#123; private T entity; @Override public void onCompleted() &#123; // 记录请求完成 recordStats(tracer, stats, entity, null); &#125; @Override public void onError(Throwable e) &#123; // 记录请求结束 recordStats(tracer, stats, null, e); logger.debug(\"Got error &#123;&#125; when executed on server &#123;&#125;\", e, server); // 发生了错误，通知listener if (listenerInvoker != null) &#123; listenerInvoker.onExceptionWithServer(e, context.toExecutionInfo()); &#125; &#125; @Override public void onNext(T entity) &#123; // 因为只有调用请求成功只有一个结果（只有一个请求）， 这里的entity就是结果，只要收到结果就代表请求成功 this.entity = entity; if (listenerInvoker != null) &#123; listenerInvoker.onExecutionSuccess(entity, context.toExecutionInfo()); &#125; &#125; private void recordStats(Stopwatch tracer, ServerStats stats, Object entity, Throwable exception) &#123; tracer.stop(); loadBalancerContext.noteRequestCompletion(stats, entity, exception, tracer.getDuration(TimeUnit.MILLISECONDS), retryHandler); &#125; &#125;); &#125; &#125;);if (maxRetrysSame &gt; 0) // 是否retry o = o.retry(retryPolicy(maxRetrysSame, true));return o;&#125; Observable&lt;T&gt; retry(Func2&lt;Integer, Throwable, Boolean&gt; predicate) 方法 123public final Observable&lt;T&gt; retry(Func2&lt;Integer, Throwable, Boolean&gt; predicate) &#123; return nest().lift(new OperatorRetryWithPredicate&lt;T&gt;(predicate));&#125; 我们看一下设置重试的回调的详细回调代码retryPolicy(maxRetrysNext, false)方法 1234567891011121314151617181920212223private Func2&lt;Integer, Throwable, Boolean&gt; retryPolicy(final int maxRetrys, final boolean same) &#123; return new Func2&lt;Integer, Throwable, Boolean&gt;() &#123; // 只有返回为true的时候才会retry @Override public Boolean call(Integer tryCount, Throwable e) &#123; // 抛出的异常是AbortExecutionException则不重试 if (e instanceof AbortExecutionException) &#123; return false; &#125; // 超过最大重试次数则不重试 if (tryCount &gt; maxRetrys) &#123; return false; &#125; if (e.getCause() != null &amp;&amp; e instanceof RuntimeException) &#123; e = e.getCause(); &#125; // 判断是否是可以重试的exception return retryHandler.isRetriableException(e, same); &#125; &#125;;&#125; 这个判断是否是可以重试的exception里面的逻辑是： 如果已经配置了ribbon.okToRetryOnAllErrors为true，则不论什么异常都会重试，我们没有这么配置，一般也不会这么配置 其他情况，就是连接失败的判断。首先需要配置ribbon.okToRetryOnConnectErrors为true，这个默认就是true；然后通过isConnectionException判断 1234567891011121314151617@Overridepublic boolean isRetriableException(Throwable e, boolean sameServer) &#123; if (okToRetryOnAllErrors) &#123; return true; &#125; else if (e instanceof ClientException) &#123; ClientException ce = (ClientException) e; if (ce.getErrorType() == ClientException.ErrorType.SERVER_THROTTLED) &#123; return !sameServer; &#125; else &#123; return false; &#125; &#125; else &#123; return okToRetryOnConnectErrors &amp;&amp; isConnectionException(e); &#125;&#125; isConnectionException(e)这个方法其实就看这个异常以及Cause中是否有SocketException，如果有则返回true。 1234567891011121314151617181920212223// SocketException异常protected List&lt;Class&lt;? extends Throwable&gt;&gt; connectionRelated = Lists.&lt;Class&lt;? extends Throwable&gt;&gt;newArrayList(SocketException.class);public boolean isConnectionException(Throwable e) &#123; return Utils.isPresentAsCause(e, connectionRelated);&#125;public class Utils &#123; public static boolean isPresentAsCause(Throwable throwableToSearchIn, Collection&lt;Class&lt;? extends Throwable&gt;&gt; throwableToSearchFor) &#123; // 循环10次 ？ int infiniteLoopPreventionCounter = 10; while (throwableToSearchIn != null &amp;&amp; infiniteLoopPreventionCounter &gt; 0) &#123; infiniteLoopPreventionCounter--; for (Class&lt;? extends Throwable&gt; c: throwableToSearchFor) &#123; if (c.isAssignableFrom(throwableToSearchIn.getClass())) &#123; return true; &#125; &#125; throwableToSearchIn = throwableToSearchIn.getCause(); &#125; return false; &#125;&#125; 总结 Ribbon的重试是在服务连接的时候报SocketException进行重试，具体逻辑是看这个异常以及Cause中是否有SocketException 参考 https://blog.csdn.net/zhxdick/article/details/79717757","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Ribbon)工作原理及源码分析二","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析二","date":"2019-08-06T16:03:03.000Z","updated":"2019-09-16T13:11:05.926Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析二/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析二/","excerpt":"","text":"回顾 由前面章节我们知道Ribbon功能主要是将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，那么如果要实现负载均衡，具体是要做哪些事呢？ 1、第一步是要维护哪些服务实例可用，需要处理临时新增了服务或者某个服务不可用了情况 2、有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例 3、然后就是将执行请求，响应处理 4、如果调用失败是不是要重试 下面将从Ribbon的源码来按照上面的步骤来分析其具体实现, 源码版本： 1234567&lt;!-- https://mvnrepository.com/artifact/com.netflix.ribbon/ribbon-core --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-core&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 下面将继续接上一章节的内容 解析1、第一步是要维护哪些服务实例可用，需要处理临时新增了服务或者某个服务不可用了情况1、1 定义服务实例Server1、2 定义服务器列表ServerList2、有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例2、1 负责选取Server的接口ILoadBalancer 2、2 负债均衡策略IRule Ribbon对于负债均衡策略的实现是通过IRule来定义的，比如前面我们接触了RoundRobinRule线性轮询策略，下面来介绍下IRule接口的各个实现 1234567891011121314151617181920212223/** * Interface that defines a \"Rule\" for a LoadBalancer. A Rule can be thought of * as a Strategy for loadbalacing. Well known loadbalancing strategies include * Round Robin, Response Time based etc. * * @author stonse * */public interface IRule&#123; /* * choose one alive server from lb.allServers or * lb.upServers according to key * * @return choosen Server object. NULL is returned if none * server is available */ public Server choose(Object key); public void setLoadBalancer(ILoadBalancer lb); public ILoadBalancer getLoadBalancer(); &#125; 子类实现 AbstractLoadBalancerRule 负债均衡策略的抽象类，主要是定义了负债均衡器ILoadBalancer对象，该对象上一章节已经介绍了12345678910111213141516171819/** * Class that provides a default implementation for setting and getting load balancer * @author stonse * */public abstract class AbstractLoadBalancerRule implements IRule, IClientConfigAware &#123; private ILoadBalancer lb; @Override public void setLoadBalancer(ILoadBalancer lb)&#123; this.lb = lb; &#125; @Override public ILoadBalancer getLoadBalancer()&#123; return lb; &#125; &#125; RandomRule 随机选择策略，使用rand.nextInt(serverCount);作为实例列表的索引值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@edu.umd.cs.findbugs.annotations.SuppressWarnings(value = \"RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE\")public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers(); List&lt;Server&gt; allList = lb.getAllServers(); int serverCount = allList.size(); if (serverCount == 0) &#123; /* * No servers. End regardless of pass, because subsequent passes * only get more restrictive. */ return null; &#125; int index = rand.nextInt(serverCount); server = upList.get(index); if (server == null) &#123; /* * The only time this should happen is if the server list were * somehow trimmed. This is a transient condition. Retry after * yielding. */ Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; // Shouldn't actually happen.. but must be transient or a bug. server = null; Thread.yield(); &#125; return server; &#125; @Overridepublic Server choose(Object key) &#123; return choose(getLoadBalancer(), key);&#125; RoundRobinRule 线性轮询策略，具体实现使用了AtomicInteger nextServerCyclicCounter;自增+1来取得下一个实例列表的索引值，并取模求余来归位123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; log.warn(\"no load balancer\"); return null; &#125; Server server = null; int count = 0; while (server == null &amp;&amp; count++ &lt; 10) &#123; List&lt;Server&gt; reachableServers = lb.getReachableServers(); List&lt;Server&gt; allServers = lb.getAllServers(); int upCount = reachableServers.size(); int serverCount = allServers.size(); if ((upCount == 0) || (serverCount == 0)) &#123; log.warn(\"No up servers available from load balancer: \" + lb); return null; &#125; int nextServerIndex = incrementAndGetModulo(serverCount); server = allServers.get(nextServerIndex); if (server == null) &#123; /* Transient. */ Thread.yield(); continue; &#125; if (server.isAlive() &amp;&amp; (server.isReadyToServe())) &#123; return (server); &#125; // Next. server = null; &#125; if (count &gt;= 10) &#123; log.warn(\"No available alive servers after 10 tries from load balancer: \" + lb); &#125; return server;&#125; /** * Inspired by the implementation of &#123;@link AtomicInteger#incrementAndGet()&#125;. * * @param modulo The modulo to bound the value of the counter. * @return The next value. */private int incrementAndGetModulo(int modulo) &#123; for (;;) &#123; int current = nextServerCyclicCounter.get(); int next = (current + 1) % modulo; if (nextServerCyclicCounter.compareAndSet(current, next)) return next; &#125;&#125; RetryRule 重试策略1234567891011121314151617181920212223242526272829303132333435public Server choose(ILoadBalancer lb, Object key) &#123; long requestTime = System.currentTimeMillis(); long deadline = requestTime + maxRetryMillis; Server answer = null; answer = subRule.choose(key); if (((answer == null) || (!answer.isAlive())) &amp;&amp; (System.currentTimeMillis() &lt; deadline)) &#123; InterruptTask task = new InterruptTask(deadline - System.currentTimeMillis()); while (!Thread.interrupted()) &#123; answer = subRule.choose(key); if (((answer == null) || (!answer.isAlive())) &amp;&amp; (System.currentTimeMillis() &lt; deadline)) &#123; /* pause and retry hoping it's transient */ Thread.yield(); &#125; else &#123; break; &#125; &#125; task.cancel(); &#125; if ((answer == null) || (!answer.isAlive())) &#123; return null; &#125; else &#123; return answer; &#125;&#125; WeightedResponseTimeRule 对RoundRobinRule的扩展，根据权重来挑选实例 BestAvailableRule 找出最空闲的服务实例 ZoneAvoidanceRule 复合判断server所在区域的性能和server的可用性选择server 3、然后就是将执行请求，响应处理 经过上面的逻辑处理，我们已经得到了对应的服务实例Server，所以我们现在就是要执行请求了，这个处理在Ribbon是通过IClient来定义的，可以看里面就一个execute()执行方法 接口上面两个泛型对象一个对应请求对象ClientRequest，另一个对应响应对象IResponse 1234567891011121314/** * A client that can execute a single request. * * @author awang * */public interface IClient&lt;S extends ClientRequest, T extends IResponse&gt; &#123; /** * Execute the request and return the response. It is expected that there is no retry and all exceptions * are thrown directly. */ public T execute(S request, IClientConfig requestConfig) throws Exception; &#125; 类继承关系图 3.1 执行请求客户端AbstractLoadBalancerAwareClient 这个类是IClient抽象实现类，主要是执行请求，还有重试及异常处理，代码使用了RxJava风格，所以看起来比较陌生，下面可以看到构造了一个LoadBalancerCommand并传入了一个ServerOperation对象 并ServerOperation实现了其call方法，这里是个接口，哇，第一次见，call()方法是具体执行请求的方法 LoadBalancerCommand的submit()方法是个入口统筹方法，里面不仅会调用ServerOperation的call方法，还做了重试及异常处理，这种设计方式可以学习学习 12345678910111213141516171819202122232425262728293031323334353637383940public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException &#123; // 获取重试处理器，这个由其他实现类动态实现 RequestSpecificRetryHandler handler = getRequestSpecificRetryHandler(request, requestConfig); // 构造LoadBalancerCommand，RxJava风格 LoadBalancerCommand&lt;T&gt; command = LoadBalancerCommand.&lt;T&gt;builder() .withLoadBalancerContext(this) .withRetryHandler(handler) .withLoadBalancerURI(request.getUri()) .build(); try &#123; return command.submit( new ServerOperation&lt;T&gt;() &#123; @Override public Observable&lt;T&gt; call(Server server) &#123; // 修改原始url为实际的url URI finalUri = reconstructURIWithServer(server, request.getUri()); S requestForServer = (S) request.replaceUri(finalUri); try &#123; // 执行请求 return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig)); &#125; catch (Exception e) &#123; return Observable.error(e); &#125; &#125; &#125;) .toBlocking() .single(); &#125; catch (Exception e) &#123; Throwable t = e.getCause(); if (t instanceof ClientException) &#123; throw (ClientException) t; &#125; else &#123; throw new ClientException(e); &#125; &#125;&#125; 我们看这行代码Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));，进入org.springframework.cloud.netflix.ribbon.apache.RibbonLoadBalancingHttpClient#execute()方法，可以看到实际上是CloseableHttpClient来发送我们的请求 1234567891011121314public RibbonApacheHttpResponse execute(RibbonApacheHttpRequest request, IClientConfig configOverride) throws Exception &#123; Builder builder = RequestConfig.custom(); IClientConfig config = configOverride != null ? configOverride : this.config; // 连接超时时间 builder.setConnectTimeout(((Integer)config.get(CommonClientConfigKey.ConnectTimeout, this.connectTimeout)).intValue()); // 读取超时时间 builder.setSocketTimeout(((Integer)config.get(CommonClientConfigKey.ReadTimeout, this.readTimeout)).intValue()); builder.setRedirectsEnabled(((Boolean)config.get(CommonClientConfigKey.FollowRedirects, this.followRedirects)).booleanValue()); RequestConfig requestConfig = builder.build(); request = this.getSecureRequest(request, configOverride); HttpUriRequest httpUriRequest = request.toRequest(requestConfig); HttpResponse httpResponse = ((CloseableHttpClient)this.delegate).execute(httpUriRequest); return new RibbonApacheHttpResponse(httpResponse, httpUriRequest.getURI());&#125; 调试代码可以看到实际已经拼装好了具体请求的参数，包括请求链接 3.2 执行命令 LoadBalancerCommand 这个构造的LoadBalancerCommand是一个RxJava风格的，从下面可以看到具体执行流程就是通过选取Server的接口ILoadBalancer来获取Server，然后就是执行请求了，它包含了重试和异常处理机制、同时还记录了执行状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138// 返回一个只包含一个Server的Observable，但是每次从负载均衡器中获取一个private Observable&lt;Server&gt; selectServer() &#123; return Observable.create(new OnSubscribe&lt;Server&gt;() &#123; @Override public void call(Subscriber&lt;? super Server&gt; next) &#123; try &#123; Server server = loadBalancerContext.getServerFromLoadBalancer(loadBalancerURI, loadBalancerKey); next.onNext(server); next.onCompleted(); &#125; catch (Exception e) &#123; next.onError(e); &#125; &#125; &#125;);&#125;public Observable&lt;T&gt; submit(final ServerOperation&lt;T&gt; operation) &#123; final ExecutionInfoContext context = new ExecutionInfoContext(); if (listenerInvoker != null) &#123; try &#123; listenerInvoker.onExecutionStart(); &#125; catch (AbortExecutionException e) &#123; return Observable.error(e); &#125; &#125; // 获取在每个服务实例重试的的次数 final int maxRetrysSame = retryHandler.getMaxRetriesOnSameServer(); // 最多尝试几个服务实例 final int maxRetrysNext = retryHandler.getMaxRetriesOnNextServer(); // 对 于每个服务实例的调用逻辑 // 默认field server是null，通过selectServer()方法获取一个Server Observable&lt;T&gt; o = (server == null ? selectServer() : Observable.just(server)) .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() &#123; @Override // 对于每个Server，按顺序映射为对于每个Server包含重试逻辑的请求调用 public Observable&lt;T&gt; call(Server server) &#123; // 设置上下文 context.setServer(server); final ServerStats stats = loadBalancerContext.getServerStats(server); // 每个Server包含重试逻辑的请求调用 Observable&lt;T&gt; o = Observable .just(server) .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() &#123; @Override public Observable&lt;T&gt; call(final Server server) &#123; context.incAttemptCount(); // 增加Server正在处理的请求计数 loadBalancerContext.noteOpenConnection(stats); // 监听器 if (listenerInvoker != null) &#123; try &#123; listenerInvoker.onStartWithServer(context.toExecutionInfo()); &#125; catch (AbortExecutionException e) &#123; return Observable.error(e); &#125; &#125; // 计时器 final Stopwatch tracer = loadBalancerContext.getExecuteTracer().start(); // operation.call(server)就是刚刚分析的AbstractLoadBalancerAwareClient传过来的ServerOperation，就是直接对这个Server调用请求 // doOnEach的操作就是记录请求前后的一些数据用于负载均衡数据统计 return operation.call(server).doOnEach(new Observer&lt;T&gt;() &#123; private T entity; @Override public void onCompleted() &#123; // 记录请求完成 recordStats(tracer, stats, entity, null); &#125; @Override public void onError(Throwable e) &#123; // 记录请求结束 recordStats(tracer, stats, null, e); logger.debug(\"Got error &#123;&#125; when executed on server &#123;&#125;\", e, server); // 发生了错误，通知listener if (listenerInvoker != null) &#123; listenerInvoker.onExceptionWithServer(e, context.toExecutionInfo()); &#125; &#125; @Override public void onNext(T entity) &#123; // 因为只有调用请求成功只有一个结果（只有一个请求）， 这里的entity就是结果，只要收到结果就代表请求成功 this.entity = entity; if (listenerInvoker != null) &#123; listenerInvoker.onExecutionSuccess(entity, context.toExecutionInfo()); &#125; &#125; private void recordStats(Stopwatch tracer, ServerStats stats, Object entity, Throwable exception) &#123; tracer.stop(); loadBalancerContext.noteRequestCompletion(stats, entity, exception, tracer.getDuration(TimeUnit.MILLISECONDS), retryHandler); &#125; &#125;); &#125; &#125;); if (maxRetrysSame &gt; 0) // 是否retry o = o.retry(retryPolicy(maxRetrysSame, true)); return o; &#125; &#125;); if (maxRetrysNext &gt; 0 &amp;&amp; server == null) // 是否retry，如果retry回调用selectServer()返回下一个Server o = o.retry(retryPolicy(maxRetrysNext, false)); // 异常处理 return o.onErrorResumeNext(new Func1&lt;Throwable, Observable&lt;T&gt;&gt;() &#123; @Override public Observable&lt;T&gt; call(Throwable e) &#123; if (context.getAttemptCount() &gt; 0) &#123; // 如果超过重试次数，则抛异常 if (maxRetrysNext &gt; 0 &amp;&amp; context.getServerAttemptCount() == (maxRetrysNext + 1)) &#123; e = new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_NEXTSERVER_EXCEEDED, \"Number of retries on next server exceeded max \" + maxRetrysNext + \" retries, while making a call for: \" + context.getServer(), e); &#125; else if (maxRetrysSame &gt; 0 &amp;&amp; context.getAttemptCount() == (maxRetrysSame + 1)) &#123; e = new ClientException(ClientException.ErrorType.NUMBEROF_RETRIES_EXEEDED, \"Number of retries exceeded max \" + maxRetrysSame + \" retries, while making a call for: \" + context.getServer(), e); &#125; &#125; if (listenerInvoker != null) &#123; listenerInvoker.onExecutionFailed(e, context.toFinalExecutionInfo()); &#125; return Observable.error(e); &#125; &#125;);&#125; 4、如果调用失败是不是要重试 下章研究 总结 由这几章我们了解到Ribbon主要由如下几个组件组成： 服务实例列表维护机制实现的接口ServerList 负责选取Server的接口ILoadBalancer 服务实例列表更新机制实现的接口ServerListUpdater 服务实例列表过滤机制ServerListFilter 负载均衡选取规则实现的接口IRule 所有Ribbon负载均衡器需要实现的接口IClient 参考 https://blog.csdn.net/zhxdick/article/details/79717757","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Ribbon)工作原理及源码分析一","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析一","date":"2019-08-06T16:03:02.000Z","updated":"2019-09-16T13:11:05.918Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析一/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)工作原理及源码分析一/","excerpt":"","text":"前言 由前面章节我们知道Ribbon功能主要是将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，那么如果要实现负载均衡，具体是要做哪些事呢？ 1、第一步是要维护哪些服务实例可用，需要处理临时新增了服务或者某个服务不可用了情况 2、有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例 3、然后就是将执行请求，响应处理 4、如果调用失败是不是要重试 下面将从Ribbon的源码来按照上面的步骤来分析其具体实现, 源码版本： 1234567&lt;!-- https://mvnrepository.com/artifact/com.netflix.ribbon/ribbon-core --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-core&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 解析1、第一步是要维护哪些服务实例可用，需要处理临时新增了服务或者某个服务不可用了情况1、1 定义服务实例Server 首先先要定义服务实例，这里这里Ribbon用com.netflix.loadbalancer.Server来定义，从成员变量可以看到host及port的定义 Server 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Class that represents a typical Server (or an addressable Node) i.e. a * Host:port identifier * * @author stonse * */public class Server &#123; public static final String UNKNOWN_ZONE = \"UNKNOWN\"; // host private String host; // 端口 private int port = 80; private String scheme; // 服务id private volatile String id; // 是否存活 private volatile boolean isAliveFlag; private String zone = UNKNOWN_ZONE; private volatile boolean readyToServe = true; // 服务器的其他元信息 private MetaInfo simpleMetaInfo = new MetaInfo() &#123; @Override public String getAppName() &#123; return null; &#125; @Override public String getServerGroup() &#123; return null; &#125; @Override public String getServiceIdForDiscovery() &#123; return null; &#125; @Override public String getInstanceId() &#123; return id; &#125; &#125;; ... 因为我们前面使用的是Consul来作为注册中心，所以我们先看看使用Consul是怎么定义服务实例的，由下面可以看到是添加了一个HealthService及存储服务实例元数据信息的metaInfo,metadata 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @author Spencer Gibb */public class ConsulServer extends Server &#123; private final MetaInfo metaInfo; private final HealthService service; private final Map&lt;String, String&gt; metadata; public ConsulServer(final HealthService healthService) &#123; super(findHost(healthService), healthService.getService().getPort()); this.service = healthService; this.metadata = ConsulServerUtils.getMetadata(this.service); metaInfo = new MetaInfo() &#123; @Override public String getAppName() &#123; return service.getService().getService(); &#125; @Override public String getServerGroup() &#123; return getMetadata().get(\"group\"); &#125; @Override public String getServiceIdForDiscovery() &#123; return null; &#125; @Override public String getInstanceId() &#123; return service.getService().getId(); &#125; &#125;; setAlive(isPassingChecks()); &#125; @Override public MetaInfo getMetaInfo() &#123; return metaInfo; &#125; public HealthService getHealthService() &#123; return this.service; &#125; public Map&lt;String, String&gt; getMetadata() &#123; return metadata; &#125; public boolean isPassingChecks() &#123; for (Check check : this.service.getChecks()) &#123; if (check.getStatus() != Check.CheckStatus.PASSING) &#123; return false; &#125; &#125; return true; &#125;&#125; 1、2 定义服务器列表ServerList 因为这里是要处理负载均衡，所以涉及到多个Server, 这里Ribbon用ServerList接口来定义服务器列表相关的方法，可以看到这两个接口有两个方法，都是返回List&lt;T extends Server&gt; getInitialListOfServers定义初次获取服务实例列表方法 getUpdatedListOfServers定义获取更新后服务实例列表方法 这里会有个Loadbalancer的Ping处理会每30秒更新服务 ServerList 123456789101112131415161718/** * Interface that defines the methods sed to obtain the List of Servers * @author stonse * * @param &lt;T&gt; */public interface ServerList&lt;T extends Server&gt; &#123; public List&lt;T&gt; getInitialListOfServers(); /** * Return updated list of servers. This is called say every 30 secs * (configurable) by the Loadbalancer's Ping cycle * */ public List&lt;T&gt; getUpdatedListOfServers(); &#125; 再看下哪些类实现了这个接口 子类解析 StaticServerList 定义静态的服务实例列表，用作服务实例固定的情况，具体有哪些服务实例由构造函数提供 AbstractServerList该类包含一个API方法，用于创建负载均衡器使用的过滤器 ConfigurationBasedServerList定义可以从配置中加载服务器列表 ConsulServerList在Consul环境下的服务实例 我们这里关注org.springframework.cloud.consul.discovery.ConsulServerList，可以看到成员变量有我们之前接触到的ConsulClient client，用于访问Consul Restful API 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * @author Spencer Gibb * @author Richard Kettelerij */public class ConsulServerList extends AbstractServerList&lt;ConsulServer&gt; &#123; // 访问Consul Restful API的客户端 private final ConsulClient client; // Consul的配置 private final ConsulDiscoveryProperties properties; // 要实现负载均衡的服务id private String serviceId; public ConsulServerList(ConsulClient client, ConsulDiscoveryProperties properties) &#123; this.client = client; this.properties = properties; &#125; protected ConsulClient getClient() &#123; return client; &#125; protected ConsulDiscoveryProperties getProperties() &#123; return properties; &#125; protected String getServiceId() &#123; return serviceId; &#125; @Override public void initWithNiwsConfig(IClientConfig clientConfig) &#123; this.serviceId = clientConfig.getClientName(); &#125; @Override public List&lt;ConsulServer&gt; getInitialListOfServers() &#123; return getServers(); &#125; @Override public List&lt;ConsulServer&gt; getUpdatedListOfServers() &#123; return getServers(); &#125; ... 我们这里关注它是怎么实现getInitialListOfServers()及getUpdatedListOfServers()方法的，可以看到都是直接调用了getServers()方法，里面的逻辑就是根据服务id调用Consul Restful API /v1/health/service/来获取服务实例 1234567891011121314private List&lt;ConsulServer&gt; getServers() &#123; if (this.client == null) &#123; return Collections.emptyList(); &#125; String tag = getTag(); // null is ok // 直接调用Consul Restful API Response&lt;List&lt;HealthService&gt;&gt; response = this.client.getHealthServices( this.serviceId, tag, this.properties.isQueryPassing(), createQueryParamsForClientRequest(), this.properties.getAclToken()); if (response.getValue() == null || response.getValue().isEmpty()) &#123; return Collections.emptyList(); &#125; return transformResponse(response.getValue());&#125; 2、有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例 上一块已经有了服务实例列表，那么现在就是要挑选具体是要调用哪个实例了，Ribbon是通过ILoadBalancer接口来抽象的 2、1 负责选取Server的接口ILoadBalancer 该接口定义了一个客户端负债均衡器需要的一系列抽象操作 123456789101112131415161718192021public interface ILoadBalancer &#123;// 向负债均衡器维护的实例列表中添加服务实例public void addServers(List&lt;Server&gt; newServers); // 通过某种策略挑选一个具体的服务实例public Server chooseServer(Object key);// 通知和标记负债均衡器某个具体实例已经停止服务public void markServerDown(Server server);@Deprecatedpublic List&lt;Server&gt; getServerList(boolean availableOnly);// 获取当前正常服务的实例列表public List&lt;Server&gt; getReachableServers();// 获取所有服务实例列表，包括正常与不正常的public List&lt;Server&gt; getAllServers();&#125; ILoadBalancer子类解析 1、AbstractLoadBalancer抽象实现类 该抽象类定义了一个关于服务实例的分组枚举类ServerGroup，包含 12345678public enum ServerGroup&#123; // 所有服务实例 ALL, // 正常服务的实例 STATUS_UP, // 停止服务的实例 STATUS_NOT_UP &#125; getServerList(ServerGroup serverGroup);添加了一个按分组来获取不同的服务实例的列表方法 LoadBalancerStats getLoadBalancerStats();获取服务实例当前的属性和统计信息 2、BaseLoadBalancer 负债均衡器的基础实现类 这个类维护了存储服务实例的列表对象，并通过IPing对象来检查服务的状态 下面是其成员变量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * A basic implementation of the load balancer where an arbitrary list of * servers can be set as the server pool. A ping can be set to determine the * liveness of a server. Internally, this class maintains an \"all\" server list * and an \"up\" server list and use them depending on what the caller asks for. * * @author stonse * */public class BaseLoadBalancer extends AbstractLoadBalancer implements PrimeConnections.PrimeConnectionListener, IClientConfigAware &#123; private static Logger logger = LoggerFactory .getLogger(BaseLoadBalancer.class); private final static IRule DEFAULT_RULE = new RoundRobinRule(); private final static SerialPingStrategy DEFAULT_PING_STRATEGY = new SerialPingStrategy(); private static final String DEFAULT_NAME = \"default\"; private static final String PREFIX = \"LoadBalancer_\"; // 负债均衡的处理规则 protected IRule rule = DEFAULT_RULE; // 检查服务实例操作的执行策略对象，默认使用SerialPingStrategy，该策略采用线性遍历`ping`服务实例的方式检查 protected IPingStrategy pingStrategy = DEFAULT_PING_STRATEGY; // 检查服务实例是否正常 protected IPing ping = null; // 所有服务实例列表 @Monitor(name = PREFIX + \"AllServerList\", type = DataSourceType.INFORMATIONAL) protected volatile List&lt;Server&gt; allServerList = Collections.synchronizedList(new ArrayList&lt;Server&gt;()); // 正常服务实例列表 @Monitor(name = PREFIX + \"UpServerList\", type = DataSourceType.INFORMATIONAL) protected volatile List&lt;Server&gt; upServerList = Collections.synchronizedList(new ArrayList&lt;Server&gt;()); protected ReadWriteLock allServerLock = new ReentrantReadWriteLock(); protected ReadWriteLock upServerLock = new ReentrantReadWriteLock(); protected String name = DEFAULT_NAME; protected Timer lbTimer = null; protected int pingIntervalSeconds = 10; protected int maxTotalPingTimeSeconds = 5; protected Comparator&lt;Server&gt; serverComparator = new ServerComparator(); protected AtomicBoolean pingInProgress = new AtomicBoolean(false); // protected LoadBalancerStats lbStats; // 用于跟踪事件发生频率的监控 private volatile Counter counter = Monitors.newCounter(\"LoadBalancer_ChooseServer\"); private PrimeConnections primeConnections; private volatile boolean enablePrimingConnections = false; private IClientConfig config; private List&lt;ServerListChangeListener&gt; changeListeners = new CopyOnWriteArrayList&lt;ServerListChangeListener&gt;(); private List&lt;ServerStatusChangeListener&gt; serverStatusListeners = new CopyOnWriteArrayList&lt;ServerStatusChangeListener&gt;(); ... 从构造函数可以看到，主要做了如下事情 this.ping对象默认赋值为空， 负债均衡的处理规则默认是线性轮循 启动一个用于定时检查Server是否健康的任务，该任务默认的执行间隔是10秒 1234567public BaseLoadBalancer() &#123; this.name = DEFAULT_NAME; this.ping = null; setRule(DEFAULT_RULE); setupPingTask(); lbStats = new LoadBalancerStats(DEFAULT_NAME);&#125; addServer()方法可向负债均衡器增加新的服务实例列表，查看注释可以看到方法不保证其唯一性也就是说可以通过添加服务的服务实例来提高此服务的命中几率 12345678910111213public void addServer(Server newServer) &#123; if (newServer != null) &#123; try &#123; ArrayList&lt;Server&gt; newList = new ArrayList&lt;Server&gt;(); newList.addAll(allServerList); newList.add(newServer); setServersList(newList); &#125; catch (Exception e) &#123; logger.error(\"LoadBalancer [&#123;&#125;]: Error adding newServer &#123;&#125;\", name, newServer.getHost(), e); &#125; &#125;&#125; chooseServer(Object key)选择服务实例，可以看到实际上是使用IRule对象来选择实例，此类将在下面详细介绍，这里只要知道是调用这个对象的方来获取实例的 1234567891011121314151617181920212223/* * Get the alive server dedicated to key * * @return the dedicated server */ public Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; // 用于跟踪事件发生频率的监控 // private volatile Counter counter = Monitors.newCounter(\"LoadBalancer_ChooseServer\"); counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); &#125; catch (Exception e) &#123; logger.warn(\"LoadBalancer [&#123;&#125;]: Error choosing server for key &#123;&#125;\", name, key, e); return null; &#125; &#125; &#125; 3、DynamicServerListLoadBalancer 对BaseLoadBalancer的扩展 该类实现了服务实例清单在运行期的动态更新能力，同时还添加了对服务实例清单的过滤功能 下面是其成员变量 123456789101112131415161718192021222324252627282930313233/** * A LoadBalancer that has the capabilities to obtain the candidate list of * servers using a dynamic source. i.e. The list of servers can potentially be * changed at Runtime. It also contains facilities wherein the list of servers * can be passed through a Filter criteria to filter out servers that do not * meet the desired criteria. * * @author stonse * */public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(DynamicServerListLoadBalancer.class); boolean isSecure = false; boolean useTunnel = false; // to keep track of modification of server lists protected AtomicBoolean serverListUpdateInProgress = new AtomicBoolean(false); // 服务实例清单 volatile ServerList&lt;T&gt; serverListImpl; // 服务实例清单的过滤 volatile ServerListFilter&lt;T&gt; filter; // 该对象实现对serverListImpl服务实例清单的更新 protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123; @Override public void doUpdate() &#123; updateListOfServers(); &#125; &#125;; protected volatile ServerListUpdater serverListUpdater; ... com.netflix.loadbalancer.ServerListUpdater为服务更新器 可以看到创建了ServerListUpdater接口的一个内部类UpdateAction并实现了其doUpdate()方法，里面又调用了updateListOfServers();方法，此定义是下面定时任务的执行方法 1234567891011121314151617181920212223242526protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123; @Override public void doUpdate() &#123; updateListOfServers(); &#125;&#125;;...@VisibleForTestingpublic void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; // 调用ConsulServerList 的getUpdatedListOfServers() servers = serverListImpl.getUpdatedListOfServers(); LOGGER.debug(\"List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;\", getIdentifier(), servers); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); LOGGER.debug(\"Filtered List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;\", getIdentifier(), servers); &#125; &#125; updateAllServerList(servers);&#125; ServerListUpdater该对象实现对serverListImpl服务实例清单的更新 123456789101112131415161718public interface ServerListUpdater &#123; // 内部类，doUpdate()实现对ServerList的具体更新操作 public interface UpdateAction &#123; void doUpdate(); &#125; // 启动服务更新器 void start(UpdateAction updateAction); // 停止 void stop(); // 获取最近的更新时间戳 String getLastUpdate(); // 获取上一次更新到现在的时间间隔 long getDurationSinceLastUpdateMs(); // 获取错过的更新周期数 int getNumberMissedCycles(); // 获取核心线程数 int getCoreThreads();&#125; com.netflix.loadbalancer.PollingServerListUpdater此类是动态服务列表更新的默认策略，也就是说DynamicServerListLoadBalancer负债均衡器中的默认实现就是它，它通过定时任务的方式对服务列表进行更新 先从用于启动服务更新器的start函数源码看起，可以看到先创建了Runnable线程，并在实现中调用了上面提到的具体更新服务实例列表的new ServerListUpdater.UpdateAction().doUpdate()方法，定时器默认是服务实例初始化延迟1秒后开始执行，30秒周期循环123456789101112131415161718192021222324252627282930313233@Overridepublic synchronized void start(final UpdateAction updateAction) &#123; if (isActive.compareAndSet(false, true)) &#123; final Runnable wrapperRunnable = new Runnable() &#123; @Override public void run() &#123; if (!isActive.get()) &#123; if (scheduledFuture != null) &#123; scheduledFuture.cancel(true); &#125; return; &#125; try &#123; updateAction.doUpdate(); lastUpdated = System.currentTimeMillis(); &#125; catch (Exception e) &#123; logger.warn(\"Failed one update cycle\", e); &#125; &#125; &#125;; scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay( wrapperRunnable, // 默认服务实例初始化延迟1秒后开始执行 initialDelayMs, // 30秒周期循环 refreshIntervalMs, TimeUnit.MILLISECONDS ); &#125; else &#123; logger.info(\"Already active, no-op\"); &#125;&#125; 回到DynamicServerListLoadBalancer类寻找是怎么启动ServerListUpdater服务更新器的 先看下构造函数 123456789101112public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter, ServerListUpdater serverListUpdater) &#123; super(clientConfig, rule, ping); this.serverListImpl = serverList; this.filter = filter; this.serverListUpdater = serverListUpdater; if (filter instanceof AbstractServerListFilter) &#123; ((AbstractServerListFilter) filter).setLoadBalancerStats(getLoadBalancerStats()); &#125; restOfInit(clientConfig);&#125; 我们关心restOfInit(clientConfig);方法用于初始化 进入该方法 12345678910111213141516void restOfInit(IClientConfig clientConfig) &#123; boolean primeConnection = this.isEnablePrimingConnections(); // turn this off to avoid duplicated asynchronous priming done in BaseLoadBalancer.setServerList() this.setEnablePrimingConnections(false); // 开启定时com.netflix.loadbalancer.ServerListUpdater#start() enableAndInitLearnNewServersFeature(); // 更新服务实例 updateListOfServers(); if (primeConnection &amp;&amp; this.getPrimeConnections() != null) &#123; this.getPrimeConnections() .primeConnections(getReachableServers()); &#125; this.setEnablePrimingConnections(primeConnection); LOGGER.info(\"DynamicServerListLoadBalancer for client &#123;&#125; initialized: &#123;&#125;\", clientConfig.getClientName(), this.toString());&#125; enableAndInitLearnNewServersFeature();方法调用了前面的com.netflix.loadbalancer.ServerListUpdater#start()方法用于开启定时 1234public void enableAndInitLearnNewServersFeature() &#123; LOGGER.info(\"Using serverListUpdater &#123;&#125;\", serverListUpdater.getClass().getSimpleName()); serverListUpdater.start(updateAction); &#125; updateListOfServers();方法，更新服务实例，这里serverListImpl实现类为ConsulServerList，前面知道ConsulServerList会调用Consul Restful API获取服务实例信息 1234567891011121314151617@VisibleForTestingpublic void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; // 调用ConsulServerList 的getUpdatedListOfServers() servers = serverListImpl.getUpdatedListOfServers(); LOGGER.debug(\"List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;\", getIdentifier(), servers); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); LOGGER.debug(\"Filtered List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;\", getIdentifier(), servers); &#125; &#125; updateAllServerList(servers);&#125; 再此更新服务实例的定时任务已经启动了 updateListOfServers();方法里面的filter.getFilteredListOfServers(servers);方法用于过滤服务清单 4、ZoneAwareLoadBalancer负债均衡器是对DynamicServerListLoadBalancer的扩展 在DynamicServerListLoadBalancer中，我们看到它并没有重写选择具体实例的chooseServer()函数，所以它依旧使用BaseLoadBalancer的线性轮询方式来选择调用的服务实例 总结参考","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Ribbon)与SpringCloud集成简单示例","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)与SpringCloud集成简单示例","date":"2019-08-06T16:03:01.000Z","updated":"2019-09-16T13:11:05.914Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)与SpringCloud集成简单示例/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)与SpringCloud集成简单示例/","excerpt":"","text":"前言 Spring Cloud Ribbon是为客户端提供负载均衡功能的服务，简单来说，就是从注册中心Eureka、Consul获取可用服务实例列表，然后将请求根据某种策略发到这些实例上面执行 简单示例1、集成ribbon1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 2、消费方 定义消费方调用方法，通过@LoadBalanced注解开启客户端负债均衡 12345678910111213141516171819202122@Configuration@RestControllerpublic class DemoController &#123; /** * 主要用来调用REST服务，本身并不具备调用分布式服务的能力，但通过@LoadBalanced注解开启客户端负债均衡 * @return */ @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125; @RequestMapping(value = \"/router\", method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_VALUE) public String router() &#123; RestTemplate restTpl = getRestTemplate(); // 根据应用名称调用服务 String json = restTpl.getForObject(\"http://eureka-provider/person/1\", String.class); return json; &#125;&#125; 消费方配置文件 1234567891011server: port: 9050spring: application: name: eureka-consumereureka: instance: hostname: localhost client: service-url: defaultZone: http://localhost:9010/eureka/,http://localhost:9020/eureka/ 3、服务方 服务提供方法, 这里就是简单模拟了一下根据personId获取人员信息，并返回对应服务的端口 1234567@RequestMapping(value = \"/person/&#123;personId&#125;\", method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_VALUE) public Person findPerson(@PathVariable(\"personId\") Integer personId, HttpServletRequest request) &#123; Person person = new Person(personId, \"songsy\", 18); person.setName(person.getName() + \"端口：\" + IpConfigurationUtils.getPort()); return person; &#125; 配置文件 123456789spring: application: name: eureka-providereureka: instance: hostname: localhost client: service-url: defaultZone: http://localhost:9010/eureka/,http://localhost:9020/eureka/ 3.1 服务方1 以9011端口启动123public static void main(String[] args) &#123; new SpringApplicationBuilder(Slave1ProviderApplication.class).properties(\"server.port=9011\").run(args);&#125; 3.2 服务方2 以9023端口启动123public static void main(String[] args) &#123; new SpringApplicationBuilder(Slave1ProviderApplication.class).properties(\"server.port=9023\").run(args);&#125; 4、测试结果 连续访问 http://localhost:9050/router 会得到不同的结果， 可以看到已经实现了负载均衡 123&#123;\"id\":1,\"name\":\"songsy端口：9023\",\"age\":18&#125;&#123;\"id\":1,\"name\":\"songsy端口：9011\",\"age\":18&#125; @LoadBalanced注解解析 上一章节Ribbon实现客户端负债均衡是通过@LoadBalanced注解来开启的，下面是@LoadBalanced 注解，查看注释可以看到该注解具体发挥作用的是LoadBalancerClient类 123456789101112/*** 使用 LoadBalancerClient 该类来配置 * Annotation to mark a RestTemplate bean to be configured to use a LoadBalancerClient * @author Spencer Gibb */@Target(&#123; ElementType.FIELD, ElementType.PARAMETER, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Qualifierpublic @interface LoadBalanced &#123;&#125; 查看LoadBalancerClient.java类可以看到主要有三种方法，这三种方法就是Ribbon的具体要做的事情 choose() 根据传入的服务实例名serviceId，从负债均衡中挑选一个对应服务的实例 reconstructURI()将 http://myservice/path/to/service构建一个真实的host:port形式的url execute() 根据挑选出来服务实例执行请求 ServiceInstanceChooser.java 12345678910public interface ServiceInstanceChooser &#123; /** * 根据传入的服务实例名serviceId，从负债均衡中挑选一个对应服务的实例 * Choose a ServiceInstance from the LoadBalancer for the specified service * @param serviceId the service id to look up the LoadBalancer * @return a ServiceInstance that matches the serviceId */ ServiceInstance choose(String serviceId);&#125; LoadBalancerClient.java 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Represents a client side load balancer * @author Spencer Gibb */public interface LoadBalancerClient extends ServiceInstanceChooser &#123; /** * 根据挑选出来服务实例执行请求 * execute request using a ServiceInstance from the LoadBalancer for the specified * service * @param serviceId the service id to look up the LoadBalancer * @param request allows implementations to execute pre and post actions such as * incrementing metrics * @return the result of the LoadBalancerRequest callback on the selected * ServiceInstance */ &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException; /** * 根据服务实例执行请求 * execute request using a ServiceInstance from the LoadBalancer for the specified * service * @param serviceId the service id to look up the LoadBalancer * @param serviceInstance the service to execute the request to * @param request allows implementations to execute pre and post actions such as * incrementing metrics * @return the result of the LoadBalancerRequest callback on the selected * ServiceInstance */ &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request) throws IOException; /** * 将 http://myservice/path/to/service 构建一个真实的host:port形式的url * Create a proper URI with a real host and port for systems to utilize. * Some systems use a URI with the logical serivce name as the host, * such as http://myservice/path/to/service. This will replace the * service name with the host:port from the ServiceInstance. * @param instance * @param original a URI with the host as a logical service name * @return a reconstructed URI */ URI reconstructURI(ServiceInstance instance, URI original);&#125; 其他 它内部提供了一个叫做ILoadBalance的接口代表负载均衡器的操作，比如有添加服务器操作、选择服务器操作、获取所有的服务器列表、获取可用的服务器列表等等。 连接服务实例超时怎么办，连接服务实例后读取内容超时怎么处理 断路器是怎么处理的 总结 负载均衡器的目的主要是根据负责均衡策略选取合适的服务端实例 参考https://blog.csdn.net/zhxdick/article/details/79449146","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Ribbon)负载均衡介绍","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)负载均衡介绍","date":"2019-08-06T16:03:00.000Z","updated":"2019-09-16T13:11:06.026Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)负载均衡介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Ribbon)负载均衡介绍/","excerpt":"","text":"前言什么是负载均衡 查看百度百科，英文名称为Load Balance，其含义就是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行 那么如果要实现负载均衡，具体是要做哪些事呢 第一步是要维护哪些服务实例可用，包括需要处理临时新增了服务或者某个服务不可用了情况 有了服务实例之后就是根据请求以及某种负载均衡规则选择服务实例 然后就是将执行请求，响应处理 如果调用失败是不是要重试 主要负载均衡策略 1、简单轮询负载均衡（RoundRobin） 以轮询的方式依次将请求调度不同的服务器，即每次调度执行i = (i + 1) mod n，并选出第i台服务器。 2、随机负载均衡 （Random） 随机选择状态为UP的Server 3、加权响应时间负载均衡 （WeightedResponseTime） 根据响应时间分配一个weight，响应时间越长，weight越小，被选中的可能性越低。 4、区域感知轮询负载均衡（ZoneAvoidanceRule） 复合判断server所在区域的性能和server的可用性选择server 总结 负载均衡器的目的主要是根据负责均衡策略选取合适的服务端实例，那么负载均衡器就需要维护一个可用的服务端清单，然后通过心跳机制来删除故障的服务端节点以保证清单中都是可以正常访问的服务端节点，此时当客户端的请求到达负载均衡服务器时，负载均衡服务器按照某种配置好的规则从可用服务端清单中选出一台服务器去处理客户端的请求。 参考https://blog.csdn.net/zhxdick/article/details/79449146","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Consul)集成源码分析之执行流程二","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之执行流程二","date":"2019-08-06T16:02:03.000Z","updated":"2019-09-16T13:11:05.871Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之执行流程二/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之执行流程二/","excerpt":"","text":"前言 上一章节通过日志信息定位ConsulServiceRegistry这个类会进行注册操作，通过断点调试发现是由ConsulAutoServiceRegistration这个类来指挥的，这一章节来介绍这个类 解析ConsulAutoServiceRegistration的配置 这个类是哪里配置呢，查看spring.factories里面配置了一个类ConsulAutoServiceRegistrationAutoConfiguration 12345678910org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.consul.discovery.RibbonConsulAutoConfiguration,\\org.springframework.cloud.consul.discovery.configclient.ConsulConfigServerAutoConfiguration,\\org.springframework.cloud.consul.serviceregistry.ConsulAutoServiceRegistrationAutoConfiguration,\\org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistryAutoConfiguration,\\org.springframework.cloud.consul.discovery.ConsulDiscoveryClientConfigurationorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.consul.discovery.configclient.ConsulDiscoveryClientConfigServiceBootstrapConfiguration 查看ConsulAutoServiceRegistrationAutoConfiguration.java类可以发现里面配置了@Bean 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * @author Spencer Gibb */@Configuration@ConditionalOnBean(AutoServiceRegistrationProperties.class)@ConditionalOnMissingBean(type = \"org.springframework.cloud.consul.discovery.ConsulLifecycle\")@ConditionalOnConsulEnabled@ConditionalOnProperty(value = \"spring.cloud.service-registry.auto-registration.enabled\", matchIfMissing = true)@AutoConfigureAfter(&#123;AutoServiceRegistrationConfiguration.class, ConsulServiceRegistryAutoConfiguration.class&#125;)public class ConsulAutoServiceRegistrationAutoConfiguration &#123; @Autowired AutoServiceRegistrationProperties autoServiceRegistrationProperties; // 注册ConsulAutoServiceRegistration @Bean @ConditionalOnMissingBean public ConsulAutoServiceRegistration consulAutoServiceRegistration( ConsulServiceRegistry registry, AutoServiceRegistrationProperties autoServiceRegistrationProperties, ConsulDiscoveryProperties properties, ConsulAutoRegistration consulRegistration) &#123; return new ConsulAutoServiceRegistration(registry, autoServiceRegistrationProperties, properties, consulRegistration); &#125; @Bean @ConditionalOnMissingBean public ConsulAutoRegistration consulRegistration(AutoServiceRegistrationProperties autoServiceRegistrationProperties, ConsulDiscoveryProperties properties, ApplicationContext applicationContext, ObjectProvider&lt;List&lt;ConsulRegistrationCustomizer&gt;&gt; registrationCustomizers, HeartbeatProperties heartbeatProperties) &#123; return ConsulAutoRegistration.registration(autoServiceRegistrationProperties, properties, applicationContext, registrationCustomizers.getIfAvailable(), heartbeatProperties); &#125; @Configuration @ConditionalOnClass(ServletContext.class) protected static class ConsulServletConfiguration &#123; @Bean public ConsulRegistrationCustomizer servletConsulCustomizer(ObjectProvider&lt;ServletContext&gt; servletContext) &#123; return new ConsulServletRegistrationCustomizer(servletContext); &#125; &#125;&#125; ConsulAutoServiceRegistration 类解析ConsulAutoServiceRegistration 继承关系图 由上图可以看到此类实现了Lifecycle接口，也就是说Spring容器启动时或者关闭时会找出所有实现了LifeCycle及其子类接口的类，并一一调用其接口方法 下面是Lifecycle接口， start()方法对应容器启动时执行的方法，stop()方法对应容器关闭时执行的方法 12345public interface Lifecycle &#123; void start(); void stop(); boolean isRunning();&#125; 所以可以猜出ConsulAutoServiceRegistration就是借助了Lifecycle接口来达到启动应用时会自动注册到Consul，应用关闭时自动注销在Consul的注册信息 回顾下上一章节的内容，可以看到是调用了start()方法 下面来看看ConsulAutoServiceRegistration是怎么实现这两个方法的，ConsulAutoServiceRegistration对这两个方法的实现在AbstractDiscoveryLifecycle类上 start() 注册consul应用信息 org.springframework.cloud.client.discovery.AbstractDiscoveryLifecycle#start() 下面可以看到是调用了register()方法，这个方法是抽象方法，由子类来实现 12345678910111213141516171819202122232425@Overridepublic void start() &#123; if (!isEnabled()) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Discovery Lifecycle disabled. Not starting\"); &#125; return; &#125; // only set the port if the nonSecurePort is 0 and this.port != 0 if (this.port.get() != 0 &amp;&amp; getConfiguredPort() == 0) &#123; setConfiguredPort(this.port.get()); &#125; // only initialize if nonSecurePort is greater than 0 and it isn't already running // because of containerPortInitializer below if (!this.running.get() &amp;&amp; getConfiguredPort() &gt; 0) &#123; register(); if (shouldRegisterManagement()) &#123; registerManagement(); &#125; this.context.publishEvent(new InstanceRegisteredEvent&lt;&gt;(this, getConfiguration())); this.running.compareAndSet(false, true); &#125;&#125; 进入此方法 org.springframework.cloud.client.serviceregistry.AbstractAutoServiceRegistration#register()，可以看到调用了ServiceRegistry&lt;R&gt; serviceRegistry对象的注册方法 1234567/** * Register the local service with the &#123;@link ServiceRegistry&#125; */@Overrideprotected void register() &#123; this.serviceRegistry.register(getRegistration());&#125; 进入org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistry#register()方法，可以看到有两步操作 添加ttlScheduler定时任务 agentServiceRegister注册服务 1234567891011121314151617@Overridepublic void register(ConsulRegistration reg) &#123; log.info(\"Registering service with consul: \" + reg.getService()); try &#123; client.agentServiceRegister(reg.getService(), properties.getAclToken()); if (heartbeatProperties.isEnabled() &amp;&amp; ttlScheduler != null) &#123; ttlScheduler.add(reg.getInstanceId()); &#125; &#125; catch (ConsulException e) &#123; if (this.properties.isFailFast()) &#123; log.error(\"Error registering service with consul: \" + reg.getService(), e); ReflectionUtils.rethrowRuntimeException(e); &#125; log.warn(\"Failfast is false. Error registering service with consul: \" + reg.getService(), e); &#125;&#125; 继续跳入，直到进入com.ecwid.consul.v1.agent.AgentConsulClient#agentServiceRegister()，这个方法是consul的包里面的，不是Spring的，可以发现底层就是发送了一个RESTFUL API请求 12345678910111213@Overridepublic Response&lt;Void&gt; agentServiceRegister(NewService newService, String token) &#123; UrlParameters tokenParam = token != null ? new SingleUrlParameters(\"token\", token) : null; String json = GsonFactory.getGson().toJson(newService); RawResponse rawResponse = rawClient.makePutRequest(\"/v1/agent/service/register\", json, tokenParam); if (rawResponse.getStatusCode() == 200) &#123; return new Response&lt;Void&gt;(null, rawResponse); &#125; else &#123; throw new OperationException(rawResponse); &#125;&#125; 查看com.ecwid.consul.v1.agent.AgentConsulClient#agentServiceRegister()方法所在包 可以看到是依赖的下面这个包 12345&lt;dependency&gt; &lt;groupId&gt;com.ecwid.consul&lt;/groupId&gt; &lt;artifactId&gt;consul-api&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt; 查看其源码可以发现这个包封装了与consul通信的各种接口，也就是说使用该包可以很方便的注册服务，注销服务 里面有个ConsulClient类是个一站式的consul-api客户端，下面可以看到是继承各种Client，每种Client提供不同类型的接口实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Full consul-api client with all supported methods. * If you like to use more specific clients, please look at *Client classes (AclClient, AgentClient etc.) * &lt;p&gt; * Implementation notes: * Do not afraid of the class size :) * There aren't any 'smart' or specific methods - all methods in this class are just delegates and auto-generated by IntelliJ IDEA * * @author Vasily Vasilkov (vgv@ecwid.com) */public class ConsulClient implements AclClient, AgentClient, CatalogClient, CoordinateClient, EventClient, HealthClient, KeyValueClient, QueryClient, SessionClient, StatusClient &#123; private final AclClient aclClient; private final AgentClient agentClient; private final CatalogClient catalogClient; private final CoordinateClient coordinateClient; private final EventClient eventClient; private final HealthClient healthClient; private final KeyValueClient keyValueClient; private final QueryClient queryClient; private final SessionClient sessionClient; private final StatusClient statusClient; public ConsulClient(ConsulRawClient rawClient) &#123; aclClient = new AclConsulClient(rawClient); agentClient = new AgentConsulClient(rawClient); catalogClient = new CatalogConsulClient(rawClient); coordinateClient = new CoordinateConsulClient(rawClient); eventClient = new EventConsulClient(rawClient); healthClient = new HealthConsulClient(rawClient); keyValueClient = new KeyValueConsulClient(rawClient); queryClient = new QueryConsulClient(rawClient); sessionClient = new SessionConsulClient(rawClient); statusClient = new StatusConsulClient(rawClient); &#125; /** * Consul client will connect to local consul agent on * 'http://localhost:8500' */ public ConsulClient() &#123; this(new ConsulRawClient()); &#125; 查看方法 stop() 注销consul应用信息 org.springframework.cloud.client.discovery.AbstractDiscoveryLifecycle#stop()下面可以看到是调用了deregister()方法，这个方法是抽象方法，由子类来实现 123456789@Overridepublic void stop() &#123; if (this.running.compareAndSet(true, false) &amp;&amp; isEnabled()) &#123; deregister(); if (shouldRegisterManagement()) &#123; deregisterManagement(); &#125; &#125;&#125; 进入此方法 org.springframework.cloud.client.serviceregistry.AbstractAutoServiceRegistration#deregister()，可以看到调用了ServiceRegistry&lt;R&gt; serviceRegistry对象的注册方法 1234567/** * De-register the local service with the &#123;@link ServiceRegistry&#125; */@Overrideprotected void deregister() &#123; this.serviceRegistry.deregister(getRegistration());&#125; 进入org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistry#deregister()方法，可以看到有两步操作 去除ttlScheduler定时 agentServiceDeregister注销服务12345678910@Overridepublic void deregister(ConsulRegistration reg) &#123; if (ttlScheduler != null) &#123; ttlScheduler.remove(reg.getInstanceId()); &#125; if (log.isInfoEnabled()) &#123; log.info(\"Deregistering service with consul: \" + reg.getInstanceId()); &#125; client.agentServiceDeregister(reg.getInstanceId());&#125; 继续跳入，直到进入com.ecwid.consul.v1.agent.AgentConsulClient#agentServiceDeregister()方法，可以发现底层就是发送了一个RESTFUL API请求 123456789101112@Overridepublic Response&lt;Void&gt; agentServiceDeregister(String serviceId, String token) &#123; UrlParameters tokenParam = token != null ? new SingleUrlParameters(\"token\", token) : null; RawResponse rawResponse = rawClient.makePutRequest(\"/v1/agent/service/deregister/\" + serviceId, \"\", tokenParam); if (rawResponse.getStatusCode() == 200) &#123; return new Response&lt;Void&gt;(null, rawResponse); &#125; else &#123; throw new OperationException(rawResponse); &#125;&#125; 总结 ConsulAutoServiceRegistration就是借助了Lifecycle接口来实现启动应用时会自动注册到Consul，应用关闭时自动注销在Consul的注册信息功能 如果我们有需求在应用启动时或者关闭时做一些额外的事情，那么借助Lifecycle接口就可以达到我们的目的，不过需要注意的在使用Lifecycle接口方法时，如果Spring容器上下文没有显式的调用容器的start和destory(或者close,stop)等方法时是不会触发接口方法的，我们可以借助SmartLifecycle接口， 实现这个接口类会在所在的上下文在调用refresh时，希望能够自己自动进行回调 参考","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Consul)集成源码分析之执行流程一","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之执行流程一","date":"2019-08-06T16:02:02.000Z","updated":"2019-09-16T13:11:05.857Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之执行流程一/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之执行流程一/","excerpt":"","text":"前言 上一章节我们知道了SpringCloud集成Consul过程就是注册bean的过程，那么有了这些bean，那它们是怎样发挥作用的呢，如果要实现微服务之间的通信就是要将本地服务信息注册得到注册中心上，那SpringCloudConsul是怎么实现的，这个是我们本章要探究的。 因为SpringCloudConsul自动配置的类很多，一个一个去找十分麻烦，所以我们这里先关注它是怎么将本地服务注册得到注册中心上，通过之前章节可以知道只要启动应用，应用就会自动将自己注册到注册中心上，因为Spring有很多钩子接口及一套生命周期，所以我们看看它是怎么实现的，我们可以将log日志改为debug，通过日志来找出那些关键信息 解析 通过启动日志查看关键字registe我们可以定位到这行日志，这些信息就是我们在SpringCloud(二)注册中心Consul章节中介绍注册服务的信息是一一对应的，所以我们可以知道SpringCloudConsul注册服务也是通过RESTful HTTP API来注册服务的 1o.s.c.c.s.ConsulServiceRegistry : Registering service with consul: NewService&#123;id='cloudUser-dev-2010', name='cloudUser', tags=[], address='10.135.95.34', port=2010, enableTagOverride=null, check=Check&#123;script='null', interval='10s', ttl='null', http='http://10.135.95.34:2010/health', tcp='null', timeout='null', deregisterCriticalServiceAfter='null', tlsSkipVerify=null, status='null'&#125;, checks=null&#125; 日志拆解 1234567891011121314151617181920&#123;id=&apos;cloudUser-dev-2010&apos;, // 服务idname=&apos;cloudUser&apos;, // 服务名tags=[], // 服务的tag，自定义，可以根据这个tag来区分同一个服务名的服务address=&apos;10.135.95.34&apos;, // 服务注册到consul的IP，服务发现，发现的就是这个IPport=2010, // 服务注册consul的PORT，发现的就是这个PORTenableTagOverride=null, check = Check&#123; // 健康检查部分 script=&apos;null&apos;, interval=&apos;10s&apos;, // 健康检查间隔时间，每隔10s，调用一次上面的URL ttl=&apos;null&apos;, http=&apos;http://10.135.95.34:2010/health&apos;, // 指定健康检查的URL，调用后只要返回20X，consul都认为是健康的 tcp=&apos;null&apos;, timeout=&apos;null&apos;, deregisterCriticalServiceAfter=&apos;null&apos;, tlsSkipVerify=null, status=&apos;null&apos;&#125;, checks=null&#125; 看日志定位到org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistry，这个类是在spring-cloud-consul-discovery包下的，上一章节有涉及到 通过类名字及方法名我们可以知道这个类是Consul服务的注册及下架的处理类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * @author Spencer Gibb */public class ConsulServiceRegistry implements ServiceRegistry&lt;ConsulRegistration&gt; &#123; private static Log log = LogFactory.getLog(ConsulServiceRegistry.class); private final ConsulClient client; private final ConsulDiscoveryProperties properties; private final TtlScheduler ttlScheduler; private final HeartbeatProperties heartbeatProperties; public ConsulServiceRegistry(ConsulClient client, ConsulDiscoveryProperties properties, TtlScheduler ttlScheduler, HeartbeatProperties heartbeatProperties) &#123; this.client = client; this.properties = properties; this.ttlScheduler = ttlScheduler; this.heartbeatProperties = heartbeatProperties; &#125; @Override public void register(ConsulRegistration reg) &#123; log.info(\"Registering service with consul: \" + reg.getService()); try &#123; client.agentServiceRegister(reg.getService(), properties.getAclToken()); if (heartbeatProperties.isEnabled() &amp;&amp; ttlScheduler != null) &#123; ttlScheduler.add(reg.getInstanceId()); &#125; &#125; catch (ConsulException e) &#123; if (this.properties.isFailFast()) &#123; log.error(\"Error registering service with consul: \" + reg.getService(), e); ReflectionUtils.rethrowRuntimeException(e); &#125; log.warn(\"Failfast is false. Error registering service with consul: \" + reg.getService(), e); &#125; &#125; @Override public void deregister(ConsulRegistration reg) &#123; if (ttlScheduler != null) &#123; ttlScheduler.remove(reg.getInstanceId()); &#125; if (log.isInfoEnabled()) &#123; log.info(\"Deregistering service with consul: \" + reg.getInstanceId()); &#125; client.agentServiceDeregister(reg.getInstanceId()); &#125; @Override public void close() &#123; &#125; @Override public void setStatus(ConsulRegistration registration, String status) &#123; if (status.equalsIgnoreCase(OUT_OF_SERVICE.getCode())) &#123; client.agentServiceSetMaintenance(registration.getInstanceId(), true); &#125; else if (status.equalsIgnoreCase(UP.getCode())) &#123; client.agentServiceSetMaintenance(registration.getInstanceId(), false); &#125; else &#123; throw new IllegalArgumentException(\"Unknown status: \"+status); &#125; &#125; @Override public Object getStatus(ConsulRegistration registration) &#123; String serviceId = registration.getServiceId(); Response&lt;List&lt;Check&gt;&gt; response = client.getHealthChecksForService(serviceId, QueryParams.DEFAULT); List&lt;Check&gt; checks = response.getValue(); for (Check check : checks) &#123; if (check.getServiceId().equals(registration.getInstanceId())) &#123; if (check.getName().equalsIgnoreCase(\"Service Maintenance Mode\")) &#123; return OUT_OF_SERVICE.getCode(); &#125; &#125; &#125; return UP.getCode(); &#125;&#125; 下面来看ConsulServiceRegistry是如何发挥作用的 ConsulServiceRegistry bean注册初始化 点击ConsulServiceRegistry的引用可以进入到org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistryAutoConfiguration类，这个类是见名是自动配置类 123456789101112131415161718192021222324252627282930313233343536373839/** * @author Spencer Gibb */@Configuration@ConditionalOnConsulEnabled@ConditionalOnProperty(value = \"spring.cloud.service-registry.enabled\", matchIfMissing = true)@AutoConfigureBefore(ServiceRegistryAutoConfiguration.class)public class ConsulServiceRegistryAutoConfiguration &#123; @Autowired(required = false) private TtlScheduler ttlScheduler; @Bean @ConditionalOnMissingBean public ConsulServiceRegistry consulServiceRegistry(ConsulClient consulClient, ConsulDiscoveryProperties properties, HeartbeatProperties heartbeatProperties) &#123; return new ConsulServiceRegistry(consulClient, properties, ttlScheduler, heartbeatProperties); &#125; @Bean @ConditionalOnMissingBean @ConditionalOnProperty(\"spring.cloud.consul.discovery.heartbeat.enabled\") public TtlScheduler ttlScheduler(ConsulClient consulClient, HeartbeatProperties heartbeatProperties) &#123; return new TtlScheduler(heartbeatProperties, consulClient); &#125; @Bean @ConditionalOnMissingBean public HeartbeatProperties heartbeatProperties() &#123; return new HeartbeatProperties(); &#125; @Bean @ConditionalOnMissingBean public ConsulDiscoveryProperties consulDiscoveryProperties(InetUtils inetUtils) &#123; return new ConsulDiscoveryProperties(inetUtils); &#125;&#125; 回顾上一章节，我们知道spring.factories里面配置了这个类，所以这个类会被Spring自动注册 12345678910org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.consul.discovery.RibbonConsulAutoConfiguration,\\org.springframework.cloud.consul.discovery.configclient.ConsulConfigServerAutoConfiguration,\\org.springframework.cloud.consul.serviceregistry.ConsulAutoServiceRegistrationAutoConfiguration,\\org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistryAutoConfiguration,\\org.springframework.cloud.consul.discovery.ConsulDiscoveryClientConfigurationorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.consul.discovery.configclient.ConsulDiscoveryClientConfigServiceBootstrapConfiguration 观察ConsulServiceRegistryAutoConfiguration类 关注@ConditionalOnProperty(value = &quot;spring.cloud.service-registry.enabled&quot;, matchIfMissing = true)这个条件注解，这里是说需要配置了该属性ConsulServiceRegistryAutoConfiguration类才生效，这个属性名是不是很熟悉，没错就是上一章节@EnableDiscoveryClient注解自动注册的AutoServiceRegistrationConfiguration类相对应的，AutoServiceRegistrationConfiguration类就是配置了这个属性 1234567891011121314/** * @author Spencer Gibb */@Configuration@EnableConfigurationProperties(AutoServiceRegistrationProperties.class)@ConditionalOnProperty(value = \"spring.cloud.service-registry.auto-registration.enabled\", matchIfMissing = true)public class AutoServiceRegistrationConfiguration &#123;&#125; @ConfigurationProperties(\"spring.cloud.service-registry.auto-registration\")public class AutoServiceRegistrationProperties &#123; ...&#125; 在这里可以得出结论@EnableDiscoveryClient是开启服务自动注册类的开关，因为@SpringCloudApplication注解默认自带这个注解，所以在SpringCloud中只要添加了注册中心的依赖，就会默认开启注册中心的功能 TtlScheduler这个Bean，这个是个定时器 HeartbeatProperties 属性配置类，对应的属性前缀：spring.cloud.consul.discovery.heartbeat，这个是心跳检测的属性配置类 123456789101112131415161718192021@ConfigurationProperties(prefix = \"spring.cloud.consul.discovery.heartbeat\")@Data@CommonsLog@Validatedpublic class HeartbeatProperties &#123; // TODO: change enabled to default to true when I stop seeing messages like // [WARN] agent: Check 'service:testConsulApp:xtest:8080' missed TTL, is now critical boolean enabled = false; @Min(1) private int ttlValue = 30; @NotNull private String ttlUnit = \"s\"; @DecimalMin(\"0.1\") @DecimalMax(\"0.9\") private double intervalRatio = 2.0 / 3.0; private Period heartbeatInterval; ConsulDiscoveryProperties属性配置类，对应的属性前缀：spring.cloud.consul.discovery，这个是Consul的主要配置类，我们平常最常使用的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167@ConfigurationProperties(\"spring.cloud.consul.discovery\")@Datapublic class ConsulDiscoveryProperties &#123; protected static final String MANAGEMENT = \"management\"; @Getter(AccessLevel.PRIVATE) @Setter(AccessLevel.PRIVATE) private InetUtils.HostInfo hostInfo; @Value(\"$&#123;consul.token:$&#123;CONSUL_TOKEN:$&#123;spring.cloud.consul.token:$&#123;SPRING_CLOUD_CONSUL_TOKEN:&#125;&#125;&#125;&#125;\") private String aclToken; /** Tags to use when registering service */ private List&lt;String&gt; tags = new ArrayList&lt;&gt;(); /** Is service discovery enabled? */ private boolean enabled = true; /** Tags to use when registering management service */ private List&lt;String&gt; managementTags = Arrays.asList(MANAGEMENT); /** Alternate server path to invoke for health checking */ private String healthCheckPath = \"/health\"; /** Custom health check url to override default */ private String healthCheckUrl; /** How often to perform the health check (e.g. 10s), defaults to 10s. */ private String healthCheckInterval = \"10s\"; /** Timeout for health check (e.g. 10s). */ private String healthCheckTimeout; /** * Timeout to deregister services critical for longer than timeout (e.g. 30m). * Requires consul version 7.x or higher. */ private String healthCheckCriticalTimeout; /** IP address to use when accessing service (must also set preferIpAddress to use) */ private String ipAddress; /** Hostname to use when accessing server */ private String hostname; /** Port to register the service under (defaults to listening port) */ private Integer port; /** Port to register the management service under (defaults to management port) */ private Integer managementPort; private Lifecycle lifecycle = new Lifecycle(); /** Use ip address rather than hostname during registration */ private boolean preferIpAddress = false; /** Source of how we will determine the address to use */ private boolean preferAgentAddress = false; private int catalogServicesWatchDelay = 10; private int catalogServicesWatchTimeout = 2; /** Service name */ private String serviceName; /** Unique service instance id */ private String instanceId; /** Service instance zone */ private String instanceZone; /** Service instance group*/ private String instanceGroup; /** * Service instance zone comes from metadata. * This allows changing the metadata tag name. */ private String defaultZoneMetadataName = \"zone\"; /** Whether to register an http or https service */ private String scheme = \"http\"; /** Suffix to use when registering management service */ private String managementSuffix = MANAGEMENT; /** * Map of serviceId's -&gt; tag to query for in server list. * This allows filtering services by a single tag. */ private Map&lt;String, String&gt; serverListQueryTags = new HashMap&lt;&gt;(); /** * Map of serviceId's -&gt; datacenter to query for in server list. * This allows looking up services in another datacenters. */ private Map&lt;String, String&gt; datacenters = new HashMap&lt;&gt;(); /** Tag to query for in service list if one is not listed in serverListQueryTags. */ private String defaultQueryTag; /** * Add the 'passing` parameter to /v1/health/service/serviceName. * This pushes health check passing to the server. */ private boolean queryPassing = false; /** Register as a service in consul. */ private boolean register = true; /** Disable automatic de-registration of service in consul. */ private boolean deregister = true; /** Register health check in consul. Useful during development of a service. */ private boolean registerHealthCheck = true; /** * Throw exceptions during service registration if true, otherwise, log * warnings (defaults to true). */ private boolean failFast = true; /** * Skips certificate verification during service checks if true, otherwise * runs certificate verification. */ private Boolean healthCheckTlsSkipVerify; @SuppressWarnings(\"unused\") private ConsulDiscoveryProperties() &#123;&#125; public ConsulDiscoveryProperties(InetUtils inetUtils) &#123; this.hostInfo = inetUtils.findFirstNonLoopbackHostInfo(); this.ipAddress = this.hostInfo.getIpAddress(); this.hostname = this.hostInfo.getHostname(); &#125; /** * @param serviceId The service who's filtering tag is being looked up * @return The tag the given service id should be filtered by, or null. */ public String getQueryTagForService(String serviceId)&#123; String tag = serverListQueryTags.get(serviceId); return tag != null ? tag : defaultQueryTag; &#125; public String getHostname() &#123; return this.preferIpAddress ? this.ipAddress : this.hostname; &#125; public void setHostname(String hostname) &#123; this.hostname = hostname; this.hostInfo.override = true; &#125; public void setIpAddress(String ipAddress) &#123; this.ipAddress = ipAddress; this.hostInfo.override = true; &#125; @Data public static class Lifecycle &#123; private boolean enabled = true; &#125;&#125; 如何注册服务的 Bean注册完成了就要发挥作用了，我们在日志处log.info(&quot;Registering service with consul: &quot; + reg.getService());打断点 1234567891011121314151617@Overridepublic void register(ConsulRegistration reg) &#123; log.info(\"Registering service with consul: \" + reg.getService()); try &#123; client.agentServiceRegister(reg.getService(), properties.getAclToken()); if (heartbeatProperties.isEnabled() &amp;&amp; ttlScheduler != null) &#123; ttlScheduler.add(reg.getInstanceId()); &#125; &#125; catch (ConsulException e) &#123; if (this.properties.isFailFast()) &#123; log.error(\"Error registering service with consul: \" + reg.getService(), e); ReflectionUtils.rethrowRuntimeException(e); &#125; log.warn(\"Failfast is false. Error registering service with consul: \" + reg.getService(), e); &#125;&#125; 查看方法执行链 下面来看看具体执行流程，可以看到还是老样子的refresh()方法 进入org.springframework.context.support.AbstractApplicationContext#refresh()方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * refresh()统一入口 * * @throws BeansException * @throws IllegalStateException */@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 准备刷新的上下文环境，例如对系统属性或者环境变量进行准备及验证 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 初始化BeanFactory，并进行XML文件读取，这一步之后ClassPathXmlApplicationContext实际上就已经包含了BeanFactory所提供的功能 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 进入prepareBeanFactory前，Spring已经完成了对配置的解析，而ApplicationContext在功能上的扩展也由此展开 // 对BeanFactory进行各种功能组件填充 @Qualifier @Autowired这两注解功能组件就是在这步骤中增加的支持 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 子类覆盖方法做额外的处理 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用工厂后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean， // 并调用其postProcessBeanFactory接口方法 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册Bean后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanPostProcessor接口的bean， // 并将它们注册到容器Bean后处理器的注册表中，这里只是注册，真正的调用在getBean时候 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 初始化消息源 初始化容器的国际化消息资源 initMessageSource(); // Initialize event multicaster for this context. // 初始化应用上下文事件广播器 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 初始化其他特殊的bean，由具体子类实现，这是个钩子方法 onRefresh(); // Check for listener beans and register them. // 注册事件监听器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 重点：初始化所有单实例的Bean，使用懒加载模式的bean除外，初始化Bean后将它们放到Spring容器的缓冲池中 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // 完成刷新并发布容器刷新事件 finishRefresh(); &#125; 可以看到注册中心的注册动作是放到最后一步finishRefresh()来执行的 123456789protected void finishRefresh() &#123; super.finishRefresh(); EmbeddedServletContainer localContainer = this.startEmbeddedServletContainer(); if (localContainer != null) &#123; // 发布事件 this.publishEvent(new EmbeddedServletContainerInitializedEvent(this, localContainer)); &#125;&#125; 我们跳入org.springframework.context.event.SimpleApplicationEventMulticaster#multicastEvent()方法可以看到这里出现了ConsulAutoServiceRegistration这个类 查看ConsulAutoServiceRegistration这个类，我们可以看到这个类实现了Spring的很多接口，比如继承了EventListener，这里涉及到了事件监听，还有继承了Lifecycle，可以猜测Spirng容器销毁时用这个接口来向consul注销服务，因为这个类比较复杂，所以放到下一章节详细介绍 然后跳到org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistry#register)方法，这个方法打印了我们上面的日志 1234567891011121314151617@Overridepublic void register(ConsulRegistration reg) &#123; log.info(\"Registering service with consul: \" + reg.getService()); try &#123; client.agentServiceRegister(reg.getService(), properties.getAclToken()); if (heartbeatProperties.isEnabled() &amp;&amp; ttlScheduler != null) &#123; ttlScheduler.add(reg.getInstanceId()); &#125; &#125; catch (ConsulException e) &#123; if (this.properties.isFailFast()) &#123; log.error(\"Error registering service with consul: \" + reg.getService(), e); ReflectionUtils.rethrowRuntimeException(e); &#125; log.warn(\"Failfast is false. Error registering service with consul: \" + reg.getService(), e); &#125;&#125; 上面只是些执行流程，下一章节将详细介绍ConsulAutoServiceRegistration这个类 总结 由于各种自动配置类的作用，SpringCloudConsul会在应用启动的时候通过RESTful HTTP API 向consul注册本地服务信息 通过日志信息定位ConsulServiceRegistry类，这个类会进行注册操作，通过断点调试发现是由ConsulAutoServiceRegistration这个类来指挥的，这个类比较复杂所以放到下一章节介绍 参考","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Consul)集成源码分析之初始化","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之初始化","date":"2019-08-06T16:02:01.000Z","updated":"2019-09-16T13:11:05.851Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之初始化/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)集成源码分析之初始化/","excerpt":"","text":"前言 上一章节介绍了Consul的一些基本概念，这一章节来介绍SpringCloud是怎样集成Consul的，按照SpringBoot的一贯作法来说这里会有一个starter pom 简单示例 下面来集成Consul 第一步：导入starter pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 第二步：直接启动就可以了，使用起来十分方便 123456789101112/** * @author songsy * @date 2019/8/14 17:43 */@SpringCloudApplicationpublic class UserApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserApplication.class, args); &#125;&#125; 解析 从上面可以看到要让SpringCloud集成Consul主要是一个spring-cloud-starter-consul-discovery的Maven依赖 spring-cloud-starter-consul-discovery 我们先来看这个starter 因为是个starter，所以我们关注pom及spring.provides文件 pom文件： 可以看到有spring-cloud-starter-consul及spring-cloud-consul-discovery两个依赖，除此之外还依赖了spring-cloud-netflix-core及spring-cloud-starter-ribbon，这两个依赖是为了开启负债均衡吧 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consul&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt; &lt;relativePath&gt;..&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;name&gt;Spring Cloud Starter Consul Discovery&lt;/name&gt; &lt;description&gt;Spring Cloud Starter Consul Discovery&lt;/description&gt; &lt;url&gt;https://projects.spring.io/spring-cloud&lt;/url&gt; &lt;organization&gt; &lt;name&gt;Pivotal Software, Inc.&lt;/name&gt; &lt;url&gt;https://www.spring.io&lt;/url&gt; &lt;/organization&gt; &lt;properties&gt; &lt;main.basedir&gt;$&#123;basedir&#125;/../..&lt;/main.basedir&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;!-- Only needed at compile time --&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; spring.provides 1provides: spring-cloud-consul-discovery 我们现在关注spring-cloud-starter-consul及spring-cloud-consul-discovery这两个依赖 1、spring-cloud-starter-consul，这里核心依赖是spring-cloud-consul-core及com.ecwid.consul:consul-api，第二包是consul依赖包 打开pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consul&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt; &lt;relativePath&gt;..&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-starter-consul&lt;/artifactId&gt; &lt;name&gt;Spring Cloud Starter Consul&lt;/name&gt; &lt;description&gt;Spring Cloud Starter Consul&lt;/description&gt; &lt;url&gt;https://projects.spring.io/spring-cloud&lt;/url&gt; &lt;organization&gt; &lt;name&gt;Pivotal Software, Inc.&lt;/name&gt; &lt;url&gt;https://www.spring.io&lt;/url&gt; &lt;/organization&gt; &lt;properties&gt; &lt;main.basedir&gt;$&#123;basedir&#125;/../..&lt;/main.basedir&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-context&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consul-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ecwid.consul&lt;/groupId&gt; &lt;artifactId&gt;consul-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- required by com.ecwid.consul but not as a pom dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2、spring-cloud-consul-discovery 先看有什么 pom依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;spring-cloud-consul-discovery&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;name&gt;Spring Cloud Consul Discovery&lt;/name&gt;&lt;description&gt;Spring Cloud Consul Discovery&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consul&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt; &lt;relativePath&gt;..&lt;/relativePath&gt;&lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-consul-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-context&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ecwid.consul&lt;/groupId&gt; &lt;artifactId&gt;consul-api&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- required by com.ecwid.consul but not as a pom dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-core&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-archaius&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-core&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-httpclient&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon-loadbalancer&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;!-- Only needed at compile time --&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring.factories，这里我们看到了一些自动配置类，这个是SpringCloud集成Consul的关键 12345678910org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.consul.discovery.RibbonConsulAutoConfiguration,\\org.springframework.cloud.consul.discovery.configclient.ConsulConfigServerAutoConfiguration,\\org.springframework.cloud.consul.serviceregistry.ConsulAutoServiceRegistrationAutoConfiguration,\\org.springframework.cloud.consul.serviceregistry.ConsulServiceRegistryAutoConfiguration,\\org.springframework.cloud.consul.discovery.ConsulDiscoveryClientConfigurationorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.consul.discovery.configclient.ConsulDiscoveryClientConfigServiceBootstrapConfiguration 其他代码 @EnableDiscoveryClient注解 @SpringCloudApplication注解里面可以看到默认有@EnableDiscoveryClient注解 123456789101112/** * @author Spencer Gibb */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreakerpublic @interface SpringCloudApplication &#123;&#125; 我们现在看@EnableDiscoveryClient注解，查看注释可以知道这个注解开启了就会自动将本地服务注册到相应的注册中心 12345678910111213141516/** * Annotation to enable a DiscoveryClient implementation. * @author Spencer Gibb */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(EnableDiscoveryClientImportSelector.class)public @interface EnableDiscoveryClient &#123; /** * If true, the ServiceRegistry will automatically register the local server. */ boolean autoRegister() default true;&#125; 进入@Import(EnableDiscoveryClientImportSelector.class) 可以看到这个类实现了ImportSelector接口，我们在之前的SpringBoot系列的@EnableAutoConfiguration自动配置章节就接触到了这个接口，ImportSelector接口的selectImports返回的数组（类的全类名）都会被注册到Spring容器中，所以可以通过这个方法来自定义注册哪些bean 从下面代码可以看到String[]是只有一个org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationConfiguration类，所以可以得到结果@EnableDiscoveryClient注解用于注册AutoServiceRegistrationConfiguration这个Bean 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Order(Ordered.LOWEST_PRECEDENCE - 100)public class EnableDiscoveryClientImportSelector extends SpringFactoryImportSelector&lt;EnableDiscoveryClient&gt; &#123; @Override public String[] selectImports(AnnotationMetadata metadata) &#123; String[] imports = super.selectImports(metadata); AnnotationAttributes attributes = AnnotationAttributes.fromMap( metadata.getAnnotationAttributes(getAnnotationClass().getName(), true)); boolean autoRegister = attributes.getBoolean(\"autoRegister\"); if (autoRegister) &#123; List&lt;String&gt; importsList = new ArrayList&lt;&gt;(Arrays.asList(imports)); importsList.add(\"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationConfiguration\"); imports = importsList.toArray(new String[0]); &#125; else &#123; Environment env = getEnvironment(); if(ConfigurableEnvironment.class.isInstance(env)) &#123; ConfigurableEnvironment configEnv = (ConfigurableEnvironment)env; LinkedHashMap&lt;String, Object&gt; map = new LinkedHashMap&lt;&gt;(); map.put(\"spring.cloud.service-registry.auto-registration.enabled\", false); MapPropertySource propertySource = new MapPropertySource( \"springCloudDiscoveryClient\", map); configEnv.getPropertySources().addLast(propertySource); &#125; &#125; return imports; &#125; @Override protected boolean isEnabled() &#123; return new RelaxedPropertyResolver(getEnvironment()).getProperty( \"spring.cloud.discovery.enabled\", Boolean.class, Boolean.TRUE); &#125; @Override protected boolean hasDefaultFactory() &#123; return true; &#125;&#125; 下面我们来关注org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationConfiguration，这里是注册了AutoServiceRegistrationProperties配置类 12345678/** * @author Spencer Gibb */@Configuration@EnableConfigurationProperties(AutoServiceRegistrationProperties.class)@ConditionalOnProperty(value = \"spring.cloud.service-registry.auto-registration.enabled\", matchIfMissing = true)public class AutoServiceRegistrationConfiguration &#123;&#125; 总结 spring-cloud-starter-consul-discovery利用了Maven传递依赖的功能定义了集成Consul所需的各种依赖，先备粮草 SpringCloud集成Consul过程就是注册bean的过程，具体实现还是通过spring.factories、EnableAutoConfiguration自动配置来实现的","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Consul)注册中心介绍","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)注册中心介绍","date":"2019-08-06T16:02:00.000Z","updated":"2019-09-16T13:11:05.845Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)注册中心介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Consul)注册中心介绍/","excerpt":"","text":"Consul 介绍 Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。与其它分布式服务注册与发现的方案，Consul 的方案更“一站式”，内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value 存储、多数据中心方案，不再需要依赖其它工具（比如 ZooKeeper 等）。 使用起来也较 为简单。Consul 使用 Go 语言编写，因此具有天然可移植性(支持Linux、windows和Mac OS X)；安装包仅包含一个可执行文件，方便部署，与 Docker 等轻量级容器可无缝配合。 Consul 基础概念 Agent: agent 就是实际运行的 consul 服务，启动时可选以 server 或者 client 模式运行，每个集群至少有 1 个 server，由于使用了 Raft 算法，所以对于每个集群你应该把它的 server 数设置成 3 或 5 个。 Server: 核心的 consul 服务，存储了所有服务注册的信息，响应查询操作，跨数据中心通信等。 Client: 用来在集群中每个机器上运行，进行服务注册 / 健康检查的进程。 Cluster: 集群，由多台共同提供服务的机器组成的集合称为集群，agent 在集群的每个成员上都要运行。 DataCenter: 数据中心。consul 支持跨数据中心组成集群。 Node: 安装了 agent，接入集群的机器称为 node。 Service: 你的服务，即服务注册和服务发现之类操作的对象。通过提供 config 文件或者调用 consul 的 HTTP API 来定义一个服务。 Consul 角色client: 客户端, 无状态, 将 HTTP 和 DNS 接口请求转发给局域网内的服务端集群。 server: 服务端, 保存配置信息, 高可用集群, 在局域网内与本地客户端通讯, 通过广域网与其它数据中心通讯。 每个数据中心的 server 数量推荐为 3 个或是 5 个。 Consul 模式 CLIENT：表示consul的client模式，就是客户端模式。是consul节点的一种模式，这种模式下，所有注册到当前节点的服务会被转发到SERVER，本身是不持久化这些信息。 SERVER：表示consul的server模式，表明这个consul是个server，这种模式下，功能和CLIENT都一样，唯一不同的是，它会把所有的信息持久化的本地，这样遇到故障，信息是可以被保留的。 SERVER-LEADER：中间那个SERVER下面有LEADER的字眼，表明这个SERVER是它们的老大，它和其它SERVER不一样的一点是，它需要负责同步注册的信息给其它的SERVER，同时也要负责各个节点的健康监测。 其它信息：其它信息包括它们之间的通信方式，还有一些协议信息，算法。它们是用于保证节点之间的数据同步，实时性要求等等一系列集群问题的解决。这些有兴趣的自己看看官方文档。 Consul 基本使用启动consul 启动节点1（server模式） -node：节点的名称 -bind：绑定的一个地址，用于节点之间通信的地址，可以是内外网，必须是可以访问到的地址 -server：这个就是表示这个节点是个SERVER -bootstrap-expect：这个就是表示期望提供的SERVER节点数目，数目一达到，它就会被激活，然后就是LEADER了 1consul agent -server -bind=172.17.0.2 -bootstrap-expect=3 -node=node1 启动节点2-3（server模式） -join：这个表示启动的时候，要加入到哪个集群内，这里就是说要加入到节点1的集群 -node-id：这个貌似版本8才加入的，这里用这个来指定唯一的节点ID，可以查看这个issue -client：这个表示注册或者查询等一系列客户端对它操作的IP，如果不指定这个IP，默认是127.0.0.1。 1consul agent -server -bind=172.17.0.3 -join=172.17.0.2 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') -node=node2 启动节点4（client模式） 除了没有-server，其它都是一样的，没有这个就说明这个节点是CLIENT1consul agent -bind=172.17.0.5 -retry-join=172.17.0.2 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') -node=node4 Consul集群 consul members查看下集群的状态 4个节点都列出来了。Status表示它们的状态，都是alive。Type表示它们的类型，三个SERVER一个CLIENT，和我们之前启动的一样。DC表示数据中心，都是dc1。 consul join 10.201.102.198 加入集群 Consul同时提供了一个漂亮的功能齐全的WEB界面,开箱即用.界面可以用来查看所有的节点,可以查看健康检查和他们的当前状态.可以读取和设置K/V 存储的数据，启动完成之后就可以使用http://127.0.0.1:8500来查询服务状态，有界面查看还是挺人性化的 节点异常consul的处理 LEADER 挂了 leader挂了，consul会重新选取出新的leader，只要超过一半的SERVER还活着，集群是可以正常工作的。node1是leader，所以把这个容器停了。 日志打印，心跳检查node1的ip超时，接着开始选举。node2被选举为新的leader 使用consul 操作 Consul 有 Commands 和 RESTful HTTP API 两种方式，具体详情可以到官网API链接里查看，使用起来十分方便 注册服务 123456789101112131415161718PUT http://127.0.0.1:8500/v1/agent/service/register&#123; &quot;ID&quot;: &quot;userServiceId1&quot;, //服务id &quot;Name&quot;: &quot;userServiceName1&quot;, //服务名 &quot;Tags&quot;: [ //服务的tag，自定义，可以根据这个tag来区分同一个服务名的服务 &quot;userService1&quot;, &quot;v1&quot; ], &quot;Address&quot;: &quot;127.0.0.1&quot;,//服务注册到consul的IP，服务发现，发现的就是这个IP &quot;Port&quot;: 8000, //服务注册consul的PORT，发现的就是这个PORT &quot;EnableTagOverride&quot;: false, &quot;Check&quot;: &#123; //健康检查部分 &quot;DeregisterCriticalServiceAfter&quot;: &quot;90m&quot;, &quot;HTTP&quot;: &quot;http://www.baidu.com&quot;, //指定健康检查的URL，调用后只要返回20X，consul都认为是健康的 &quot;Interval&quot;: &quot;10s&quot; //健康检查间隔时间，每隔10s，调用一次上面的URL &#125;&#125; 下架服务 Sample Request 1PUT http://127.0.0.1:8500/v1/catalog/service/&#123;serviceId&#125; Sample Response 1status 200 ok 查看所有的服务 Sample Request 1GET http://127.0.0.1:8500/v1/agent/services Sample Response 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; &quot;userServiceId1&quot;: &#123; &quot;Kind&quot;: &quot;&quot;, &quot;ID&quot;: &quot;userServiceId1&quot;, &quot;Service&quot;: &quot;userServiceName1&quot;, &quot;Tags&quot;: [ &quot;userService1&quot;, &quot;v1&quot; ], &quot;Meta&quot;: &#123;&#125;, &quot;Port&quot;: 8001, &quot;Address&quot;: &quot;127.0.0.1&quot;, &quot;EnableTagOverride&quot;: false, &quot;CreateIndex&quot;: 0, &quot;ModifyIndex&quot;: 0, &quot;ProxyDestination&quot;: &quot;&quot;, &quot;Connect&quot;: null &#125;, &quot;userServiceId2&quot;: &#123; &quot;Kind&quot;: &quot;&quot;, &quot;ID&quot;: &quot;userServiceId2&quot;, &quot;Service&quot;: &quot;userServiceName2&quot;, &quot;Tags&quot;: [ &quot;userService2&quot;, &quot;v1&quot; ], &quot;Meta&quot;: &#123;&#125;, &quot;Port&quot;: 8001, &quot;Address&quot;: &quot;127.0.0.1&quot;, &quot;EnableTagOverride&quot;: false, &quot;CreateIndex&quot;: 0, &quot;ModifyIndex&quot;: 0, &quot;ProxyDestination&quot;: &quot;&quot;, &quot;Connect&quot;: null &#125;, &quot;userServiceId3&quot;: &#123; &quot;Kind&quot;: &quot;&quot;, &quot;ID&quot;: &quot;userServiceId3&quot;, &quot;Service&quot;: &quot;userServiceName3&quot;, &quot;Tags&quot;: [ &quot;userService3&quot;, &quot;v1&quot; ], &quot;Meta&quot;: &#123;&#125;, &quot;Port&quot;: 8001, &quot;Address&quot;: &quot;127.0.0.1&quot;, &quot;EnableTagOverride&quot;: false, &quot;CreateIndex&quot;: 0, &quot;ModifyIndex&quot;: 0, &quot;ProxyDestination&quot;: &quot;&quot;, &quot;Connect&quot;: null &#125;&#125; 查看某个服务 Sample Request 1GET http://127.0.0.1:8500/v1/catalog/service/&#123;serviceName&#125; Sample Response 123456789101112131415161718192021222324252627282930313233[ &#123; &quot;ID&quot;: &quot;3c1b78a3-701a-2625-f617-94cade896b47&quot;, &quot;Node&quot;: &quot;DESKTOP-DT6DIHG&quot;, &quot;Address&quot;: &quot;127.0.0.1&quot;, &quot;Datacenter&quot;: &quot;dc1&quot;, &quot;TaggedAddresses&quot;: &#123; &quot;lan&quot;: &quot;127.0.0.1&quot;, &quot;wan&quot;: &quot;127.0.0.1&quot; &#125;, &quot;NodeMeta&quot;: &#123; &quot;consul-network-segment&quot;: &quot;&quot; &#125;, &quot;ServiceKind&quot;: &quot;&quot;, &quot;ServiceID&quot;: &quot;userServiceId1&quot;, &quot;ServiceName&quot;: &quot;userServiceName1&quot;, &quot;ServiceTags&quot;: [ &quot;userService1&quot;, &quot;v1&quot; ], &quot;ServiceAddress&quot;: &quot;127.0.0.1&quot;, &quot;ServiceMeta&quot;: &#123;&#125;, &quot;ServicePort&quot;: 8001, &quot;ServiceEnableTagOverride&quot;: false, &quot;ServiceProxyDestination&quot;: &quot;&quot;, &quot;ServiceConnect&quot;: &#123; &quot;Native&quot;: false, &quot;Proxy&quot;: null &#125;, &quot;CreateIndex&quot;: 3220, &quot;ModifyIndex&quot;: 3220 &#125;] KV Store 存值 列出所有节点 1GET http://consul.rocks/v1/catelog/nodes Consul 工作原理 logo 1、当 Producer 启动的时候，会向 Consul 发送一个 post 请求，告诉 Consul 自己的 IP 和 Port 2、Consul 接收到 Producer 的注册后，每隔10s（默认）会向 Producer 发送一个健康检查的请求，检验Producer是否健康 3、当 Consumer 发送 GET 方式请求 /api/address 到 Producer 时，会先从 Consul 中拿到一个存储服务 IP 和 Port 的临时表，从表中拿到 Producer 的 IP 和 Port 后再发送 GET 方式请求 /api/address 4、该临时表每隔10s会更新，只包含有通过了健康检查的 Producer Consul 的优势 使用 Raft 算法来保证一致性, 比复杂的 Paxos 算法更直接. 相比较而言, zookeeper 采用的是 Paxos, 而 etcd 使用的则是 Raft。 支持多数据中心，内外网的服务采用不同的端口进行监听。 多数据中心集群可以避免单数据中心的单点故障,而其部署则需要考虑网络延迟, 分片等情况等。zookeeper和 etcd 均不提供多数据中心功能的支持。 支持健康检查。 etcd 不提供此功能。 支持 http 和 dns 协议接口。 zookeeper 的集成较为复杂, etcd 只支持 http 协议。 官方提供 web 管理界面, etcd 无此功能。 综合比较, Consul 作为服务注册和配置管理的新星, 比较值得关注和研究。 其他 consul 默认使用下列端口 8300(tcp): Server RPC，server 用于接受其他 agent 的请求 8301(tcp,udp): Serf LAN，数据中心内 gossip 交换数据用 8302(tcp,udp): Serf WAN，跨数据中心 gossip 交换数据用 8400(tcp): CLI RPC，接受命令行的 RPC 调用 8500(tcp): HTTP API 及 Web UI 8600(tcp udp): DNS 服务，可以把它配置到 53 端口来响应 dns 请求 测试开发环境下可以使用consul agent -dev来启动consul，该模式下（该节点的启动不能用于生产环境，因为该模式下不会持久化任何状态），该启动模式仅仅是为了快速便捷的启动单节点consul，该节点处于server模式且是leader 参考 官网：https://www.consul.io https://www.cnblogs.com/xiaohanlin/p/8016803.html https://farer.org/2018/05/17/consul-notes/ 参考：http://www.ityouknow.com/springcloud/2018/07/20/spring-cloud-consul.html","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud(Eureka)服务治理介绍","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Eureka)服务治理介绍","date":"2019-08-06T16:01:00.000Z","updated":"2019-09-16T13:11:05.876Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Eureka)服务治理介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Eureka)服务治理介绍/","excerpt":"","text":"前言什么是 Eureka Eureka是Netflix开发的服务发现框架，本身是一个基于REST的服务，主要用于定位运行在AWS域中的中间层服务，以达到负载均衡和中间层服务故障转移的目的。SpringCloud将它集成在其子项目spring-cloud-netflix中，以实现SpringCloud的服务发现功能。 解析服务发现 服务发现就像聊天室一个,每个用户来的时候去服务器上注册,这样他的好友们就能看到你,你同时也将获取好友的上线列表.在微服务中,服务就相当于聊天室的用户,而服务注册中心就像聊天室服务器一样。 目前服务发现的解决方案有Eureka,Consul,Etcd,Zookeeper,SmartStack等等 Eureka Client通过HTTP(或者TCP,UDP)去Eureka Server册和获取服务列表,为了高可用一般会有多个 Eureka Server可以组成集群，Eureka会移除那些心跳检查未到达的服务. 其他 因为此组件官方没有在维护了，所以在此没有更多研究，可以参考其他解决方案比如Consul","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringCloud()SpringCloudNetflix","slug":"backend/framework/spring/spring-cloud/analysis/SpringCloud(Netflix)SpringCloudNetflix","date":"2019-08-06T16:00:00.000Z","updated":"2019-09-16T13:11:05.902Z","comments":true,"path":"2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Netflix)SpringCloudNetflix/","link":"","permalink":"http://www.songshuiyang.com/2019/08/07/backend/framework/spring/spring-cloud/analysis/SpringCloud(Netflix)SpringCloudNetflix/","excerpt":"","text":"Spring Cloud Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 Spring Cloud组成 Spring Cloud的子项目，大致可分成两类，对于我们想快速实践微服务的开发者来说，第一类子项目就已经足够使用 第一类是对现有成熟框架Spring Boot的封装和抽象，比如对Netflix服务组件的封装，也是数量最多的项目 第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream扮演的就是kafka, ActiveMQ这样的角色 Spring Cloud Netflix SpringCloud下包含了多个工程，其中的Spring Cloud Netflix提供了一系列搭建微服务基础架构的功能组件，Netflix的部分组件及功能特性如下： Eureka（服务注册与发现框架）：一个基于REST风格的服务组件，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移 Hystrix（服务容错组件）：容错管理工具，旨在通过控制服务和第三方库的节点，从而对延迟和故障提供强大的容村能力 Zuul（服务网关）：边缘服务工具，提供动态路由、监控、贪心、安全等边缘服务 Ribbon（客户端负载均衡器）：提供客户端负载均衡算法，将Netflix的中间层服务连接起来 Feign（声明式HTTP客户端）：可以创建声明式、模板化的HTTP客户端，进行微服务调用 下面的章节将详细介绍这些Spring Cloud Netflix组件 总结 专人做专事，Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，提供了标准化的、全站式的技术方案 参考 官网传送：https://spring.io/projects/spring-cloud 百度百科 https://baike.baidu.com/item/spring%20cloud/20269825?fr=aladdin","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.songshuiyang.com/categories/SpringCloud/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://www.songshuiyang.com/tags/Spring-Cloud/"}]},{"title":"SpringBoot(八)配置Mybatis多数据源","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(八)配置Mybatis多数据源","date":"2019-08-05T16:08:00.000Z","updated":"2019-09-16T13:11:05.664Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(八)配置Mybatis多数据源/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(八)配置Mybatis多数据源/","excerpt":"","text":"背景 同一个项目数据操作有时会涉及到多个数据库，所以需要在后台配置多个数据源，通过特定的设置选择指定的数据库 目的 可以配置多个数据源，项目默认使用master数据源，当有新的数据源需求时，可以通过注解的形式动态切换数据源 实现 源码: https://github.com/songshuiyang/iframe application.yml 配置数据源1234567891011121314151617181920212223242526272829spring: application: name: iframe# 主数据库master: datasource: use-jndi: false jndi-name: jdbc/datasource url: jdbc:mysql://127.0.0.1:3306/iframe?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false username: root password: root driver-class: com.mysql.jdbc.Driver initial-size: 0 min-idle: 10 max-active: 100 max-wait: 20000# 从数据库slave: datasource: use-jndi: false jndi-name: jdbc/datasource url: jdbc:mysql://127.0.0.1:3306/iframe?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false username: root password: root driver-class: com.mysql.jdbc.Driver initial-size: 0 min-idle: 10 max-active: 100 max-wait: 20000 Config.java 解析数据源配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/** * 继承TransactionManagementConfigurer可以自定义事务管理器 * @author songsy * @Date 2018/11/7 17:09 */@Configuration@EnableTransactionManagementpublic class Config implements TransactionManagementConfigurer &#123; private static final Logger logger = LoggerFactory.getLogger(Config.class); @Autowired Environment env; /** * 实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器 * * @return */ @Override public PlatformTransactionManager annotationDrivenTransactionManager() &#123; return transactionManager(); &#125; /** * 数据源 * * @return */ @Bean(name = \"dataSource\") public DynamicDataSource dataSource() &#123; Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); for (String prefix : DATA_SOURCE_PREFIX) &#123; targetDataSources.put(prefix, createDataSource(prefix)); &#125; DynamicDataSource dynamicDataSource = new DynamicDataSource(); dynamicDataSource.setTargetDataSources(targetDataSources); dynamicDataSource.setDefaultTargetDataSource(targetDataSources.get(MASTER_DATA_SOURCE_PREFIX)); return dynamicDataSource; &#125; /** * 创建事务管理器 * * @return */ @Bean public PlatformTransactionManager transactionManager() &#123; DataSourceTransactionManager txManager = new DataSourceTransactionManager(); txManager.setDataSource(dataSource()); return txManager; &#125; /** * 创建数据源 * * @param prefix * @return */ private DataSource createDataSource(String prefix) &#123; // 是否使用数据源 boolean useJndi = env.getProperty(prefix + \".\" + \"datasource.use-jndi\", Boolean.class, false); // 数据源名称 String jndiName = env.getProperty(prefix + \".\" + \"datasource.jndi-name\", \"\"); // 数据库链接 String url = env.getProperty(prefix + \".\" + \"datasource.url\", \"\"); String username = env.getProperty(prefix + \".\" + \"datasource.username\", \"\"); String password = env.getProperty(prefix + \".\" + \"datasource.password\", \"\"); String driverClass = env.getProperty(prefix + \".\" + \"datasource.driver-class\", \"\"); // 数据源默认初始链接数 int initialSize = env.getProperty(prefix + \".\" + \"datasource.initial-size\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_INIT_SIZE); // 数据源最大连接数 int maxActive = env.getProperty(prefix + \".\" + \"datasource.max-active\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_MAX_ACTIVE); // 数据源最小连接数 int minIdle = env.getProperty(prefix + \".\" + \"datasource.min-idle\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_MIN_IDLE); // 配置获取连接等待超时的时间 int maxWait = env.getProperty(prefix + \".\" + \"datasource.max-wait\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_MAX_WAIT); if (useJndi) &#123; try &#123; logger.debug(\"get datasource from jndi - [&#123;&#125;].\", jndiName); Context context = new InitialContext(); DataSource dataSource = (DataSource) context.lookup(jndiName); return dataSource; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; else &#123; logger.debug(\"create druid datasource.\"); logger.debug(\"url - &#123;&#125;.\", url); logger.debug(\"username - &#123;&#125;.\", username); logger.debug(\"password - &#123;&#125;.\", password); logger.debug(\"driverClass - &#123;&#125;.\", driverClass); logger.debug(\"initialSize - &#123;&#125;.\", initialSize); logger.debug(\"maxActive - &#123;&#125;.\", maxActive); logger.debug(\"minIdle - &#123;&#125;.\", minIdle); try &#123; DruidDataSource datasource = new DruidDataSource(); datasource.setUrl(url); datasource.setDriverClassName(driverClass); datasource.setUsername(username); datasource.setPassword(password); datasource.setInitialSize(initialSize); datasource.setMaxActive(maxActive); datasource.setMinIdle(minIdle); datasource.setMaxWait(maxWait); datasource.setFilters(\"stat,slf4j\"); datasource.setProxyFilters(getDruidFilters()); return datasource; &#125; catch (Exception e) &#123; &#125; &#125; return null; &#125; public List&lt;Filter&gt; getDruidFilters() &#123; Slf4jLogFilter slf4jLogFilter = new Slf4jLogFilter(); slf4jLogFilter.setDataSourceLogEnabled(false); slf4jLogFilter.setStatementLogEnabled(false); slf4jLogFilter.setStatementExecutableSqlLogEnable(true); slf4jLogFilter.setResultSetLogEnabled(false); slf4jLogFilter.setResultSetCloseAfterLogEnabled(false); slf4jLogFilter.setConnectionLogEnabled(false); List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); filters.add(new StatFilter()); filters.add(slf4jLogFilter); return filters; &#125;&#125; 新增 @BindingDataSources 注解，通过该注解实现数据源切换 123456789101112/** * 绑定数据源注解 * @author songsy * @Date 2018/11/7 17:33 */@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface BindingDataSources &#123; String value() default \"master\";&#125; 新增 DynamicDataSource.java 实现切换数据源 123456789101112/** * 继承AbstractRoutingDataSource实现determineCurrentLookupKey方法，该方法可以实现数据库的动态切换 * @author songsy * @Date 2018/11/7 17:17 */public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceHolder.getDataSource(); &#125;&#125; 新增 DynamicDataSourceHolder.java 保存当前线程绑定的数据源信息1234567891011121314151617181920212223/** * 保存当前线程绑定的数据源信息 * @author songsy * @Date 2018/11/7 17:18 */public class DynamicDataSourceHolder &#123; private static final ThreadLocal&lt;String&gt; dataSourceHolder = new ThreadLocal&lt;&gt;(); public static void setDataSource(String dataSource) &#123; Assert.notNull(dataSource, \"dataSource cannot be null\"); dataSourceHolder.set(dataSource); &#125; public static String getDataSource() &#123; return dataSourceHolder.get(); &#125; public static void removeDataSource() &#123; dataSourceHolder.remove(); &#125;&#125; 通过 DynamicDataSourceAspect.java AOP切面来获取数据源注解信息并设置到 private static final ThreadLocal&lt;String&gt; dataSourceHolder = new ThreadLocal&lt;&gt;(); 变量中，那么determineCurrentLookupKey 方法就可以根据当前线程数据源key值去动态切换数据源 1234567891011121314151617181920212223242526272829303132/** * 配置数据源切面 * @author songsy * @Date 2018/11/7 17:35 */@Aspect@Order(-1)// 保证该AOP在@Transactional之前执行@Componentpublic class DynamicDataSourceAspect &#123; private final static Logger logger = LoggerFactory.getLogger(DynamicDataSourceAspect.class); @Pointcut(\"@annotation(com.songsy.iframe.core.persistence.datasource.annotation.BindingDataSources)\") public void pointcut() &#123; &#125; @Before(\"pointcut() &amp;&amp; @annotation(bindingDataSources)\") public void setDynamicDataSource(JoinPoint point, BindingDataSources bindingDataSources) &#123; Object target = point.getTarget(); Method method = ((MethodSignature) point.getSignature()).getMethod(); logger.debug(\"切换数据源: 类名 - &#123;&#125;\", target.getClass().getCanonicalName()); logger.debug(\"切换数据源: 方法名 - &#123;&#125;\", method.getName()); String key = bindingDataSources.value(); DynamicDataSourceHolder.setDataSource(key); logger.debug(\"切换数据源：[&#123;&#125;] 数据源切换成功.\", DynamicDataSourceHolder.getDataSource()); &#125; @After(\"pointcut()\") public void clearDynamicDataSource(JoinPoint point) &#123; DynamicDataSourceHolder.removeDataSource(); &#125;&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(七)内嵌Tomcat启动原理解析","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(七)内嵌Tomcat启动原理解析","date":"2019-08-05T16:07:00.000Z","updated":"2019-09-16T13:11:05.531Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(七)内嵌Tomcat启动原理解析/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(七)内嵌Tomcat启动原理解析/","excerpt":"","text":"前言 我们知道在使用Spring Boot项目的时候可以不用依赖外部Tomcat就可以启动，那么Spring Boot是怎么做到的呢？其实就是只需要引入spring-boot-starter-web，在应用启动时会自动启动嵌入版的tomcat作为应用服务器，下面我们来学习下其实现原理。 解析TomcatEmbeddedServletContainerFactory 自动配置 嵌入版的tomcat起作用的关键是TomcatEmbeddedServletContainerFactory，下面将讲解该类的注册 第四章节已经介绍了自动配置的实现，查看spring-boot-autoconfigure模块的META-INF/spring.factories文件，关注EmbeddedServletContainerAutoConfiguration这个配置类，看类名可以翻译为嵌入式的Servlet容器自动配置类，所以以后如果想知道其他功能是怎么被集成进来的，可以在spring.factories中找找对应的自动配置类 12345678org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\... org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\...org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 进入EmbeddedServletContainerAutoConfiguration.java，可以看到使用不同的@Conditional注解可以针对不同的环境情况选择注册不同的Bean，下面根据条件会注册不同的Servlet容器 注册Tomcat容器工厂 注册Jetty容器工厂 注册Undertow容器工厂 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112/** * 嵌入式的`Servlet`容器自动配置类 * * &#123;@link EnableAutoConfiguration Auto-configuration&#125; for an embedded servlet containers. * * @author Phillip Webb * @author Dave Syer * @author Ivan Sopov * @author Stephane Nicoll */@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication // 注解表明只有在web环境下才会创建容器相关信息，因此应用无需容器则使用@Import(BeanPostProcessorsRegistrar.class)public class EmbeddedServletContainerAutoConfiguration &#123; /** * 注册Tomcat容器工厂 * 由于存在@ConditionalOnMissingBean注解，因此优先使用用户自定义的EmbeddedServletContainerFactory * * Nested configuration if Tomcat is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * 注册Jetty容器工厂 * * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * 注册Undertow容器工厂 * * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; /** * Registers a &#123;@link EmbeddedServletContainerCustomizerBeanPostProcessor&#125;. Registered * via &#123;@link ImportBeanDefinitionRegistrar&#125; for early registration. */ public static class BeanPostProcessorsRegistrar implements ImportBeanDefinitionRegistrar, BeanFactoryAware &#123; private ConfigurableListableBeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; if (beanFactory instanceof ConfigurableListableBeanFactory) &#123; this.beanFactory = (ConfigurableListableBeanFactory) beanFactory; &#125; &#125; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; if (this.beanFactory == null) &#123; return; &#125; registerSyntheticBeanIfMissing(registry, \"embeddedServletContainerCustomizerBeanPostProcessor\", EmbeddedServletContainerCustomizerBeanPostProcessor.class); registerSyntheticBeanIfMissing(registry, \"errorPageRegistrarBeanPostProcessor\", ErrorPageRegistrarBeanPostProcessor.class); &#125; private void registerSyntheticBeanIfMissing(BeanDefinitionRegistry registry, String name, Class&lt;?&gt; beanClass) &#123; if (ObjectUtils.isEmpty( this.beanFactory.getBeanNamesForType(beanClass, true, false))) &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(beanClass); beanDefinition.setSynthetic(true); registry.registerBeanDefinition(name, beanDefinition); &#125; &#125; &#125;&#125; 我们这里关注TomcatEmbeddedServletContainerFactory类，下面是类继承关系图： TomcatEmbeddedServletContainerFactory类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class TomcatEmbeddedServletContainerFactory extends AbstractEmbeddedServletContainerFactory implements ResourceLoaderAware &#123; private static final Charset DEFAULT_CHARSET = Charset.forName(\"UTF-8\"); private static final Set&lt;Class&lt;?&gt;&gt; NO_CLASSES = Collections.emptySet(); /** * The class name of default protocol used. */ public static final String DEFAULT_PROTOCOL = \"org.apache.coyote.http11.Http11NioProtocol\"; private File baseDirectory; private List&lt;Valve&gt; engineValves = new ArrayList&lt;Valve&gt;(); private List&lt;Valve&gt; contextValves = new ArrayList&lt;Valve&gt;(); private List&lt;LifecycleListener&gt; contextLifecycleListeners = new ArrayList&lt;LifecycleListener&gt;(); private List&lt;TomcatContextCustomizer&gt; tomcatContextCustomizers = new ArrayList&lt;TomcatContextCustomizer&gt;(); private List&lt;TomcatConnectorCustomizer&gt; tomcatConnectorCustomizers = new ArrayList&lt;TomcatConnectorCustomizer&gt;(); private List&lt;Connector&gt; additionalTomcatConnectors = new ArrayList&lt;Connector&gt;(); private ResourceLoader resourceLoader; private String protocol = DEFAULT_PROTOCOL; private Set&lt;String&gt; tldSkipPatterns = new LinkedHashSet&lt;String&gt;( TldSkipPatterns.DEFAULT); private Charset uriEncoding = DEFAULT_CHARSET; private int backgroundProcessorDelay; /** * Create a new &#123;@link TomcatEmbeddedServletContainerFactory&#125; instance. */ public TomcatEmbeddedServletContainerFactory() &#123; super(); &#125; /** * Create a new &#123;@link TomcatEmbeddedServletContainerFactory&#125; that listens for * requests using the specified port. * @param port the port to listen on */ public TomcatEmbeddedServletContainerFactory(int port) &#123; super(port); &#125; /** * Create a new &#123;@link TomcatEmbeddedServletContainerFactory&#125; with the specified * context path and port. * @param contextPath the root context path * @param port the port to listen on */ public TomcatEmbeddedServletContainerFactory(String contextPath, int port) &#123; super(contextPath, port); &#125; /** * 获取EmbeddedServletContainer * * @param initializers &#123;@link ServletContextInitializer&#125;s that should be applied as * the container starts * @return */ @Override public EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; // 构建Tomcat实例 Tomcat tomcat = new Tomcat(); // 配置Tomcat的基本环境 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); // 将配置好的Tomcat传入进去。返回一个EmbeddedServletContainer 并且启动tomcat容器 return getTomcatEmbeddedServletContainer(tomcat); &#125; ... TomcatEmbeddedServletContainerFactory类，这个类是创建Tomcat容器的工厂类，可以看到这个类实现了EmbeddedServletContainerFactory接口 查看EmbeddedServletContainerFactory接口，该接口只有一个方法，该方法用于获取Servlet容器（EmbeddedServletContainer） 1234public interface EmbeddedServletContainerFactory &#123; EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers); &#125; TomcatEmbeddedServletContainerFactory类实现了getEmbeddedServletContainer()方法，可以看到Tomcat tomcat = new Tomcat()是创建了一个汤姆猫，然后构造为EmbeddedServletContainer对象 1234567891011121314151617181920212223242526272829/** * 获取EmbeddedServletContainer * * @param initializers &#123;@link ServletContextInitializer&#125;s that should be applied as * the container starts * @return */@Override public EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; // 构建Tomcat实例 Tomcat tomcat = new Tomcat(); // 配置Tomcat的基本环境 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); // 将配置好的Tomcat传入进去。返回一个EmbeddedServletContainer 并且启动tomcat容器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 查看EmbeddedServletContainer接口，该接口是Servlet容器的抽象，可以看到有三个方法，start() stop() getPort(); 12345678910111213141516171819202122232425262728public interface EmbeddedServletContainer &#123; /** * 启动容器 * * Starts the embedded servlet container. Calling this method on an already started * container has no effect. * @throws EmbeddedServletContainerException if the container cannot be started */ void start() throws EmbeddedServletContainerException; /** * 停止容器 * * Stops the embedded servlet container. Calling this method on an already stopped * container has no effect. * @throws EmbeddedServletContainerException if the container cannot be stopped */ void stop() throws EmbeddedServletContainerException; /** * 获取服务端口 * * Return the port this server is listening on. * @return the port (or -1 if none) */ int getPort(); &#125; 下图是显示了Spring Boot定义了哪些容器 UndertowEmbeddedServletContainer (org.springframework.boot.context.embedded.undertow) MockEmbeddedServletContainer (org.springframework.boot.context.embedded) TomcatEmbeddedServletContainer (org.springframework.boot.context.embedded.tomcat) JettyEmbeddedServletContainer (org.springframework.boot.context.embedded.jetty) EmbeddedServletContainer.java 到这里TomcatEmbeddedServletContainerFactory已经自动注册完成了，使用@Conditional相关注解可以控制只有在web环境下才会创建容器相关信息，有了容器的创建工厂之后就可以使用Servlet容器了EmbeddedServletContainer TomcatEmbeddedServletContainer 创建 由上面可以知道TomcatEmbeddedServletContainer的创建是由TomcatEmbeddedServletContainerFactory类的getEmbeddedServletContainer()方法来实现的，从下面private final Tomcat tomcat;可以看到我们的Tomcat猫 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class TomcatEmbeddedServletContainer implements EmbeddedServletContainer &#123; private static final Log logger = LogFactory.getLog(TomcatEmbeddedServletContainer.class); private static final AtomicInteger containerCounter = new AtomicInteger(-1); private final Object monitor = new Object(); private final Map&lt;Service, Connector[]&gt; serviceConnectors = new HashMap&lt;Service, Connector[]&gt;(); // Tomcat猫 private final Tomcat tomcat; private final boolean autoStart; private volatile boolean started; /** * Create a new &#123;@link TomcatEmbeddedServletContainer&#125; instance. * @param tomcat the underlying Tomcat server */ public TomcatEmbeddedServletContainer(Tomcat tomcat) &#123; this(tomcat, true); &#125; /** * Create a new &#123;@link TomcatEmbeddedServletContainer&#125; instance. * @param tomcat the underlying Tomcat server * @param autoStart if the server should be started */ public TomcatEmbeddedServletContainer(Tomcat tomcat, boolean autoStart) &#123; Assert.notNull(tomcat, \"Tomcat Server must not be null\"); this.tomcat = tomcat; this.autoStart = autoStart; // 启动容器 initialize(); &#125; private void initialize() throws EmbeddedServletContainerException &#123; TomcatEmbeddedServletContainer.logger .info(\"Tomcat initialized with port(s): \" + getPortsDescription(false)); synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); try &#123; // Remove service connectors to that protocol binding doesn't happen // yet removeServiceConnectors(); // Start the server to trigger initialization listeners // 启动 Tomcat this.tomcat.start(); // We can re-throw failure exception directly in the main thread rethrowDeferredStartupExceptions(); Context context = findContext(); try &#123; ContextBindings.bindClassLoader(context, getNamingToken(context), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; // Naming is not enabled. Continue &#125; // Unlike Jetty, all Tomcat threads are daemon threads. We create a // blocking non-daemon to stop immediate shutdown startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; containerCounter.decrementAndGet(); throw ex; &#125; &#125; catch (Exception ex) &#123; throw new EmbeddedServletContainerException( \"Unable to start embedded Tomcat\", ex); &#125; &#125; &#125; ... TomcatEmbeddedServletContainer 使用 有了TomcatServletContainer之后就需要启动了，那么Spring Boot是哪里触发调用的呢，可以在TomcatEmbeddedServletContainer的initialize()方法里打个断点 打好断点之后就是启动Spring Boot项目了，由下图可以看到是从ApplicationContext的refresh()开始触发的 现在我们从main方法开始一步步跟进 1、main方法开始 1234567 public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleTomcatJspApplication.class, args); &#125;public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; // 创建 SpringApplication 对象，并执行运行。 return new SpringApplication(sources).run(args);&#125; 2、进入org.springframework.boot.SpringApplication#run(java.lang.String...)方法，由之前的第三章节可以知道这里我们的到的ApplicationContext实现类是AnnotationConfigEmbeddedWebApplicationContext，看名字可以知道这个类是基于注解配置的嵌入式Web应用容器 12345678910111213141516171819202122232425public ConfigurableApplicationContext run(String... args) &#123; // 创建 StopWatch 对象，并启动。StopWatch 主要用于简单统计 run 启动过程的时长。 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; // 配置 headless 属性，这个逻辑，可以无视，和 AWT 相关。 configureHeadlessProperty(); // 获得 SpringApplicationRunListener 的数组，并启动监听 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; // 创建 ApplicationArguments 对象 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 加载属性配置。执行完成后，所有的 environment 的属性都会加载进来，包括 application.properties 和外部的属性配置。 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); // 打印 Spring Banner Banner printedBanner = printBanner(environment); // 创建 Spring 容器。 context = createApplicationContext(); analyzers = new FailureAnalyzers(context); // 主要是调用所有初始化类的 initialize 方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 初始化 Spring 容器。 refreshContext(context); 3、进入refreshContext(context);方法，下面可以看到是调用了refresh(context);方法 12345678910111213private void refreshContext(ConfigurableApplicationContext context) &#123; // 开启（刷新）Spring 容器 refresh(context); // 注册 ShutdownHook 钩子 if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException ex) &#123; // Not allowed in some environments. &#125; &#125;&#125; 4、一直跳入可以发现进入到了org.springframework.boot.context.embedded.EmbeddedWebApplicationContext#onRefresh方法，EmbeddedWebApplicationContext重写了onRefresh()方法，在调父类super.onRefresh();方法之后又调用了createEmbeddedServletContainer();方法用于创建及启动容器 123456789101112@Overrideprotected void onRefresh() &#123; super.onRefresh(); try &#123; // 创建及启动容器 createEmbeddedServletContainer(); &#125; catch (Throwable ex) &#123; throw new ApplicationContextException(\"Unable to start embedded container\", ex); &#125;&#125; 5、进入createEmbeddedServletContainer()方法可以看到通过org.springframework.boot.context.embedded.EmbeddedServletContainerFactory#getEmbeddedServletContainer()方法来创建了EmbeddedServletContainer，到现在就是和之前的内容联系起来了 12345678910111213141516171819private void createEmbeddedServletContainer() &#123; EmbeddedServletContainer localContainer = this.embeddedServletContainer; ServletContext localServletContext = getServletContext(); if (localContainer == null &amp;&amp; localServletContext == null) &#123; EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); // 获取EmbeddedServletContainer this.embeddedServletContainer = containerFactory.getEmbeddedServletContainer(getSelfInitializer()); &#125; else if (localServletContext != null) &#123; try &#123; getSelfInitializer().onStartup(localServletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException(\"Cannot initialize servlet context\", ex); &#125; &#125; initPropertySources();&#125; 6、可以看到containerFactory.getEmbeddedServletContainer(getSelfInitializer()); 的参数getSelfInitializer()是个ServletContextInitializer对象 getSelfInitializer()方法获得的Servlet初始化器内部会去构造一个ServletContextInitializerBeans(Servlet初始化器的集合)，ServletContextInitializerBeans构造的时候会去Spring容器中查找ServletContextInitializer类型的bean，其中ServletRegistrationBean、FilterRegistrationBean、ServletListenerRegistrationBean会被找出(如果有定义)，这3种ServletContextInitializer会在onStartup方法中将Servlet、Filter、Listener添加到Servlet容器中(如果我们只定义了Servlet、Filter或者Listener，ServletContextInitializerBeans内部会调用addAdaptableBeans方法把它们包装成RegistrationBean 12345678private org.springframework.boot.web.servlet.ServletContextInitializer getSelfInitializer() &#123; return new ServletContextInitializer() &#123; @Override public void onStartup(ServletContext servletContext) throws ServletException &#123; selfInitialize(servletContext); &#125; &#125;;&#125; 7、进入containerFactory.getEmbeddedServletContainer(getSelfInitializer());继续跳入，就来到了TomcatEmbeddedServletContainer.initialize();方法 12345678910111213141516171819202122public TomcatEmbeddedServletContainer(Tomcat tomcat, boolean autoStart) &#123; Assert.notNull(tomcat, \"Tomcat Server must not be null\"); this.tomcat = tomcat; this.autoStart = autoStart; // 启动容器 initialize();&#125; private void initialize() throws EmbeddedServletContainerException &#123; TomcatEmbeddedServletContainer.logger .info(\"Tomcat initialized with port(s): \" + getPortsDescription(false)); synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); try &#123; // Remove service connectors to that protocol binding doesn't happen // yet removeServiceConnectors(); // Start the server to trigger initialization listeners // 启动 Tomcat this.tomcat.start(); 其他总结 SpringBoot内置了Servlet容器，这样项目的发布、部署就不需要额外的Servlet容器，直接启动jar包即可 如果是Web程序，那么会构造AnnotationConfigEmbeddedWebApplicationContext类型的Spring容器，AnnotationConfigEmbeddedWebApplicationContext类型的Spring容器在refresh的过程中会在onRefresh方法中创建内置的Servlet容器。 参考 芋道源码 http://www.iocoder.cn https://www.jianshu.com/p/043579ae733f","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(六)Starter解析及自己定制实现","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(六)Starter解析及自己定制实现","date":"2019-08-05T16:06:00.000Z","updated":"2020-01-04T12:21:52.216Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(六)Starter解析及自己定制实现/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(六)Starter解析及自己定制实现/","excerpt":"","text":"前言 SpringBoot 能够快速的接入各种框架的关键是靠各种Starter来实现的，比如我们想搭建一个Web应用，只要在POM依赖中添加spring-boot-starter-web就可以完成，它会帮我们自动引入各种Web应用所需的依赖并完成Bean的自动注册 Starter 主要用来简化依赖用的，Spring Boot 通过starter依赖为项目的依赖管理提供帮助，starter依赖起始就是特殊的maven依赖，利用了传递依赖解析，把常用库聚合在一起,组成了几个为特定功能而定制的依赖 SpringBoot自带的Starter见下图，因为太多了所以只截了部分 解析spring-boot-starter-web 解析 查看spring-boot-starter-web的源码，见下图可以发现就两个文件，pom.xml定义了会自动导入哪些依赖，spring.provides也是告诉我们，通过在我们的构建中包含 spring-webmvc,spring-web,jackson-databind 作为依赖 为什么spring.provides定义了依赖又要在pom.xml再次定义？这个问题还需研究 META-INF/spring.provides 1provides: spring-webmvc,spring-web,jackson-databind spring-boot-starters/spring-boot-starter-web/pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starters&lt;/artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;name&gt;Spring Boot Web Starter&lt;/name&gt; &lt;description&gt;Starter for building web, including RESTful, applications using Spring MVC. Uses Tomcat as the default embedded container&lt;/description&gt; &lt;url&gt;http://projects.spring.io/spring-boot/&lt;/url&gt; &lt;organization&gt; &lt;name&gt;Pivotal Software, Inc.&lt;/name&gt; &lt;url&gt;http://www.spring.io&lt;/url&gt; &lt;/organization&gt; &lt;properties&gt; &lt;main.basedir&gt;$&#123;basedir&#125;/../..&lt;/main.basedir&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 自己定制实现Starter 我们知道spring-boot-actuator 中已经内置了非常多的 Endpoint比如health、info、beans、metrics、httptrace、shutdown，只要添加spring-boot-actuator依赖就可以获得这些功能 如果要我们自己来实现这些功能要怎么实现呢，下面我们将创建自己Starter来实现一个简单的功能，比如实现一个 可以获取系统应用状态的功能，只要在应用中导入Starter依赖并开启注解就可以使用该功能 创建项目，项目结构如下图所示： 我们这里为了方便，所以将Starter的定义及实现（添加了几个类）放到了一个包下，一般是Starter里面就一个META-INF/spring.factories及pom.xml文件 META-INF/spring.factories 这里配置了一个自动配置的类，只要导入了Starter Pom依赖，启动SpringBoot应用的时候就会自动注册这个类com.songsy.springcloud.plus.starter.CloudAutoConfiguration 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.songsy.springcloud.plus.starter.CloudAutoConfiguration CloudAutoConfiguration.java此类定义了一个Bean，这个Bean是个Controller，可以看到调用此链接/system/info就返回了一些应用信息，这里只是为了测试功能所以就返回了固定值 @Configuration 标识此类是Spring的配置类，相当于一个bean.xml文件 @ConditionalOnBean(CloudMarkerConfiguration.Marker.class) 标识只有当前Spring容器注册了CloudMarkerConfiguration.Marker这个Bean的时候此CloudAutoConfiguration配置类才生效 CloudAutoConfiguration.java 123456789101112131415161718192021@Configuration@ConditionalOnBean(CloudMarkerConfiguration.Marker.class)public class CloudAutoConfiguration &#123; @RestController @RequestMapping(\"/system\") class SystemController &#123; @GetMapping(\"/info\") public Map&lt;String, Object&gt; getInfo() &#123; Map&lt;String, Object&gt; objectMap = new HashMap&lt;String, Object&gt;(8); objectMap.put(\"appName\",\"spring-cloud-plus-parent\"); objectMap.put(\"groupId\",\"com.songsy.springcloud.plus\"); objectMap.put(\"artifactId\",\"cloud-parent\"); objectMap.put(\"version\",\"1.0-SNAPSHOT\"); objectMap.put(\"currentTimeMillis\",System.currentTimeMillis()); return objectMap; &#125; &#125;&#125; CloudMarkerConfiguration.Marker 这个是个标识类 123456789101112131415161718/** * 注册Marker标记bean，使&#123;@link CloudAutoConfiguration&#125;配置类生效 * * @author songsy * @date 2019/8/15 18:09 */@Configurationpublic class CloudMarkerConfiguration &#123; @Bean public Marker zuulProxyMarkerBean() &#123; return new Marker(); &#125; class Marker &#123; &#125;&#125; @EnableCloudAutoConfig 注解是开启此功能的开关，可以看到只要使用了此注解，就会注册CloudMarkerConfiguration.class 这个Bean，有了此Bean之后CloudAutoConfiguration.java的条件(@ConditionalOnBean(CloudMarkerConfiguration.Marker.class))就成立了 123456789101112/** * 开启自动配置 * * @author songsy * @date 2019/8/15 18:15 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(CloudMarkerConfiguration.class)public @interface EnableCloudAutoConfig &#123;&#125; 如何使用 把上面的Starter打成maven jar包 在其他应用中导入pom依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.songsy.springcloud.plus&lt;/groupId&gt; &lt;artifactId&gt;cloud-starter&lt;/artifactId&gt;&lt;/dependency&gt; 启动类加上@EnableCloudAutoConfig注解 123456789@EnableCloudAutoConfig@SpringBootApplicationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 启动访问/system/info链接，可以看到可以得到结果 1234567&#123; \"artifactId\": \"cloud-parent\", \"version\": \"1.0-SNAPSHOT\", \"appName\": \"spring-cloud-plus-parent\", \"groupId\": \"com.songsy.springcloud.plus\", \"currentTimeMillis\": 1565939848850&#125; 其他总结 Starter可以说是SpringBoot的灵魂，官方已经将一些常用的功能封装了，要什么就添加什么，万物皆可配置，我们也可以根据自己业务需求实现自己的Starter 参考","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(五)@Conditional按条件注册Bean","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(五)@Conditional按条件注册Bean","date":"2019-08-05T16:05:00.000Z","updated":"2019-09-16T13:11:05.660Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(五)@Conditional按条件注册Bean/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(五)@Conditional按条件注册Bean/","excerpt":"","text":"前言 从@EnableAutoConfiguration自动配置功能实现可以看到SpringBoot大量使用了各种@Conditional根据条件，决定类是否加载到Spring Ioc容器中 解析定义解析 下面是@Conditional的定义，可以看到可以在类或者方法上面使用，value需要传入一个Class数组，并且这个类需要继承Condition接口 123456789101112@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Conditional &#123; /** * All &#123;@link Condition&#125;s that must &#123;@linkplain Condition#matches match&#125; * in order for the component to be registered. */ Class&lt;? extends Condition&gt;[] value();&#125; Condition.java 12345678910111213public interface Condition &#123; /** * Determine if the condition matches. * @param context the condition context * @param metadata metadata of the &#123;@link org.springframework.core.type.AnnotationMetadata class&#125; * or &#123;@link org.springframework.core.type.MethodMetadata method&#125; being checked. * @return &#123;@code true&#125; if the condition matches and the component can be registered * or &#123;@code false&#125; to veto registration. */ boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);&#125; Condition.java接口用于定义是否符合条件 @param conditionContext:判断条件能使用的上下文环境 ConditionContext.java123456789101112public interface ConditionContext &#123; BeanDefinitionRegistry getRegistry(); ConfigurableListableBeanFactory getBeanFactory(); Environment getEnvironment(); ResourceLoader getResourceLoader(); ClassLoader getClassLoader(); &#125; @param annotatedTypeMetadata:注解所在位置的注释信息 使用示例 这是一个简单的例子，现在问题来了，如果我想根据当前操作系统来注入Person实例，windows下注入bill，linux下注入linus，怎么实现呢？ 首先，创建一个WindowsCondition类，conditionContext提供了多种方法，方便获取各种信息，也是SpringBoot中 @ConditonalOnXX注解多样扩展的基础。 12345678910111213141516171819202122public class WindowsCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; // 获取ioc使用的beanFactory ConfigurableListableBeanFactory beanFactory = conditionContext.getBeanFactory(); // 获取类加载器 ClassLoader classLoader = conditionContext.getClassLoader(); // 获取当前环境信息 Environment environment = conditionContext.getEnvironment(); // 获取bean定义的注册类 BeanDefinitionRegistry registry = conditionContext.getRegistry(); // 获得当前系统名 String property = environment.getProperty(\"os.name\"); // 包含Windows则说明是windows系统，返回true if (property.contains(\"Windows\"))&#123; return true; &#125; return false; &#125;&#125; 接着，创建LinuxCondition类： 1234567891011121314public class LinuxCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; Environment environment = conditionContext.getEnvironment(); String property = environment.getProperty(\"os.name\"); if (property.contains(\"Linux\"))&#123; return true; &#125; return false; &#125;&#125; 1、标注在方法上，一个方法只能注入一个bean实例，所以@Conditional标注在方法上只能控制一个bean实例是否注入。 12345678910111213141516171819@Configurationpublic class BeanConfig &#123; // 只有一个类时，大括号可以省略 // 如果WindowsCondition的实现方法返回true，则注入这个bean @Conditional(&#123;WindowsCondition.class&#125;) @Bean(name = \"bill\") public Person person1()&#123; return new Person(\"Bill Gates\",62); &#125; // 如果LinuxCondition的实现方法返回true，则注入这个bean @Conditional(&#123;LinuxCondition.class&#125;) @Bean(\"linus\") public Person person2()&#123; return new Person(\"Linus\",48); &#125;&#125; 2、标注在类上，一个类中可以注入很多实例，@Conditional标注在类上就决定了一批bean是否注入。 1234567891011121314@Conditional(&#123;WindowsCondition.class&#125;)@Configurationpublic class BeanConfig &#123; @Bean(name = \"bill\") public Person person1()&#123; return new Person(\"Bill Gates\",62); &#125; @Bean(\"linus\") public Person person2()&#123; return new Person(\"Linus\",48); &#125;&#125; SpringBootCondition 的进击 为了满足更加丰富的 Condition（条件）的需要，Spring Boot 进一步拓展了更多的实现类，如下图所示： org.springframework.boot.autoconfigure.condition.SpringBootCondition ，是 Spring Boot 实现Condition 的抽象类，且是 Spring Boot 所有 Condition 实现类的基类，分别对应如下注解： @ConditionalOnBean：当容器里有指定 Bean 的条件下。 @ConditionalOnMissingBean：当容器里没有指定 Bean 的情况下。 @ConditionalOnSingleCandidate：当指定 Bean 在容器中只有一个，或者虽然有多个但是指定首选 Bean 。 @ConditionalOnClass：当类路径下有指定类的条件下。 @ConditionalOnMissingClass：当类路径下没有指定类的条件下。 @ConditionalOnProperty：指定的属性是否有指定的值 @ConditionalOnResource：类路径是否有指定的值 @ConditionalOnExpression：基于 SpEL 表达式作为判断条件。 @ConditionalOnJava：基于 Java 版本作为判断条件 @ConditionalOnJndi：在 JNDI 存在的条件下差在指定的位置 @ConditionalOnNotWebApplication：当前项目不是 Web 项目的条件下 @ConditionalOnWebApplication：当前项目是 Web项 目的条件下。 @ConditionalOnBean 注解解析 查看该注解，可以看到实际上还是在@Conditional的基础上进行了包装 12345678910111213141516@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnBeanCondition.class)public @interface ConditionalOnBean &#123; Class&lt;?&gt;[] value() default &#123;&#125;; String[] type() default &#123;&#125;; Class&lt;? extends Annotation&gt;[] annotation() default &#123;&#125;; String[] name() default &#123;&#125;; SearchStrategy search() default SearchStrategy.ALL;&#125; OnBeanCondition.class 哪里生效的 查看哪里生效的可以直接在matches()方法打好断点，见下图可以看到是从refresh()方法开始触发，然后执行BeanFactoryPostProcessor钩子接口，最终跳到org.springframework.context.annotation.ConditionEvaluator#shouldSkip()方法 进入org.springframework.context.annotation.ConditionEvaluator#shouldSkip()方法，这里的condition.matches(this.context, metadata)方法就执行了Condition的接口方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class ConditionEvaluator &#123; private final ConditionContextImpl context; /** * Create a new &#123;@link ConditionEvaluator&#125; instance. */ public ConditionEvaluator(BeanDefinitionRegistry registry, Environment environment, ResourceLoader resourceLoader) &#123; this.context = new ConditionContextImpl(registry, environment, resourceLoader); &#125; /** * Determine if an item should be skipped based on &#123;@code @Conditional&#125; annotations. * The &#123;@link ConfigurationPhase&#125; will be deduced from the type of item (i.e. a * &#123;@code @Configuration&#125; class will be &#123;@link ConfigurationPhase#PARSE_CONFIGURATION&#125;) * @param metadata the meta data * @return if the item should be skipped */ public boolean shouldSkip(AnnotatedTypeMetadata metadata) &#123; return shouldSkip(metadata, null); &#125; /** * Determine if an item should be skipped based on &#123;@code @Conditional&#125; annotations. * @param metadata the meta data * @param phase the phase of the call * @return if the item should be skipped */ public boolean shouldSkip(AnnotatedTypeMetadata metadata, ConfigurationPhase phase) &#123; if (metadata == null || !metadata.isAnnotated(Conditional.class.getName())) &#123; return false; &#125; if (phase == null) &#123; if (metadata instanceof AnnotationMetadata &amp;&amp; ConfigurationClassUtils.isConfigurationCandidate((AnnotationMetadata) metadata)) &#123; return shouldSkip(metadata, ConfigurationPhase.PARSE_CONFIGURATION); &#125; return shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN); &#125; List&lt;Condition&gt; conditions = new ArrayList&lt;Condition&gt;(); for (String[] conditionClasses : getConditionClasses(metadata)) &#123; for (String conditionClass : conditionClasses) &#123; Condition condition = getCondition(conditionClass, this.context.getClassLoader()); conditions.add(condition); &#125; &#125; AnnotationAwareOrderComparator.sort(conditions); for (Condition condition : conditions) &#123; ConfigurationPhase requiredPhase = null; if (condition instanceof ConfigurationCondition) &#123; requiredPhase = ((ConfigurationCondition) condition).getConfigurationPhase(); &#125; if (requiredPhase == null || requiredPhase == phase) &#123; // 执行matches()方法 if (!condition.matches(this.context, metadata)) &#123; return true; &#125; &#125; &#125; return false; &#125; 其他总结 使用@Condition注解可以根据不同条件创建不同Bean，SpringBoot在此基础上又定义了一些定制版的@Condition，这样可以更方便的实现自动配置 @Condition实现原理： 是在执行AnnotationConfigApplicationContext#refresh方法，调用invokeBeanFactoryPostProcessors，执行 BeanFactoryPostProcessor的postProcessBeanDefinitionRegistry 方法 会加载bean的定义信息 会执行ConditionEvaluator#shouldSkip判断这个类是否应该被跳过 然后就会调用我们自定义的ColorCondition#matches方法 如果返回false，则不会注册对应bean到ioc容器中 参考 https://blog.csdn.net/xcy1193068639/article/details/81491071","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(四)@EnableAutoConfiguration自动配置","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(四)@EnableAutoConfiguration自动配置","date":"2019-08-05T16:04:00.000Z","updated":"2020-01-04T12:21:52.221Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(四)@EnableAutoConfiguration自动配置/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(四)@EnableAutoConfiguration自动配置/","excerpt":"","text":"前言 SpringBoot到底是怎么做到自动配置的？从代码里看项目SpringBoot的项目启动类只有一个注解@SpringBootApplication和一个run方法。 12345678910111213@SpringBootApplicationpublic class SampleTomcatJspApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(SampleTomcatJspApplication.class); &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleTomcatJspApplication.class, args); &#125;&#125; 解析 查看@SpringBootApplication注解，可以看到这个注解又被其他注解修饰了 @Inherited java.lang.annotation.@Inherited 注解，使用此注解声明出来的自定义注解，在使用此自定义注解时，如果注解在类上面时，子类会自动继承此注解，否则的话，子类不会继承此注解。这里一定要记住，使用@Inherited 声明出来的注解，只有在类上使用时才会有效，对方法，属性等其他无效。 @SpringBootConfiguration 标记这是一个 Spring Boot 配置类， 它上面继承自 @Configuration 注解，所以两者功能也一致，可以将当前类内声明的一个或多个以 @Bean 注解标记的方法的实例纳入到 Spring 容器中，并且实例名就是方法名。 @EnableAutoConfiguration 用于开启自动配置功能，是 spring-boot-autoconfigure 项目最核心的注解 @ComponentScan 扫描指定路径下的 Component（@Componment、@Configuration、@Service） 1234567891011121314151617181920212223@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @AliasFor(annotation = EnableAutoConfiguration.class, attribute = \"exclude\") Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor(annotation = EnableAutoConfiguration.class, attribute = \"excludeName\") String[] excludeName() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = \"basePackages\") String[] scanBasePackages() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = \"basePackageClasses\") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 这么多注解我们这里关注@EnableAutoConfiguration注解，可以看到是使用了@Import(EnableAutoConfigurationImportSelector.class)注解， @Import用来导入一个或多个类（会被Spring容器管理），或者配置类（配置类里的@Bean标记的类也会被Spring容器管理），有了这个注解我们可以通过添加注解的形式来注册Bean 12345678910111213141516171819202122232425@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage // 主要功能自动配置包，它会获取主程序类所在的包路径，并将包路径（包括子包）下的所有组件注册到 Spring IOC 容器中。@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; 查看EnableAutoConfigurationImportSelector.class的继承关系图 上面的图可以看到EnableAutoConfigurationImportSelector类是实现了ImportSelectors接口 实现了ImportSelectors接口的类通常与常规的@Import注解作用相同，然而，它也可能被延迟处理，直到所有被@Configuration标记的类处理完之后采取处理 123456789public interface ImportSelector &#123; /** * Select and return the names of which class(es) should be imported based on * the &#123;@link AnnotationMetadata&#125; of the importing @&#123;@link Configuration&#125; class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);&#125; ImportSelector接口的selectImports返回的数组（类的全类名）都会被注册到Spring容器中，所以可以通过这个方法来自定义注册哪些bean 我们来看它是实现这个接口的，可以看到主体逻辑是调用getCandidateConfigurations(annotationMetadata, attributes);获取了list，然后进行去重、排序、筛选排除 123456789101112131415161718192021222324252627@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; try &#123; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); // 获取META-INF/spring.factories配置的类名 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // 去重 configurations = removeDuplicates(configurations); // 排序 configurations = sort(configurations, autoConfigurationMetadata); // 筛选排除 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return configurations.toArray(new String[configurations.size()]); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125;&#125; 进入getCandidateConfigurations(annotationMetadata, attributes)方法，从下面的方法可以看到是读取了META-INF/spring.factories的配置，这个文件配置了哪些类需要被注册为Bean 1234567891011121314151617181920212223242526272829protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations;&#125;public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = classLoader != null ? classLoader.getResources(\"META-INF/spring.factories\") : ClassLoader.getSystemResources(\"META-INF/spring.factories\"); ArrayList result = new ArrayList(); while(urls.hasMoreElements()) &#123; URL url = (URL)urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException var8) &#123; throw new IllegalArgumentException(\"Unable to load [\" + factoryClass.getName() + \"] factories from location [\" + \"META-INF/spring.factories\" + \"]\", var8); &#125;&#125; 查看spring-boot-autoconfigure模块的META-INF/spring.factories文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnClassCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration# Failure analyzersorg.springframework.boot.diagnostics.FailureAnalyzer=\\org.springframework.boot.autoconfigure.diagnostics.analyzer.NoSuchBeanDefinitionFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.DataSourceBeanCreationFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer# Template availability providersorg.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.web.JspTemplateAvailabilityProvider 获取到了哪些Bean需要自动配置，我们来看下是哪里调用了，下图是这个方法的调用链 由上面的调用链可以看到容器执行了refresh()时触发的，这个方法在之前Spring系列有过介绍，现在来回顾一下 进入refresh()方法，可以看到是执行了invokeBeanFactoryPostProcessors(beanFactory)方法 123456789101112131415161718192021222324252627@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 准备刷新的上下文环境，例如对系统属性或者环境变量进行准备及验证 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 初始化BeanFactory，并进行XML文件读取，这一步之后ClassPathXmlApplicationContext实际上就已经包含了BeanFactory所提供的功能 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 进入prepareBeanFactory前，Spring已经完成了对配置的解析，而ApplicationContext在功能上的扩展也由此展开 // 对BeanFactory进行各种功能组件填充 @Qualifier @Autowired这两注解功能组件就是在这步骤中增加的支持 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 子类覆盖方法做额外的处理 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用工厂后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean， // 并调用其postProcessBeanFactory接口方法 invokeBeanFactoryPostProcessors(beanFactory); ... 可以看到是执行了工厂后处理器，根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean，查看invokeBeanDefinitionRegistryPostProcessors()方法是执行了BeanDefinitionRegistryPostProcessor接口postProcessBeanDefinitionRegistry(registry)方法 1234567private static void invokeBeanDefinitionRegistryPostProcessors( Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry) &#123; for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanDefinitionRegistry(registry); &#125;&#125; BeanDefinitionRegistryPostProcessor接口继承了BeanFactoryPostProcessor接口，这里是执行实现了BeanDefinitionRegistryPostProcessor接口Bean的postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry)方法，用于注册bean 其他 使用@Configuration注解的类MyConfig与启动类Application如果不在同一包下,才需要配置spring.factories AopAutoConfiguration 自动配置1234567891011121314151617181920@Configuration@ConditionalOnClass(&#123; EnableAspectJAutoProxy.class, Aspect.class, Advice.class &#125;)@ConditionalOnProperty(prefix = \"spring.aop\", name = \"auto\", havingValue = \"true\", matchIfMissing = true)public class AopAutoConfiguration &#123; @Configuration @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = true) public static class JdkDynamicAutoProxyConfiguration &#123; &#125; @Configuration @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = false) public static class CglibAutoProxyConfiguration &#123; &#125;&#125; CacheAutoConfiguration 自动配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@Configuration@ConditionalOnClass(CacheManager.class)@ConditionalOnBean(CacheAspectSupport.class)@ConditionalOnMissingBean(value = CacheManager.class, name = \"cacheResolver\")@EnableConfigurationProperties(CacheProperties.class)@AutoConfigureBefore(HibernateJpaAutoConfiguration.class)@AutoConfigureAfter(&#123; CouchbaseAutoConfiguration.class, HazelcastAutoConfiguration.class, RedisAutoConfiguration.class &#125;)@Import(CacheConfigurationImportSelector.class)public class CacheAutoConfiguration &#123; static final String VALIDATOR_BEAN_NAME = \"cacheAutoConfigurationValidator\"; @Bean @ConditionalOnMissingBean public CacheManagerCustomizers cacheManagerCustomizers( ObjectProvider&lt;List&lt;CacheManagerCustomizer&lt;?&gt;&gt;&gt; customizers) &#123; return new CacheManagerCustomizers(customizers.getIfAvailable()); &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public static CacheManagerValidatorPostProcessor cacheAutoConfigurationValidatorPostProcessor() &#123; return new CacheManagerValidatorPostProcessor(); &#125; @Bean(name = VALIDATOR_BEAN_NAME) public CacheManagerValidator cacheAutoConfigurationValidator() &#123; return new CacheManagerValidator(); &#125; @Configuration @ConditionalOnClass(LocalContainerEntityManagerFactoryBean.class) @ConditionalOnBean(AbstractEntityManagerFactoryBean.class) protected static class CacheManagerJpaDependencyConfiguration extends EntityManagerFactoryDependsOnPostProcessor &#123; public CacheManagerJpaDependencyConfiguration() &#123; super(\"cacheManager\"); &#125; &#125; /** * &#123;@link BeanFactoryPostProcessor&#125; to ensure that the &#123;@link CacheManagerValidator&#125; * is triggered before &#123;@link CacheAspectSupport&#125; but without causing early * instantiation. */ static class CacheManagerValidatorPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; for (String name : beanFactory.getBeanNamesForType(CacheAspectSupport.class, false, false)) &#123; BeanDefinition definition = beanFactory.getBeanDefinition(name); definition.setDependsOn( append(definition.getDependsOn(), VALIDATOR_BEAN_NAME)); &#125; &#125; private String[] append(String[] array, String value) &#123; String[] result = new String[array == null ? 1 : array.length + 1]; if (array != null) &#123; System.arraycopy(array, 0, result, 0, array.length); &#125; result[result.length - 1] = value; return result; &#125; &#125; /** * Bean used to validate that a CacheManager exists and provide a more meaningful * exception. */ static class CacheManagerValidator &#123; @Autowired private CacheProperties cacheProperties; @Autowired(required = false) private CacheManager cacheManager; @PostConstruct public void checkHasCacheManager() &#123; Assert.notNull(this.cacheManager, \"No cache manager could \" + \"be auto-configured, check your configuration (caching \" + \"type is '\" + this.cacheProperties.getType() + \"')\"); &#125; &#125; /** * &#123;@link ImportSelector&#125; to add &#123;@link CacheType&#125; configuration classes. */ static class CacheConfigurationImportSelector implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; CacheType[] types = CacheType.values(); String[] imports = new String[types.length]; for (int i = 0; i &lt; types.length; i++) &#123; imports[i] = CacheConfigurations.getConfigurationClass(types[i]); &#125; return imports; &#125; &#125;&#125; 总结 Spring Boot实现自动配置是通过@EnableAutoConfiguration及BeanDefinitionRegistryPostProcessor接口来实现的，这个注解使用了@Import注解，@Import用来导入一个或多个类（会被Spring容器管理），或者配置类（配置类里的@Bean标记的类也会被Spring容器管理），有了这个注解我们可以通过添加注解的形式来注册Bean @Import注解一般和ImportSelectors接口搭配使用， 实现了ImportSelectors接口的类通常与常规的@Import注解作用相同，ImportSelector接口的selectImports返回的数组（类的全类名）都会被注册到Spring容器中，所以可以通过这个方法来自定义注册哪些bean，然而，它也可能被延迟处理，直到所有被@Configuration标记的类处理完之后采取处理 Spring Boot 在启动时扫描项目所依赖的 jar 包，寻找包含spring.factories 文件的 jar 包，根据 spring.factories 配置加载 AutoConfigure 类。 在自动配置类AutoConfigure 类下然后将满足条件(@ConditionalOnXxx)的@Bean放入到Spring容器中Spring Context 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(三)下载源码及SpringApplication","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(三)下载源码及SpringApplication","date":"2019-08-05T16:03:00.000Z","updated":"2020-01-04T12:21:52.212Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(三)下载源码及SpringApplication/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(三)下载源码及SpringApplication/","excerpt":"","text":"前言 要研究Spring Boot 就需要下载它的源码，传送门：https://github.com/spring-projects/spring-boot 导入Spring Boot 源码 这里是选用了spring-boot-1.5.6.RELEASE版本与之前写的源码分析章节中spring-framework-4.3.10.RELEASE版本是相对应的，下面是目录结构 下载后执行clean install -Dmaven.test.skip=true命令，然而并不是那么顺利，直接运行会报错，和spring-framework-4.3.10.RELEASE的源码的编译一样还是要改文件才能正常编译 注释下面的依赖，不然会报找不到的错 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot&lt;/artifactId&gt; &lt;type&gt;test-jar&lt;/type&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 注释根pom不必要的模块，不然报错 12&lt;module&gt;spring-boot-test-autoconfigure&lt;/module&gt;&lt;module&gt;spring-boot-devtools&lt;/module&gt; 注释根pom不必要的插件 123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt; &lt;version&gt;2.17&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.puppycrawl.tools&lt;/groupId&gt; &lt;artifactId&gt;checkstyle&lt;/artifactId&gt; &lt;version&gt;7.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; 注释spring-boot-tools模块下的pom.xml的模块，不然报错 12&lt;module&gt;spring-boot-gradle-plugin&lt;/module&gt;&lt;module&gt;spring-boot-maven-plugin&lt;/module&gt; 将一些报错模块测试包Mark Directory as -&gt; Excluded，也可以直接干掉 编译通过之后就可以在本地调spring-boot-samples目录下的示例代码了 解析 查看Spring Boot的示例代码 使用 @SpringBootApplication 注解，标明是 Spring Boot 应用。通过它，可以开启自动配置的功能。 调用 SpringApplication#run(Class&lt;?&gt;... primarySources) 方法，启动 Spring Boot 应用。123456789101112@SpringBootApplicationpublic class SampleTomcatJspApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(SampleTomcatJspApplication.class); &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleTomcatJspApplication.class, args); &#125;&#125; SpringApplication 跟进SpringApplication.run(SampleTomcatJspApplication.class, args)方法，可以看到是调用了SpringApplication的静态方法，最终是创建 SpringApplication 对象并执行public ConfigurableApplicationContext run(String... args)方法 12345678public static ConfigurableApplicationContext run(Object source, String... args) &#123; return run(new Object[] &#123; source &#125;, args);&#125;public static ConfigurableApplicationContext run(Object[] sources, String[] args) &#123; // 创建 SpringApplication 对象，并执行运行。 return new SpringApplication(sources).run(args);&#125; 进入org.springframework.boot.SpringApplication#run(java.lang.String...)方法，可以看到主要逻辑也是构造ApplicationContext容器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Run the Spring application, creating and refreshing a new * &#123;@link ApplicationContext&#125;. * @param args the application arguments (usually passed from a Java main method) * @return a running &#123;@link ApplicationContext&#125; */public ConfigurableApplicationContext run(String... args) &#123; // 创建 StopWatch 对象，并启动。StopWatch 主要用于简单统计 run 启动过程的时长。 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; // 配置 headless 属性，这个逻辑，可以无视，和 AWT 相关。 configureHeadlessProperty(); // 获得 SpringApplicationRunListener 的数组，并启动监听 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; // 创建 ApplicationArguments 对象 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 加载属性配置。执行完成后，所有的 environment 的属性都会加载进来，包括 application.properties 和外部的属性配置。 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); // 打印 Spring Banner Banner printedBanner = printBanner(environment); // 创建 Spring 容器。 context = createApplicationContext(); analyzers = new FailureAnalyzers(context); // 主要是调用所有初始化类的 initialize 方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 初始化 Spring 容器。 refreshContext(context); // 执行 Spring 容器的初始化的后置逻辑 afterRefresh(context, applicationArguments); // 通知 SpringApplicationRunListener 的数组，Spring 容器启动完成 listeners.finished(context, null); // 停止 StopWatch 统计时长 stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; // 如果发生异常，则进行处理，并抛出 IllegalStateException 异常 handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; Print Banner Banner printedBanner = printBanner(environment);用于打印Spring，也可以自己添加banner.txt修改打印 1234567 . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: 进入printBanner(environment)方法可以看到是构造了一个SpringApplicationBannerPrinter对象 123456789101112131415private Banner printBanner(ConfigurableEnvironment environment) &#123; if (this.bannerMode == Banner.Mode.OFF) &#123; return null; &#125; ResourceLoader resourceLoader = this.resourceLoader != null ? this.resourceLoader : new DefaultResourceLoader(getClassLoader()); // 构造SpringApplicationBannerPrinter SpringApplicationBannerPrinter bannerPrinter = new SpringApplicationBannerPrinter( resourceLoader, this.banner); if (this.bannerMode == Mode.LOG) &#123; // 打印在log file中 return bannerPrinter.print(environment, this.mainApplicationClass, logger); &#125; return bannerPrinter.print(environment, this.mainApplicationClass, System.out);&#125; 查看SpringApplicationBannerPrinter 12345678910111213141516171819202122class SpringApplicationBannerPrinter &#123; // 配置该属性用于配置自定义banner的位置 static final String BANNER_LOCATION_PROPERTY = \"banner.location\"; // 图片BANNER_IMAGE? static final String BANNER_IMAGE_LOCATION_PROPERTY = \"banner.image.location\"; // 默认banner的存放位置 static final String DEFAULT_BANNER_LOCATION = \"banner.txt\"; static final String[] IMAGE_EXTENSION = &#123; \"gif\", \"jpg\", \"png\" &#125;; // 默认打印处理类 private static final Banner DEFAULT_BANNER = new SpringBootBanner(); private final ResourceLoader resourceLoader; private final Banner fallbackBanner; SpringApplicationBannerPrinter(ResourceLoader resourceLoader, Banner fallbackBanner) &#123; this.resourceLoader = resourceLoader; this.fallbackBanner = fallbackBanner; &#125; ... SpringBootBanner默认打印处理类，可以看到是直接拼接了一个字符数组然后for 12345678910111213141516171819202122232425262728293031323334353637383940/** * Default Banner implementation which writes the 'Spring' banner. * * @author Phillip Webb */class SpringBootBanner implements Banner &#123; private static final String[] BANNER = &#123; \"\", \" . ____ _ __ _ _\", \" /\\\\\\\\ / ___'_ __ _ _(_)_ __ __ _ \\\\ \\\\ \\\\ \\\\\", \"( ( )\\\\___ | '_ | '_| | '_ \\\\/ _` | \\\\ \\\\ \\\\ \\\\\", \" \\\\\\\\/ ___)| |_)| | | | | || (_| | ) ) ) )\", \" ' |____| .__|_| |_|_| |_\\\\__, | / / / /\", \" =========|_|==============|___/=/_/_/_/\" &#125;; private static final String SPRING_BOOT = \" :: Spring Boot :: \"; private static final int STRAP_LINE_SIZE = 42; @Override public void printBanner(Environment environment, Class&lt;?&gt; sourceClass, PrintStream printStream) &#123; // 循环打印 for (String line : BANNER) &#123; printStream.println(line); &#125; String version = SpringBootVersion.getVersion(); version = (version == null ? \"\" : \" (v\" + version + \")\"); String padding = \"\"; while (padding.length() &lt; STRAP_LINE_SIZE - (version.length() + SPRING_BOOT.length())) &#123; padding += \" \"; &#125; printStream.println(AnsiOutput.toString(AnsiColor.GREEN, SPRING_BOOT, AnsiColor.DEFAULT, padding, AnsiStyle.FAINT, version)); printStream.println(); &#125;&#125; Create ApplicationContext context = createApplicationContext();用于创建ApplicationContext，不同环境会创建不同的 非web环境构造AnnotationConfigApplicationContext web环境构造AnnotationConfigEmbeddedWebApplicationContext 12345678910111213141516171819202122232425262728293031323334/** * 非web环境构造的application context * The class name of application context that will be used by default for non-web * environments. */public static final String DEFAULT_CONTEXT_CLASS = \"org.springframework.context.\" + \"annotation.AnnotationConfigApplicationContext\";/** * web环境构造的application context * The class name of application context that will be used by default for web * environments. */public static final String DEFAULT_WEB_CONTEXT_CLASS = \"org.springframework.\" + \"boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext\";protected ConfigurableApplicationContext createApplicationContext() &#123; // 根据 webApplicationType 类型，获得 ApplicationContext 类型 Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; contextClass = Class.forName(this.webEnvironment ? DEFAULT_WEB_CONTEXT_CLASS : DEFAULT_CONTEXT_CLASS); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Unable create a default ApplicationContext, \" + \"please specify an ApplicationContextClass\", ex); &#125; &#125; // 创建 ApplicationContext 对象 return (ConfigurableApplicationContext) BeanUtils.instantiate(contextClass);&#125; Refresh ApplicationContext refreshContext(context);用于初始化 Spring 容器，可以看到主要逻辑也是调用ApplicationContext的refresh()方法 123456789101112131415161718private void refreshContext(ConfigurableApplicationContext context) &#123; // 开启（刷新）Spring 容器 refresh(context); // 注册 ShutdownHook 钩子 if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException ex) &#123; // Not allowed in some environments. &#125; &#125;&#125;protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext) applicationContext).refresh();&#125; Call Runners afterRefresh(context, applicationArguments);用于执行 Spring 容器的初始化后的后置逻辑，可以看到是执行了ApplicationRunner及CommandLineRunner接口的run方法，如果你想在Spring Boot容器构造完成之后额外做一些事情，可以实现这两个接口来定义 ApplicationRunner中run方法的参数为ApplicationArguments 示例代码：12345678@Component@Order(value = 10)public class AgentApplicationRun2 implements ApplicationRunner &#123; @Override public void run(ApplicationArguments applicationArguments) throws Exception &#123; &#125;&#125; CommandLineRunner接口中run方法的参数为String数组。想要更详细地获取命令行参数，那就使用ApplicationRunner接口 示例代码123456789101112131415161718192021222324252627282930313233343536 @Component @Order(value = 11) public class AgentApplicationRun implements CommandLineRunner &#123; @Override public void run(String... strings) throws Exception &#123; &#125; &#125; ``` * `ApplicationRunner ````javaprotected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) &#123; callRunners(context, args);&#125;private void callRunners(ApplicationContext context, ApplicationArguments args) &#123; // 获得所有 Runner List&lt;Object&gt; runners = new ArrayList&lt;Object&gt;(); // 获得所有 ApplicationRunner Bean runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); // 获得所有 CommandLineRunner Bean runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); // 排序 runners AnnotationAwareOrderComparator.sort(runners); // 遍历 Runner 数组，执行逻辑 for (Object runner : new LinkedHashSet&lt;Object&gt;(runners)) &#123; if (runner instanceof ApplicationRunner) &#123; callRunner((ApplicationRunner) runner, args); &#125; if (runner instanceof CommandLineRunner) &#123; callRunner((CommandLineRunner) runner, args); &#125; &#125;&#125; 总结 Spring Boot启动的过程就是构建ApplicationContext容器的过程，不同环境会创建不同的ApplicationContext，得到ApplicationContext之后就是会refresh(context) 这个过程的细节我们之前的Spring系列已经有所介绍，反正我们能得到的结果就是已经构造了一个可用的容器 非web环境构造AnnotationConfigApplicationContext web环境构造AnnotationConfigEmbeddedWebApplicationContext 参考 芋道源码 http://www.iocoder.cn https://blog.csdn.net/weixin_38362455/article/details/83023025","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(二)构建及配置SpringBoot项目","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(二)构建及配置SpringBoot项目","date":"2019-08-05T16:02:00.000Z","updated":"2019-09-16T13:11:05.627Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(二)构建及配置SpringBoot项目/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(二)构建及配置SpringBoot项目/","excerpt":"","text":"集成Spring boot 构建SpringBoot项目，先配置Maven配置，下面有两种方式 方式一 集成Spring Boot时，官方示例中，都是让我们继承一个Spring的 spring-boot-starter-parent 这个parent，这样就集成了123456789101112&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 方式二 一般情况下，在我们自己的项目中，会定义一下自己的Maven parent 项目，这种情况下，上面的这种做法就行不通了。那么，该如何来做呢？其实，在Spring的官网也给出了变通的方法的，在我们自己 parent 项目中，加下下面的声明： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 请注意，它的 type是pom，scope 是import，这种类型的 dependency 只能在 dependencyManagement 标签中声明，然后，把我们项目中的 子项目 中，parent 的声明，修改为我们自己项目的parent 项目就可以了，比如，我的是： 123456789101112131415161718192021 &lt;parent&gt; &lt;groupId&gt;com.songsy&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-parent&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; ``` * 然后新增一个启动类及配置文件`application.properties`就完成了一个`Boot`项目的构建```java@SpringBootApplicationpublic class SampleTomcatJspApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(SampleTomcatJspApplication.class); &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleTomcatJspApplication.class, args); &#125;&#125; 不同环境不同配置文件 针对各环境新建不同的配置文件 application-dev.properties、application-test.properties、application-prod.properties , 在这三个文件均都设置不同的server.port属性，如：dev环境设置为8080，test环境设置为9090，prod环境设置为80 application.properties中设置spring.profiles.active=dev，就是说默认以dev环境设置 采用命令行的形式 12345执行java -jar xxx.jar，可以观察到服务端口被设置为8080，也就是默认的开发环境（dev）执行java -jar xxx.jar --spring.profiles.active=test，可以观察到服务端口被设置为9090，也就是测试环境的配置（test）执行java -jar xxx.jar --spring.profiles.active=prod，可以观察到服务端口被设置为80，也就是生产环境的配置（prod） 打包 Spring Boot 项目 引入 spring-boot-maven-plugin 插件，执行 mvn clean package 命令，将 Spring Boot 项目打成一个 Fat Jar 。后续，我们就可以直接使用 java -jar 运行。 123456789101112131415&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;useSystemClassLoader&gt;false&lt;/useSystemClassLoader&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 数据文件的加载顺序 在命令行中传入的参数 SPRING_APPLICATION_JSON: 以JSON格式配置在系统环境变量中的内容 java:comp/env 的JNDI属性 Java的系统属性，可以通过System.getProperties() 操作系统的环境变量 通过 random.* 配置的随机属性 位当前jar之外，针对不同{profile}环境的配置文件内容, application-{profile}.yml 位当前jar之内，针对不同{profile}环境的配置文件内容, application-{profile}.yml 位当前jar之外，application.yml 位当前jar之内，application.yml 总结参考 芋道源码 http://www.iocoder.cn 详见： http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#using-boot-maven-without-a-parent 参考： https://blog.csdn.net/rainbow702/article/details/55046298","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"SpringBoot(一)前言","slug":"backend/framework/spring/spring-boot/analysis/SpringBoot(一)前言","date":"2019-08-05T16:01:00.000Z","updated":"2020-01-04T12:21:52.207Z","comments":true,"path":"2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(一)前言/","link":"","permalink":"http://www.songshuiyang.com/2019/08/06/backend/framework/spring/spring-boot/analysis/SpringBoot(一)前言/","excerpt":"","text":"前言 Spring Boot 是 Spring 的子项目，正如其名字，提供 Spring 的引导Boot的功能。 通过 Spring Boot ，我们开发者可以快速配置 Spring 项目，引入各种 Spring MVC、Spring Transaction、Spring AOP、MyBatis 等等框架，而无需不断重复编写繁重的 Spring 配置，降低了 Spring 的使用成本。 核心功能 独立运行的Spring项目,可以以jar包的形式独立运行, 运行一个Spring boot项目只要通过 java -jar xx.jar 内嵌Tomcat, Jetty, Undertow 无需以war包形式部署项目 提供starter简化Maven配置 自动配置Bean, 极大的减少了我们要使用的配置 优点 快速构建项目 对主流开发框架的无配置集成 项目可独立运行 提供运行时的应用监控 Starter POMs Starter 主要用来简化依赖用的，Spring Boot 通过starter依赖为项目的依赖管理提供帮助.starter依赖起始就是特殊的maven依赖,利用了传递依赖解析,把常用库聚合在一起,组成了几个为特定功能而定制的依赖. 所有的starters遵循一个相似的命名模式：spring-boot-starter-，在这里是一种特殊类型的应用程序。eg: 名称 描述 spring-boot-starter 对自动配置、日志记录和YAML支持，核心starter spring-boot-starter-thymeleaf 对Thymeleaf模板引擎的支持，Spring mvc的集成 spring-boot-starter-web 对web支持，包括RESTful，使用tomcat作为默认容器 spring-boot-starter-data-jpa 对jpa支持 总结参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.songshuiyang.com/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://www.songshuiyang.com/tags/Spring-Boot/"}]},{"title":"Spring Mvc源码(十)RequestBody注解解析之RequestResponseBodyMethodProcessor","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(十)RequestBody注解解析之RequestResponseBodyMethodProcessor","date":"2019-08-02T16:10:00.000Z","updated":"2020-01-04T12:21:52.236Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(十)RequestBody注解解析之RequestResponseBodyMethodProcessor/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(十)RequestBody注解解析之RequestResponseBodyMethodProcessor/","excerpt":"","text":"1.1 前言 RequestResponseBodyMethodProcessor 的作用是处理被@RequestBody注解的参数，和@ResponseBody注解的返回值 查看RequestResponseBodyMethodProcessor继承关系，可以看到它是同时继承了HandlerMethodArgumentResolver和HandlerMethodReturnValueHandler，所以就是说它同时具有参数对象解析及结果对象解析的功能，野心很大 2.1 解析 RequestResponseBodyMethodProcessor.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177/** * 处理被@RequestBody注解的参数，和@ResponseBody注解的返回值 * * Resolves method arguments annotated with &#123;@code @RequestBody&#125; and handles return * values from methods annotated with &#123;@code @ResponseBody&#125; by reading and writing * to the body of the request or response with an &#123;@link HttpMessageConverter&#125;. * * &lt;p&gt;An &#123;@code @RequestBody&#125; method argument is also validated if it is annotated * with &#123;@code @javax.validation.Valid&#125;. In case of validation failure, * &#123;@link MethodArgumentNotValidException&#125; is raised and results in an HTTP 400 * response status code if &#123;@link DefaultHandlerExceptionResolver&#125; is configured. * * @author Arjen Poutsma * @author Rossen Stoyanchev * @author Juergen Hoeller * @since 3.1 */public class RequestResponseBodyMethodProcessor extends AbstractMessageConverterMethodProcessor &#123; /** * Basic constructor with converters only. Suitable for resolving * &#123;@code @RequestBody&#125;. For handling &#123;@code @ResponseBody&#125; consider also * providing a &#123;@code ContentNegotiationManager&#125;. */ public RequestResponseBodyMethodProcessor(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; super(converters); &#125; /** * Basic constructor with converters and &#123;@code ContentNegotiationManager&#125;. * Suitable for resolving &#123;@code @RequestBody&#125; and handling * &#123;@code @ResponseBody&#125; without &#123;@code Request~&#125; or * &#123;@code ResponseBodyAdvice&#125;. */ public RequestResponseBodyMethodProcessor(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters, ContentNegotiationManager manager) &#123; super(converters, manager); &#125; /** * Complete constructor for resolving &#123;@code @RequestBody&#125; method arguments. * For handling &#123;@code @ResponseBody&#125; consider also providing a * &#123;@code ContentNegotiationManager&#125;. * @since 4.2 */ public RequestResponseBodyMethodProcessor(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters, List&lt;Object&gt; requestResponseBodyAdvice) &#123; super(converters, null, requestResponseBodyAdvice); &#125; /** * Complete constructor for resolving &#123;@code @RequestBody&#125; and handling * &#123;@code @ResponseBody&#125;. */ public RequestResponseBodyMethodProcessor(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters, ContentNegotiationManager manager, List&lt;Object&gt; requestResponseBodyAdvice) &#123; super(converters, manager, requestResponseBodyAdvice); &#125; /** * 检测参数是否使用了@RequestBody注解 * * @param parameter the method parameter to check * @return */ @Override public boolean supportsParameter(MethodParameter parameter) &#123; return parameter.hasParameterAnnotation(RequestBody.class); &#125; /** * 检测返回结果是否使用了@ResponseBody注解 * * @param returnType the method return type to check * @return */ @Override public boolean supportsReturnType(MethodParameter returnType) &#123; return (AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ResponseBody.class) || returnType.hasMethodAnnotation(ResponseBody.class)); &#125; /** * 处理被@RequestBody注解的参数 * * Throws MethodArgumentNotValidException if validation fails. * @throws HttpMessageNotReadableException if &#123;@link RequestBody#required()&#125; * is &#123;@code true&#125; and there is no body content or if there is no suitable * converter to read the content with. */ @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; parameter = parameter.nestedIfOptional(); Object arg = readWithMessageConverters(webRequest, parameter, parameter.getNestedGenericParameterType()); String name = Conventions.getVariableNameForParameter(parameter); WebDataBinder binder = binderFactory.createBinder(webRequest, arg, name); if (arg != null) &#123; validateIfApplicable(binder, parameter); if (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) &#123; throw new MethodArgumentNotValidException(parameter, binder.getBindingResult()); &#125; &#125; mavContainer.addAttribute(BindingResult.MODEL_KEY_PREFIX + name, binder.getBindingResult()); return adaptArgumentIfNecessary(arg, parameter); &#125; /** * * @param webRequest the current request * @param parameter the method parameter descriptor (may be &#123;@code null&#125;) * @param paramType the type of the argument value to be created * @param &lt;T&gt; * @return * @throws IOException * @throws HttpMediaTypeNotSupportedException * @throws HttpMessageNotReadableException */ @Override protected &lt;T&gt; Object readWithMessageConverters(NativeWebRequest webRequest, MethodParameter parameter, Type paramType) throws IOException, HttpMediaTypeNotSupportedException, HttpMessageNotReadableException &#123; HttpServletRequest servletRequest = webRequest.getNativeRequest(HttpServletRequest.class); ServletServerHttpRequest inputMessage = new ServletServerHttpRequest(servletRequest); Object arg = readWithMessageConverters(inputMessage, parameter, paramType); if (arg == null) &#123; if (checkRequired(parameter)) &#123; throw new HttpMessageNotReadableException(\"Required request body is missing: \" + parameter.getMethod().toGenericString()); &#125; &#125; return arg; &#125; /** * 检查RequestBody注解是否required * @param parameter * @return */ protected boolean checkRequired(MethodParameter parameter) &#123; return (parameter.getParameterAnnotation(RequestBody.class).required() &amp;&amp; !parameter.isOptional()); &#125; /** * 处理@ResponseBody注解的返回值 * * @param returnValue the value returned from the handler method * @param returnType the type of the return value. This type must have * previously been passed to &#123;@link #supportsReturnType&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @throws IOException * @throws HttpMediaTypeNotAcceptableException * @throws HttpMessageNotWritableException */ @Override public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123; mavContainer.setRequestHandled(true); ServletServerHttpRequest inputMessage = createInputMessage(webRequest); ServletServerHttpResponse outputMessage = createOutputMessage(webRequest); // Try even with null return value. ResponseBodyAdvice could get involved. writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage); &#125;&#125; 2.1.1 处理被@RequestBody注解的参数解析 参数解析需要关注此类是怎么实现的HandlerMethodArgumentResolver接口的 12345678910111213141516171819202122232425262728293031323334public interface HandlerMethodArgumentResolver &#123; /** * 是否支持 * * Whether the given &#123;@linkplain MethodParameter method parameter&#125; is * supported by this resolver. * @param parameter the method parameter to check * @return &#123;@code true&#125; if this resolver supports the supplied parameter; * &#123;@code false&#125; otherwise */ boolean supportsParameter(MethodParameter parameter); /** * 根据request解析方法参数值 * * Resolves a method parameter into an argument value from a given request. * A &#123;@link ModelAndViewContainer&#125; provides access to the model for the * request. A &#123;@link WebDataBinderFactory&#125; provides a way to create * a &#123;@link WebDataBinder&#125; instance when needed for data binding and * type conversion purposes. * @param parameter the method parameter to resolve. This parameter must * have previously been passed to &#123;@link #supportsParameter&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @param binderFactory a factory for creating &#123;@link WebDataBinder&#125; instances * @return the resolved argument value, or &#123;@code null&#125; * @throws Exception in case of errors with the preparation of argument values */ Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception;&#125; 查看boolean supportsParameter(MethodParameter parameter);方法的实现，实现很简单就是判断是否使用了@RequestBody注解 12345678910/** * 检测参数是否使用了@RequestBody注解 * * @param parameter the method parameter to check * @return */@Overridepublic boolean supportsParameter(MethodParameter parameter) &#123; return parameter.hasParameterAnnotation(RequestBody.class);&#125; 查看public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) 方法的实现 123456789101112131415161718192021222324252627/** * 处理被@RequestBody注解的参数 * * Throws MethodArgumentNotValidException if validation fails. * @throws HttpMessageNotReadableException if &#123;@link RequestBody#required()&#125; * is &#123;@code true&#125; and there is no body content or if there is no suitable * converter to read the content with. */@Overridepublic Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; parameter = parameter.nestedIfOptional(); // 主体逻辑 Object arg = readWithMessageConverters(webRequest, parameter, parameter.getNestedGenericParameterType()); String name = Conventions.getVariableNameForParameter(parameter); WebDataBinder binder = binderFactory.createBinder(webRequest, arg, name); if (arg != null) &#123; // 校验参数是否正确 @Valid注解开启 validateIfApplicable(binder, parameter); if (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) &#123; throw new MethodArgumentNotValidException(parameter, binder.getBindingResult()); &#125; &#125; mavContainer.addAttribute(BindingResult.MODEL_KEY_PREFIX + name, binder.getBindingResult()); return adaptArgumentIfNecessary(arg, parameter);&#125; 进入Object arg = readWithMessageConverters(webRequest, parameter, parameter.getNestedGenericParameterType()); 12345678910111213141516@Overrideprotected &lt;T&gt; Object readWithMessageConverters(NativeWebRequest webRequest, MethodParameter parameter, Type paramType) throws IOException, HttpMediaTypeNotSupportedException, HttpMessageNotReadableException &#123; HttpServletRequest servletRequest = webRequest.getNativeRequest(HttpServletRequest.class); ServletServerHttpRequest inputMessage = new ServletServerHttpRequest(servletRequest); // 主体逻辑 Object arg = readWithMessageConverters(inputMessage, parameter, paramType); if (arg == null) &#123; if (checkRequired(parameter)) &#123; throw new HttpMessageNotReadableException(\"Required request body is missing: \" + parameter.getMethod().toGenericString()); &#125; &#125; return arg;&#125; 继续进入Object arg = readWithMessageConverters(inputMessage, parameter, paramType); ，可以看到是遍历 this.messageConverters ，通过canRead方法判断转换器是否支持对参数的转换，然后执行read方法完成转换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * Create the method argument value of the expected parameter type by reading * from the given HttpInputMessage. * @param &lt;T&gt; the expected type of the argument value to be created * @param inputMessage the HTTP input message representing the current request * @param parameter the method parameter descriptor (may be &#123;@code null&#125;) * @param targetType the target type, not necessarily the same as the method * parameter type, e.g. for &#123;@code HttpEntity&lt;String&gt;&#125;. * @return the created method argument value * @throws IOException if the reading from the request fails * @throws HttpMediaTypeNotSupportedException if no suitable message converter is found */@SuppressWarnings(\"unchecked\")protected &lt;T&gt; Object readWithMessageConverters(HttpInputMessage inputMessage, MethodParameter parameter, Type targetType) throws IOException, HttpMediaTypeNotSupportedException, HttpMessageNotReadableException &#123; MediaType contentType; boolean noContentType = false; try &#123; contentType = inputMessage.getHeaders().getContentType(); &#125; catch (InvalidMediaTypeException ex) &#123; throw new HttpMediaTypeNotSupportedException(ex.getMessage()); &#125; if (contentType == null) &#123; noContentType = true; contentType = MediaType.APPLICATION_OCTET_STREAM; &#125; Class&lt;?&gt; contextClass = (parameter != null ? parameter.getContainingClass() : null); Class&lt;T&gt; targetClass = (targetType instanceof Class ? (Class&lt;T&gt;) targetType : null); if (targetClass == null) &#123; ResolvableType resolvableType = (parameter != null ? ResolvableType.forMethodParameter(parameter) : ResolvableType.forType(targetType)); targetClass = (Class&lt;T&gt;) resolvableType.resolve(); &#125; HttpMethod httpMethod = ((HttpRequest) inputMessage).getMethod(); Object body = NO_VALUE; try &#123; inputMessage = new EmptyBodyCheckingHttpInputMessage(inputMessage); // 遍历 this.messageConverters 选择适合的消息处理器来处理参数 for (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) &#123; Class&lt;HttpMessageConverter&lt;?&gt;&gt; converterType = (Class&lt;HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(); if (converter instanceof GenericHttpMessageConverter) &#123; GenericHttpMessageConverter&lt;?&gt; genericConverter = (GenericHttpMessageConverter&lt;?&gt;) converter; // 判断是否适合处理参数 if (genericConverter.canRead(targetType, contextClass, contentType)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Read [\" + targetType + \"] as \\\"\" + contentType + \"\\\" with [\" + converter + \"]\"); &#125; if (inputMessage.getBody() != null) &#123; inputMessage = getAdvice().beforeBodyRead(inputMessage, parameter, targetType, converterType); body = genericConverter.read(targetType, contextClass, inputMessage); body = getAdvice().afterBodyRead(body, inputMessage, parameter, targetType, converterType); &#125; else &#123; body = getAdvice().handleEmptyBody(null, inputMessage, parameter, targetType, converterType); &#125; break; &#125; &#125; else if (targetClass != null) &#123; if (converter.canRead(targetClass, contentType)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Read [\" + targetType + \"] as \\\"\" + contentType + \"\\\" with [\" + converter + \"]\"); &#125; if (inputMessage.getBody() != null) &#123; inputMessage = getAdvice().beforeBodyRead(inputMessage, parameter, targetType, converterType); body = ((HttpMessageConverter&lt;T&gt;) converter).read(targetClass, inputMessage); body = getAdvice().afterBodyRead(body, inputMessage, parameter, targetType, converterType); &#125; else &#123; body = getAdvice().handleEmptyBody(null, inputMessage, parameter, targetType, converterType); &#125; break; &#125; &#125; &#125; &#125; catch (IOException ex) &#123; throw new HttpMessageNotReadableException(\"I/O error while reading input message\", ex); &#125; if (body == NO_VALUE) &#123; if (httpMethod == null || !SUPPORTED_METHODS.contains(httpMethod) || (noContentType &amp;&amp; inputMessage.getBody() == null)) &#123; return null; &#125; throw new HttpMediaTypeNotSupportedException(contentType, this.allSupportedMediaTypes); &#125; return body;&#125; 查看this.messageConverters有哪些呢？见下图 下图是主要MessageConverter的功能介绍 2.1.2 处理被@ResponseBody注解的返回值解析 返回值解析需要关注此类是怎样实现HandlerMethodArgumentResolver接口的方法的 1234567891011121314151617181920212223242526272829303132public interface HandlerMethodReturnValueHandler &#123; /** * 是否支持 * * Whether the given &#123;@linkplain MethodParameter method return type&#125; is * supported by this handler. * @param returnType the method return type to check * @return &#123;@code true&#125; if this handler supports the supplied return type; * &#123;@code false&#125; otherwise */ boolean supportsReturnType(MethodParameter returnType); /** * 处理结果集 * * Handle the given return value by adding attributes to the model and * setting a view or setting the * &#123;@link ModelAndViewContainer#setRequestHandled&#125; flag to &#123;@code true&#125; * to indicate the response has been handled directly. * @param returnValue the value returned from the handler method * @param returnType the type of the return value. This type must have * previously been passed to &#123;@link #supportsReturnType&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @throws Exception if the return value handling results in an error */ void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception;&#125; 查看boolean supportsReturnType(MethodParameter returnType);的方法的实现，实现也很简单就是判断是否使用了@ResponseBody注解 1234567891011/** * 检测返回结果是否使用了@ResponseBody注解 * * @param returnType the method return type to check * @return */@Overridepublic boolean supportsReturnType(MethodParameter returnType) &#123; return (AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ResponseBody.class) || returnType.hasMethodAnnotation(ResponseBody.class));&#125; 查看public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest)的实现123456789101112131415161718192021222324/** * 处理@ResponseBody注解的返回值 * * @param returnValue the value returned from the handler method * @param returnType the type of the return value. This type must have * previously been passed to &#123;@link #supportsReturnType&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @throws IOException * @throws HttpMediaTypeNotAcceptableException * @throws HttpMessageNotWritableException */@Overridepublic void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123; mavContainer.setRequestHandled(true); ServletServerHttpRequest inputMessage = createInputMessage(webRequest); ServletServerHttpResponse outputMessage = createOutputMessage(webRequest); // Try even with null return value. ResponseBodyAdvice could get involved. writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage);&#125; 2.1.3 HttpMessageConverter HttpMessageConverter接口定义了5个方法，用于将HTTP请求报文转换为Java对象，以及将Java对象转换为HTTP响应报文。 对应到SpringMVC的Controller方法，read方法即是读取HTTP请求转换为参数对象，write方法即是将返回值对象转换为HTTP响应报文。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * Strategy interface that specifies a converter that can convert from and to HTTP requests and responses. * * @author Arjen Poutsma * @author Juergen Hoeller * @since 3.0 */public interface HttpMessageConverter&lt;T&gt; &#123; /** * 当前转换器是否能将HTTP报文转换为对象类型 * * Indicates whether the given class can be read by this converter. * @param clazz the class to test for readability * @param mediaType the media type to read (can be &#123;@code null&#125; if not specified); * typically the value of a &#123;@code Content-Type&#125; header. * @return &#123;@code true&#125; if readable; &#123;@code false&#125; otherwise */ boolean canRead(Class&lt;?&gt; clazz, MediaType mediaType); /** * 当前转换器是否能将对象类型转换为HTTP报文 * * Indicates whether the given class can be written by this converter. * @param clazz the class to test for writability * @param mediaType the media type to write (can be &#123;@code null&#125; if not specified); * typically the value of an &#123;@code Accept&#125; header. * @return &#123;@code true&#125; if writable; &#123;@code false&#125; otherwise */ boolean canWrite(Class&lt;?&gt; clazz, MediaType mediaType); /** * 转换器能支持的HTTP媒体类型 * * Return the list of &#123;@link MediaType&#125; objects supported by this converter. * @return the list of supported media types */ List&lt;MediaType&gt; getSupportedMediaTypes(); /** * 转换HTTP报文为特定类型 * * Read an object of the given type from the given input message, and returns it. * @param clazz the type of object to return. This type must have previously been passed to the * &#123;@link #canRead canRead&#125; method of this interface, which must have returned &#123;@code true&#125;. * @param inputMessage the HTTP input message to read from * @return the converted object * @throws IOException in case of I/O errors * @throws HttpMessageNotReadableException in case of conversion errors */ T read(Class&lt;? extends T&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException; /** * 将特定类型对象转换为HTTP报文 * * Write an given object to the given output message. * @param t the object to write to the output message. The type of this object must have previously been * passed to the &#123;@link #canWrite canWrite&#125; method of this interface, which must have returned &#123;@code true&#125;. * @param contentType the content type to use when writing. May be &#123;@code null&#125; to indicate that the * default content type of the converter must be used. If not &#123;@code null&#125;, this media type must have * previously been passed to the &#123;@link #canWrite canWrite&#125; method of this interface, which must have * returned &#123;@code true&#125;. * @param outputMessage the message to write to * @throws IOException in case of I/O errors * @throws HttpMessageNotWritableException in case of conversion errors */ void write(T t, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException;&#125; Spring MVC定义了两个接口来操作这两个过程，参数解析器和返回值处理器在底层处理时，都是通过HttpMessageConverter进行转换。流程如下： 参数解析器HandlerMethodArgumentResolver 返回值处理器HandlerMethodReturnValueHandler 下图是HttpMessageConverter的工作流程图 在Spring mvc启动时默认会加载下面的几种HttpMessageConverter，相关代码在org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport中的addDefaultHttpMessageConverters 123456789101112131415161718192021222324252627282930313233343536/** * Adds a set of default HttpMessageConverter instances to the given list. * Subclasses can call this method from &#123;@link #configureMessageConverters(List)&#125;. * @param messageConverters the list to add the default message converters to */protected final void addDefaultHttpMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters) &#123; StringHttpMessageConverter stringConverter = new StringHttpMessageConverter(); stringConverter.setWriteAcceptCharset(false); messageConverters.add(new ByteArrayHttpMessageConverter()); messageConverters.add(stringConverter); messageConverters.add(new ResourceHttpMessageConverter()); messageConverters.add(new SourceHttpMessageConverter&lt;Source&gt;()); messageConverters.add(new AllEncompassingFormHttpMessageConverter()); if (romePresent) &#123; messageConverters.add(new AtomFeedHttpMessageConverter()); messageConverters.add(new RssChannelHttpMessageConverter()); &#125; if (jackson2XmlPresent) &#123; ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.xml().applicationContext(this.applicationContext).build(); messageConverters.add(new MappingJackson2XmlHttpMessageConverter(objectMapper)); &#125; else if (jaxb2Present) &#123; messageConverters.add(new Jaxb2RootElementHttpMessageConverter()); &#125; if (jackson2Present) &#123; ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json().applicationContext(this.applicationContext).build(); messageConverters.add(new MappingJackson2HttpMessageConverter(objectMapper)); &#125; else if (gsonPresent) &#123; messageConverters.add(new GsonHttpMessageConverter()); &#125;&#125; 3.1 总结 我们知道，Http请求和响应报文本质上都是一串字符串，当请求报文来到Java世界，它会被封装成为一个ServletInputStream的输入流，供我们读取报文。响应报文则是通过一个ServletOutputStream的输出流，来输出响应报文，我们得到输入输出流之后需要把它转成我们的Java实体类对象，这个是怎样转换的呢，就是通过我们的HttpMessageConverter消息转换器来实现的 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html https://my.oschina.net/lichhao/blog/172562 http://www.chinacion.cn/article/608.html","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(九)方法参数解析器HandlerMethodArgumentResolver","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(九)方法参数解析器HandlerMethodArgumentResolver","date":"2019-08-02T16:09:00.000Z","updated":"2019-09-16T13:11:06.116Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(九)方法参数解析器HandlerMethodArgumentResolver/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(九)方法参数解析器HandlerMethodArgumentResolver/","excerpt":"","text":"1.1 前言 回顾上一章节的方法参数解析器的入口，可以看到Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);这行代码是获取方法参数值，这里是返回的是个数组， getMethodArgumentValues(request, mavContainer, providedArgs)里面的逻辑就是遍历每一个参数进行解析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// org.springframework.web.method.support.InvocableHandlerMethod#invokeForRequestpublic Object invokeForRequest(NativeWebRequest request, org.springframework.web.method.support.ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; // 1、这里得到了方法参数值 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &#123; logger.trace(\"Invoking '\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"' with arguments \" + Arrays.toString(args)); &#125; // 2、传入方法参数值并执行方法 Object returnValue = doInvoke(args); if (logger.isTraceEnabled()) &#123; logger.trace(\"Method [\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"] returned [\" + returnValue + \"]\"); &#125; // 3、返回结果 return returnValue;&#125;/** * 根据当前请求获取方法的请求参数 * Get the method argument values for the current request. * 先是判断相应类型的参数已经在providedArgs中提供了，如果有的话就是直接返回，否则则使用argumentResolvers解析 * */private Object[] getMethodArgumentValues(NativeWebRequest request, org.springframework.web.method.support.ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; // 获取方法的参数，在HanderMethod中 MethodParameter[] parameters = getMethodParameters(); // 用于保存解析出参数的值 Object[] args = new Object[parameters.length]; // 遍历每一个参数进行解析 for (int i = 0; i &lt; parameters.length; i++) &#123; MethodParameter parameter = parameters[i]; // 给Parameter设置参数名解析器 parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); // 如果相应类型的参数已经在providedArgs中提供了，则直接设置到parameter args[i] = resolveProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; if (this.argumentResolvers.supportsParameter(parameter)) &#123; try &#123; // 使用argumentResolvers解析参数 args[i] = this.argumentResolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); continue; &#125; catch (Exception ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(getArgumentResolutionErrorMessage(\"Failed to resolve\", i), ex); &#125; throw ex; &#125; &#125; // 解析不出来，抛异常 if (args[i] == null) &#123; throw new IllegalStateException(\"Could not resolve method parameter at index \" + parameter.getParameterIndex() + \" in \" + parameter.getMethod().toGenericString() + \": \" + getArgumentResolutionErrorMessage(\"No suitable resolver for\", i)); &#125; &#125; return args;&#125; Spring Mvc的方法参数解析是交给HandlerMethodArgumentResolver来实现的，由下面可以看到是这个接口就两个方法，第一个方法是判断解析器是否支持该参数，第二个方法是根据request并将http的请求参数解析为Java Bean 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 方法参数解析器 * * Strategy interface for resolving method parameters into argument values in * the context of a given request. * * @author Arjen Poutsma * @since 3.1 * @see HandlerMethodReturnValueHandler */public interface HandlerMethodArgumentResolver &#123; /** * 是否支持 * * Whether the given &#123;@linkplain MethodParameter method parameter&#125; is * supported by this resolver. * @param parameter the method parameter to check * @return &#123;@code true&#125; if this resolver supports the supplied parameter; * &#123;@code false&#125; otherwise */ boolean supportsParameter(MethodParameter parameter); /** * 根据request解析方法参数值 * * Resolves a method parameter into an argument value from a given request. * A &#123;@link ModelAndViewContainer&#125; provides access to the model for the * request. A &#123;@link WebDataBinderFactory&#125; provides a way to create * a &#123;@link WebDataBinder&#125; instance when needed for data binding and * type conversion purposes. * @param parameter the method parameter to resolve. This parameter must * have previously been passed to &#123;@link #supportsParameter&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @param binderFactory a factory for creating &#123;@link WebDataBinder&#125; instances * @return the resolved argument value, or &#123;@code null&#125; * @throws Exception in case of errors with the preparation of argument values */ Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception;&#125; 通过调试可以看到有下面这些argumentResolvers，看类名称是不是很熟悉，就是我们平常使用的@RequestBody @RequestParam 是一一对应的，还是专人做专事，可以得出不同的参数是有不同的参数解析组件来专门处理的 下面来看主要XXXArgumentResolver的作用 123456789101112131415161. SessionAttributeMethodArgumentResolver 针对 被 @SessionAttribute 修饰的参数起作用, 参数的获取一般通过 HttpServletRequest.getAttribute(name, RequestAttributes.SCOPE_SESSION) 2. RequestParamMethodArgumentResolver 针对被 @RequestParam 注解修饰, 但类型不是 Map, 或类型是 Map, 并且 @RequestParam 中指定 name, 一般通过 MultipartHttpServletRequest | HttpServletRequest 获取数据3. RequestHeaderMethodArgumentResolver 针对 参数被 RequestHeader 注解, 并且 参数不是 Map 类型, 数据通过 HttpServletRequest.getHeaderValues(name) 获取4. RequestAttributeMethodArgumentResolver 针对 被 @RequestAttribute 修饰的参数起作用, 参数的获取一般通过 HttpServletRequest.getAttribute(name, RequestAttributes.SCOPE_REQUEST)5. PathVariableMethodArgumentResolver 解决被注解 @PathVariable 注释的参数 &lt;- 这个注解对应的是 uri 中的数据, 在解析 URI 中已经进行解析好了 &lt;- 在 RequestMappingInfoHandlerMapping.handleMatch -&gt; getPathMatcher().extractUriTemplateVariables6. MatrixVariableMethodArgumentResolver 针对被 @MatrixVariable 注解修饰的参数起作用, 从 HttpServletRequest 中获取去除 ; 的 URI Template Variables 获取数据7. ExpressionValueMethodArgumentResolver 针对被 @Value 修饰, 返回 ExpressionValueNamedValueInfo8. ServletCookieValueMethodArgumentResolver 针对被 @CookieValue 修饰, 通过 HttpServletRequest.getCookies 获取对应数据 2.1 解析2.1.1 PathVariableMethodArgumentResolver 这个ArgumentResolver解析类是解析被注解 @PathVariable 注释的参数，这个注解会把url上面的值解析到对应的方法参数上，比如下面的例子，参数id会解析为1，参数name会解析为name 12345678// http://127.0.0.1/user/view/1/songsy@GetMapping(\"/view/&#123;id&#125;/&#123;name&#125;\")public ResponseMO view(@PathVariable Integer id, @PathVariable String name) &#123; IUser iUser = userService.selectByPrimaryKey(id); iUser.setUsername(name); return success(iUser);&#125; 下面来看Spring MVC是怎样把url上面的值解析到对应的方法参数上，首先要获取url上面的值，那么是在哪里获取的呢？，回顾之前的org.springframework.web.servlet.handler.AbstractHandlerMethodMapping#lookupHandlerMethod方法，这个方法是查找当前request请求 最为匹配的处理方法HandlerMethod，如果有多个匹配结果，则选择最佳匹配结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 查找当前request请求 最为匹配的处理方法HandlerMethod，如果有多个匹配结果，则选择最佳匹配结果 * * Look up the best-matching handler method for the current request. * If multiple matches are found, the best match is selected. * @param lookupPath mapping lookup path within the current servlet mapping * @param request the current request * @return the best-matching handler method, or &#123;@code null&#125; if no match * @see #handleMatch(Object, String, HttpServletRequest) * @see #handleNoMatch(Set, String, HttpServletRequest) */protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches = new ArrayList&lt;Match&gt;(); // 根据URL来获取,springMVC会在初始化的时候建立URL和相应RequestMappingInfo的映射。如果不是restful接口，这里就可以直接获取到了 List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath); if (directPathMatches != null) &#123; // 匹配校验 根据directPathMatches获取到List&lt;Match&gt; matches中 addMatchingMappings(directPathMatches, matches, request); &#125; if (matches.isEmpty()) &#123; // 全盘扫描 // No choice but to go through all mappings... addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request); &#125; // 得到匹配结果 if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); Collections.sort(matches, comparator); if (logger.isTraceEnabled()) &#123; logger.trace(\"Found \" + matches.size() + \" matching mapping(s) for [\" + lookupPath + \"] : \" + matches); &#125; Match bestMatch = matches.get(0); if (matches.size() &gt; 1) &#123; if (CorsUtils.isPreFlightRequest(request)) &#123; return PREFLIGHT_AMBIGUOUS_MATCH; &#125; Match secondBestMatch = matches.get(1); // 如果最佳匹配 第二佳匹配都是同一个则报错 if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123; Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException(\"Ambiguous handler methods mapped for HTTP path '\" + request.getRequestURL() + \"': &#123;\" + m1 + \", \" + m2 + \"&#125;\"); &#125; &#125; // 设置HttpServletRequest值 如解析url上的属性值 handleMatch(bestMatch.mapping, lookupPath, request); return bestMatch.handlerMethod; &#125; else &#123; // 没有找到匹配，返回null return handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request); &#125;&#125; 关注handleMatch(bestMatch.mapping, lookupPath, request);方法，看注释可以看到是Expose URI template variables，这里主要是对HttpServletRequest进行setAttribute 12345678910111213141516171819202122232425262728293031323334353637383940/** * Expose URI template variables, matrix variables, and producible media types in the request. * @see HandlerMapping#URI_TEMPLATE_VARIABLES_ATTRIBUTE * @see HandlerMapping#MATRIX_VARIABLES_ATTRIBUTE * @see HandlerMapping#PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE */@Overrideprotected void handleMatch(RequestMappingInfo info, String lookupPath, HttpServletRequest request) &#123; super.handleMatch(info, lookupPath, request); String bestPattern; Map&lt;String, String&gt; uriVariables; Map&lt;String, String&gt; decodedUriVariables; Set&lt;String&gt; patterns = info.getPatternsCondition().getPatterns(); if (patterns.isEmpty()) &#123; bestPattern = lookupPath; uriVariables = Collections.emptyMap(); decodedUriVariables = Collections.emptyMap(); &#125; else &#123; bestPattern = patterns.iterator().next(); // 获取url上的参数值 uriVariables = getPathMatcher().extractUriTemplateVariables(bestPattern, lookupPath); decodedUriVariables = getUrlPathHelper().decodePathVariables(request, uriVariables); &#125; request.setAttribute(BEST_MATCHING_PATTERN_ATTRIBUTE, bestPattern); request.setAttribute(HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE, decodedUriVariables); if (isMatrixVariableContentAvailable()) &#123; Map&lt;String, MultiValueMap&lt;String, String&gt;&gt; matrixVars = extractMatrixVariables(request, uriVariables); request.setAttribute(HandlerMapping.MATRIX_VARIABLES_ATTRIBUTE, matrixVars); &#125; if (!info.getProducesCondition().getProducibleMediaTypes().isEmpty()) &#123; Set&lt;MediaType&gt; mediaTypes = info.getProducesCondition().getProducibleMediaTypes(); request.setAttribute(PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE, mediaTypes); &#125;&#125; 注意下面这个方法，可以看到是获取了url上面的参数值封装为Map&lt;String, String&gt;并赋值到request中 123456789101112Map&lt;String, String&gt; uriVariables;Map&lt;String, String&gt; decodedUriVariables;...// 获取url上的参数值uriVariables = getPathMatcher().extractUriTemplateVariables(bestPattern, lookupPath);decodedUriVariables = getUrlPathHelper().decodePathVariables(request, uriVariables);... request.setAttribute(HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE, decodedUriVariables); 到这里HttpServletRequest已经有参数值了，现在是如何赋值到对应的参数中，这里我们的PathVariableMethodArgumentResolver就发挥作用了 我们关注它是怎么实现HandlerMethodArgumentResolver接口的两个方法的 supportsParameter()方法 代码如下，可以看到是看参数值有没有被PathVariable注解修饰1234567891011@Overridepublic boolean supportsParameter(MethodParameter parameter) &#123; if (!parameter.hasParameterAnnotation(PathVariable.class)) &#123; return false; &#125; if (Map.class.isAssignableFrom(parameter.nestedIfOptional().getNestedParameterType())) &#123; String paramName = parameter.getParameterAnnotation(PathVariable.class).value(); return StringUtils.hasText(paramName); &#125; return true;&#125; resolveArgument()方法 代码如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Overridepublic final Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; NamedValueInfo namedValueInfo = getNamedValueInfo(parameter); MethodParameter nestedParameter = parameter.nestedIfOptional(); // 获取参数名 Object resolvedName = resolveStringValue(namedValueInfo.name); if (resolvedName == null) &#123; throw new IllegalArgumentException( \"Specified name must not resolve to null: [\" + namedValueInfo.name + \"]\"); &#125; // 根据参数名获取参数值 Object arg = resolveName(resolvedName.toString(), nestedParameter, webRequest); if (arg == null) &#123; if (namedValueInfo.defaultValue != null) &#123; arg = resolveStringValue(namedValueInfo.defaultValue); &#125; else if (namedValueInfo.required &amp;&amp; !nestedParameter.isOptional()) &#123; handleMissingValue(namedValueInfo.name, nestedParameter, webRequest); &#125; arg = handleNullValue(namedValueInfo.name, arg, nestedParameter.getNestedParameterType()); &#125; else if (\"\".equals(arg) &amp;&amp; namedValueInfo.defaultValue != null) &#123; arg = resolveStringValue(namedValueInfo.defaultValue); &#125; if (binderFactory != null) &#123; WebDataBinder binder = binderFactory.createBinder(webRequest, null, namedValueInfo.name); try &#123; arg = binder.convertIfNecessary(arg, parameter.getParameterType(), parameter); &#125; catch (ConversionNotSupportedException ex) &#123; throw new MethodArgumentConversionNotSupportedException(arg, ex.getRequiredType(), namedValueInfo.name, parameter, ex.getCause()); &#125; catch (TypeMismatchException ex) &#123; throw new MethodArgumentTypeMismatchException(arg, ex.getRequiredType(), namedValueInfo.name, parameter, ex.getCause()); &#125; &#125; handleResolvedValue(arg, namedValueInfo.name, parameter, mavContainer, webRequest); return arg;&#125; 2.1.1 RequestParamMethodArgumentResolver2.1.1 RequestAttributeMethodArgumentResolver3.1 总结 HandlerMethodArgumentResolver 的方法参数绑定处理是针对于不同的方法参数有专门的ArgumentResolver 专人做专事，专业 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(八)RequestMappingHandlerAdapter","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(八)RequestMappingHandlerAdapter","date":"2019-08-02T16:08:00.000Z","updated":"2020-01-04T12:21:52.231Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(八)RequestMappingHandlerAdapter/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(八)RequestMappingHandlerAdapter/","excerpt":"","text":"1.1 前言 RequestMappingHandlerAdapter是 HanlderAdapter 中最复杂的也是最常用的处理适配器，他的作用是根据HanlderMapping找到的Handler调用我们Controller 里的方法 既然是调用方法我们推测它的工作应该主要设及3步: 1、方法参数绑定 2、方法执行 3、返回结果处理 方法执行的流程已经在代码里写好了，重点是参数绑定及结果处理，各个方法参数类型不同个数不同，想想就复杂，下面来看人家是怎么做的 2.1 RequestMappingHandlerAdapter初始化解析 查看RequestMappingHandlerAdapter的继承关系 RequestMappingHandlerAdapter.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * An &#123;@link AbstractHandlerMethodAdapter&#125; that supports &#123;@link HandlerMethod&#125;s * with their method argument and return type signature, as defined via * &#123;@code @RequestMapping&#125;. * * &lt;p&gt;Support for custom argument and return value types can be added via * &#123;@link #setCustomArgumentResolvers&#125; and &#123;@link #setCustomReturnValueHandlers&#125;. * Or alternatively, to re-configure all argument and return value types, * use &#123;@link #setArgumentResolvers&#125; and &#123;@link #setReturnValueHandlers&#125;. * * @author Rossen Stoyanchev * @author Juergen Hoeller * @since 3.1 * @see HandlerMethodArgumentResolver * @see HandlerMethodReturnValueHandler */public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; private List&lt;HandlerMethodArgumentResolver&gt; customArgumentResolvers; // 用于给处理器方法和注释了@ModelAttribute的方法设置参数 private HandlerMethodArgumentResolverComposite argumentResolvers; // 用于添加了@initBinder的方法设置参数 private HandlerMethodArgumentResolverComposite initBinderArgumentResolvers; private List&lt;HandlerMethodReturnValueHandler&gt; customReturnValueHandlers; // 用于将处理器的返回值处理为ModelAndView类型 private HandlerMethodReturnValueHandlerComposite returnValueHandlers; private List&lt;ModelAndViewResolver&gt; modelAndViewResolvers; private ContentNegotiationManager contentNegotiationManager = new ContentNegotiationManager(); private List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters; private List&lt;Object&gt; requestResponseBodyAdvice = new ArrayList&lt;Object&gt;(); private WebBindingInitializer webBindingInitializer; private AsyncTaskExecutor taskExecutor = new SimpleAsyncTaskExecutor(\"MvcAsync\"); private Long asyncRequestTimeout; private CallableProcessingInterceptor[] callableInterceptors = new CallableProcessingInterceptor[0]; private DeferredResultProcessingInterceptor[] deferredResultInterceptors = new DeferredResultProcessingInterceptor[0]; private boolean ignoreDefaultModelOnRedirect = false; private int cacheSecondsForSessionAttributeHandlers = 0; private boolean synchronizeOnSession = false; private SessionAttributeStore sessionAttributeStore = new DefaultSessionAttributeStore(); private ParameterNameDiscoverer parameterNameDiscoverer = new DefaultParameterNameDiscoverer(); private ConfigurableBeanFactory beanFactory; private final Map&lt;Class&lt;?&gt;, SessionAttributesHandler&gt; sessionAttributesHandlerCache = new ConcurrentHashMap&lt;Class&lt;?&gt;, SessionAttributesHandler&gt;(64); private final Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; initBinderCache = new ConcurrentHashMap&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt;(64); private final Map&lt;ControllerAdviceBean, Set&lt;Method&gt;&gt; initBinderAdviceCache = new LinkedHashMap&lt;ControllerAdviceBean, Set&lt;Method&gt;&gt;(); private final Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; modelAttributeCache = new ConcurrentHashMap&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt;(64); private final Map&lt;ControllerAdviceBean, Set&lt;Method&gt;&gt; modelAttributeAdviceCache = new LinkedHashMap&lt;ControllerAdviceBean, Set&lt;Method&gt;&gt;(); public RequestMappingHandlerAdapter() &#123; StringHttpMessageConverter stringHttpMessageConverter = new StringHttpMessageConverter(); stringHttpMessageConverter.setWriteAcceptCharset(false); // see SPR-7316 this.messageConverters = new ArrayList&lt;HttpMessageConverter&lt;?&gt;&gt;(4); this.messageConverters.add(new ByteArrayHttpMessageConverter()); this.messageConverters.add(stringHttpMessageConverter); this.messageConverters.add(new SourceHttpMessageConverter&lt;Source&gt;()); this.messageConverters.add(new AllEncompassingFormHttpMessageConverter()); &#125; 可以看到实现了InitializingBean接口，这个方法注册了this.argumentResolvers this.initBinderArgumentResolvers this.returnValueHandlers 123456789101112131415161718@Overridepublic void afterPropertiesSet() &#123; // Do this first, it may add ResponseBody advice beans initControllerAdviceCache(); if (this.argumentResolvers == null) &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultArgumentResolvers(); this.argumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.initBinderArgumentResolvers == null) &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = getDefaultInitBinderArgumentResolvers(); this.initBinderArgumentResolvers = new HandlerMethodArgumentResolverComposite().addResolvers(resolvers); &#125; if (this.returnValueHandlers == null) &#123; List&lt;HandlerMethodReturnValueHandler&gt; handlers = getDefaultReturnValueHandlers(); this.returnValueHandlers = new HandlerMethodReturnValueHandlerComposite().addHandlers(handlers); &#125;&#125; 例如getDefaultArgumentResolvers方法，可以看到是直接写死了有那些默认的参数解析组件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Return the list of argument resolvers to use including built-in resolvers * and custom resolvers provided via &#123;@link #setCustomArgumentResolvers&#125;. */private List&lt;HandlerMethodArgumentResolver&gt; getDefaultArgumentResolvers() &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = new ArrayList&lt;HandlerMethodArgumentResolver&gt;(); // Annotation-based argument resolution resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), false)); resolvers.add(new RequestParamMapMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.PathVariableMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.PathVariableMapMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.MatrixVariableMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.MatrixVariableMapMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.ServletModelAttributeMethodProcessor(false)); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.RequestPartMethodArgumentResolver(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestHeaderMethodArgumentResolver(getBeanFactory())); resolvers.add(new RequestHeaderMapMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.ServletCookieValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new ExpressionValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.SessionAttributeMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.RequestAttributeMethodArgumentResolver()); // Type-based argument resolution resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.ServletRequestMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.ServletResponseMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.RedirectAttributesMethodArgumentResolver()); resolvers.add(new ModelMethodProcessor()); resolvers.add(new MapMethodProcessor()); resolvers.add(new ErrorsMethodArgumentResolver()); resolvers.add(new SessionStatusMethodArgumentResolver()); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.UriComponentsBuilderMethodArgumentResolver()); // Custom arguments if (getCustomArgumentResolvers() != null) &#123; resolvers.addAll(getCustomArgumentResolvers()); &#125; // Catch-all resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), true)); resolvers.add(new org.springframework.web.servlet.mvc.method.annotation.ServletModelAttributeMethodProcessor(true)); return resolvers;&#125; 2.2 处理解析 查看 RequestMappingHandlerAdapter 类是怎么实现的HandlerAdapter接口的handle方法的，由下面代码可以看到是转到了handleInternal(HttpServletRequest request,HttpServletResponse response, HandlerMethod handlerMethod)这个方法来处理，进入该方法 1234567891011121314151617181920212223242526272829303132333435363738394041// org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter#handle@Overridepublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125;// org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter#handleInternal@Overrideprotected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ModelAndView mav; // 检查是否支持当前的请求，如果不支持则抛出异常 checkRequest(request); // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123; mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No HttpSession available -&gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // 具体执行请求的处理 // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); &#125; if (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; prepareResponse(response); &#125; &#125; return mav;&#125; 关注mav = invokeHandlerMethod(request, response, handlerMethod);方法，进入该方法之后可以看到该方法主要是一些参数准备及组装各种处理单元，先备兵粮 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Invoke the &#123;@link RequestMapping&#125; handler method preparing a &#123;@link ModelAndView&#125; * if view resolution is required. * @since 4.2 * @see #createInvocableHandlerMethod(HandlerMethod) */protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &#123; // 创建WebDataBinder，WebDataBinder用于参数绑定，将符合条件的注释了@InitBinder的方法找出来 WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); // 用来处理Model，在处理器具体处理之前对Model进行初始化，在处理完请求之后对Model参数进行更新 ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); // 继承自HandlerMethod，实际请求的处理就是通过它来执行的，包括参数绑定，请求处理，以及返回值处理都是在它里面完成 org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); invocableMethod.setDataBinderFactory(binderFactory); invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); // ModelAndViewContainer承载着整个请求过程中数据的传递工作 ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); modelFactory.initModel(webRequest, mavContainer, invocableMethod); mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Found concurrent result value [\" + result + \"]\"); &#125; invocableMethod = invocableMethod.wrapConcurrentResult(result); &#125; // 执行方法 invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &#123; return null; &#125; return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125;&#125; 这个方法重点关注ServletInvocableHandlerMethod此对象，该类继承自HandlerMethod，实际请求的处理就是通过它来执行的，包括参数绑定，请求处理，以及返回值处理都是在它里面完成 123456// 继承自HandlerMethod，实际请求的处理就是通过它来执行的，包括参数绑定，请求处理，以及返回值处理都是在它里面完成org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);invocableMethod.setDataBinderFactory(binderFactory);invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); 查看上面代码可以看到这里设置了参数解析器 结果解析器 等等 ServletInvocableHandlerMethod 解析 先查看ServletInvocableHandlerMethod的继承关系，此类的继承关系有三层 顶层HandlerMethod类，该类封装了方法调用相关信息，比如是属于哪个bean下的的，那个Method，方法的参数MethodParameter[]等等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 封装了方法调用相关信息,子类还提供调用,参数准备和返回值处理的职责 * * Encapsulates information about a handler method consisting of a * &#123;@linkplain #getMethod() method&#125; and a &#123;@linkplain #getBean() bean&#125;. * Provides convenient access to method parameters, the method return value, * method annotations, etc. * * &lt;p&gt;The class may be created with a bean instance or with a bean name * (e.g. lazy-init bean, prototype bean). Use &#123;@link #createWithResolvedBean()&#125; * to obtain a &#123;@code HandlerMethod&#125; instance with a bean instance resolved * through the associated &#123;@link BeanFactory&#125;. * * @author Arjen Poutsma * @author Rossen Stoyanchev * @author Juergen Hoeller * @author Sam Brannen * @since 3.1 */public class HandlerMethod &#123; /** Logger that is available to subclasses */ protected final Log logger = LogFactory.getLog(getClass()); private final Object bean; private final BeanFactory beanFactory; private final Class&lt;?&gt; beanType; private final Method method; private final Method bridgedMethod; /** * 方法的参数 */ private final MethodParameter[] parameters; private HttpStatus responseStatus; private String responseStatusReason; private HandlerMethod resolvedFromHandlerMethod; ... InvocableHandlerMethod 类 HandlerMethod类的基础上添加了方法调用功能及注册了参数解析组件 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 在 HandlerMethod类的基础上添加了方法调用功能及注册了参数解析组件 * * Provides a method for invoking the handler method for a given request after resolving its * method argument values through registered &#123;@link HandlerMethodArgumentResolver&#125;s. * * &lt;p&gt;Argument resolution often requires a &#123;@link WebDataBinder&#125; for data binding or for type * conversion. Use the &#123;@link #setDataBinderFactory(WebDataBinderFactory)&#125; property to supply * a binder factory to pass to argument resolvers. * * &lt;p&gt;Use &#123;@link #setHandlerMethodArgumentResolvers&#125; to customize the list of argument resolvers. * * @author Rossen Stoyanchev * @author Juergen Hoeller * @since 3.1 */public class InvocableHandlerMethod extends HandlerMethod &#123; /** * 用于参数解析器ArgumentResolver */ private WebDataBinderFactory dataBinderFactory; /** * 解析参数 */ private org.springframework.web.method.support.HandlerMethodArgumentResolverComposite argumentResolvers = new org.springframework.web.method.support.HandlerMethodArgumentResolverComposite(); /** * 用来获取参数名 */ private ParameterNameDiscoverer parameterNameDiscoverer = new DefaultParameterNameDiscoverer(); /** * Create an instance from a &#123;@code HandlerMethod&#125;. */ public InvocableHandlerMethod(HandlerMethod handlerMethod) &#123; super(handlerMethod); &#125; ... 得到ServletInvocableHandlerMethod 对象之后进入到ServletInvocableHandlerMethod 类的invocableMethod.invokeAndHandle(webRequest, mavContainer); 方法，可以说这个方法是RequestMappingHandlerAdapter的核心方法，可以看到Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); 是执行了方法体，得到returnValue 之后就是调用this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest);该方法处理结果对象 123456789101112131415161718192021222324252627282930313233343536/** * Invoke the method and handle the return value through one of the * configured &#123;@link HandlerMethodReturnValueHandler&#125;s. * @param webRequest the current request * @param mavContainer the ModelAndViewContainer for this request * @param providedArgs \"given\" arguments matched by type (not resolved) */public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) &#123; if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; &#125; mavContainer.setRequestHandled(false); try &#123; this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex); &#125; throw ex; &#125;&#125; 进入Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); 方法，可以看到该方法很简单，先是得到方法参数Object[] args，然后执行Object returnValue = doInvoke(args); 该方法得到结果 1234567891011121314151617181920212223242526272829303132/** * Invoke the method after resolving its argument values in the context of the given request. * &lt;p&gt;Argument values are commonly resolved through &#123;@link HandlerMethodArgumentResolver&#125;s. * The &#123;@code providedArgs&#125; parameter however may supply argument values to be used directly, * i.e. without argument resolution. Examples of provided argument values include a * &#123;@link WebDataBinder&#125;, a &#123;@link SessionStatus&#125;, or a thrown exception instance. * Provided argument values are checked before argument resolvers. * @param request the current request * @param mavContainer the ModelAndViewContainer for this request * @param providedArgs \"given\" arguments matched by type, not resolved * @return the raw value returned by the invoked method * @exception Exception raised if no suitable argument resolver can be found, * or if the method raised an exception */public Object invokeForRequest(NativeWebRequest request, org.springframework.web.method.support.ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; // 1、这里得到了方法参数值 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &#123; logger.trace(\"Invoking '\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"' with arguments \" + Arrays.toString(args)); &#125; // 2、传入方法参数值并执行方法 Object returnValue = doInvoke(args); if (logger.isTraceEnabled()) &#123; logger.trace(\"Method [\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"] returned [\" + returnValue + \"]\"); &#125; // 3、返回结果 return returnValue;&#125; 2.1.1 方法参数绑定 方法参数的绑定需要关注Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); 这行代码，先进入该方法，可以看到该方法先是判断相应类型的参数已经在providedArgs中提供了，如果有的话就是直接返回，否则则使用argumentResolvers解析 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 根据当前请求获取方法的请求参数 * Get the method argument values for the current request. * */private Object[] getMethodArgumentValues(NativeWebRequest request, org.springframework.web.method.support.ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; // 获取方法的参数，在HanderMethod中 MethodParameter[] parameters = getMethodParameters(); // 用于保存解析出参数的值 Object[] args = new Object[parameters.length]; // 遍历每一个参数进行解析 for (int i = 0; i &lt; parameters.length; i++) &#123; MethodParameter parameter = parameters[i]; // 给Parameter设置参数名解析器 parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); // 如果相应类型的参数已经在providedArgs中提供了，则直接设置到parameter args[i] = resolveProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; if (this.argumentResolvers.supportsParameter(parameter)) &#123; try &#123; // 使用argumentResolvers解析参数 args[i] = this.argumentResolvers.resolveArgument( parameter, mavContainer, request, this.dataBinderFactory); continue; &#125; catch (Exception ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(getArgumentResolutionErrorMessage(\"Failed to resolve\", i), ex); &#125; throw ex; &#125; &#125; // 解析不出来，抛异常 if (args[i] == null) &#123; throw new IllegalStateException(\"Could not resolve method parameter at index \" + parameter.getParameterIndex() + \" in \" + parameter.getMethod().toGenericString() + \": \" + getArgumentResolutionErrorMessage(\"No suitable resolver for\", i)); &#125; &#125; return args;&#125; 在RequestMappingHandlerAdapter中只有argumentResolvers解析，因为invocableMethod.invokeAndHandle(webRequest, mavContainer); 只传了两个参数，到了Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); 方法之后也是没有传入providedArgs的，由上面代码可以看到先是调用supportsParameter()方法判断当前解析器是否支持这个参数解析，如果支持的话就是调用resolveArgument()方法来解析，这两个方法都是HandlerMethodArgumentResolver接口的方法 argumentResolvers 存放在HandlerMethodArgumentResolverComposite 类中，所有的ArgumentResolver都存放在List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers中，也可以看到该类也做了一个argumentResolverCacheCache缓存处理，也是为了性能 12345678910111213141516171819202122232425262728/** * HandlerMethodArgumentResolver 的仓库 * * Resolves method parameters by delegating to a list of registered &#123;@link HandlerMethodArgumentResolver&#125;s. * Previously resolved method parameters are cached for faster lookups. * * @author Rossen Stoyanchev * @author Juergen Hoeller * @since 3.1 */public class HandlerMethodArgumentResolverComposite implements HandlerMethodArgumentResolver &#123; protected final Log logger = LogFactory.getLog(getClass()); private final List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers = new LinkedList&lt;HandlerMethodArgumentResolver&gt;(); private final Map&lt;MethodParameter, HandlerMethodArgumentResolver&gt; argumentResolverCache = new ConcurrentHashMap&lt;MethodParameter, HandlerMethodArgumentResolver&gt;(256); /** * Add the given &#123;@link HandlerMethodArgumentResolver&#125;. */ public HandlerMethodArgumentResolverComposite addResolver(HandlerMethodArgumentResolver resolver) &#123; this.argumentResolvers.add(resolver); return this; &#125; 通过调试可以看到有下面这些argumentResolvers，看类名称是不是很熟悉，就是我们平常使用的@RequestBody @RequestParam 是一一对应的，还是专人做专事，可以得出不同的参数是有不同的参数解析组件来专门处理的 下面来看主要XXXArgumentResolver的作用 123456789101112131415161. SessionAttributeMethodArgumentResolver 针对 被 @SessionAttribute 修饰的参数起作用, 参数的获取一般通过 HttpServletRequest.getAttribute(name, RequestAttributes.SCOPE_SESSION) 2. RequestParamMethodArgumentResolver 针对被 @RequestParam 注解修饰, 但类型不是 Map, 或类型是 Map, 并且 @RequestParam 中指定 name, 一般通过 MultipartHttpServletRequest | HttpServletRequest 获取数据3. RequestHeaderMethodArgumentResolver 针对 参数被 RequestHeader 注解, 并且 参数不是 Map 类型, 数据通过 HttpServletRequest.getHeaderValues(name) 获取4. RequestAttributeMethodArgumentResolver 针对 被 @RequestAttribute 修饰的参数起作用, 参数的获取一般通过 HttpServletRequest.getAttribute(name, RequestAttributes.SCOPE_REQUEST)5. PathVariableMethodArgumentResolver 解决被注解 @PathVariable 注释的参数 &lt;- 这个注解对应的是 uri 中的数据, 在解析 URI 中已经进行解析好了 &lt;- 在 RequestMappingInfoHandlerMapping.handleMatch -&gt; getPathMatcher().extractUriTemplateVariables6. MatrixVariableMethodArgumentResolver 针对被 @MatrixVariable 注解修饰的参数起作用, 从 HttpServletRequest 中获取去除 ; 的 URI Template Variables 获取数据7. ExpressionValueMethodArgumentResolver 针对被 @Value 修饰, 返回 ExpressionValueNamedValueInfo8. ServletCookieValueMethodArgumentResolver 针对被 @CookieValue 修饰, 通过 HttpServletRequest.getCookies 获取对应数据 然后进入HandlerMethodArgumentResolverComposite类的args[i] = this.argumentResolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); 方法，可以看到逻辑十分简单，就是遍历this.argumentResolvers 然后做了个缓存处理，得到HandlerMethodArgumentResolver之后就是调用resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);方法了，该方法是参数解析的主体方法 12345678910111213141516171819202122232425262728293031323334353637/** * 迭代注册过的 HandlerMethodArgumentResolver, 然后找到对应的ArgumentResolver * Iterate over registered &#123;@link HandlerMethodArgumentResolver&#125;s and invoke the one that supports it. * @throws IllegalStateException if no suitable &#123;@link HandlerMethodArgumentResolver&#125; is found. */@Overridepublic Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); if (resolver == null) &#123; throw new IllegalArgumentException(\"Unknown parameter type [\" + parameter.getParameterType().getName() + \"]\"); &#125; return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);&#125;/** * 先从缓存里取，没有的再遍历，注意这里是先来先得的 * Find a registered &#123;@link HandlerMethodArgumentResolver&#125; that supports the given method parameter. */private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) &#123; HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter); if (result == null) &#123; for (HandlerMethodArgumentResolver methodArgumentResolver : this.argumentResolvers) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Testing if argument resolver [\" + methodArgumentResolver + \"] supports [\" + parameter.getGenericParameterType() + \"]\"); &#125; if (methodArgumentResolver.supportsParameter(parameter)) &#123; result = methodArgumentResolver; this.argumentResolverCache.put(parameter, result); break; &#125; &#125; &#125; return result;&#125; 再来回顾HandlerMethodArgumentResolver接口，该接口就两个方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 方法参数解析器 * * Strategy interface for resolving method parameters into argument values in * the context of a given request. * * @author Arjen Poutsma * @since 3.1 * @see HandlerMethodReturnValueHandler */public interface HandlerMethodArgumentResolver &#123; /** * 是否支持 * * Whether the given &#123;@linkplain MethodParameter method parameter&#125; is * supported by this resolver. * @param parameter the method parameter to check * @return &#123;@code true&#125; if this resolver supports the supplied parameter; * &#123;@code false&#125; otherwise */ boolean supportsParameter(MethodParameter parameter); /** * 根据request解析方法参数值 * * Resolves a method parameter into an argument value from a given request. * A &#123;@link ModelAndViewContainer&#125; provides access to the model for the * request. A &#123;@link WebDataBinderFactory&#125; provides a way to create * a &#123;@link WebDataBinder&#125; instance when needed for data binding and * type conversion purposes. * @param parameter the method parameter to resolve. This parameter must * have previously been passed to &#123;@link #supportsParameter&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @param binderFactory a factory for creating &#123;@link WebDataBinder&#125; instances * @return the resolved argument value, or &#123;@code null&#125; * @throws Exception in case of errors with the preparation of argument values */ Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception;&#125; HandlerMethodArgumentResolver的 resolveArgument 的解析将在之后的章节介绍 2.2.2 方法执行 回到InvocableHandlerMethod类的invokeForRequest 方法，上一小节介绍了方法参数绑定的主体逻辑(Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);)，这一小节介绍Object returnValue = doInvoke(args);，该行代码是方法执行的主体方法 123456789101112131415161718public Object invokeForRequest(NativeWebRequest request, org.springframework.web.method.support.ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; // 1、这里得到了方法参数值 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &#123; logger.trace(\"Invoking '\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"' with arguments \" + Arrays.toString(args)); &#125; // 2、传入方法参数值并执行方法 Object returnValue = doInvoke(args); if (logger.isTraceEnabled()) &#123; logger.trace(\"Method [\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"] returned [\" + returnValue + \"]\"); &#125; // 3、返回结果 return returnValue;&#125; 进入Object returnValue = doInvoke(args); 方法，可以看到调用了getBridgedMethod().invoke(getBean(), args); 来执行方法，getBridgedMethod() 得到的是private final Method bridgedMethod，百度了一下这个桥接方法的用途是为了和jdk1.5之前的字节码兼容. 因为范型是在jdk1.5之后才引入的. 在jdk1.5之前例如集合的操作都是没有范型支持的, 所以生成的字节码中参数都是用Object接收的, 所以也可以往集合中放入任意类型的对象, 集合类型的校验也被拖到运行期. 1234567891011121314151617181920212223242526272829303132/** * Invoke the handler method with the given argument values. */protected Object doInvoke(Object... args) throws Exception &#123; // 强制将他变为可调用 即使是private方法 ReflectionUtils.makeAccessible(getBridgedMethod()); try &#123; return getBridgedMethod().invoke(getBean(), args); &#125; catch (IllegalArgumentException ex) &#123; assertTargetBean(getBridgedMethod(), getBean(), args); String text = (ex.getMessage() != null ? ex.getMessage() : \"Illegal argument\"); throw new IllegalStateException(getInvocationErrorMessage(text, args), ex); &#125; catch (InvocationTargetException ex) &#123; // Unwrap for HandlerExceptionResolvers ... Throwable targetException = ex.getTargetException(); if (targetException instanceof RuntimeException) &#123; throw (RuntimeException) targetException; &#125; else if (targetException instanceof Error) &#123; throw (Error) targetException; &#125; else if (targetException instanceof Exception) &#123; throw (Exception) targetException; &#125; else &#123; String text = getInvocationErrorMessage(\"Failed to invoke handler method\", args); throw new IllegalStateException(text, targetException); &#125; &#125;&#125; 在此方法执行完成 2.2.3 返回结果处理 方法执行完成之后就对返回结果的处理了，回到ServletInvocableHandlerMethod类，现在方法体已经执行了，就是对结果对象的处理了 1234567891011121314151617181920212223242526272829303132333435/** * Invoke the method and handle the return value through one of the * configured &#123;@link HandlerMethodReturnValueHandler&#125;s. * @param webRequest the current request * @param mavContainer the ModelAndViewContainer for this request * @param providedArgs \"given\" arguments matched by type (not resolved) */public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) &#123; if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; &#125; mavContainer.setRequestHandled(false); try &#123; this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex); &#125; throw ex; &#125;&#125; 查看上面的代码可以看到this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest); 这行代码作用是对结果对象的处理，查看returnValueHandlers 对象（private HandlerMethodReturnValueHandlerComposite returnValueHandlers;）可以看到和我们之前的参数绑定的处理是相似的，HandlerMethodReturnValueHandlerComposite存放了各种结果处理组件 HandlerMethodReturnValueHandlerComposite.java 123456789101112131415/** * Handles method return values by delegating to a list of registered &#123;@link HandlerMethodReturnValueHandler&#125;s. * Previously resolved return types are cached for faster lookups. * * @author Rossen Stoyanchev * @since 3.1 */public class HandlerMethodReturnValueHandlerComposite implements AsyncHandlerMethodReturnValueHandler &#123; protected final Log logger = LogFactory.getLog(getClass()); // 结果处理组件 private final List&lt;HandlerMethodReturnValueHandler&gt; returnValueHandlers = new ArrayList&lt;HandlerMethodReturnValueHandler&gt;(); HandlerMethodReturnValueHandler.java 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 结果对象处理 * * Strategy interface to handle the value returned from the invocation of a * handler method . * * @author Arjen Poutsma * @since 3.1 * @see HandlerMethodArgumentResolver */public interface HandlerMethodReturnValueHandler &#123; /** * 是否支持 * * Whether the given &#123;@linkplain MethodParameter method return type&#125; is * supported by this handler. * @param returnType the method return type to check * @return &#123;@code true&#125; if this handler supports the supplied return type; * &#123;@code false&#125; otherwise */ boolean supportsReturnType(MethodParameter returnType); /** * 处理结果集 * * Handle the given return value by adding attributes to the model and * setting a view or setting the * &#123;@link ModelAndViewContainer#setRequestHandled&#125; flag to &#123;@code true&#125; * to indicate the response has been handled directly. * @param returnValue the value returned from the handler method * @param returnType the type of the return value. This type must have * previously been passed to &#123;@link #supportsReturnType&#125; which must * have returned &#123;@code true&#125;. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @throws Exception if the return value handling results in an error */ void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception;&#125; 进入handleReturnValue方法，可以看到和之前方法参数绑定处理是一样的套路的 12345678910111213141516171819202122232425262728/** * 迭代注册过的 HandlerMethodReturnValueHandler, 然后找到对应的ReturnValueHandler * Iterate over registered &#123;@link HandlerMethodReturnValueHandler&#125;s and invoke the one that supports it. * @throws IllegalStateException if no suitable &#123;@link HandlerMethodReturnValueHandler&#125; is found. */@Overridepublic void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType); if (handler == null) &#123; throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName()); &#125; handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);&#125;private HandlerMethodReturnValueHandler selectHandler(Object value, MethodParameter returnType) &#123; boolean isAsyncValue = isAsyncReturnValue(value, returnType); for (HandlerMethodReturnValueHandler handler : this.returnValueHandlers) &#123; if (isAsyncValue &amp;&amp; !(handler instanceof AsyncHandlerMethodReturnValueHandler)) &#123; continue; &#125; if (handler.supportsReturnType(returnType)) &#123; return handler; &#125; &#125; return null;&#125; 如下图可以看到有如下this.returnValueHandlers 3.1 总结 RequestMappingHandlerAdapter 的功能主要是 1、方法参数绑定 2、方法执行 3、返回结果处理 HandlerMethodArgumentResolver 的方法参数绑定处理是针对于不同的方法参数有专门的ArgumentResolver 专人做专事，专业 HandlerMethodReturnValueHandler 的返回结果处理也是和参数处理那样是针对于不同的返回对象有专门的ReturnValueHandler 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(七)处理适配器HanlderAdapter","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(七)处理适配器HanlderAdapter","date":"2019-08-02T16:07:00.000Z","updated":"2019-09-16T13:11:06.095Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(七)处理适配器HanlderAdapter/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(七)处理适配器HanlderAdapter/","excerpt":"","text":"1.1 前言 前几章介绍了HandlerMapping处理流程， HandlerMapping负责根据request请求找到对应的Handler处理器及Interceptor拦截器，得到处理器Handler之后，Spring MVC 又根据该Handler 找出对应的 HandlerAdapter，这一章节来介绍HandlerAdapter，HandlerAdapter是具体使用Handler 来干活的 下面还是方法体doDispatch(HttpServletRequest request, HttpServletResponse response) 的处理代码，可以看到得到Handler处理器之后就是遍历所有的 HandlerAdapter，找到可以处理该 Handler 的 HandlerAdapter，找到之后就是mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); 调用真正的处理方法了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; // 获取当前请求的WebAsyncManager，如果没找到则创建并与请求关联 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // 检查是否是文件上传请求 Multipart，有则将请求转换为 Multipart 请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. // 遍历所有的 HandlerMapping 找到与请求对应的 Handler，并将其与一堆拦截器封装到 HandlerExecution 对象中 mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. // 遍历所有的 HandlerAdapter，找到可以处理该 Handler 的 HandlerAdapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. // 处理 last-modified 请求头 String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // 执行相应拦截器Interceptor的preHandle if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. // 执行实际的处理程序，执行Controller里的方法 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); 2.1 处理适配器HanlderAdapter解析2.1.1 HanlderAdapter 解析 先看HanlderAdapter 这个接口有哪些方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * Handler 处理适配器, 适配不同的 Handler * * MVC framework SPI, allowing parameterization of the core MVC workflow. * * &lt;p&gt;Interface that must be implemented for each handler type to handle a request. * This interface is used to allow the &#123;@link DispatcherServlet&#125; to be indefinitely * extensible. The &#123;@code DispatcherServlet&#125; accesses all installed handlers through * this interface, meaning that it does not contain code specific to any handler type. * * &lt;p&gt;Note that a handler can be of type &#123;@code Object&#125;. This is to enable * handlers from other frameworks to be integrated with this framework without * custom coding, as well as to allow for annotation-driven handler objects that * do not obey any specific Java interface. * * &lt;p&gt;This interface is not intended for application developers. It is available * to handlers who want to develop their own web workflow. * * &lt;p&gt;Note: &#123;@code HandlerAdapter&#125; implementors may implement the &#123;@link * org.springframework.core.Ordered&#125; interface to be able to specify a sorting * order (and thus a priority) for getting applied by the &#123;@code DispatcherServlet&#125;. * Non-Ordered instances get treated as lowest priority. * * @author Rod Johnson * @author Juergen Hoeller * @see org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter * @see org.springframework.web.servlet.handler.SimpleServletHandlerAdapter */public interface HandlerAdapter &#123; /** * 检测 HandlerAdapter 是否支持这个 handler * * Given a handler instance, return whether or not this &#123;@code HandlerAdapter&#125; * can support it. Typical HandlerAdapters will base the decision on the handler * type. HandlerAdapters will usually only support one handler type each. * &lt;p&gt;A typical implementation: * &lt;p&gt;&#123;@code * return (handler instanceof MyHandler); * &#125; * @param handler handler object to check * @return whether or not this object can use the given handler */ boolean supports(Object handler); /** * 处理 HttpServletRequest 的入口方法 * * Use the given handler to handle this request. * The workflow that is required may vary widely. * @param request current HTTP request * @param response current HTTP response * @param handler handler to use. This object must have previously been passed * to the &#123;@code supports&#125; method of this interface, which must have * returned &#123;@code true&#125;. * @throws Exception in case of errors * @return ModelAndView object with the name of the view and the required * model data, or &#123;@code null&#125; if the request has been handled directly */ ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; /** * 获取Http 请求中的lastModifiedTime * * Same contract as for HttpServlet's &#123;@code getLastModified&#125; method. * Can simply return -1 if there's no support in the handler class. * @param request current HTTP request * @param handler handler to use * @return the lastModified value for the given handler * @see javax.servlet.http.HttpServlet#getLastModified * @see org.springframework.web.servlet.mvc.LastModified#getLastModified */ long getLastModified(HttpServletRequest request, Object handler);&#125; 下图是HanlderAdapter涉及子类的继承关系，看方法名是不是很熟悉，没错和前几章的HandlerMapping是差不多是一一对应的 image 查看这些类可以看到除了RequestMappingHandlerAdapter 的实现比较复杂之外，其他的HandlerAdapter都是调用Handler里固定的方法，比如下图的SimpleControllerHandlerAdapter 1234567891011121314151617181920212223public class SimpleControllerHandlerAdapter implements HandlerAdapter &#123; @Override public boolean supports(Object handler) &#123; return (handler instanceof Controller); &#125; @Override public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return ((Controller) handler).handleRequest(request, response); &#125; @Override public long getLastModified(HttpServletRequest request, Object handler) &#123; if (handler instanceof LastModified) &#123; return ((LastModified) handler).getLastModified(request); &#125; return -1L; &#125;&#125; 查看AbstractHandlerMethodAdapter可以看到内容也很少，HandlerAdapter 接口的实现都转发到自己的抽象方法里去了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * Abstract base class for &#123;@link HandlerAdapter&#125; implementations that support * handlers of type &#123;@link HandlerMethod&#125;. * * @author Arjen Poutsma * @since 3.1 */public abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered &#123; private int order = Ordered.LOWEST_PRECEDENCE; public AbstractHandlerMethodAdapter() &#123; // no restriction of HTTP methods by default super(false); &#125; /** * Specify the order value for this HandlerAdapter bean. * &lt;p&gt;Default value is &#123;@code Integer.MAX_VALUE&#125;, meaning that it's non-ordered. * @see org.springframework.core.Ordered#getOrder() */ public void setOrder(int order) &#123; this.order = order; &#125; @Override public int getOrder() &#123; return this.order; &#125; /** * 先判断是否是HandlerMethod，然后转向抽象方法supportsInternal * This implementation expects the handler to be an &#123;@link HandlerMethod&#125;. * @param handler the handler instance to check * @return whether or not this adapter can adapt the given handler */ @Override public final boolean supports(Object handler) &#123; return (handler instanceof HandlerMethod &amp;&amp; supportsInternal((HandlerMethod) handler)); &#125; /** * Given a handler method, return whether or not this adapter can support it. * @param handlerMethod the handler method to check * @return whether or not this adapter can adapt the given method */ protected abstract boolean supportsInternal(HandlerMethod handlerMethod); /** * 转向抽象方法 handleInternal() * This implementation expects the handler to be an &#123;@link HandlerMethod&#125;. */ @Override public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler); &#125; /** * Use the given handler method to handle the request. * @param request current HTTP request * @param response current HTTP response * @param handlerMethod handler method to use. This object must have previously been passed to the * &#123;@link #supportsInternal(HandlerMethod)&#125; this interface, which must have returned &#123;@code true&#125;. * @return ModelAndView object with the name of the view and the required model data, * or &#123;@code null&#125; if the request has been handled directly * @throws Exception in case of errors */ protected abstract ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception; /** * 转向抽象方法 getLastModifiedInternal() * This implementation expects the handler to be an &#123;@link HandlerMethod&#125;. */ @Override public final long getLastModified(HttpServletRequest request, Object handler) &#123; return getLastModifiedInternal(request, (HandlerMethod) handler); &#125; /** * Same contract as for &#123;@link javax.servlet.http.HttpServlet#getLastModified(HttpServletRequest)&#125;. * @param request current HTTP request * @param handlerMethod handler method to use * @return the lastModified value for the given handler */ protected abstract long getLastModifiedInternal(HttpServletRequest request, HandlerMethod handlerMethod);&#125; 2.1.2 各个 HandlerAdapter作用AnnotationMethodHandlerAdapterAnnotationMethodHandlerAdapter主要是适配注解类处理器，注解类处理器就是我们经常使用的@Controller的这类处理器，不过该类已经被@Deprecated 标记了（@deprecated as of Spring 3.2, in favor of`） 1234@Overridepublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125; HttpRequestHandlerAdapterHttpRequestHandlerAdapter 主要是适配静态资源处理器，静态资源处理器就是实现了HttpRequestHandler接口的处理器，这类处理器的作用是处理通过SpringMVC来访问的静态资源的请求。 123456789101112131415@Overridepublic ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((HttpRequestHandler) handler).handleRequest(request, response); return null;&#125;``` #### SimpleControllerHandlerAdapter`SimpleControllerHandlerAdapter` 是`Controller`处理适配器，适配实现了`Controller`接口或`Controller`接口子类的处理器，比如我们经常自己写的`Controller`来继承`MultiActionController````java@Overridepublic ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return ((Controller) handler).handleRequest(request, response);&#125; SimpleServletHandlerAdapterSimpleServletHandlerAdapter是Servlet处理适配器,适配实现了Servlet接口或Servlet的子类的处理器，我们不仅可以在web.xml里面配置Servlet，其实也可以用SpringMVC来配置Servlet，不过这个适配器很少用到，而且SpringMVC默认的适配器没有他，默认的是前面的三种。 12345@Overridepublic ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; ((Servlet) handler).service(request, response); return null;&#125; 2.1.3 HandlerAdapter 注册过程 HandlerAdapter 注册过程 和 HandlerMapping 的注册过程是一样的，回到DispatcherServlet 类中onRefresh 方法 1234567891011121314151617181920/** * Initialize the strategy objects that this servlet uses. * &lt;p&gt;May be overridden in subclasses in order to initialize further strategy objects. */protected void initStrategies(ApplicationContext context) &#123; // 上传组件组件初始化 initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); // 请求映射处理组件初始化 initHandlerMappings(context); // 处理适配器组建初始化 initHandlerAdapters(context); // 异常处理组件初始化 initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); // 视图处理组件初始化 initViewResolvers(context); initFlashMapManager(context);&#125; 进入initHandlerAdapters(context); 从下面代码也可以看到也是通过扫描HandlerAdapter类 bean的形式来注册HandlerAdapter 1234567891011121314151617181920212223242526272829303132333435363738/** * Initialize the HandlerAdapters used by this class. * &lt;p&gt;If no HandlerAdapter beans are defined in the BeanFactory for this namespace, * we default to SimpleControllerHandlerAdapter. */private void initHandlerAdapters(ApplicationContext context) &#123; this.handlerAdapters = null; if (this.detectAllHandlerAdapters) &#123; // 加载所有实现了HandlerAdapter接口的bean // Find all HandlerAdapters in the ApplicationContext, including ancestor contexts. Map&lt;String, HandlerAdapter&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerAdapter.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerAdapters = new ArrayList&lt;HandlerAdapter&gt;(matchingBeans.values()); // We keep HandlerAdapters in sorted order. AnnotationAwareOrderComparator.sort(this.handlerAdapters); &#125; &#125; else &#123; try &#123; HandlerAdapter ha = context.getBean(HANDLER_ADAPTER_BEAN_NAME, HandlerAdapter.class); this.handlerAdapters = Collections.singletonList(ha); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we'll add a default HandlerAdapter later. &#125; &#125; // Ensure we have at least some HandlerAdapters, by registering // default HandlerAdapters if no other adapters are found. if (this.handlerAdapters == null) &#123; this.handlerAdapters = getDefaultStrategies(context, HandlerAdapter.class); if (logger.isDebugEnabled()) &#123; logger.debug(\"No HandlerAdapters found in servlet '\" + getServletName() + \"': using default\"); &#125; &#125;&#125; 3.1 适配器设计模式 HanlderAdapter看后缀名就可以理解它使用了适配器模式 Spring MVC的handler有多种形式，由于实现方式不一样， Handler 有可能是一个 HandlerMethod（封装了 Controller 中的方法）对象，也有可能是一个 Controller 对象、 HttpRequestHandler 对象或 Servlet 对象，而这个 Handler 具体是什么对象，调用方式就不确定了。 如果正常编写调用，就需要使用多个if else判断instance of，再添加实现方式，就需要修改源码，不符合对扩展开放，对修改关闭原则， 所以针对这种情况设计了HanlderAdapter，如果是添加了新的Handler只要添加一个新的HanlderAdapter就可以完成扩展 4.1 总结 HanlderAdapter 从字面上的意思就是处理适配器，他的作用就是根据用户的请求调用具体的方法，根据HandlerMapping传过来Hanler与注册好的HandlerAdapter一一匹配，如果找到了其中一种HandlerAdapter是支持传过来的controller类型，那么该HandlerAdapter会调用自己的handle方法 不同的HanlderAdapter可以适应不同的request需求 5.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html https://www.jianshu.com/p/3d6df6b725e4 https://blog.csdn.net/weixin_38399962/article/details/85288660","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(六)基于注解实现的RequestMappingHandlerMapping工作流程","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(六)基于注解实现的RequestMappingHandlerMapping工作流程","date":"2019-08-02T16:06:00.000Z","updated":"2019-09-16T13:11:06.233Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(六)基于注解实现的RequestMappingHandlerMapping工作流程/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(六)基于注解实现的RequestMappingHandlerMapping工作流程/","excerpt":"","text":"1.1 前言 上一章节介绍了 RequestMappingHandlerMapping 这个 HandlerMapping 的加载过程，这一章节来介绍RequestMappingHandlerMapping实现流程 2.1 找到与请求对应的 Handler 解析 还是回到这个方法doDispatch(HttpServletRequest request, HttpServletResponse response) ，下面的代码是发挥RequestMappingHandlerMapping作用的地方 12345678910HandlerExecutionChain mappedHandler = null;...// Determine handler for the current request.// 遍历所有的 HandlerMapping 找到与请求对应的 Handler，并将其与一堆拦截器封装到 HandlerExecution 对象中mappedHandler = getHandler(processedRequest);if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return;&#125; 进入 getHandler方法，这里会遍历到我们的RequestMappingHandlerMapping 这个HandlerMapping，通过HandlerExecutionChain handler = hm.getHandler(request); 得到HandlerExecutionChain 12345678910111213141516protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 循环handlerMappings eg: RequestMappingHandlerMapping、SimpleUrlHandlerMapping、BeanNameUrlHandlerMapping for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace( \"Testing handler map [\" + hm + \"] in DispatcherServlet with name '\" + getServletName() + \"'\"); &#125; // 遍历HandlerMapping实现类的找到对应的 HandlerExecutionChain HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; // 注意这里是找到第一个就直接返回 return handler; &#125; &#125; return null;&#125; 进入hm.getHandler(request); 会跳到我们的AbstractHandlerMapping 类中，RequestMappingHandlerMapping 继承该类，由下面代码可以看到这里这里获取了 handler 及 Interceptor 并封装为HandlerExecutionChain 返回调用者 1234567891011121314151617181920212223242526272829303132/** * Look up a handler for the given request, falling back to the default * handler if no specific one is found. * @param request current HTTP request * @return the corresponding handler instance, or the default handler * @see #getHandlerInternal */@Overridepublic final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 在这里获取 处理器handler，模板方法实现， RequestMappingHandlerMapping 跳到 AbstractHandlerMethodMapping Object handler = getHandlerInternal(request); if (handler == null) &#123; handler = getDefaultHandler(); &#125; if (handler == null) &#123; return null; &#125; // Bean name or resolved handler? if (handler instanceof String) &#123; String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; // 获取 拦截器Interceptor HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; 关注Object handler = getHandlerInternal(request); 这里是获取handler的地方，这时又会跳到AbstractHandlerMethodMapping 类中，这样跳来跳去可以看到封装的特性及使用模板方法提高了扩展性 1234567891011121314151617181920212223242526272829/** * Look up a handler method for the given request. */@Overrideprotected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; // 获取请求url路径 localhost:8080/pub/account/list &gt;&gt;&gt; /pub/account/list String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); if (logger.isDebugEnabled()) &#123; logger.debug(\"Looking up handler method for path \" + lookupPath); &#125; // mappingRegistry添加读锁，其他线程只能读不能写 this.mappingRegistry.acquireReadLock(); try &#123; // 根据request获取对应的HandlerMethod HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); if (logger.isDebugEnabled()) &#123; if (handlerMethod != null) &#123; logger.debug(\"Returning handler method [\" + handlerMethod + \"]\"); &#125; else &#123; logger.debug(\"Did not find handler method for [\" + lookupPath + \"]\"); &#125; &#125; return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123; this.mappingRegistry.releaseReadLock(); &#125;&#125; 关注 HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); 这行代码，进入该方法，可以看到这个方法的作用是得到HandlerMethod 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 查找当前request请求 最为匹配的处理方法HandlerMethod，如果有多个匹配结果，则选择最佳匹配结果 * Look up the best-matching handler method for the current request. * If multiple matches are found, the best match is selected. * @param lookupPath mapping lookup path within the current servlet mapping * @param request the current request * @return the best-matching handler method, or &#123;@code null&#125; if no match * @see #handleMatch(Object, String, HttpServletRequest) * @see #handleNoMatch(Set, String, HttpServletRequest) */protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches = new ArrayList&lt;Match&gt;(); // 根据URL来获取,springMVC会在初始化的时候建立URL和相应RequestMappingInfo的映射。如果不是restful接口，这里就可以直接获取到了， lookupPath: /pub/account/list List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath); if (directPathMatches != null) &#123; // 匹配校验 addMatchingMappings(directPathMatches, matches, request); &#125; if (matches.isEmpty()) &#123; // 全盘扫描 // No choice but to go through all mappings... addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request); &#125; // 得到匹配结果 if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); Collections.sort(matches, comparator); if (logger.isTraceEnabled()) &#123; logger.trace(\"Found \" + matches.size() + \" matching mapping(s) for [\" + lookupPath + \"] : \" + matches); &#125; Match bestMatch = matches.get(0); if (matches.size() &gt; 1) &#123; if (CorsUtils.isPreFlightRequest(request)) &#123; return PREFLIGHT_AMBIGUOUS_MATCH; &#125; Match secondBestMatch = matches.get(1); // 如果最佳匹配 第二佳匹配都是同一个则报错 if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123; Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException(\"Ambiguous handler methods mapped for HTTP path '\" + request.getRequestURL() + \"': &#123;\" + m1 + \", \" + m2 + \"&#125;\"); &#125; &#125; // 设置HttpServletRequest值 handleMatch(bestMatch.mapping, lookupPath, request); return bestMatch.handlerMethod; &#125; else &#123; // 没有找到匹配，返回null return handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request); &#125;&#125; 查看这行代码可以看到是通过url来获取this.mappingRegistry.getMappingsByUrl(lookupPath);，进入该方法，可以看到this.urlLookup是MappingRegistry类中的一个Map,直接通过 url为key得到值 123456789101112131415161718192021222324class MappingRegistry &#123; private final Map&lt;T, MappingRegistration&lt;T&gt;&gt; registry = new HashMap&lt;T, MappingRegistration&lt;T&gt;&gt;(); private final Map&lt;T, HandlerMethod&gt; mappingLookup = new LinkedHashMap&lt;T, HandlerMethod&gt;(); private final MultiValueMap&lt;String, T&gt; urlLookup = new LinkedMultiValueMap&lt;String, T&gt;(); private final Map&lt;String, List&lt;HandlerMethod&gt;&gt; nameLookup = new ConcurrentHashMap&lt;String, List&lt;HandlerMethod&gt;&gt;(); private final Map&lt;HandlerMethod, CorsConfiguration&gt; corsLookup = new ConcurrentHashMap&lt;HandlerMethod, CorsConfiguration&gt;(); private final ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(); ... */ public List&lt;T&gt; getMappingsByUrl(String urlPath) &#123; // MultiValueMap&lt;String, T&gt; urlLookup 就是个map return this.urlLookup.get(urlPath); &#125; 下图是this.urlLookup.get(urlPath) 的到的结果，返回的是个list image 返回到lookupHandlerMethod(String lookupPath, HttpServletRequest request) 方法，这里使用了Match做了匹配处理，得到最佳Match bestMatch 对象，最后返回HandlerMethod，在此终于得到了HandlerMethod 得到HandlerMethod对象之后，返回到getHandler(HttpServletRequest request)方法中，下面主要逻辑是整合了HandlerMethod及HandlerInterceptor并存放在HandlerExecutionChain对象 1234567891011121314151617181920212223242526272829303132/** * Look up a handler for the given request, falling back to the default * handler if no specific one is found. * @param request current HTTP request * @return the corresponding handler instance, or the default handler * @see #getHandlerInternal */@Overridepublic final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 在这里获取 处理器handler，模板方法实现， RequestMappingHandlerMapping 跳到 AbstractHandlerMethodMapping Object handler = getHandlerInternal(request); if (handler == null) &#123; handler = getDefaultHandler(); &#125; if (handler == null) &#123; return null; &#125; // Bean name or resolved handler? if (handler instanceof String) &#123; String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; // 获取 拦截器Interceptor HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; 3.1 总结 RequestMappingHandlerMapping 的主要功能就是通过 reqeust 获取 HandlerExecutionChain 的 HandlerMethod、Interceptor。 下图是RequestMappingHandlerMapping工作流程图，可以看到RequestMappingHandlerMapping 一个类的实现分了4层，HandlerMapping 接口定义顶级方法，两个抽象类又分两次封装，由上而下，逐渐细分功能 image 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(五)基于注解实现的RequestMappingHandlerMapping加载过程","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(五)基于注解实现的RequestMappingHandlerMapping加载过程","date":"2019-08-02T16:05:00.000Z","updated":"2019-09-16T13:11:06.164Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(五)基于注解实现的RequestMappingHandlerMapping加载过程/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(五)基于注解实现的RequestMappingHandlerMapping加载过程/","excerpt":"","text":"1.1 前言 上一章节介绍了请求映射处理组件HandlerMapping的主体处理流程，根据request url 获取对应的处理器Handler，这一章节来详细介绍我们平常最多使用的RequestMappingHandlerMapping的加载，这个HandlerMapping 是怎样加载基于@Controller,@RequestMapping 实现的Controller 2.1 解析 接下来我们关注RequestMappingHandlerMapping这个HandlerMapping，因为这个是我们开发过程中最为常用的HandlerMapping，那么它是怎样实现HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception; 这个方法，先看一下RequestMappingHandlerMapping的继承关系 image 2.1.1 RequestMappingHandlerMapping 加载过程 由上图可以看到RequestMappingHandlerMapping 的父类AbstractHandlerMethodMapping 实现了InitializingBean 接口，InitializingBean接口为bean提供了初始化方法的方式，它只包括afterPropertiesSet方法，凡是继承该接口的类， 在初始化bean的时候都会执行该方法。 1234567891011121314public interface InitializingBean &#123; /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;&#125; 下面是Spring Bean的生命周期图 查看AbstractHandlerMethodMapping类 afterPropertiesSet()的实现 1234567/** * Detects handler methods at initialization. */@Overridepublic void afterPropertiesSet() &#123; initHandlerMethods();&#125; 又抽象了一个方法，通过方法名可以得到它的用途是初始化HandlerMethods，进入initHandlerMethods(); 方法，这个方法是扫描ApplicationContext 所有的bean，如果发现了该bean所在的类有@Controller注解及@RequestMapping注解的话，则检查这个类的所有方法，如果是标注了@RequestMapping注解的方法则会注册为HandlerMethod 1234567891011121314151617181920212223242526272829303132333435363738/** * Scan beans in the ApplicationContext, detect and register handler methods. * @see #isHandler(Class) * @see #getMappingForMethod(Method, Class) * @see #handlerMethodsInitialized(Map) */protected void initHandlerMethods() &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Looking for request mappings in application context: \" + getApplicationContext()); &#125; // 首先拿到容器的所有的beanName数组 String[] beanNames = (this.detectHandlerMethodsInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(getApplicationContext(), Object.class) : getApplicationContext().getBeanNamesForType(Object.class)); for (String beanName : beanNames) &#123; if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; // 得到bean类型 Class&lt;?&gt; beanType = null; try &#123; beanType = getApplicationContext().getType(beanName); &#125; catch (Throwable ex) &#123; // An unresolvable bean type, probably from a lazy bean - let's ignore it. if (logger.isDebugEnabled()) &#123; logger.debug(\"Could not resolve target class for bean with name '\" + beanName + \"'\", ex); &#125; &#125; // 检查bean所在的类是否有Controller注解及RequestMapping注解 if (beanType != null &amp;&amp; isHandler(beanType)) &#123; // 负责将Handler保存到Map里 detectHandlerMethods(beanName); &#125; &#125; &#125; // 对Handler进行一些初始化，是一个模板方法 handlerMethodsInitialized(getHandlerMethods());&#125; String[] beanNames 示例 iamge 进入isHandler(beanType)方法，，此方法由RequestMappingHandlerMapping实现， 此方法检查bean所在的类是否有@Controller注解及@RequestMapping注解，可以看到此方法的实现是在RequestMappingHandlerMapping里，是不是看到了我们熟悉的两个注解 12345678910/** * 检查bean所在的类是否有Controller注解及RequestMapping注解 * &#123;@inheritDoc&#125; * Expects a handler to have a type-level @&#123;@link Controller&#125; annotation. */@Overrideprotected boolean isHandler(Class&lt;?&gt; beanType) &#123; return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) || AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class));&#125; 如果该bean有 Controller注解及RequestMapping注解，则执行detectHandlerMethods(beanName);方法，下面举个例子，我们有一个UserController里面有五个方法，下面来看是怎么处理这个类的 12345678910111213141516171819202122232425262728293031323334@RestController@RequestMapping(\"/pub/account\")public class UserController &#123; @Autowired private UserService userService; @GetMapping(\"/list\") public List&lt;User&gt; findAll() &#123; return userService.findAll(); &#125; @GetMapping(\"/view\") public User view() &#123; return userService.findById(1); &#125; @GetMapping(\"/&#123;id&#125;\") public User view(@PathVariable(\"id\") Integer id) &#123; return userService.findById(id); &#125; @PostMapping(\"/\") public void updateUser(@RequestBody User user) &#123; User user1 = userService.findById(user.getId()); user1.setUsername(\"update\"); userService.saveSelective(user1); &#125; @DeleteMapping(\"/&#123;id&#125;\") public void deleteUser(@PathVariable(\"id\") Integer id) &#123; userService.logicDeleteOne(id); &#125;&#125; 进入detectHandlerMethods(beanName);方法，可以看到Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods 获取到了我们五个方法，Map&lt;Method, T&gt; methods 以Method为key，RequestMappingInfo为value image 1234567891011121314151617181920212223242526272829303132333435/** * Look for handler methods in a handler. * @param handler the bean name of a handler or a handler instance */protected void detectHandlerMethods(final Object handler) &#123; // 获取Handler的类型 Class&lt;?&gt; handlerType = (handler instanceof String ? getApplicationContext().getType((String) handler) : handler.getClass()); final Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType); // 这里获取 RequestMapping方法，会过滤掉普通方法 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, new MethodIntrospector.MetadataLookup&lt;T&gt;() &#123; @Override public T inspect(Method method) &#123; try &#123; return getMappingForMethod(method, userType); &#125; catch (Throwable ex) &#123; throw new IllegalStateException(\"Invalid mapping on handler class [\" + userType.getName() + \"]: \" + method, ex); &#125; &#125; &#125;); if (logger.isDebugEnabled()) &#123; logger.debug(methods.size() + \" request handler methods found on \" + userType + \": \" + methods); &#125; for (Map.Entry&lt;Method, T&gt; entry : methods.entrySet()) &#123; Method invocableMethod = AopUtils.selectInvocableMethod(entry.getKey(), userType); T mapping = entry.getValue(); // 注册 mappingRegistry registerHandlerMethod(handler, invocableMethod, mapping); &#125;&#125; 进入getMappingForMethod(method, userType) ，此方法在RequestMappingHandlerMapping实现，这里解析分两步解析，一个是方法method解析，另一个是方法所在类handlerType的解析，然后拼接成一个RequestMappingInfo，可以看到也是对RequestMapping注解的解析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 没有使用 &#123;@code @RequestMapping&#125; 注解会返回null * Uses method and type-level @&#123;@link RequestMapping&#125; annotations to create * the RequestMappingInfo. * @return the created RequestMappingInfo, or &#123;@code null&#125; if the method * does not have a &#123;@code @RequestMapping&#125; annotation. * @see #getCustomMethodCondition(Method) * @see #getCustomTypeCondition(Class) */@Overrideprotected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123; // 解析method的@RequestMapping RequestMappingInfo info = createRequestMappingInfo(method); if (info != null) &#123; // 解析Class的@RequestMapping RequestMappingInfo typeInfo = createRequestMappingInfo(handlerType); if (typeInfo != null) &#123; // 合并两个RequestMappingInfo 比如url拼接 info = typeInfo.combine(info); &#125; &#125; // 不是RequestMapping方法返回null return info;&#125;private RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123; // 拿到注解 RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class); RequestCondition&lt;?&gt; condition = (element instanceof Class ? getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element)); return (requestMapping != null ? createRequestMappingInfo(requestMapping, condition) : null);&#125;protected RequestMappingInfo createRequestMappingInfo( RequestMapping requestMapping, RequestCondition&lt;?&gt; customCondition) &#123; // 用@RequestMapping的属性生成RequestMappingInfo return RequestMappingInfo .paths(resolveEmbeddedValuesInPatterns(requestMapping.path())) .methods(requestMapping.method()) .params(requestMapping.params()) .headers(requestMapping.headers()) .consumes(requestMapping.consumes()) .produces(requestMapping.produces()) .mappingName(requestMapping.name()) .customCondition(customCondition) .options(this.config) .build();&#125; RequestMappingInfo.java 对请求映射的一个抽象，它包含了请求路径，请求方法，请求头等信息。其实可以看做是@RequestMapping的一个对应类。 12345678910111213141516171819public final class RequestMappingInfo implements RequestCondition&lt;RequestMappingInfo&gt; &#123; private final String name; private final PatternsRequestCondition patternsCondition; private final RequestMethodsRequestCondition methodsCondition; private final ParamsRequestCondition paramsCondition; private final HeadersRequestCondition headersCondition; private final ConsumesRequestCondition consumesCondition; private final ProducesRequestCondition producesCondition; private final RequestConditionHolder customConditionHolder; ... 返回到detectHandlerMethods方法 123456789101112131415161718192021222324252627282930protected void detectHandlerMethods(final Object handler) &#123; // 获取Handler的类型 Class&lt;?&gt; handlerType = (handler instanceof String ? getApplicationContext().getType((String) handler) : handler.getClass()); final Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType); // 这里获取 RequestMapping方法，会过滤掉普通方法 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, new MethodIntrospector.MetadataLookup&lt;T&gt;() &#123; @Override public T inspect(Method method) &#123; try &#123; return getMappingForMethod(method, userType); &#125; catch (Throwable ex) &#123; throw new IllegalStateException(\"Invalid mapping on handler class [\" + userType.getName() + \"]: \" + method, ex); &#125; &#125; &#125;); if (logger.isDebugEnabled()) &#123; logger.debug(methods.size() + \" request handler methods found on \" + userType + \": \" + methods); &#125; for (Map.Entry&lt;Method, T&gt; entry : methods.entrySet()) &#123; Method invocableMethod = AopUtils.selectInvocableMethod(entry.getKey(), userType); T mapping = entry.getValue(); // 注册 mappingRegistry registerHandlerMethod(handler, invocableMethod, mapping); &#125;&#125; 得到Map&lt;Method, T&gt; methods之后，就是把这些信息保存起来，registerHandlerMethod(handler, invocableMethod, mapping); 这行代码就是做的这个功能 123456789101112131415161718192021222324252627282930313233343536373839404142protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method);&#125; public void register(T mapping, Object handler, Method method) &#123; // 加锁 this.readWriteLock.writeLock().lock(); try &#123; // 创建HandlerMethod HandlerMethod handlerMethod = createHandlerMethod(handler, method); assertUniqueMethodMapping(handlerMethod, mapping); if (logger.isInfoEnabled()) &#123; logger.info(\"Mapped \\\"\" + mapping + \"\\\" onto \" + handlerMethod); &#125; this.mappingLookup.put(mapping, handlerMethod); List&lt;String&gt; directUrls = getDirectUrls(mapping); for (String url : directUrls) &#123; this.urlLookup.add(url, mapping); &#125; String name = null; if (getNamingStrategy() != null) &#123; name = getNamingStrategy().getName(handlerMethod, mapping); addMappingName(name, handlerMethod); &#125; CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping); if (corsConfig != null) &#123; this.corsLookup.put(handlerMethod, corsConfig); &#125; /** * private final Map&lt;T, MappingRegistration&lt;T&gt;&gt; registry = new HashMap&lt;T, MappingRegistration&lt;T&gt;&gt;(); * key: RequestMappingInfo */ this.registry.put(mapping, new MappingRegistration&lt;T&gt;(mapping, handlerMethod, directUrls, name)); &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125;&#125; 查看private final Map&lt;T, MappingRegistration&lt;T&gt;&gt; registry 对象，见下图key值是RequestMappingInfo value是MappingRegistration image MappingRegistration.java 1234567891011private static class MappingRegistration&lt;T&gt; &#123; private final T mapping; private final HandlerMethod handlerMethod; private final List&lt;String&gt; directUrls; private final String mappingName; ... 3.1 总结 Spring Mvc提供了各种各样的抽象，你能感受到面向对象的魅力。 RequestMappingInfo 这个类是对请求映射的一个抽象，它包含了请求路径，请求方法，请求头等信息。其实可以看做是@RequestMapping的一个对应类。 HandlerMethod这个类封装了处理器实例（Controller Bean）和 处理方法实例（Method）以及方法参数数组（MethodParameter[]） MethodParameter 这个类从2.0就有了，它封装了方法某个参数的相关信息及行为，如该参数的索引，该参数所属方法实例或构造器实例，该参数的类型等。 HandlerMapping 该接口的实现类用来定义请求和处理器之前的映射关系，其中只定义了一个方法getHandler。 AbstractHandlerMethodMapping 这是HandlerMapping的一个基本实现类，该类定义了请求与HandlerMethod实例的映射关系。 RequestMappingInfoHandlerMapping这个是AbstractHandlerMethodMapping的实现类，他维护了一个RequestMappingInfo和HandlerMethod的Map属性。 RequestMappingHandlerMapping 这个是RequestMappingInfoHandlerMapping的子类，它将@RequestMapping注解转化为RequestMappingInfo实例，并为父类使用。也就是我们处理@RequestMapping的终点。 InitializingBean 这个接口定义了其实现Bean在容器完成属性设置后可以执行自定义初始化操作，我们的AbstractHandlerMethodMapping便实现了这个接口，并且定义了一组自定义操作，就是用来检测处理我们的@RequestMapping注解。 RequestMappingHandlerMapping 这个类的初始化过程主要是构建private final MappingRegistry mappingRegistry的过程，用于找出被@RequestMapping注解修饰的方法，并构造成HanderMethod对象，然后就是放到MappingRegistry mappingRegistry对象中，用于根据request找到对应的处理方法并调用 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html https://www.cnblogs.com/taotingkai/p/8438360.html","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(四)请求映射处理组件HandlerMapping","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(四)请求映射处理组件HandlerMapping","date":"2019-08-02T16:04:00.000Z","updated":"2019-09-16T13:11:06.254Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(四)请求映射处理组件HandlerMapping/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(四)请求映射处理组件HandlerMapping/","excerpt":"","text":"1.1 前言 上一章节介绍了Spring Mvc执行一个普通请求的整体流程，这一章节介绍其请求映射处理组件HandlerMapping 的作用 HandlerMapping负责根据request请求找到对应的Handler处理器及Interceptor拦截器,并将它们封装在HandlerExecutionChain对象内，返回给中央调度器 2.1 请求映射处理组件HandlerMapping 解析2.1.1 HandlerMapping 解析 先来回顾核心方法体doDispatch(HttpServletRequest request, HttpServletResponse response)，查看HandlerMapping 对应的处理逻辑 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; // 获取当前请求的WebAsyncManager，如果没找到则创建并与请求关联 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // 检查是否有 Multipart，有则将请求转换为 Multipart 请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. // 遍历所有的 HandlerMapping 找到与请求对应的 Handler，并将其与一堆拦截器封装到 HandlerExecution 对象中 mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. // 遍历所有的 HandlerAdapter，找到可以处理该 Handler 的 HandlerAdapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. // 处理 last-modified 请求头 String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. // 执行实际的处理程序 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); // 遍历拦截器，执行它们的 postHandle() 方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; // 处理执行结果，是一个 ModelAndView 或 Exception，然后进行渲染 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion // 遍历拦截器，执行它们的 afterCompletion() 方法 if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 下面是请求映射处理组件HandlerMapping 主要的处理代码 12345678910HandlerExecutionChain mappedHandler = null;...// Determine handler for the current request.// 遍历所有的 HandlerMapping 找到与请求对应的 Handler，并将其与一堆拦截器封装到 HandlerExecution 对象中mappedHandler = getHandler(processedRequest);if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return;&#125; 继续在doDispatch方法中mappedHandler = getHandler(processedRequest); 这行代码打好断点，进入该方法 12345678910111213141516171819202122232425 /** List of HandlerMappings used by this servlet */ private List&lt;HandlerMapping&gt; handlerMappings; /** * Return the HandlerExecutionChain for this request. * &lt;p&gt;Tries all handler mappings in order. * @param request current HTTP request * @return the HandlerExecutionChain, or &#123;@code null&#125; if no handler could be found */protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; // 循环handlerMappings eg: RequestMappingHandlerMapping、SimpleUrlHandlerMapping、BeanNameUrlHandlerMapping for (HandlerMapping hm : this.handlerMappings) &#123; if (logger.isTraceEnabled()) &#123; logger.trace( \"Testing handler map [\" + hm + \"] in DispatcherServlet with name '\" + getServletName() + \"'\"); &#125; // 遍历HandlerMapping实现类的找到对应的 HandlerExecutionChain HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; // 注意这里是找到第一个就直接返回 return handler; &#125; &#125; return null;&#125; 可以看到是遍历了this.handlerMappings这个对象，这个对象是个list， 在调试过程中，我们可以看到，默认加载的是如下图所示的的HandlerMapping， this.handlerMappings这个对象是怎么初始化的呢 回顾第二章节的DispatcherServlet的onRefresh(wac);方法 1234567891011121314151617181920protected void onRefresh(ApplicationContext context) &#123; // initStrategies方法内部会初始化各个策略接口的实现类。 initStrategies(context);&#125;protected void initStrategies(ApplicationContext context) &#123; // 上传组件组件初始化 initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); // 请求映射处理组件初始化 initHandlerMappings(context); // 处理适配器组建初始化 initHandlerAdapters(context); // 异常处理组件初始化 initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); // 视图处理组件初始化 initViewResolvers(context); initFlashMapManager(context);&#125; 进入initHandlerMappings(context); 方法 12345678910111213141516171819202122232425262728293031323334private void initHandlerMappings(ApplicationContext context) &#123; this.handlerMappings = null; if (this.detectAllHandlerMappings) &#123; // Find all HandlerMappings in the ApplicationContext, including ancestor contexts. // 在ApplicationContext bean中找到所有HandlerMappings， beansOfTypeIncludingAncestors 返回给定类型或子类型的所有bean Map&lt;String, HandlerMapping&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerMappings = new ArrayList&lt;HandlerMapping&gt;(matchingBeans.values()); // We keep HandlerMappings in sorted order. AnnotationAwareOrderComparator.sort(this.handlerMappings); &#125; &#125; else &#123; try &#123; HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class); this.handlerMappings = Collections.singletonList(hm); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we'll add a default HandlerMapping later. &#125; &#125; // Ensure we have at least one HandlerMapping, by registering // a default HandlerMapping if no other mappings are found. if (this.handlerMappings == null) &#123; // 在这里将设置 this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class); if (logger.isDebugEnabled()) &#123; logger.debug(\"No HandlerMappings found in servlet '\" + getServletName() + \"': using default\"); &#125; &#125;&#125; 关注this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class); 这行代码，可以看到this.handlerMappings 在这里赋值，继续进入该方法 1234567891011121314151617181920212223242526272829protected &lt;T&gt; List&lt;T&gt; getDefaultStrategies(ApplicationContext context, Class&lt;T&gt; strategyInterface) &#123; String key = strategyInterface.getName(); String value = defaultStrategies.getProperty(key); if (value != null) &#123; String[] classNames = StringUtils.commaDelimitedListToStringArray(value); List&lt;T&gt; strategies = new ArrayList&lt;T&gt;(classNames.length); for (String className : classNames) &#123; try &#123; Class&lt;?&gt; clazz = ClassUtils.forName(className, DispatcherServlet.class.getClassLoader()); Object strategy = createDefaultStrategy(context, clazz); strategies.add((T) strategy); &#125; catch (ClassNotFoundException ex) &#123; throw new BeanInitializationException( \"Could not find DispatcherServlet's default strategy class [\" + className + \"] for interface [\" + key + \"]\", ex); &#125; catch (LinkageError err) &#123; throw new BeanInitializationException( \"Error loading DispatcherServlet's default strategy class [\" + className + \"] for interface [\" + key + \"]: problem with class file or dependent class\", err); &#125; &#125; return strategies; &#125; else &#123; return new LinkedList&lt;T&gt;(); &#125; &#125; 从可以看到String value = defaultStrategies.getProperty(key); 这里使用了我们的配置对象private static final Properties defaultStrategies; defaultStrategies 是哪里初始化的呢？可以看到是在static代码块中读取一个配置文件并把它注册为Properties defaultStrategies对象 123456789101112131415161718192021/** * Name of the class path resource (relative to the DispatcherServlet class) * that defines DispatcherServlet's default strategy names. */private static final String DEFAULT_STRATEGIES_PATH = \"DispatcherServlet.properties\";... static &#123; // Load default strategy implementations from properties file. // This is currently strictly internal and not meant to be customized // by application developers. try &#123; // DEFAULT_STRATEGIES_PATH: DispatcherServlet.properties ClassPathResource resource = new ClassPathResource(DEFAULT_STRATEGIES_PATH, DispatcherServlet.class); defaultStrategies = PropertiesLoaderUtils.loadProperties(resource); &#125; catch (IOException ex) &#123; throw new IllegalStateException(\"Could not load '\" + DEFAULT_STRATEGIES_PATH + \"': \" + ex.getMessage()); &#125; &#125; 这里是读取了DEFAULT_STRATEGIES_PATH变量，查看变量可以发现是DispatcherServlet.properties，所以查看DispatcherServlet.properties文件，该文件在Spring web mvc 包下 123456789101112131415161718192021222324# Default implementation classes for DispatcherServlet&apos;s strategy interfaces.# Used as fallback when no matching beans are found in the DispatcherServlet context.# Not meant to be customized by application developers.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager 上面配置的了org.springframework.web.servlet.HandlerMapping默认有BeanNameUrlHandlerMapping及DefaultAnnotationHandlerMapping，所以之后执行createDefaultStrategy 方法就是根据Class对象来创建bean 123protected Object createDefaultStrategy(ApplicationContext context, Class&lt;?&gt; clazz) &#123; return context.getAutowireCapableBeanFactory().createBean(clazz);&#125; 下面来介绍三种常用的HandlerMapping的作用 RequestMappingHandlerMapping是三个中最常用的handlerMapping，使用注解方式最为方便快捷，SpringMvc项目开发都是采用这种形式，配合@RequestMapping()相关注释就可以完成开发 12345678910111213141516171819&lt;!-- 注册HandlerMapper、HandlerAdapter两个映射类 --&gt;&lt;mvc:annotation-driven /&gt; &lt;!-- 访问静态资源 --&gt;&lt;mvc:default-servlet-handler /&gt; &lt;!-- 配置扫描的包 --&gt;&lt;context:component-scan base-package=\"com.songsy.*\" /&gt; @RestController@RequestMapping(\"/hello\")public class HelloController &#123; protected final Log logger = LogFactory.getLog(this.getClass()); @RequestMapping(\"/index\") public String index()&#123; return \"test\"; &#125;&#125; SimpleUrlHandlerMapping SimpleUrlHandlerMapping的Controller处理类需要实现Controller接口，并注册成Bean就可以完成配置，处理逻辑写在handleRequest方法体内 12345678910111213141516171819&lt;bean class=\"org.springframework.web.servlet.handler.SimpleUrlHandlerMapping\"&gt; &lt;property name=\"mappings\"&gt; &lt;props&gt; &lt;prop key=\"/simpleUrlHandlerMapping.do\"&gt;welcomeController&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt;/** * @author Rob Harrop */public class WelcomeController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) &#123; return new ModelAndView(\"welcomeView\"); &#125;&#125; BeanNameUrlHandlerMapping需要配置 &lt;bean id=&quot;/index&quot; class=&quot;com.alipay.web.TestController&quot; /&gt;，注意在bean的id中要加上斜杆，Controller方面的测试代码跟前面的SimpleUrlHandlerMapping一样，实现Controller，重写handlerRequest()方法即可。 下一章节来跟进RequestMappingHandlerMapping这个HandlerMapping 的具体实现 3.1 总结 HandlerMapping我们知道他的作用是根据request找到对应的Handler，Handler具体表现形式可以为类，也可以为方法，上面的三种常用的HandlerMapping有其介绍，我们平常使用@RequestMapping注解来标识一个方法，这个注解的作用就是将这个方法注册为Handler 为什么需要要多种HandlerMapping呢，当然是为了其可扩展性，实现HandlerMapping接口就可以实现自定义Handler的获取，从而实现定制化 Spring Mvc 大量使用了模版方法模式，父类定义流程，子类实现，而这些口子都是所谓的模板方法，可以自由指定，从而保证了灵活性，良好的抽象设计，是整个框架变得非常灵活 Spring Mvc 核心类中所有的变量声明，几乎都以接口的形式给出，并没有绑定在具体的实现类上 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html https://www.jianshu.com/p/e4f1c9326223 https://blog.csdn.net/gaoshan12345678910/article/details/81778587 https://blog.csdn.net/lang_programmer/article/details/71598042","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(三)核心分发器DispatcherServlet处理流程","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(三)核心分发器DispatcherServlet处理流程","date":"2019-08-02T16:03:00.000Z","updated":"2019-09-16T13:11:06.099Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(三)核心分发器DispatcherServlet处理流程/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(三)核心分发器DispatcherServlet处理流程/","excerpt":"","text":"1.1 前言上一章节介绍了DispatcherServlet的初始化过程，这一章节介绍核心分发器DispatcherServlet是怎样处理请求的 2.1 DispatcherServlet 处理请求过程 既然DispatcherServlet本身是Servlet，我们就要专注于它的service、doGet、doPost等相关方法，在FrameworkServlet里可以看到service、doGet、doPost这些方法的重载实现，可以看到都是流转到processRequest(request, response);这个方法中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Override the parent class implementation in order to intercept PATCH requests. */@Overrideprotected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; HttpMethod httpMethod = HttpMethod.resolve(request.getMethod()); if (HttpMethod.PATCH == httpMethod || httpMethod == null) &#123; processRequest(request, response); &#125; else &#123; super.service(request, response); &#125;&#125;/** * Delegate GET requests to processRequest/doService. * &lt;p&gt;Will also be invoked by HttpServlet's default implementation of &#123;@code doHead&#125;, * with a &#123;@code NoBodyResponse&#125; that just captures the content length. * @see #doService * @see #doHead */@Overrideprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;/** * Delegate POST requests to &#123;@link #processRequest&#125;. * @see #doService */@Overrideprotected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;/** * Delegate PUT requests to &#123;@link #processRequest&#125;. * @see #doService */@Overrideprotected final void doPut(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125;/** * Delegate DELETE requests to &#123;@link #processRequest&#125;. * @see #doService */@Overrideprotected final void doDelete(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125; 根据service方法，我们一步步找到一个方法链service –&gt; processRequest –&gt; doService –&gt; doDispatch，我们最终将目光定位在doDispatch，因为从它的方法体就可以看出它是整个SpringMVC的核心方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * Process the actual dispatching to the handler. * &lt;p&gt;The handler will be obtained by applying the servlet's HandlerMappings in order. * The HandlerAdapter will be obtained by querying the servlet's installed HandlerAdapters * to find the first that supports the handler class. * &lt;p&gt;All HTTP methods are handled by this method. It's up to HandlerAdapters or handlers * themselves to decide which methods are acceptable. * @param request current HTTP request * @param response current HTTP response * @throws Exception in case of any kind of processing failure */protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; // 获取当前请求的WebAsyncManager，如果没找到则创建并与请求关联 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // 检查是否有 Multipart，有则将请求转换为 Multipart 请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. // 遍历所有的 HandlerMapping 找到与请求对应的 Handler，并将其与一堆拦截器封装到 HandlerExecution 对象中 mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. // 遍历所有的 HandlerAdapter，找到可以处理该 Handler 的 HandlerAdapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. // 处理 last-modified 请求头 String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. // 执行实际的处理程序 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); // 遍历拦截器，执行它们的 postHandle() 方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; // 处理执行结果，是一个 ModelAndView 或 Exception，然后进行渲染 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion // 遍历拦截器，执行它们的 afterCompletion() 方法 if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 说它是核心一点也不为过，从上述代码的中文注释可以看出，它包含了解析请求，执行相关拦截器，执行handle方法，这行代码是真正执行我们controller的方法mv = ha.handle(processedRequest, response, mappedHandler.getHandler());，那SpringMvc是怎样找到我们的方法的呢，下面的章节将介绍 3.1 总结 Spring Mvc 的处理方式是先在顶层设计好整体结构，然后将具体的处理交给不同的组件具体去实现 DispatcherServlet中的doDispatch方法完成了具体的请求处理，下面是主要流程 遍历所有的 HandlerMapping 找到与请求对应的 Handler，并将其与一堆拦截器封装到 HandlerExecutionChain 对象中 遍历所有的 HandlerAdapter，找到可以处理该 Handler 的 HandlerAdapter 执行相应拦截器Interceptor的preHandle方法 HandlerAdapter 执行Hander，由Hander 执行实际的处理程序，执行Controller里的方法 调用processDispatchResult处理结果 执行相应拦截器Interceptor的postHandle方法 本章只是介绍下Spring MVC的主要流程，下面的章节将详细介绍这些流程，下面是流程图 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html http://www.cnblogs.com/fangjian0423/p/springMVC-dispatcherServlet.html https://blog.csdn.net/lang_programmer/article/details/71598042","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(二)核心分发器DispatcherServlet初始化","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(二)核心分发器DispatcherServlet初始化","date":"2019-08-02T16:02:00.000Z","updated":"2020-01-04T12:21:52.227Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(二)核心分发器DispatcherServlet初始化/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(二)核心分发器DispatcherServlet初始化/","excerpt":"","text":"1.1 前言我们都知道DispatcherServlet是前端控制器，是整个Spring Mvc的入口，但是这个前端控制器里面又有很多箱子，每一个箱子都有其独有的功能，当我们翻开一个箱子之后看看里面有什么的时候，又会发现箱子里面装着又一个箱子，所以我们需要一个个的探究这些箱子。 2.1 DispatcherServlet 初始化过程2.1.1 配置 DispatcherServlet 首先，Tomcat每次启动时都会加载并解析/WEB-INF/web.xml文件，所以可以先从web.xml找突破口，主要代码如下 1234567891011121314151617181920212223242526&lt;!-- 初始化参数 需要告诉Spring配置文件的位置 --&gt;&lt;init-param &gt; &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/applicationContext.xml&lt;/param-value&gt;&lt;/init-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt;&lt;servlet &gt; &lt;servlet-name &gt;spring-mvc&lt;/servlet-name&gt; &lt;!-- servlet类 --&gt; &lt;servlet-class &gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 初始化参数 --&gt; &lt;init-param &gt; &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 启动时加载 --&gt; &lt;load-on-startup &gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping &gt; &lt;servlet-name &gt;spring-mvc&lt;/servlet-name&gt; &lt;url-pattern &gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 2.1.1.1 ContextLoaderListener 先来看下面的配置文件，这里配置了Spring的配置文件路径及一个监听类ContextLoaderListener 1234567&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; 我们知道在是使用Spring的时候通常是使用ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);的方式来获取Spring容器的，现在我们是要将Spring容器与Web环境联系起来，所以需要通过这个类ContextLoaderListener将两者联系起来，那么它是怎么实现联系的呢？ 查看ContextLoaderListener类，可以看到它实现了ServletContextListener这个接口，这个是属于Servlet的类，如果实现了ServletContextListener这个接口，在web.xml配置这个监听器，启动容器时，就会默认执行它实现的方法contextInitialized()及contextDestroyed() 12345678910111213141516171819202122232425262728293031323334353637383940// org.springframework.web.context.ContextLoaderListenerpublic class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public ContextLoaderListener() &#123;&#125; public ContextLoaderListener(WebApplicationContext context) &#123; super(context); &#125; /** * ServletContext启动之后会调用此方法 * * Initialize the root web application context. */ @Override public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext()); &#125; /** * ServletContext关闭之后会调用此方法 * * Close the root web application context. */ @Override public void contextDestroyed(ServletContextEvent event) &#123; closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125;&#125;// javax.servlet.ServletContextListenerpublic interface ServletContextListener extends EventListener &#123; public void contextInitialized(ServletContextEvent sce); public void contextDestroyed(ServletContextEvent sce);&#125; ContextLoaderListener类继承关系 1、ServletContext启动之后会调用此方法contextInitialized(ServletContextEvent event) 进入此方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; // web.xml中存在多次ContextLoader定义抛异常 if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException( \"Cannot initialize context because there is already a root application context present - \" + \"check whether you have multiple ContextLoader* definitions in your web.xml!\"); &#125; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log(\"Initializing Spring root WebApplicationContext\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Root WebApplicationContext: initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. if (this.context == null) &#123; // 创建WebApplicationContext this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; // 构造Spring容器 configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; // 将WebApplicationContext记录在servletContext中 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; // 映射当前的类加载器与创建的实例到全局变量中currentContextPerThread currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Published root WebApplicationContext as ServletContext attribute with name [\" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + \"]\"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info(\"Root WebApplicationContext: initialization completed in \" + elapsedTime + \" ms\"); &#125; return this.context; &#125; catch (RuntimeException ex) &#123; logger.error(\"Context initialization failed\", ex); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; logger.error(\"Context initialization failed\", err); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125;&#125; 可以看到上面主要逻辑分为以下几个步骤 1、创建WebApplicationContext对象 代码12345678protected WebApplicationContext createWebApplicationContext(ServletContext sc) &#123; Class&lt;?&gt; contextClass = determineContextClass(sc); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException(\"Custom context class [\" + contextClass.getName() + \"] is not of type [\" + ConfigurableWebApplicationContext.class.getName() + \"]\"); &#125; return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; 2、构造Spring容器，这个很重要 进入configureAndRefreshWebApplicationContext(cwac, servletContext);，可以看到主要逻辑是读取了我们上面配置的contextConfigLocation配置路径，然后执行了wac.refresh();方法，这个方法是构造Spring容器的核心方法12345678910111213141516171819202122232425262728293031323334353637383940protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; // The application context id is still set to its original default value // -&gt; assign a more useful id based on available information String idParam = sc.getInitParameter(CONTEXT_ID_PARAM); if (idParam != null) &#123; wac.setId(idParam); &#125; else &#123; // Generate default id... wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; // 在Spring也存一份ServletContext wac.setServletContext(sc); /** * 读取contextConfigLocation配置路径 * &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; */ String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (configLocationParam != null) &#123; wac.setConfigLocation(configLocationParam); &#125; // The wac environment's #initPropertySources will be called in any case when the context // is refreshed; do it eagerly here to ensure servlet property sources are in place for // use in any post-processing or initialization that occurs below prior to #refresh ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(sc, null); &#125; customizeContext(sc, wac); // 核心 refresh()方法 wac.refresh();&#125; 3、构建完成之后将此对象放在servletContext中，这样就可以在Web服务中使用Spring容器了，开发者能够在客户端请求提供服务之前向ServletContext中添加任意的对象，ServletContext在web容器运行期间都是可见的 代码1servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); 4、映射当前的类加载器与创建的实例到全局变量中currentContextPerThread中 代码 12345678910111213141516171819202122/** * Map from (thread context) ClassLoader to corresponding 'current' WebApplicationContext. */private static final Map&lt;ClassLoader, WebApplicationContext&gt; currentContextPerThread = new ConcurrentHashMap&lt;ClassLoader, WebApplicationContext&gt;(1); /** * The 'current' WebApplicationContext, if the ContextLoader class is * deployed in the web app ClassLoader itself. */private static volatile WebApplicationContext currentContext; ... ClassLoader ccl = Thread.currentThread().getContextClassLoader();if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context;&#125;else if (ccl != null) &#123; // 映射当前的类加载器与创建的实例到全局变量中currentContextPerThread currentContextPerThread.put(ccl, this.context);&#125; 2、ServletContext关闭之后会调用此方法contextDestroyed(ServletContextEvent event) 这里的逻辑主要是销毁Spring容器及清理Web容器1234567891011121314151617181920212223242526@Overridepublic void contextDestroyed(ServletContextEvent event) &#123; closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext());&#125; public void closeWebApplicationContext(ServletContext servletContext) &#123; servletContext.log(\"Closing Spring root WebApplicationContext\"); try &#123; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ((ConfigurableWebApplicationContext) this.context).close(); &#125; &#125; finally &#123; ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = null; &#125; else if (ccl != null) &#123; currentContextPerThread.remove(ccl); &#125; servletContext.removeAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE); if (this.parentContextRef != null) &#123; this.parentContextRef.release(); &#125; &#125; &#125; 2.1.1.2 DispatcherServlet 上面通过ContextLoaderListener已经将Spring容器构建起来了并与Web容器联系起来了，但Spring MVC的核心逻辑是在DispatcherServlet中进行的，这就是下面web.xml配置的 12345678910111213141516&lt;servlet &gt; &lt;servlet-name &gt;spring-mvc&lt;/servlet-name&gt; &lt;!-- servlet类 --&gt; &lt;servlet-class &gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 初始化参数 --&gt; &lt;init-param &gt; &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 启动时加载 --&gt; &lt;load-on-startup &gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping &gt; &lt;servlet-name &gt;spring-mvc&lt;/servlet-name&gt; &lt;url-pattern &gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 可以看到 DispatcherServlet 本身就是个Servlet，servlet的生命周期是由servlet容器来控制的，可分为以下几个阶段： 1、初始化阶段: 先加载servlet类并构建，然后执行其init()方法进行初始化，这个步骤只会执行一次 2、运行阶段：当servlet容器收到一个请求时，会创建servletRequest和servletResponse对象，并其将作为参数调用service()方法，执行业务逻辑 3、销毁阶段：销毁当然是销毁servlet，释放servlet所占用的资源，比如关闭数据库连接，关闭文件输入输出类等等 上面回顾了一些servlet的一些知识，那么DispatcherServlet也是围绕这几个阶段来处理请求的，下面看看DispatcherServlet做了什么呢，我们先看下DispatcherServlet的继承关系，重点关注HttpServletBean 和FrameworkServlet 这两个类 12345GenericServlet (javax.servlet) HttpServlet (javax.servlet.http) HttpServletBean (org.springframework.web.servlet) FrameworkServlet (org.springframework.web.servlet) DispatcherServlet (org.springframework.web.servlet) 通过上图可以看到 DispatcherServlet 实现了Spring 的ApplicationContextAware、EnvironmentCapable、 EnvironmentAware这些Spring中的接口，XXXAware在Spring中表示对XXX可以感知，通俗点可以说在某个类中想使用Spring的一些东西，就可以实现XXXAware接口告诉Spring我要这个东西，比如ApplicationContextAware，该接口只有一个方法就是setApplicationContext(ApplicationContext applicationContext), 通过该方法可以得到ApplicationContext，Spring容器会检测容器中的所有Bean，如果发现某个Bean实现了ApplicationContextAware接口，Spring容器会在创建该Bean之后，自动调用该Bean的setApplicationContextAware()方法，调用该方法时，会将容器本身作为参数传给该方法——该方法中的实现部分将Spring传入的参数（容器本身）赋给该类对象的applicationContext实例变量，因此接下来可以通过该applicationContext实例变量来访问容器本身。实现XXXCapable接口表示可以得到某种能力，实现EnvironmentCapable接口说明可以得到Environment的能力，也就是可以提供Environment ApplicationContextAware 代码1234567@Overridepublic void setApplicationContext(ApplicationContext applicationContext) &#123; if (this.webApplicationContext == null &amp;&amp; applicationContext instanceof WebApplicationContext) &#123; this.webApplicationContext = (WebApplicationContext) applicationContext; this.webApplicationContextInjected = true; &#125;&#125; EnvironmentCapable 代码1234567@Override public ConfigurableEnvironment getEnvironment() &#123; if (this.environment == null) &#123; this.environment = createEnvironment(); &#125; return this.environment; &#125; 2.1.1.2.1 父类HttpServletBean HttpServletBean 覆写了GenericServlet 的init方法，此方法是第一次访问该DispatcherServlet的时候就会执行，对初始化过程做了一些处理，HttpServletBean 这个类的作用主要做一些初始化的工作，将web.xml中配置的参数设置到ServletConfig中。比如servlet标签的子标签init-param标签中配置的参数(classpath:/spring-mvc.xml)，第二个就是调用FrameworkServlet子类方法构建及发布WebApplicationContext 1234567891011121314151617181920212223242526272829303132333435@Overridepublic final void init() throws ServletException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Initializing servlet '\" + getServletName() + \"'\"); &#125; // 构造过程中会使用ServletConfig对象找出web.xml配置文件中的配置参数 比如web.xml配置的&lt;init-param &gt; // 并设置到ServletConfig // Set bean properties from init parameters. PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; // 使用BeanWrapper构造DispatcherServlet BeanWrapper是Spring提供用来操作JavaBean属性的工具，使用它可以直接修改一个对象的属性 BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); // 模板方法 initBeanWrapper(bw); // 设置DispatcherServlet属性 bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; if (logger.isErrorEnabled()) &#123; logger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex); &#125; throw ex; &#125; &#125; // 触发子类&#123;@link FrameworkServlet#initServletBean() &#125; 用构建及发布WebApplicationContext initServletBean(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Servlet '\" + getServletName() + \"' configured successfully\"); &#125;&#125; 2.1.1.2.2 父类FrameworkServlet 关注initServletBean()方法，该方法的实现在FrameworkServlet 类里，这个类的作用是将Servlet与Spring容器上下文关联。其实也就是初始化FrameworkServlet的属性webApplicationContext 1234567891011121314151617181920212223242526272829303132/** * Overridden method of &#123;@link HttpServletBean&#125;, invoked after any bean properties * have been set. Creates this servlet's WebApplicationContext. */@Overrideprotected final void initServletBean() throws ServletException &#123; getServletContext().log(\"Initializing Spring FrameworkServlet '\" + getServletName() + \"'\"); if (this.logger.isInfoEnabled()) &#123; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization started\"); &#125; long startTime = System.currentTimeMillis(); try &#123; // 初始化 WebApplicationContext (即SpringMVC的IOC容器) this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; catch (RuntimeException ex) &#123; this.logger.error(\"Context initialization failed\", ex); throw ex; &#125; if (this.logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; this.logger.info(\"FrameworkServlet '\" + getServletName() + \"': initialization completed in \" + elapsedTime + \" ms\"); &#125;&#125; 进入this.webApplicationContext = initWebApplicationContext();方法，这个方法的作用是先得到根上下文rootContext 然后创建webApplicationContext并设置根上下文（将 Spring 的容器设为 SpringMVC 容器的父容器），这里的容器涉及到两个，一个是Spring父容器，另一个是SpringMVC 容器，所以需要把这两个容器合并，最后就是发布这个整合版的 WebApplicationContext 容器到 ServletContext 中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * Initialize and publish the WebApplicationContext for this servlet. * &lt;p&gt;Delegates to &#123;@link #createWebApplicationContext&#125; for actual creation * of the context. Can be overridden in subclasses. * @return the WebApplicationContext instance * @see #FrameworkServlet(WebApplicationContext) * @see #setContextClass * @see #setContextConfigLocation */protected WebApplicationContext initWebApplicationContext() &#123; // 获取ContextLoaderListener 初始化并注册在 ServletContext 中的Spring 的容器容器，这里是父容器 WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // A context instance was injected at construction time -&gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; set // the root application context (if any; may be null) as the parent // 将 Spring 的容器设为 SpringMVC 容器的父容器 cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; // No context instance was injected at construction time -&gt; see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id // 如果 WebApplicationContext 为空，则进行查找，能找到说明上下文已经在别处初始化。 wac = findWebApplicationContext(); &#125; if (wac == null) &#123; // No context instance is defined for this servlet -&gt; create a local one // 如果 WebApplicationContext 仍为空，则以 Spring 的容器为父上下文建立一个新的，并设置根上下文为父上下文 wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -&gt; trigger initial onRefresh manually here. // 模版方法，由 DispatcherServlet 实现 onRefresh(wac); &#125; if (this.publishContext) &#123; // Publish the context as a servlet context attribute. // 发布这个 WebApplicationContext 容器到 ServletContext 中 String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Published WebApplicationContext of servlet '\" + getServletName() + \"' as ServletContext attribute with name [\" + attrName + \"]\"); &#125; &#125; return wac;&#125; Spring父容器 回顾上面的配置文件的配置，这里就是指定了Spring父容器的配置 1234&lt;init-param &gt; &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/applicationContext.xml&lt;/param-value&gt;&lt;/init-param&gt; 父容器的构建关注WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext());方法，这里是就是获取我们上面在ContextLoaderListener 初始化并注册在 ServletContext 的WebApplicationContext 进入此方法，可以看到是直接从ServletContext中获取sc.getAttribute(attrName); 123456789101112131415161718192021222324 public static WebApplicationContext getWebApplicationContext(ServletContext sc) &#123; return getWebApplicationContext(sc, WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE);&#125;public static WebApplicationContext getWebApplicationContext(ServletContext sc, String attrName) &#123; Assert.notNull(sc, \"ServletContext must not be null\"); // 从ServletContext中获取 Object attr = sc.getAttribute(attrName); if (attr == null) &#123; return null; &#125; if (attr instanceof RuntimeException) &#123; throw (RuntimeException) attr; &#125; if (attr instanceof Error) &#123; throw (Error) attr; &#125; if (attr instanceof Exception) &#123; throw new IllegalStateException((Exception) attr); &#125; if (!(attr instanceof WebApplicationContext)) &#123; throw new IllegalStateException(\"Context attribute is not of type WebApplicationContext: \" + attr); &#125; return (WebApplicationContext) attr;&#125; 这里的WebApplicationContext的值是什么时候弄进去的呢，回顾一下ContextLoaderListener的initWebApplicationContext()方法，下面第三步servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);就把WebApplicationContext赋值到了ServletContext中 123456789101112131415161718192021222324252627282930public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; ... try &#123; // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. if (this.context == null) &#123; // 1、创建WebApplicationContext this.context = createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; // 2、构造Spring容器 configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; // 3、将WebApplicationContext记录在servletContext中 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);... SpringMVC 容器 回顾上面的配置文件的配置，这里就是指定了SpringMVC父容器的配置 1234&lt;init-param &gt; &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/spring-mvc.xml&lt;/param-value&gt;&lt;/init-param&gt; SpringMVC 容器的构建关注wac = createWebApplicationContext(rootContext);方法，这里是以 Spring父容器为基础构建一个新的SpringMVC 容器 123456789101112131415161718192021222324252627282930313233343536protected WebApplicationContext createWebApplicationContext(WebApplicationContext parent) &#123; return createWebApplicationContext((ApplicationContext) parent);&#125;protected WebApplicationContext createWebApplicationContext(ApplicationContext parent) &#123; Class&lt;?&gt; contextClass = getContextClass(); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Servlet with name '\" + getServletName() + \"' will try to create custom WebApplicationContext context of class '\" + contextClass.getName() + \"'\" + \", using parent context [\" + parent + \"]\"); &#125; if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException( \"Fatal initialization error in servlet with name '\" + getServletName() + \"': custom WebApplicationContext class [\" + contextClass.getName() + \"] is not of type ConfigurableWebApplicationContext\"); &#125; ConfigurableWebApplicationContext wac = (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass); wac.setEnvironment(getEnvironment()); wac.setParent(parent); /** * 这里配置了ConfigLocation * * &lt;init-param &gt; * &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; * &lt;param-value &gt;classpath:/spring-mvc.xml&lt;/param-value&gt; * &lt;/init-param&gt; */ wac.setConfigLocation(getContextConfigLocation()); configureAndRefreshWebApplicationContext(wac); return wac;&#125; 上面已经得到了SpringMVC 的容器，继续走下面的逻辑 1234567if (!this.refreshEventReceived) &#123; // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -&gt; trigger initial onRefresh manually here. // 刷新Spring MVC，模版方法，由 DispatcherServlet 实现 onRefresh(wac);&#125; 进入onRefresh(wac); 由 DispatcherServlet 实现，这里的操作就是Spring Mvc自身的初始化过程 12345678910111213141516171819202122232425262728293031/** * This implementation calls &#123;@link #initStrategies&#125;. */@Overrideprotected void onRefresh(ApplicationContext context) &#123; // initStrategies方法内部会初始化各个策略接口的实现类。 initStrategies(context); &#125;/** * Initialize the strategy objects that this servlet uses. * &lt;p&gt;May be overridden in subclasses in order to initialize further strategy objects. */protected void initStrategies(ApplicationContext context) &#123; // 上传组件初始化，注册后每个请求会检查是否包含multipart initMultipartResolver(context); // 国际化组件初始化 initLocaleResolver(context); // 主题解析器初始化 initThemeResolver(context); // 核心：请求映射处理组件初始化 initHandlerMappings(context); // 处理适配器组建初始化 initHandlerAdapters(context); // 异常处理组件初始化 initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); // 视图处理组件初始化 initViewResolvers(context); initFlashMapManager(context);&#125; 到这里SpringMVC 的容器已经初始完成了，那么就需要发布这个容器了，可以看到还是设置到ServletContext中，这样的话就可以在整个Web环境中使用该容器了 12345678910if (this.publishContext) &#123; // Publish the context as a servlet context attribute. // 发布这个 WebApplicationContext 容器到 ServletContext 中 String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Published WebApplicationContext of servlet '\" + getServletName() + \"' as ServletContext attribute with name [\" + attrName + \"]\"); &#125;&#125; 2.1.1 DispatcherServlet 默认加载bean DispatcherServlet 初始化的时候会默认加载一些组件，代码如下，可以看到是在static代码块中读取一个配置文件并把它注册为Properties defaultStrategies对象 1234567891011121314151617181920/** * Name of the class path resource (relative to the DispatcherServlet class) * that defines DispatcherServlet's default strategy names. */private static final String DEFAULT_STRATEGIES_PATH = \"DispatcherServlet.properties\";... static &#123; // Load default strategy implementations from properties file. // This is currently strictly internal and not meant to be customized // by application developers. try &#123; ClassPathResource resource = new ClassPathResource(DEFAULT_STRATEGIES_PATH, DispatcherServlet.class); defaultStrategies = PropertiesLoaderUtils.loadProperties(resource); &#125; catch (IOException ex) &#123; throw new IllegalStateException(\"Could not load '\" + DEFAULT_STRATEGIES_PATH + \"': \" + ex.getMessage()); &#125; &#125; 查看DispatcherServlet.properties文件，该文件在Spring web mvc 包下 123456789101112131415161718192021222324# Default implementation classes for DispatcherServlet&apos;s strategy interfaces.# Used as fallback when no matching beans are found in the DispatcherServlet context.# Not meant to be customized by application developers.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager 从如上配置可以看出DispatcherServlet 配置的是一些类的全限定名，那它是在哪里调用的呢，还是回到之前的onRefresh(wac); 的initStrategies(ApplicationContext context)方法 2.1.2 自定义标签解析 如果需要使用Spring则需要添加上面的标签用于开启Spring MVC的功能，可以知道这个标签是属于Spring的自定义标签，所以找到对应的命名空间处理器NamespaceHandler 可以定位到MvcNamespaceHandler 123456789101112131415161718192021public class MvcNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser(\"annotation-driven\", new AnnotationDrivenBeanDefinitionParser()); registerBeanDefinitionParser(\"default-servlet-handler\", new DefaultServletHandlerBeanDefinitionParser()); registerBeanDefinitionParser(\"interceptors\", new InterceptorsBeanDefinitionParser()); registerBeanDefinitionParser(\"resources\", new ResourcesBeanDefinitionParser()); registerBeanDefinitionParser(\"view-controller\", new ViewControllerBeanDefinitionParser()); registerBeanDefinitionParser(\"redirect-view-controller\", new ViewControllerBeanDefinitionParser()); registerBeanDefinitionParser(\"status-controller\", new ViewControllerBeanDefinitionParser()); registerBeanDefinitionParser(\"view-resolvers\", new ViewResolversBeanDefinitionParser()); registerBeanDefinitionParser(\"tiles-configurer\", new TilesConfigurerBeanDefinitionParser()); registerBeanDefinitionParser(\"freemarker-configurer\", new FreeMarkerConfigurerBeanDefinitionParser()); registerBeanDefinitionParser(\"velocity-configurer\", new VelocityConfigurerBeanDefinitionParser()); registerBeanDefinitionParser(\"groovy-configurer\", new GroovyMarkupConfigurerBeanDefinitionParser()); registerBeanDefinitionParser(\"script-template-configurer\", new ScriptTemplateConfigurerBeanDefinitionParser()); registerBeanDefinitionParser(\"cors\", new CorsBeanDefinitionParser()); &#125;&#125; 关注registerBeanDefinitionParser(&quot;annotation-driven&quot;, new AnnotationDrivenBeanDefinitionParser()); 进入到AnnotationDrivenBeanDefinitionParser的parse方法，可以看到主要逻辑就是构造各种BeanDefinition并注册到容器中，可以发现有我们最常用RequestMappingHandlerMapping、RequestMappingHandlerAdapter、DefaultHandlerExceptionResolver等等，这些bean是Spring MVC的重要组成部分，具体功能在以后的章节将会介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; Object source = parserContext.extractSource(element); XmlReaderContext readerContext = parserContext.getReaderContext(); CompositeComponentDefinition compDefinition = new CompositeComponentDefinition(element.getTagName(), source); parserContext.pushContainingComponent(compDefinition); RuntimeBeanReference contentNegotiationManager = getContentNegotiationManager(element, source, parserContext); // 注册 RequestMappingHandlerMapping RootBeanDefinition handlerMappingDef = new RootBeanDefinition(RequestMappingHandlerMapping.class); handlerMappingDef.setSource(source); handlerMappingDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); handlerMappingDef.getPropertyValues().add(\"order\", 0); handlerMappingDef.getPropertyValues().add(\"contentNegotiationManager\", contentNegotiationManager); if (element.hasAttribute(\"enable-matrix-variables\")) &#123; Boolean enableMatrixVariables = Boolean.valueOf(element.getAttribute(\"enable-matrix-variables\")); handlerMappingDef.getPropertyValues().add(\"removeSemicolonContent\", !enableMatrixVariables); &#125; else if (element.hasAttribute(\"enableMatrixVariables\")) &#123; Boolean enableMatrixVariables = Boolean.valueOf(element.getAttribute(\"enableMatrixVariables\")); handlerMappingDef.getPropertyValues().add(\"removeSemicolonContent\", !enableMatrixVariables); &#125; configurePathMatchingProperties(handlerMappingDef, element, parserContext); readerContext.getRegistry().registerBeanDefinition(HANDLER_MAPPING_BEAN_NAME , handlerMappingDef); RuntimeBeanReference corsConfigurationsRef = MvcNamespaceUtils.registerCorsConfigurations(null, parserContext, source); handlerMappingDef.getPropertyValues().add(\"corsConfigurations\", corsConfigurationsRef); RuntimeBeanReference conversionService = getConversionService(element, source, parserContext); RuntimeBeanReference validator = getValidator(element, source, parserContext); RuntimeBeanReference messageCodesResolver = getMessageCodesResolver(element); // 注册 ConfigurableWebBindingInitializer RootBeanDefinition bindingDef = new RootBeanDefinition(ConfigurableWebBindingInitializer.class); bindingDef.setSource(source); bindingDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); bindingDef.getPropertyValues().add(\"conversionService\", conversionService); bindingDef.getPropertyValues().add(\"validator\", validator); bindingDef.getPropertyValues().add(\"messageCodesResolver\", messageCodesResolver); ManagedList&lt;?&gt; messageConverters = getMessageConverters(element, source, parserContext); ManagedList&lt;?&gt; argumentResolvers = getArgumentResolvers(element, parserContext); ManagedList&lt;?&gt; returnValueHandlers = getReturnValueHandlers(element, parserContext); String asyncTimeout = getAsyncTimeout(element); RuntimeBeanReference asyncExecutor = getAsyncExecutor(element); ManagedList&lt;?&gt; callableInterceptors = getCallableInterceptors(element, source, parserContext); ManagedList&lt;?&gt; deferredResultInterceptors = getDeferredResultInterceptors(element, source, parserContext); // 注册 RequestMappingHandlerAdapter RootBeanDefinition handlerAdapterDef = new RootBeanDefinition(RequestMappingHandlerAdapter.class); handlerAdapterDef.setSource(source); handlerAdapterDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); handlerAdapterDef.getPropertyValues().add(\"contentNegotiationManager\", contentNegotiationManager); handlerAdapterDef.getPropertyValues().add(\"webBindingInitializer\", bindingDef); handlerAdapterDef.getPropertyValues().add(\"messageConverters\", messageConverters); addRequestBodyAdvice(handlerAdapterDef); addResponseBodyAdvice(handlerAdapterDef); if (element.hasAttribute(\"ignore-default-model-on-redirect\")) &#123; Boolean ignoreDefaultModel = Boolean.valueOf(element.getAttribute(\"ignore-default-model-on-redirect\")); handlerAdapterDef.getPropertyValues().add(\"ignoreDefaultModelOnRedirect\", ignoreDefaultModel); &#125; else if (element.hasAttribute(\"ignoreDefaultModelOnRedirect\")) &#123; // \"ignoreDefaultModelOnRedirect\" spelling is deprecated Boolean ignoreDefaultModel = Boolean.valueOf(element.getAttribute(\"ignoreDefaultModelOnRedirect\")); handlerAdapterDef.getPropertyValues().add(\"ignoreDefaultModelOnRedirect\", ignoreDefaultModel); &#125; if (argumentResolvers != null) &#123; handlerAdapterDef.getPropertyValues().add(\"customArgumentResolvers\", argumentResolvers); &#125; if (returnValueHandlers != null) &#123; handlerAdapterDef.getPropertyValues().add(\"customReturnValueHandlers\", returnValueHandlers); &#125; if (asyncTimeout != null) &#123; handlerAdapterDef.getPropertyValues().add(\"asyncRequestTimeout\", asyncTimeout); &#125; if (asyncExecutor != null) &#123; handlerAdapterDef.getPropertyValues().add(\"taskExecutor\", asyncExecutor); &#125; handlerAdapterDef.getPropertyValues().add(\"callableInterceptors\", callableInterceptors); handlerAdapterDef.getPropertyValues().add(\"deferredResultInterceptors\", deferredResultInterceptors); readerContext.getRegistry().registerBeanDefinition(HANDLER_ADAPTER_BEAN_NAME , handlerAdapterDef); String uriCompContribName = MvcUriComponentsBuilder.MVC_URI_COMPONENTS_CONTRIBUTOR_BEAN_NAME; // 注册 CompositeUriComponentsContributorFactoryBean RootBeanDefinition uriCompContribDef = new RootBeanDefinition(CompositeUriComponentsContributorFactoryBean.class); uriCompContribDef.setSource(source); uriCompContribDef.getPropertyValues().addPropertyValue(\"handlerAdapter\", handlerAdapterDef); uriCompContribDef.getPropertyValues().addPropertyValue(\"conversionService\", conversionService); readerContext.getRegistry().registerBeanDefinition(uriCompContribName, uriCompContribDef); // 注册 ConversionServiceExposingInterceptor RootBeanDefinition csInterceptorDef = new RootBeanDefinition(ConversionServiceExposingInterceptor.class); csInterceptorDef.setSource(source); csInterceptorDef.getConstructorArgumentValues().addIndexedArgumentValue(0, conversionService); // 注册 MappedInterceptor RootBeanDefinition mappedCsInterceptorDef = new RootBeanDefinition(MappedInterceptor.class); mappedCsInterceptorDef.setSource(source); mappedCsInterceptorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); mappedCsInterceptorDef.getConstructorArgumentValues().addIndexedArgumentValue(0, (Object) null); mappedCsInterceptorDef.getConstructorArgumentValues().addIndexedArgumentValue(1, csInterceptorDef); String mappedInterceptorName = readerContext.registerWithGeneratedName(mappedCsInterceptorDef); // 注册 ExceptionHandlerExceptionResolver RootBeanDefinition exceptionHandlerExceptionResolver = new RootBeanDefinition(ExceptionHandlerExceptionResolver.class); exceptionHandlerExceptionResolver.setSource(source); exceptionHandlerExceptionResolver.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); exceptionHandlerExceptionResolver.getPropertyValues().add(\"contentNegotiationManager\", contentNegotiationManager); exceptionHandlerExceptionResolver.getPropertyValues().add(\"messageConverters\", messageConverters); exceptionHandlerExceptionResolver.getPropertyValues().add(\"order\", 0); addResponseBodyAdvice(exceptionHandlerExceptionResolver); if (argumentResolvers != null) &#123; exceptionHandlerExceptionResolver.getPropertyValues().add(\"customArgumentResolvers\", argumentResolvers); &#125; if (returnValueHandlers != null) &#123; exceptionHandlerExceptionResolver.getPropertyValues().add(\"customReturnValueHandlers\", returnValueHandlers); &#125; String methodExceptionResolverName = readerContext.registerWithGeneratedName(exceptionHandlerExceptionResolver); // 注册 ResponseStatusExceptionResolver RootBeanDefinition responseStatusExceptionResolver = new RootBeanDefinition(ResponseStatusExceptionResolver.class); responseStatusExceptionResolver.setSource(source); responseStatusExceptionResolver.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); responseStatusExceptionResolver.getPropertyValues().add(\"order\", 1); String responseStatusExceptionResolverName = readerContext.registerWithGeneratedName(responseStatusExceptionResolver); // 注册 DefaultHandlerExceptionResolver RootBeanDefinition defaultExceptionResolver = new RootBeanDefinition(DefaultHandlerExceptionResolver.class); defaultExceptionResolver.setSource(source); defaultExceptionResolver.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); defaultExceptionResolver.getPropertyValues().add(\"order\", 2); String defaultExceptionResolverName = readerContext.registerWithGeneratedName(defaultExceptionResolver); parserContext.registerComponent(new BeanComponentDefinition(handlerMappingDef, HANDLER_MAPPING_BEAN_NAME)); parserContext.registerComponent(new BeanComponentDefinition(handlerAdapterDef, HANDLER_ADAPTER_BEAN_NAME)); parserContext.registerComponent(new BeanComponentDefinition(uriCompContribDef, uriCompContribName)); parserContext.registerComponent(new BeanComponentDefinition(exceptionHandlerExceptionResolver, methodExceptionResolverName)); parserContext.registerComponent(new BeanComponentDefinition(responseStatusExceptionResolver, responseStatusExceptionResolverName)); parserContext.registerComponent(new BeanComponentDefinition(defaultExceptionResolver, defaultExceptionResolverName)); parserContext.registerComponent(new BeanComponentDefinition(mappedCsInterceptorDef, mappedInterceptorName)); // Ensure BeanNameUrlHandlerMapping (SPR-8289) and default HandlerAdapters are not \"turned off\" MvcNamespaceUtils.registerDefaultComponents(parserContext, source); parserContext.popAndRegisterContainingComponent(); return null;&#125; 3.1 总结 HttpServletBean 继承了HttpServlet，所以主要逻辑还是执行其init()进行Servlet的初始化任务，主要有下面逻辑 1、解析参数配置：将web.xml中配置的参数设置到ServletConfig中。比如servlet标签的子标签init-param标签中配置的参数。 2、触发子类{@link FrameworkServlet#initServletBean() }方法 用与构建及发布WebApplicationContext FrameworkServlet 将Servlet与Spring容器上下文关联。其实也就是初始化FrameworkServlet的属性webApplicationContext，这个属性代表SpringMVC容器，它有个父类上下文，既web.xml中配置的ContextLoaderListener监听器初始化的容器上下文。 DispatcherServlet 初始化各个功能的实现类。比如文件上传处理、异常处理、视图处理、请求映射处理等。 DispatcherServlet会自动注册一些特殊的Bean，无需我们注册，如果我们注册了，默认的将不会注册。 因此BeanNameUrlHandlerMapping、SimpleControllerHandlerAdapter是不需要注册的，DispatcherServlet默认会注册这两个Bean。 4.1 参考官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html http://www.cnblogs.com/fangjian0423/p/springMVC-dispatcherServlet.html https://blog.csdn.net/lang_programmer/article/details/71598042","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc源码(一)Spring Mvc介绍","slug":"backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(一)Spring Mvc介绍","date":"2019-08-02T16:01:00.000Z","updated":"2019-09-16T13:11:06.092Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(一)Spring Mvc介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/analysis/Spring Mvc源码(一)Spring Mvc介绍/","excerpt":"","text":"1.1 什么是Spring Mvc 在JavaEE体系结构中一个应用可以划分为四个层次，从上到下分别是应用层、Web层、业务层、持久层，现在的项目大都是按照这种结构来开发，我们这一系列介绍的是Web层的处理框架Spring Mvc Spring Web Mvc是一种基于Java的轻量级Web框架，使用了MVC架构模式的思想，将web层进行职责解耦，基于请求驱动指的就是使用请求-响应模型，框架的目的就是帮助我们简化开发。 2.1 为什么要使用Spring Mvc2.1.1 没有使用Spring Mvc会怎么样在Web开发模式中，主要有两个开发模式，称为模式一（Mode I）和模式二（Mode II）. 模式二是因为受不了模式一的缺点而进化出来的，而Spring Mvc则是模式二的进化版本，下面是两种模式的介绍： 模式一（Mode I）指的就是在开发中将显示层、控制层、数据层的操作统一交给JSP或者JavaBean来进行处理！ 优点 开发速度贼快，适合炒鸡简单的应用 缺点 程序的可读性差、复用性低、代码复杂！什么jsp代码、html代码都往上面写，这肯定很难阅读，很难重用！ 要求开发者不仅要掌握 Java ，还要有高超的前端水平 前端和后端相互依赖，前端需要等待后端完成，后端也依赖前端完成，才能进行有效的测试 模式二（Mode II）中所有的开发都是以Servlet为主体展开的，由Servlet接收所有的客户端请求，然后根据请求调用相对应的JavaBean，并所有的显示结果交给JSP完成！，也就是俗称的MVC设计模式 优点 相比模式一，耦合度降低了，添加了Servlet来协调视图处理及业务数据处理 缺点 需要定义大量的Servlet来处理应用 MVC设计模式 模型层（Mode）：模型是什么呢？ 模型就是数据，就是 dao,bean 显示层（View）：视图是什么呢？ 就是网页, JSP，用来展示模型中的数据 控制层（Controller）：控制器是什么？ 控制器的作用就是把不同的数据(Model)，显示在不同的视图(View)上，Servlet 扮演的就是这样的角色，在Spring MVC中DispatcherServlet就是这个特殊的控制器 很多应用程序的问题在于处理业务数据的对象和显示业务数据的视图之间存在紧密耦合， 模式二（Mode II）就很完美吗，不不不，还可以进行优化，所以有了Web Mvc框架 常见的Web Mvc框架有Sturts及主角Spring Mvc 2.1.2 对比其他WEB框架有那些优势 使用简单，对于开发人员来说实现一个功能肯定是实现越简单越好，Spring Mvc配合一系列注解即可完成Web应用的开发，尤其是在SpringBoot上的体现越明显 性能上Spring会稍微比Struts快。Spring mvc是基于方法的设计，而Sturts是基于类，每次发一次请求都会实例一个action，每个action都会被注入属性，而Spring基于方法，粒度更细，但要小心把握像在Servlet控制数据一样。 易于和Spring容器集成，毕竟是自己家里人 3.1 使用Spring Mvc4.1 总结 框架本身就是为了找到一个平衡，用哪个合适，就用哪个 5.1 参考 官方文档: https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html https://www.cnblogs.com/wmyskxz/p/8848461.html","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring Mvc()中文乱码问题","slug":"backend/framework/spring/spring-mvc/Spring mvc 中文乱码问题","date":"2019-08-02T16:00:01.000Z","updated":"2019-09-16T13:11:06.088Z","comments":true,"path":"2019/08/03/backend/framework/spring/spring-mvc/Spring mvc 中文乱码问题/","link":"","permalink":"http://www.songshuiyang.com/2019/08/03/backend/framework/spring/spring-mvc/Spring mvc 中文乱码问题/","excerpt":"一： 解决GET请求参数到了后台中文乱码问题 方式一: 修改tomcat配置, 暂时做法，没有找到更好的解决办法，换了tomcat了又要重新配置123把tomcat下，server.xml下，添加如下配置，就解决了． &lt;Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" URIEncoding=\"UTF-8\"/&gt; 方式二: 自定义filter, 解决了get请求中文参数问题，但post请求参数到了后台就gg了","text":"一： 解决GET请求参数到了后台中文乱码问题 方式一: 修改tomcat配置, 暂时做法，没有找到更好的解决办法，换了tomcat了又要重新配置123把tomcat下，server.xml下，添加如下配置，就解决了． &lt;Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" URIEncoding=\"UTF-8\"/&gt; 方式二: 自定义filter, 解决了get请求中文参数问题，但post请求参数到了后台就gg了 新建 CustomEncodingFilter.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.ecut.core.web.filter;import org.springframework.cglib.proxy.InvocationHandler;import org.springframework.cglib.proxy.Proxy;import org.springframework.web.filter.OncePerRequestFilter;import javax.servlet.FilterChain;import javax.servlet.ServletException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.lang.reflect.Method;public class CustomEncodingFilter extends OncePerRequestFilter &#123; private String encoding; public void setEncoding(String encoding) &#123; this.encoding = encoding; &#125; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException &#123; // 设置请求响应字符编码 request.setCharacterEncoding(encoding); response.setCharacterEncoding(encoding); // 传递给目标servlet或jsp的实际上是动态代理的对象，而不是原始的HttpServletRequest对象 request = (HttpServletRequest) Proxy.newProxyInstance(request.getClass().getClassLoader(), request.getClass().getInterfaces(), new MyInvacationHandler(request)); chain.doFilter(request, response); &#125; class MyInvacationHandler implements InvocationHandler &#123; private HttpServletRequest request; MyInvacationHandler(HttpServletRequest request)&#123; this.request=request; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; switch (method.getName()) &#123; case \"getParameter\": String value = request.getParameter((String)args[0]); try &#123; if(value != null)&#123; value=new String(value.getBytes(\"ISO-8859-1\"),encoding); &#125; &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return value; case \"getParameterValues\": String[] values = request.getParameterValues((String)args[0]); if (values != null) &#123; for (int i = 0; i &lt; values.length; i++) &#123; try &#123; values[i] = new String(values[i].getBytes(\"ISO-8859-1\"),encoding); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return values; default: return method.invoke(request, args); &#125; &#125; &#125;&#125; 配置web.xml 1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.ecut.core.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 二： 解决POST请求参数到了后台中文乱码问题1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;","categories":[{"name":"SpringMvc","slug":"SpringMvc","permalink":"http://www.songshuiyang.com/categories/SpringMvc/"}],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"http://www.songshuiyang.com/tags/spring-mvc/"},{"name":"spring","slug":"spring","permalink":"http://www.songshuiyang.com/tags/spring/"}]},{"title":"Spring系列(七四)Spring事务之Mybatis集成事务管理","slug":"backend/framework/spring/analysis/Spring系列(七四)Spring事务之Mybatis集成事务管理","date":"2019-08-01T16:00:04.000Z","updated":"2019-09-16T13:11:04.986Z","comments":true,"path":"2019/08/02/backend/framework/spring/analysis/Spring系列(七四)Spring事务之Mybatis集成事务管理/","link":"","permalink":"http://www.songshuiyang.com/2019/08/02/backend/framework/spring/analysis/Spring系列(七四)Spring事务之Mybatis集成事务管理/","excerpt":"","text":"前言 使用 MyBatis-Spring 的主要原因是它允许 MyBatis 参与到 Spring 的事务管理中。而 不是给 MyBatis 创建一个新的特定的事务管理器,MyBatis-Spring 利用了存在于 Spring 中的 DataSourceTransactionManager。 如何集成 Spring的事务管理 配置 DataSourceTransactionManager Bean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;!-- 数据库连接池 --&gt;&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;!-- 基本属性 url、IUser、password --&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://127.0.0.1:3306/iframe?useUnicode=true&amp;amp;characterEncoding=UTF-8\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=\"initialSize\" value=\"1\"/&gt; &lt;property name=\"minIdle\" value=\"1\"/&gt; &lt;property name=\"maxActive\" value=\"20\"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=\"maxWait\" value=\"60000\"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=\"timeBetweenEvictionRunsMillis\" value=\"60000\"/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=\"minEvictableIdleTimeMillis\" value=\"300000\"/&gt; &lt;!-- 用来检测连接是否有效的sql，要求是一个查询语句。 如果validationQuery为null，testOnBorrow、testOnReturn、 testWhileIdle都不会其作用 --&gt; &lt;property name=\"validationQuery\" value=\"SELECT 1 FROM DUAL\"/&gt; &lt;property name=\"testWhileIdle\" value=\"true\"/&gt; &lt;property name=\"testOnBorrow\" value=\"false\"/&gt; &lt;property name=\"testOnReturn\" value=\"false\"/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 如果用Oracle，则把poolPreparedStatements配置为true，mysql可以配置为false --&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;property name=\"maxPoolPreparedStatementPerConnectionSize\" value=\"20\"/&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name=\"filters\" value=\"stat,wall,log4j\"/&gt; &lt;!-- 如果配置了proxyFilters，此配置可以不配置 druid.stat.mergeSql=true 合并执行的相同sql，避免因为参数不同而统计多条sql语句 druid.stat.slowSqlMillis=10000 用来配置SQL慢的标准，执行时间超过slowSqlMillis的就是慢 &lt;property name=\"connectionProperties\" value=\"druid.stat.mergeSql=true;druid.stat.slowSqlMillis=10000\" /&gt; --&gt; &lt;!-- 监控统计拦截的filters --&gt; &lt;!-- 并在filters属性中配置了log4j --&gt; &lt;!--&lt;property name=\"proxyFilters\"&gt;--&gt; &lt;!--&lt;list&gt;--&gt; &lt;!--&lt;ref bean=\"stat-filter\" /&gt;--&gt; &lt;!--&lt;ref bean=\"log-filter\" /&gt;--&gt; &lt;!--&lt;/list&gt;--&gt; &lt;!--&lt;/property&gt;--&gt; &lt;!-- 连接属性 --&gt; &lt;property name=\"connectionProperties\"&gt; &lt;value&gt;clientEncoding=UTF-8&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSessionFactory\" /&gt; &lt;constructor-arg index=\"1\" value=\"BATCH\" /&gt;&lt;/bean&gt;&lt;!-- 配置SqlSessionFactory对象 --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"org.springframework.iframe.entity\"/&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\"/&gt;&lt;/bean&gt;&lt;!-- 配置扫描Dao接口包，动态实现Dao接口，注入到spring容器中 --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"org.springframework.iframe.mapper\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt;&lt;tx:annotation-driven proxy-target-class=\"false\" transaction-manager=\"transactionManager\" /&gt; 要注意, 为事务管理器指定的 DataSource 必须和用来创建 SqlSessionFactoryBean 的 是同一个数据源,否则事务管理器就无法工作了。 一旦 Spring 的 DataSourceTransactionManager 配置好了,你可以在 Spring 中你可以使用@Transactional 注解来完成事物操作。在事务处理期间,一个单独的 SqlSession 对象（线程级别）将会被创建 和使用。当事务完成时,这个 SqlSession 会以合适的方式提交或回滚。相反如果没有开启事物那么SqlSession 对象就是方法级别的了，每次调用Mapper里的方法都会返回一个新的SqlSession 来处理，下面来看其内部是怎么实现的 事务实现解析 与Spring集成以后，Spring提供了一个全局唯一的SqlSessionTemplate 来完成DefailtSqlSession的功能 进入SqlSessionTemplate 可以看到里面有个SqlSession 属性，看属性名可以看出这里又用了动态代理，为什么又要代理呢？下面来看看 12// SqlSession代理private final SqlSession sqlSessionProxy; 观察其构造方法，这里形成SqlSession代理类，再来看动态代理类SqlSessionInterceptor做了什么 123456789101112131415public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sqlSessionFactory, \"Property 'sqlSessionFactory' is required\"); notNull(executorType, \"Property 'executorType' is required\"); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; // 形成SqlSession代理类 this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor()); &#125; 进入SqlSessionInterceptor类，这个SqlSession代理类的出现是为了让Spring 来管理SqlSession 的，从而实现事务管理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * SqlSession 代理类，MyBatis路由方法调用得到有Spring Transaction的SqlSession * Proxy needed to route MyBatis method calls to the proper SqlSession got * from Spring's Transaction Manager * It also unwraps exceptions thrown by &#123;@code Method#invoke(Object, Object...)&#125; to * pass a &#123;@code PersistenceException&#125; to the &#123;@code PersistenceExceptionTranslator&#125;. */private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 获取SqlSession(这个SqlSession才是真正使用的，它不是线程安全的) SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; // 调用真实SqlSession的方法 Object result = method.invoke(sqlSession, args); // 判断一下当前的sqlSession是否被Spring托管 if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() // 没有使用事务 sqlSession.commit(true); &#125; return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator.translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; // 关闭SqlSession,如果sqlSession被Spring管理 则调用holder.released(); 使计数器-1 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; &#125;&#125; 进入getSqlSession()方法，这里是获取SqlSession 的方法 1234567891011121314151617181920public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); notNull(executorType, NO_EXECUTOR_TYPE_SPECIFIED); // 根据sqlSessionFactory从当前线程对应的资源map中获取SqlSessionHolder SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); SqlSession session = sessionHolder(executorType, holder); if (session != null) &#123; return session; &#125; // 如果找不到，则根据执行类型构造一个新的sqlSession LOGGER.debug(() -&gt; \"Creating a new SqlSession\"); session = sessionFactory.openSession(executorType); registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session;&#125; 关注TransactionSynchronizationManager 内部成员，这里使用TreadLocal记录事务的一些属性，用于应用扩展同步器的使用，在事务的开启，挂起，提交等各个点上回调应用的逻辑 1234567891011121314151617181920212223 // 应用代码随事务的声明周期绑定的对象private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;&gt;(\"Transactional resources\"); // synchronizations-使用的同步器，用于应用扩展private static final ThreadLocal&lt;Set&lt;TransactionSynchronization&gt;&gt; synchronizations = new NamedThreadLocal&lt;&gt;(\"Transaction synchronizations\"); // 事务的名称private static final ThreadLocal&lt;String&gt; currentTransactionName = new NamedThreadLocal&lt;&gt;(\"Current transaction name\"); // 事务是否是只读private static final ThreadLocal&lt;Boolean&gt; currentTransactionReadOnly = new NamedThreadLocal&lt;&gt;(\"Current transaction read-only status\"); // 事务的隔离界别private static final ThreadLocal&lt;Integer&gt; currentTransactionIsolationLevel = new NamedThreadLocal&lt;&gt;(\"Current transaction isolation level\"); // 事务是否开启private static final ThreadLocal&lt;Boolean&gt; actualTransactionActive = new NamedThreadLocal&lt;&gt;(\"Actual transaction active\"); 回到SqlSessionInterceptor 类invoke方法，这里有个if判断if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) { 来判断是否开启了Spring事务，如果该Session未被Spring托管则自动commit 12345678public static boolean isSqlSessionTransactional(SqlSession session, SqlSessionFactory sessionFactory) &#123; notNull(session, NO_SQL_SESSION_SPECIFIED); notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); return (holder != null) &amp;&amp; (holder.getSqlSession() == session);&#125; 关注invoke方法的finally块的 closeSqlSession()方法，如果是开启了事务则没有执行session.close(); 123456finally &#123; if (sqlSession != null) &#123; // 关闭SqlSession,如果sqlSession被Spring管理 则调用holder.released(); 使计数器-1 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; 1234567891011121314public static void closeSqlSession(SqlSession session, SqlSessionFactory sessionFactory) &#123; notNull(session, NO_SQL_SESSION_SPECIFIED); notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); if ((holder != null) &amp;&amp; (holder.getSqlSession() == session)) &#123; LOGGER.debug(() -&gt; \"Releasing transactional SqlSession [\" + session + \"]\"); // 如果是开启了事务 SqlSession是没有被close的，所以方法体内使用的是一个SqlSession，当然一级缓存是生效的 holder.released(); &#125; else &#123; LOGGER.debug(() -&gt; \"Closing non transactional SqlSession [\" + session + \"]\"); session.close(); &#125;&#125; 总结 通过上述代码可以得出如果开启了事务，同一事务中同一个sqlSessionFactory创建的唯一sqlSession，一个事务中使用的是同一个sqlSession，为什么要用同一个sqlSession呢，是为了使用同一个connection (JDBC) 如果没有开启事务，调用一次mapper里的方法将会新建一个sqlSession来执行方法 参考 http://www.mybatis.org/spring/zh/factorybean.html https://www.cnblogs.com/daxin/p/3544188.html","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(七三)Spring事务之PlatformTransactionManager","slug":"backend/framework/spring/analysis/Spring系列(七三)Spring事务之PlatformTransactionManager","date":"2019-08-01T16:00:03.000Z","updated":"2019-09-16T13:11:04.962Z","comments":true,"path":"2019/08/02/backend/framework/spring/analysis/Spring系列(七三)Spring事务之PlatformTransactionManager/","link":"","permalink":"http://www.songshuiyang.com/2019/08/02/backend/framework/spring/analysis/Spring系列(七三)Spring事务之PlatformTransactionManager/","excerpt":"","text":"前言 Spring 事务的管理，是通过 org.springframework.transaction.PlatformTransactionManager 进行管理 1234567891011121314// PlatformTransactionManager.javapublic interface PlatformTransactionManager &#123; // 根据事务定义 TransactionDefinition ，获得 TransactionStatus 。 TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException; // 根据情况，提交事务 void commit(TransactionStatus status) throws TransactionException; // 根据情况，回滚事务 void rollback(TransactionStatus status) throws TransactionException; &#125; PlatformTransactionManager 是负责事务管理的接口，一共有三个接口方法，分别负责事务的获得、提交、回滚。 #getTransaction(TransactionDefinition definition) 根据事务定义 TransactionDefinition ，获得 TransactionStatus 为什么不是创建事务呢？因为如果当前如果已经有事务，则不会进行创建，一般来说会跟当前线程进行绑定。如果不存在事务，则进行创建 什么返回的是 TransactionStatus 对象？在 TransactionStatus 中，不仅仅包含事务属性，还包含事务的其它信息，例如是否只读、是否为新创建的事务等等 #commit(TransactionStatus status) 根据 TransactionStatus 情况，提交事务 为什么根据 TransactionStatus 情况，进行提交？例如说，带@Transactional 注解的的 A 方法，会调用 @Transactional 注解的的 B 方法。 在 B 方法结束调用后，会执行 PlatformTransactionManager#commit(TransactionStatus status) 方法，此处事务是不能、也不会提交的。 而是在 A 方法结束调用后，执行 PlatformTransactionManager#commit(TransactionStatus status) 方法，提交事务。 #rollback(TransactionStatus status) 根据 TransactionStatus 情况，回滚事务 为什么根据 TransactionStatus 情况，进行回滚？原因同 #commit(TransactionStatus status) 方法。 子类 先来一张PlatformTransactionManager接口的子类图 PlatformTransactionManager 有抽象子类 org.springframework.transaction.support.AbstractPlatformTransactionManager ，基于 模板方法模式实现事务整体逻辑的骨架，而抽象 #doCommit(DefaultTransactionStatus status)、#doRollback(DefaultTransactionStatus status) 等等方法，交由子类类来实现。 不同的数据持久层框架，会有其对应的 PlatformTransactionManager 实现类 HibernateTransactionManager 和Hibernate5 的事务管理做集成 DataSourceTransactionManager 和 JDBC 的事务管理做集成。所以，它也适用于 MyBatis、Spring JDBC 等等。 最常使用的 JpaTransactionManager 和 JPA 的事务管理做集成 其他支持类TransactionDefinition @Transactional 注解的属性，会解析成 org.springframework.transaction.TransactionDefinition 对象，即事务定义 12345678910public interface TransactionDefinition &#123; int getPropagationBehavior(); // 事务的传播行为 int getIsolationLevel(); // 事务的隔离级别 int getTimeout(); // 事务的超时时间 boolean isReadOnly(); // 事务是否只读 @Nullable String getName(); // 事务的名字&#125; TransactionDefinition继承关系图 @Transactional 注解的 rollbackFor、rollbackForClassName、noRollbackFor、noRollbackForClassName 属性貌似没体现出来？它们提现在 TransactionDefinition 的实现类 RuleBasedTransactionAttribute中。 TransactionStatus TransactionStatus 接口，记录事务的状态，不仅仅包含事务本身，还包含事务的其它信息 12345678910111213141516171819202122232425262728293031323334353637// TransactionStatus.javapublic interface TransactionStatus extends SavepointManager, Flushable &#123; /** * 是否是新创建的事务 */ boolean isNewTransaction(); /** * 是否有 Savepoint * * 在 &#123;@link TransactionDefinition#PROPAGATION_NESTED&#125; 传播级别使用。 */ boolean hasSavepoint(); /** * 设置为只回滚 */ void setRollbackOnly(); /** * 是否为只回滚 */ boolean isRollbackOnly(); /** * 执行 flush 操作 */ @Override void flush(); /** * 是否事务已经完成 */ boolean isCompleted();&#125; TransactionStatus继承关系图 为什么没有事务对象呢？在 TransactionStatus 的实现类 DefaultTransactionStatus 中，有个 Object transaction 属性，表示事务对象。 #isNewTransaction() 方法，表示是否是新创建的事务。有什么用呢？ 我们对 #commit(TransactionStatus status) 方法的解释。通过该方法，我们可以判断，当前事务是否当前方法所创建的，只有创建事务的方法，才能且应该真正的提交事务。 子类 org.springframework.transaction.interceptor.TransactionAttribute 支持定义返回异常回滚的事务定义接口 org.springframework.transaction.interceptor.RuleBasedTransactionAttribute 基于 {@link RollbackRuleAttribute} 的事务定义实现类 每个 @Transactional 注解的方法及每个&lt;tx:method /&gt;``XML的配置 都会被解析成此对象 总结 使用 Spring 事务有什么优点？ 通过 PlatformTransactionManager ，为不同的数据层持久框架提供统一的 API ，无需关心到底是原生 JDBC、Spring JDBC、JPA、Hibernate 还是 MyBatis 。 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(七二)Spring事务之具体执行过程","slug":"backend/framework/spring/analysis/Spring系列(七二)Spring事务之具体执行过程","date":"2019-08-01T16:00:02.000Z","updated":"2019-09-16T13:11:04.970Z","comments":true,"path":"2019/08/02/backend/framework/spring/analysis/Spring系列(七二)Spring事务之具体执行过程/","link":"","permalink":"http://www.songshuiyang.com/2019/08/02/backend/framework/spring/analysis/Spring系列(七二)Spring事务之具体执行过程/","excerpt":"","text":"前言 我们知道在JDBC中处理事务，都是通过Connection完成的，同一事务中所有的操作，都在使用同一个Connection对象，Connection的三个方法与事务有关，万变不离其宗，Spring的事务也是基于JDBC来实现的，那么Spring是怎么来写这些代码的呢，这就是本章要介绍的内容。 1234567891011try &#123; // 设置是否为自动提交事务，如果true（默认值为true）表示自动提交，也就是每条执行的SQL语句都是一个单独的事务， // 如果设置为false，那么相当于开启了事务了；con.setAutoCommit(false) 表示开启事务。 con.setAutoCommit(false); ...... // 提交事务 con.commit(); &#125; catch（） &#123; // 回滚事务 con.rollback();&#125; 上一章节介绍了&lt;tx:annotation-driven&gt;标签是开启事务的开关，配置了这个就可以使用注解@Transactional来开启事务了，下面通过一个例子看看Spring事务的执行过程 下面的updateUserByRuntimeException()方法添加了@Transactional注解，这个方法先是插入一条记录，然后再更新另一条记录，如果没有开启事务的话，会执行第一条sql语句，第二条sql语句不会执行 123456789101112// org.springframework.iframe.service.impl.UserServiceImpl@Transactionalpublic void updateUserByRuntimeException (IUser iUser) throws NullPointerException&#123; log.info(\"开启事务\"); if (userMapper.insertSelective(iUser) == 1) &#123; throw new NullPointerException(\"运行时异常\"); &#125; IUser iUser2 = userMapper.selectByPrimaryKey(1); iUser2.setAge(iUser2.getAge() + 1); userMapper.updateByPrimaryKeySelective(iUser2);&#125; 测试类及配置文件 12345678910111213141516171819// org.springframework.iframe.test.transaction.TransactionTests@Slf4jpublic class TransactionTests &#123; private final ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(\"beans/applicationContext.xml\"); /** * 运行时异常事务处理 * 事务会回滚 */ @Test public void runtimeExceptionTransactionTest() throws Exception &#123; UserService userService = xmlApplicationContext.getBean(UserService.class); IUser iUser = new IUser(); iUser.setUsername(\"运行时异常 事务会回滚\"); iUser.setAge(1); userService.updateUserByRuntimeException(iUser); &#125; 12345678910111213141516171819// beans/applicationContext.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd\"&gt; &lt;!-- ComponentScanBeanDefinitionParser--&gt; &lt;context:component-scan base-package = \"org.springframework.iframe.*\"/&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;import resource=\"applicationContext-dao.xml\"/&gt;&lt;/beans&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// beans/applicationContext-dao.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 数据库连接池 --&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://127.0.0.1:3306/iframe?useUnicode=true&amp;amp;characterEncoding=UTF-8\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt; &lt;property name=\"initialSize\" value=\"1\"/&gt; &lt;property name=\"minIdle\" value=\"1\"/&gt; &lt;property name=\"maxActive\" value=\"20\"/&gt; &lt;property name=\"maxWait\" value=\"60000\"/&gt; &lt;property name=\"timeBetweenEvictionRunsMillis\" value=\"60000\"/&gt; &lt;property name=\"minEvictableIdleTimeMillis\" value=\"300000\"/&gt; &lt;property name=\"validationQuery\" value=\"SELECT 1 FROM DUAL\"/&gt; &lt;property name=\"testWhileIdle\" value=\"true\"/&gt; &lt;property name=\"testOnBorrow\" value=\"false\"/&gt; &lt;property name=\"testOnReturn\" value=\"false\"/&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;property name=\"maxPoolPreparedStatementPerConnectionSize\" value=\"20\"/&gt; &lt;property name=\"filters\" value=\"stat,wall,log4j\"/&gt; &lt;property name=\"connectionProperties\"&gt; &lt;value&gt;clientEncoding=UTF-8&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSessionFactory\" /&gt; &lt;constructor-arg index=\"1\" value=\"BATCH\" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactory对象 --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"org.springframework.iframe.entity\"/&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\"/&gt; &lt;/bean&gt; &lt;!-- 配置扫描Dao接口包，动态实现Dao接口，注入到spring容器中 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"org.springframework.iframe.mapper\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;tx:annotation-driven proxy-target-class=\"false\" transaction-manager=\"transactionManager\" /&gt;&lt;/beans&gt; 调试 现在来执行测试类，执行UserService userService = xmlApplicationContext.getBean(UserService.class);见下图可以看到userService是JdkDynamicAopProxy对象，由此可以得到Spring事务是通过AOP来实现的，由AOP来完成事务方法的织入及执行 进入userService.updateUserByRuntimeException(iUser);方法，会跳到JdkDynamicAopProxy类的invoke()方法，这些逻辑和我们之前介绍AOP章节的内容是一致的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * Implementation of &#123;@code InvocationHandler.invoke&#125;. * &lt;p&gt;Callers will see exactly the exception thrown by the target, * unless a hook method throws an exception. */@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class&lt;?&gt; targetClass = null; Object target = null; try &#123; // 如果被代理的目标对象要执行的方法是equal则执行JdkDynamicAopProxy（即代理对象的equal）方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; // 如果被代理的目标对象要执行的方法是hashCode则执行JdkDynamicAopProxy（即代理对象的hashCode）方法 else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; // 有时候目标对象内部的自我调用将无法实施切面中的增强则需要通过此属性暴露代理 if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // May be null. Get as late as possible to minimize the time we \"own\" the target, // in case it comes from a pool. target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; // Get the interception chain for this method. // 获取当前方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); // 如果没有发现任何拦截器那么直接调用切点方法 retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... // 将拦截器封装在ReflectiveMethodInvocation，以便于使用其proceed进行链接表用拦截器 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. // 执行拦截器链 retVal = invocation.proceed(); &#125; // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned \"this\" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; // 返回结果 else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( \"Null return value from advice does not match primitive return type for: \" + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; 上面要注意的是List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);，获取当前方法的拦截器链，由下图可以看到这里得到的是TransactionInterceptor事务拦截器，是不是有些眉目了 得到拦截器之后就是执行invocation.proceed();方法了 123456789101112131415161718192021222324252627282930313233@Overridepublic Object proceed() throws Throwable &#123; // We start with an index of -1 and increment early. // 执行完所有增强后执行切点方法，从索引为-1的拦截器开始，并递增，如果拦截器迭代调用完成，则调用目标方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 获取下一个要执行的拦截器 沿着拦截器链执行 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. // 对方法进行动态匹配，切点的匹配就在这里进行 InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. // 不匹配则跳过这个拦截器调用下一个 return proceed(); &#125; &#125; else &#123; // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. // 这是一个拦截器，直接调用它，将this作为参数传递以保证当前实例中调用链的执行 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125;&#125; 进入((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this)方法执行拦截器的方法 1234567891011121314151617// org.springframework.transaction.interceptor.TransactionInterceptor#invoke@Overridepublic Object invoke(final MethodInvocation invocation) throws Throwable &#123; // Work out the target class: may be &#123;@code null&#125;. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupport's invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, new InvocationCallback() &#123; @Override public Object proceedWithInvocation() throws Throwable &#123; return invocation.proceed(); &#125; &#125;);&#125; 执行invokeWithinTransaction()进入到TransactionInterceptor的父类中TransactionAspectSupport，下面的方法可以说是Spring事务的核心代码了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction/** * General delegate for around-advice-based subclasses, delegating to several other template * methods on this class. Able to handle &#123;@link CallbackPreferringPlatformTransactionManager&#125; * as well as regular &#123;@link PlatformTransactionManager&#125; implementations. * @param method the Method being invoked * @param targetClass the target class that we're invoking the method on * @param invocation the callback to use for proceeding with the target invocation * @return the return value of the method, if any * @throws Throwable propagated from the target invocation */protected Object invokeWithinTransaction(Method method, Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // If the transaction attribute is null, the method is non-transactional. // 获取对应的事务属性 final TransactionAttribute txAttr = getTransactionAttributeSource().getTransactionAttribute(method, targetClass); // 获取beanFactory中的transactionManager final PlatformTransactionManager tm = determineTransactionManager(txAttr); // 构造方法唯一标识(service.UserServiceImpl.save) final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); // 声明式事务处理 if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. // 创建事物 创建TransactionInfo 完成了目标方法运行前的事务准备工作 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. // 方法调用 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // target invocation exception // 回滚事务 注意：只对RuntimeException回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; // 清除信息 cleanupTransactionInfo(txInfo); &#125; // 提交事务 commitTransactionAfterReturning(txInfo); return retVal; &#125; else &#123; // 编程式事务处理 // It's a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in. try &#123; Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, new TransactionCallback&lt;Object&gt;() &#123; @Override public Object doInTransaction(TransactionStatus status) &#123; TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); try &#123; return invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; // A RuntimeException: will lead to a rollback. if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; // A normal return value: will lead to a commit. return new ThrowableHolder(ex); &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125; &#125;); // Check result: It might indicate a Throwable to rethrow. if (result instanceof ThrowableHolder) &#123; throw ((ThrowableHolder) result).getThrowable(); &#125; else &#123; return result; &#125; &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; &#125;&#125; 上面的逻辑分为声明式事务处理及编程式事务处理，我们这里关注声明式事务处理，由上面可以看到主要逻辑分为下面几点，是不是有些上面JDBC事务代码的影子了 1、创建事务 2、方法调用 3、如有异常回滚事务 4、提交事务 1、创建事务 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);这行代码是创建事务的逻辑，可以看到是封装了一个TransactionInfo对象，现在先进入createTransactionIfNecessary()方法 1234567891011121314151617181920212223242526272829303132// org.springframework.transaction.interceptor.TransactionAspectSupport#createTransactionIfNecessaryprotected TransactionInfo createTransactionIfNecessary( PlatformTransactionManager tm, TransactionAttribute txAttr, final String joinpointIdentification) &#123; // If no name specified, apply method identification as transaction name. // 如果没有名称指定则使用方法唯一标识，并使用DelegatingTransactionAttribute封装txAttr if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123; // 核心 获取TransactionStatus 这里有建立事务连接 status = tm.getTransaction(txAttr); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Skipping transactional joinpoint [\" + joinpointIdentification + \"] because no transaction manager has been configured\"); &#125; &#125; &#125; // 根据指定的属性与status准备一个TransactionInfo return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);&#125; 关注status = tm.getTransaction(txAttr);方法，这里是建立事务连接关键 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// org.springframework.transaction.support.AbstractPlatformTransactionManager#getTransaction@Overridepublic final TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException &#123; Object transaction = doGetTransaction(); // Cache debug flag to avoid repeated checks. boolean debugEnabled = logger.isDebugEnabled(); if (definition == null) &#123; // Use defaults if no transaction definition given. definition = new DefaultTransactionDefinition(); &#125; // 判断当前线程是否存在事务，判断依据为当前线程记录的连接不为空且连接中(connectionHolder)中的transactionActive属性不为空 if (isExistingTransaction(transaction)) &#123; // Existing transaction found -&gt; check propagation behavior to find out how to behave. // 当前线程已经存在事务 return handleExistingTransaction(definition, transaction, debugEnabled); &#125; // Check definition settings for new transaction. // 事务超时设置验证 if (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) &#123; throw new InvalidTimeoutException(\"Invalid transaction timeout\", definition.getTimeout()); &#125; // No existing transaction found -&gt; check propagation behavior to find out how to proceed. // 如果当前线程不存在事务，propagationBehavior声明为PROPAGATION_MANDATORY 抛异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123; throw new IllegalTransactionStateException( \"No existing transaction found for transaction marked with propagation 'mandatory'\"); &#125; else if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; // 需要新建事务 SuspendedResourcesHolder suspendedResources = suspend(null); if (debugEnabled) &#123; logger.debug(\"Creating new transaction with name [\" + definition.getName() + \"]: \" + definition); &#125; try &#123; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); /** * 构建transaction ，包括设置ConnectionHolder、隔离级别、timout */ doBegin(transaction, definition); // 新同步事务的设置，针对与当前线程的设置，将事务信息记录在当前线程中 prepareSynchronization(status, definition); return status; &#125; catch (RuntimeException ex) &#123; resume(null, suspendedResources); throw ex; &#125; catch (Error err) &#123; resume(null, suspendedResources); throw err; &#125; &#125; else &#123; // Create \"empty\" transaction: no actual transaction, but potentially synchronization. if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(\"Custom isolation level specified but no actual transaction initiated; \" + \"isolation level will effectively be ignored: \" + definition); &#125; boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null); &#125;&#125; 进入doBegin(transaction, definition);方法，可以看到Connection newCon = this.dataSource.getConnection();这里获取了JDBC的Connection，然后就是通过con.setAutoCommit(false);来开启事务了，获取数据库连接之后就是通过TransactionSynchronizationManager.bindResource(getDataSource(), txObject.getConnectionHolder());来将连接绑定到当前线程中（使用ThreadLocal来实现） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 构建transaction，包括设置ConnectionHolder、隔离级别、timeout * 如果是新连接，绑定到当前线程，这个函数已经开始尝试了对数据库连接的获取 * * This implementation sets the isolation level but ignores the timeout. */@Overrideprotected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try &#123; // 尝试获取连接，当然并不是每次都获取新的连接，如果当前线程中ConnectionHolder已经存在，则不需要再次获取 if (txObject.getConnectionHolder() == null || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; Connection newCon = this.dataSource.getConnection(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Acquired Connection [\" + newCon + \"] for JDBC transaction\"); &#125; txObject.setConnectionHolder(new ConnectionHolder(newCon), true); &#125; txObject.getConnectionHolder().setSynchronizedWithTransaction(true); con = txObject.getConnectionHolder().getConnection(); // 设置隔离级别 Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // Switch to manual commit if necessary. This is very expensive in some JDBC drivers, // so we don't want to do it unnecessarily (for example if we've explicitly // configured the connection pool to set it already). // 更改Connection自动提交设置，由Spring控制提交 if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) &#123; logger.debug(\"Switching JDBC Connection [\" + con + \"] to manual commit\"); &#125; con.setAutoCommit(false); &#125; prepareTransactionalConnection(con, definition); // 设置判断当前线程是否存在事务的依据 txObject.getConnectionHolder().setTransactionActive(true); // 设置过期时间 int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; // Bind the connection holder to the thread. if (txObject.isNewConnectionHolder()) &#123; // 将当前获取到的连接绑定到当前线程 TransactionSynchronizationManager.bindResource(getDataSource(), txObject.getConnectionHolder()); &#125; &#125; catch (Throwable ex) &#123; if (txObject.isNewConnectionHolder()) &#123; DataSourceUtils.releaseConnection(con, this.dataSource); txObject.setConnectionHolder(null, false); &#125; throw new CannotCreateTransactionException(\"Could not open JDBC Connection for transaction\", ex); &#125;&#125; 2、方法调用123456789101112131415161718192021// 创建事物 创建TransactionInfo 完成了目标方法运行前的事务准备工作TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);Object retVal = null;try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. // 方法调用 retVal = invocation.proceedWithInvocation();&#125;catch (Throwable ex) &#123; // target invocation exception // 回滚事务 注意：只对RuntimeException回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex;&#125;finally &#123; // 清除信息 cleanupTransactionInfo(txInfo);&#125;// 提交事务commitTransactionAfterReturning(txInfo); 上面获取了TransactionInfo之后就是来执行方法了，进入invocation.proceedWithInvocation();，可以看到又回到了上面的org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction的方法中，这里执行的是invocation.proceed();方法 123456789101112131415@Overridepublic Object invoke(final MethodInvocation invocation) throws Throwable &#123; // Work out the target class: may be &#123;@code null&#125;. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupport's invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, new InvocationCallback() &#123; @Override public Object proceedWithInvocation() throws Throwable &#123; return invocation.proceed(); &#125; &#125;);&#125; 进入invocation.proceed();方法，又回到了ReflectiveMethodInvocation#proceed方法，只不过现在是执行的invokeJoinpoint();方法 123456789101112131415161718192021222324252627282930313233// org.springframework.aop.framework.ReflectiveMethodInvocation#proceedpublic Object proceed() throws Throwable &#123; // We start with an index of -1 and increment early. // 执行完所有增强后执行切点方法，从索引为-1的拦截器开始，并递增，如果拦截器迭代调用完成，则调用目标方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 获取下一个要执行的拦截器 沿着拦截器链执行 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. // 对方法进行动态匹配，切点的匹配就在这里进行 InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. // 不匹配则跳过这个拦截器调用下一个 return proceed(); &#125; &#125; else &#123; // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. // 这是一个拦截器，直接调用它，将this作为参数传递以保证当前实例中调用链的执行 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; 进入invokeJoinpoint();方法，下面的使用了反射(method.invoke(target, args);)执行了我们的org.springframework.iframe.service.impl.UserServiceImpl#updateUserByRuntimeException方法 12345678910111213141516171819202122232425protected Object invokeJoinpoint() throws Throwable &#123; return AopUtils.invokeJoinpointUsingReflection(this.target, this.method, this.arguments);&#125;public static Object invokeJoinpointUsingReflection(Object target, Method method, Object[] args) throws Throwable &#123; // 使用反射执行方法 try &#123; ReflectionUtils.makeAccessible(method); return method.invoke(target, args); &#125; catch (InvocationTargetException ex) &#123; // Invoked method threw a checked exception. // We must rethrow it. The client won't see the interceptor. throw ex.getTargetException(); &#125; catch (IllegalArgumentException ex) &#123; throw new AopInvocationException(\"AOP configuration seems to be invalid: tried calling method [\" + method + \"] on target [\" + target + \"]\", ex); &#125; catch (IllegalAccessException ex) &#123; throw new AopInvocationException(\"Could not access method [\" + method + \"]\", ex); &#125;&#125; 进入org.springframework.iframe.service.impl.UserServiceImpl#updateUserByRuntimeException方法，这里插入一条记录之后就抛出一个异常，之后的逻辑就是下面的了 1234567891011@Override@Transactionalpublic void updateUserByRuntimeException (IUser iUser) throws NullPointerException&#123; log.info(\"开启事务\"); if (userMapper.insertSelective(iUser) == 1) &#123; throw new NullPointerException(\"运行时异常\"); &#125; IUser iUser2 = userMapper.selectByPrimaryKey(1); iUser2.setAge(iUser2.getAge() + 1); userMapper.updateByPrimaryKeySelective(iUser2);&#125; 3、如有异常回滚事务 上面的throw new NullPointerException(&quot;运行时异常&quot;);抛出了一个空指针异常，所以被我们下面的逻辑给catch到了 12345678910111213141516171819202122// 创建事物 创建TransactionInfo 完成了目标方法运行前的事务准备工作TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);Object retVal = null;try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. // 方法调用 retVal = invocation.proceedWithInvocation();&#125;catch (Throwable ex) &#123; // target invocation exception // 回滚事务 注意：只对RuntimeException回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex;&#125;finally &#123; // 清除信息 cleanupTransactionInfo(txInfo);&#125;// 提交事务commitTransactionAfterReturning(txInfo);return retVal; 关注completeTransactionAfterThrowing(txInfo, ex);方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// org.springframework.transaction.interceptor.TransactionAspectSupport#completeTransactionAfterThrowing/** * Handle a throwable, completing the transaction. * We may commit or roll back, depending on the configuration. * @param txInfo information about the current transaction * @param ex throwable encountered */protected void completeTransactionAfterThrowing(TransactionInfo txInfo, Throwable ex) &#123; // 当抛出异常时首先判断当前是否存在事务，这是基础依据 if (txInfo != null &amp;&amp; txInfo.hasTransaction()) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Completing transaction for [\" + txInfo.getJoinpointIdentification() + \"] after exception: \" + ex); &#125; // 这里判断是否回滚默认的依据是抛出的异常是否是 (ex instanceof RuntimeException || ex instanceof Error)，我们熟悉的Exception默认是不处理的 if (txInfo.transactionAttribute.rollbackOn(ex)) &#123; try &#123; // 核心 根据TransactionStatus信息进行回滚处理 txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus()); &#125; catch (TransactionSystemException ex2) &#123; logger.error(\"Application exception overridden by rollback exception\", ex); ex2.initApplicationException(ex); throw ex2; &#125; catch (RuntimeException ex2) &#123; logger.error(\"Application exception overridden by rollback exception\", ex); throw ex2; &#125; catch (Error err) &#123; logger.error(\"Application exception overridden by rollback error\", ex); throw err; &#125; &#125; else &#123; // 如果不满足回滚条件即使抛出异常也同样会提交 // We don't roll back on this exception. // Will still roll back if TransactionStatus.isRollbackOnly() is true. try &#123; txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125; catch (TransactionSystemException ex2) &#123; logger.error(\"Application exception overridden by commit exception\", ex); ex2.initApplicationException(ex); throw ex2; &#125; catch (RuntimeException ex2) &#123; logger.error(\"Application exception overridden by commit exception\", ex); throw ex2; &#125; catch (Error err) &#123; logger.error(\"Application exception overridden by commit error\", ex); throw err; &#125; &#125; &#125;&#125; 下面先判断当前是否存在事务，可以看到Spring的严谨，然后就是判断抛出的异常是否是RuntimeException及Error，之后就是rollback 判断抛出的异常是否是RuntimeException及Error 进入txInfo.transactionAttribute.rollbackOn(ex)方法一直进入直到看到下面的代码，可以看到这里的异常判断只处理了RuntimeException及Error异常，另一个编译型异常Exception是不处理的，这个在开发过程中需要特别注意12345... public boolean rollbackOn(Throwable ex) &#123; return (ex instanceof RuntimeException || ex instanceof Error);&#125; rollback 进入txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus());方法之后一直进入直到进入下面的代码，可以看到这里使用txObject.getConnectionHolder().getConnection();获取了我们之前新建的Connection，得到之后就是执行con.rollback();方法了12345678910111213141516// org.springframework.jdbc.datasource.DataSourceTransactionManager#doRollback @Overrideprotected void doRollback(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) &#123; logger.debug(\"Rolling back JDBC transaction on Connection [\" + con + \"]\"); &#125; try &#123; con.rollback(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(\"Could not roll back JDBC transaction\", ex); &#125;&#125; 4、提交事务 上面可以知道如果有异常的话是执行completeTransactionAfterThrowing(txInfo, ex);方法进行事务回滚，然后抛异常之后的逻辑都不执行 12345678910111213141516171819202122// 创建事物 创建TransactionInfo 完成了目标方法运行前的事务准备工作TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);Object retVal = null;try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. // 方法调用 retVal = invocation.proceedWithInvocation();&#125;catch (Throwable ex) &#123; // target invocation exception // 回滚事务 注意：只对RuntimeException回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex;&#125;finally &#123; // 清除信息 cleanupTransactionInfo(txInfo);&#125;// 提交事务commitTransactionAfterReturning(txInfo);return retVal; 如果没有异常的话会执行commitTransactionAfterReturning(txInfo);方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123protected void commitTransactionAfterReturning(TransactionInfo txInfo) &#123; if (txInfo != null &amp;&amp; txInfo.hasTransaction()) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Completing transaction for [\" + txInfo.getJoinpointIdentification() + \"]\"); &#125; txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125;&#125;// 进入 org.springframework.transaction.support.AbstractPlatformTransactionManager#commit@Overridepublic final void commit(TransactionStatus status) throws TransactionException &#123; if (status.isCompleted()) &#123; throw new IllegalTransactionStateException( \"Transaction is already completed - do not call commit or rollback more than once per transaction\"); &#125; DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status; if (defStatus.isLocalRollbackOnly()) &#123; if (defStatus.isDebug()) &#123; logger.debug(\"Transactional code has requested rollback\"); &#125; processRollback(defStatus); return; &#125; if (!shouldCommitOnGlobalRollbackOnly() &amp;&amp; defStatus.isGlobalRollbackOnly()) &#123; if (defStatus.isDebug()) &#123; logger.debug(\"Global transaction is marked as rollback-only but transactional code requested commit\"); &#125; processRollback(defStatus); // Throw UnexpectedRollbackException only at outermost transaction boundary // or if explicitly asked to. if (status.isNewTransaction() || isFailEarlyOnGlobalRollbackOnly()) &#123; throw new UnexpectedRollbackException( \"Transaction rolled back because it has been marked as rollback-only\"); &#125; return; &#125; // 事务提交 processCommit(defStatus);&#125;private void processCommit(DefaultTransactionStatus status) throws TransactionException &#123; try &#123; boolean beforeCompletionInvoked = false; try &#123; // 预留口子方法执行额外逻辑 prepareForCommit(status); triggerBeforeCommit(status); triggerBeforeCompletion(status); beforeCompletionInvoked = true; boolean globalRollbackOnly = false; if (status.isNewTransaction() || isFailEarlyOnGlobalRollbackOnly()) &#123; globalRollbackOnly = status.isGlobalRollbackOnly(); &#125; if (status.hasSavepoint()) &#123; if (status.isDebug()) &#123; logger.debug(\"Releasing transaction savepoint\"); &#125; // 如果存在保存点则清除保存点信息 status.releaseHeldSavepoint(); &#125; else if (status.isNewTransaction()) &#123; if (status.isDebug()) &#123; logger.debug(\"Initiating transaction commit\"); &#125; // 如果时独立事务直接提交 doCommit(status); &#125; // Throw UnexpectedRollbackException if we have a global rollback-only // marker but still didn't get a corresponding exception from commit. if (globalRollbackOnly) &#123; throw new UnexpectedRollbackException( \"Transaction silently rolled back because it has been marked as rollback-only\"); &#125; &#125; catch (UnexpectedRollbackException ex) &#123; // can only be caused by doCommit triggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK); throw ex; &#125; catch (TransactionException ex) &#123; // can only be caused by doCommit if (isRollbackOnCommitFailure()) &#123; doRollbackOnCommitException(status, ex); &#125; else &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN); &#125; throw ex; &#125; catch (RuntimeException ex) &#123; if (!beforeCompletionInvoked) &#123; triggerBeforeCompletion(status); &#125; doRollbackOnCommitException(status, ex); throw ex; &#125; catch (Error err) &#123; if (!beforeCompletionInvoked) &#123; triggerBeforeCompletion(status); &#125; // 提交过程中出现异常则回滚 doRollbackOnCommitException(status, err); throw err; &#125; // Trigger afterCommit callbacks, with an exception thrown there // propagated to callers but the transaction still considered as committed. try &#123; triggerAfterCommit(status); &#125; finally &#123; triggerAfterCompletion(status, TransactionSynchronization.STATUS_COMMITTED); &#125; &#125; finally &#123; cleanupAfterCompletion(status); &#125;&#125; 关注核心方法doCommit(status);这里是提交事务的关键，当然如果提交事务的时候发生了异常也会执行回滚操作，由下图可以看到Spring由那些类实现了此方法 我们这里进入的是org.springframework.jdbc.datasource.DataSourceTransactionManager#doCommit方法，终于看到我们熟悉的con.commit();方法 1234567891011121314151617// org.springframework.jdbc.datasource.DataSourceTransactionManager#doCommit@Overrideprotected void doCommit(DefaultTransactionStatus status) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) &#123; logger.debug(\"Committing JDBC transaction on Connection [\" + con + \"]\"); &#125; try &#123; // 提交事务 con.commit(); &#125; catch (SQLException ex) &#123; throw new TransactionSystemException(\"Could not commit JDBC transaction\", ex); &#125;&#125; 在此Spring事务的执行完成!!! 其他 为什么在 Spring 事务中不能切换数据源？ 在 Spring 的事务管理中所使用的数据库连接会和当前线程所绑定，即使我们设置了另外一个数据源，使用的还是当前的数据源连接。 什么是事务的传播级别？分成哪些传播级别？ 事务的传播行为，指的是当前带有事务配置的方法，需要怎么处理事务。 例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。 有一点需要注意，事务的传播级别，并不是数据库事务规范中的名词，而是 Spring 自身所定义的。通过事务的传播级别，Spring 才知道如何处理事务，是创建一个新事务呢，还是继续使用当前的事务。 在TransactionDefinition 接口中，定义了三类七种传播级别。代码如下 TransactionDefinition.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445// TransactionDefinition.java// ========== 支持当前事务的情况 ========== /** * 如果当前存在事务，则使用该事务。 * 如果当前没有事务，则创建一个新的事务。 */int PROPAGATION_REQUIRED = 0;/** * 如果当前存在事务，则使用该事务。 * 如果当前没有事务，则以非事务的方式继续运行。 */int PROPAGATION_SUPPORTS = 1;/** * 如果当前存在事务，则使用该事务。 * 如果当前没有事务，则抛出异常。 */int PROPAGATION_MANDATORY = 2;// ========== 不支持当前事务的情况 ========== /** * 创建一个新的事务。 * 如果当前存在事务，则把当前事务挂起。 */int PROPAGATION_REQUIRES_NEW = 3;/** * 以非事务方式运行。 * 如果当前存在事务，则把当前事务挂起。 */int PROPAGATION_NOT_SUPPORTED = 4;/** * 以非事务方式运行。 * 如果当前存在事务，则抛出异常。 */int PROPAGATION_NEVER = 5;// ========== 其他情况 ========== /** * 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行。 * 如果当前没有事务，则等价于 &#123;@link TransactionDefinition#PROPAGATION_REQUIRED&#125; */int PROPAGATION_NESTED = 6; 分类之后，其实还是比较好记的。当然，绝大数场景，我们只用 PROPAGATION_REQUIRED 传播级别。 总结 事务说白了就是“绑架”一个数据库连接，更改数据库的自动提交功能，使用手动提交机制。Spring把这一系列操作属性及数据库连接放到了ThreadLocal中，而ThreadLocal的key为“当前线程的值”，可以说一个线程一个连接一个事务` 声明式事务管理建立在AOP之上的，其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务 默认情况下Spring中的事务处理只对RuntimeException运行时异常进行回滚，对Exception编译性异常不会进行回滚 通过使用声明式事务，使业务代码和事务管理的逻辑分离，更加清晰。 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(七一)Spring事务之解析事务自定义标签","slug":"backend/framework/spring/analysis/Spring系列(七一)Spring事务之解析事务自定义标签","date":"2019-08-01T16:00:01.000Z","updated":"2019-09-16T13:11:04.955Z","comments":true,"path":"2019/08/02/backend/framework/spring/analysis/Spring系列(七一)Spring事务之解析事务自定义标签/","link":"","permalink":"http://www.songshuiyang.com/2019/08/02/backend/framework/spring/analysis/Spring系列(七一)Spring事务之解析事务自定义标签/","excerpt":"","text":"前言 Spring事务让我们从复杂的事务处理中得到解脱，使我们再不需要去处理获得连接、关闭连接、事务提交和回滚等操作，Spring事务分为声明式事务和编程式事务，其中编程式事务因为对代码入侵较大所以不被推荐使用，我们平常最常使用的是声明式事务也就是通过@Transactional注解的形式开启事务 编程式事务 示例代码123456789101112131415161718192021@Autowiredprivate TransactionTemplate transactionTemplate;@Autowiredprivate PlatformTransactionManager transactionManager;//开启事务保存数据boolean result = transactionTemplate.execute(new TransactionCallback&lt;Boolean&gt;() &#123; @Override public Boolean doInTransaction(TransactionStatus status) &#123; try &#123; // TODO something &#125; catch (Exception e) &#123; //TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); //手动开启事务回滚 status.setRollbackOnly(); logger.error(e.getMessage(), e); return false; &#125; return true; &#125;&#125;); 声明式事务 xml配置 123456&lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt; &lt;tx:annotation-driven proxy-target-class=\"false\" transaction-manager=\"transactionManager\" /&gt; &lt;tx:annotation-driven&gt;标签是开启声明式事务的开关，配置了这个就可以使用注解@Transactional来开启事务了 123456789101112// org.springframework.iframe.service.impl.UserServiceImpl#updateUserByRuntimeException @Transactionalpublic void updateUserByRuntimeException (IUser iUser) throws NullPointerException&#123; log.info(\"开启事务\"); if (userMapper.insertSelective(iUser) == 1) &#123; throw new NullPointerException(\"运行时异常\"); &#125; IUser iUser2 = userMapper.selectByPrimaryKey(1); iUser2.setAge(iUser2.getAge() + 1); userMapper.updateByPrimaryKeySelective(iUser2);&#125; 也可以用xml的方式配置那些方法需要加事务 xml配置 12345678910111213141516171819202122232425262728&lt;!-- 配置事务通知属性 --&gt;&lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!-- 定义事务传播属性 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"insert*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"edit*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"add*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"new*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"set*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"remove*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"change*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"check*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"get*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"find*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"load*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" propagation=\"REQUIRED\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; &lt;!-- 配置事务切面 --&gt;&lt;aop:config&gt; &lt;aop:pointcut id=\"serviceOperation\" expression=\"execution(* org.springframework.iframe.service.*.*(..))\"/&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"serviceOperation\"/&gt;&lt;/aop:config&gt; 从上面可以看到编程式事务需要配置哪些方法需要事务控制，比如&lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot;/&gt;配置的就是insert开头的方法会有事务控制，然后aop:config配置了事务切面，上面的配置是org.springframework.iframe.service包下方法名符合insert*、update*规则的方法会有事务控制 解析声明式事务原理解析 由上面介绍可以看到开启声明式事务的关键是&lt;tx:annotation-driven&gt;标签，由前些章节知识积累可以发现这个标签也是自定义标签，所以需要找到对应的NamespaceHandler 先查看NamespaceHandler的实现类 根据名称可以定位到TxNamespaceHandler，下面代码可以看到标签的解析是给通过TxAdviceBeanDefinitionParser类进行解析，标签的解析是通过AnnotationDrivenBeanDefinitionParser类进行解析12345678910111213141516public class TxNamespaceHandler extends NamespaceHandlerSupport &#123; static final String TRANSACTION_MANAGER_ATTRIBUTE = \"transaction-manager\"; static final String DEFAULT_TRANSACTION_MANAGER_BEAN_NAME = \"transactionManager\"; static String getTransactionManagerName(Element element) &#123; return (element.hasAttribute(TRANSACTION_MANAGER_ATTRIBUTE) ? element.getAttribute(TRANSACTION_MANAGER_ATTRIBUTE) : DEFAULT_TRANSACTION_MANAGER_BEAN_NAME); &#125; @Override public void init() &#123; // 对&lt;tx:advice/&gt;标签的解析 registerBeanDefinitionParser(\"advice\", new TxAdviceBeanDefinitionParser()); // 对&lt;tx:annotation-driven/&gt;标签的解析 registerBeanDefinitionParser(\"annotation-driven\", new AnnotationDrivenBeanDefinitionParser()); registerBeanDefinitionParser(\"jta-transaction-manager\", new JtaTransactionManagerBeanDefinitionParser()); &#125; &#125; AnnotationDrivenBeanDefinitionParser 进入parse()方法开始解析 123456789101112131415@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; registerTransactionalEventListenerFactory(parserContext); String mode = element.getAttribute(\"mode\"); if (\"aspectj\".equals(mode)) &#123; // mode=\"aspectj\" registerTransactionAspect(element, parserContext); &#125; else &#123; // mode=\"proxy\" // 提供对aspectj方式进行事务切入的支持 AopAutoProxyConfigurer.configureAutoProxyCreator(element, parserContext); &#125; return null;&#125; 我们这里是进入AopAutoProxyConfigurer.configueAutoProxyCreator(element, parserContext);方法，可以看到下面逻辑主要是注册了一些bean，这些bean支撑了整个事务功能，后面会详细说明 InfrastructureAdvisorAutoProxyCreator AnnotationTransactionAttributeSource TransactionInterceptor BeanFactoryTransactionAttributeSourceAdvisor 进入AopAutoProxyConfigurer.configureAutoProxyCreator(element, parserContext);方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Inner class to just introduce an AOP framework dependency when actually in proxy mode. */private static class AopAutoProxyConfigurer &#123; public static void configureAutoProxyCreator(Element element, ParserContext parserContext) &#123; // 注册 InfrastructureAdvisorAutoProxyCreator bean 这个类继承了 BeanPostProcessor，这里实现了AOP代理对象的创建 AopNamespaceUtils.registerAutoProxyCreatorIfNecessary(parserContext, element); String txAdvisorBeanName = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME; if (!parserContext.getRegistry().containsBeanDefinition(txAdvisorBeanName)) &#123; Object eleSource = parserContext.extractSource(element); // 创建 AnnotationTransactionAttributeSource definition. RootBeanDefinition sourceDef = new RootBeanDefinition( \"org.springframework.transaction.annotation.AnnotationTransactionAttributeSource\"); sourceDef.setSource(eleSource); sourceDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); // 注册TransactionAttributeSource bean，并使用Spring中的定义规则生成beanname String sourceName = parserContext.getReaderContext().registerWithGeneratedName(sourceDef); // 创建 TransactionInterceptor definition. RootBeanDefinition interceptorDef = new RootBeanDefinition(TransactionInterceptor.class); interceptorDef.setSource(eleSource); interceptorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); // &lt;tx:annotation-driven/&gt;标签在不指定transaction-manager属性的时候，会默认寻找id固定名为transactionManager的bean作为事务管理器 registerTransactionManager(element, interceptorDef); interceptorDef.getPropertyValues().add(\"transactionAttributeSource\", new RuntimeBeanReference(sourceName)); // 注册TransactionInterceptor bean， String interceptorName = parserContext.getReaderContext().registerWithGeneratedName(interceptorDef); // 创建 BeanFactoryTransactionAttributeSourceAdvisor definition. RootBeanDefinition advisorDef = new RootBeanDefinition(BeanFactoryTransactionAttributeSourceAdvisor.class); advisorDef.setSource(eleSource); advisorDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); // 将sourceName的bean注入advisorDef的transactionAttributeSource属性中 // 并将前两个BeanDefinition添加到第三个BeanDefinition的属性当中 advisorDef.getPropertyValues().add(\"transactionAttributeSource\", new RuntimeBeanReference(sourceName)); advisorDef.getPropertyValues().add(\"adviceBeanName\", interceptorName); if (element.hasAttribute(\"order\")) &#123; advisorDef.getPropertyValues().add(\"order\", element.getAttribute(\"order\")); &#125; // 注册BeanFactoryTransactionAttributeSourceAdvisor bean parserContext.getRegistry().registerBeanDefinition(txAdvisorBeanName, advisorDef); // 创建CompositeComponentDefinition CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), eleSource); compositeDef.addNestedComponent(new BeanComponentDefinition(sourceDef, sourceName)); compositeDef.addNestedComponent(new BeanComponentDefinition(interceptorDef, interceptorName)); compositeDef.addNestedComponent(new BeanComponentDefinition(advisorDef, txAdvisorBeanName)); parserContext.registerComponent(compositeDef); &#125; &#125;&#125; AopNamespaceUtils.registerAutoProxyCreatorIfNecessary(parserContext, element);，这里注册了 InfrastructureAdvisorAutoProxyCreator bean 这个类继承了 BeanPostProcessor，这里实现了AOP代理对象的创建 所以关注InfrastructureAdvisorAutoProxyCreator的postProcessAfterInitialization()方法，进入其父类AbstractAutoProxyCreator中，这行代码是不是很熟悉没错就是创建AOP动态代理对象的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445// org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#postProcessAfterInitializationpublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; // 根据给定的bean的class和name构建出个key，格式: beanClassName_beanName Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; // 如果它适合被代理，则需要封装指定的bean return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125;protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 如果已经处理过 if (beanName != null &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; // 无需增强 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // 给定的bean类是否代表一个基础设施类，基础设施类不应代理，或者配置了指定bean不需要自动代理 if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // Create proxy if we have advice. // 如果存在增强方法则创建代理 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); // 如果获取到了增强则需要针对增强创建代理 if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 1、获取增强方法或者增强器 2、根据获取的增强进行代理 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 关注Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);这里是检查是否存在增强方法，如果有的话则创建代理，这里的内容AOP章节已经介绍了些 1234567891011121314151617181920@Overrideprotected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, TargetSource targetSource) &#123; // 获取所有的增强以及寻找所有增强中适用于bean的增强并应用 List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; &#125; return advisors.toArray();&#125;protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 获取所有增强器 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 从所有增强器中找出适合的增强器 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 可以看到先是获取了所有的增强器，然后在所有增强器中找出适合的增强器并返回 获取所有增强器 进入findCandidateAdvisors();方法之后直接跳到findAdvisorBeans()方法，关注advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Advisor.class, true, false);方法这里获取所有对应Advisor.class的类 回顾之前的AopAutoProxyConfigurer.configureAutoProxyCreator(element, parserContext);方法是注册了BeanFactoryTransactionAttributeSourceAdvisor，看名称可以知道是继承了Advisor接口，所以这里获取增强器也会把这个类添加进来123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public List&lt;Advisor&gt; findAdvisorBeans() &#123; // Determine list of advisor bean names, if not cached already. String[] advisorNames = null; synchronized (this) &#123; advisorNames = this.cachedAdvisorBeanNames; if (advisorNames == null) &#123; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the auto-proxy creator apply to them! // 获取所有的beanName advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this.beanFactory, Advisor.class, true, false); this.cachedAdvisorBeanNames = advisorNames; &#125; &#125; if (advisorNames.length == 0) &#123; return new LinkedList&lt;Advisor&gt;(); &#125; List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;(); // 循环所有的beanname找出对应的增强方法 for (String name : advisorNames) &#123; if (isEligibleBean(name)) &#123; if (this.beanFactory.isCurrentlyInCreation(name)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Skipping currently created advisor '\" + name + \"'\"); &#125; &#125; else &#123; try &#123; advisors.add(this.beanFactory.getBean(name, Advisor.class)); &#125; catch (BeanCreationException ex) &#123; Throwable rootCause = ex.getMostSpecificCause(); if (rootCause instanceof BeanCurrentlyInCreationException) &#123; BeanCreationException bce = (BeanCreationException) rootCause; if (this.beanFactory.isCurrentlyInCreation(bce.getBeanName())) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Skipping advisor '\" + name + \"' with dependency on currently created bean: \" + ex.getMessage()); &#125; // Ignore: indicates a reference back to the bean we're trying to advise. // We want to find advisors other than the currently created bean itself. continue; &#125; &#125; throw ex; &#125; &#125; &#125; &#125; return advisors;&#125; 从所有增强器中找出适合的增强器 上面已经获取了所有增强器，接下来就是匹配符合条件的增强器了，下面关注最后一个canApply()方法可以看到if (advisor instanceof PointcutAdvisor)判断 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253protected List&lt;Advisor&gt; findAdvisorsThatCanApply( List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123; // 过滤已经得到的advisors return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123; ProxyCreationContext.setCurrentProxiedBeanName(null); &#125;&#125; public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) &#123; if (candidateAdvisors.isEmpty()) &#123; return candidateAdvisors; &#125; List&lt;Advisor&gt; eligibleAdvisors = new LinkedList&lt;Advisor&gt;(); // 首先处理引介增强 for (Advisor candidate : candidateAdvisors) &#123; // canApply真正的匹配 if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; boolean hasIntroductions = !eligibleAdvisors.isEmpty(); for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor) &#123; // 引介增强已经处理 // already processed continue; &#125; // 对于普通bean的处理 if (canApply(candidate, clazz, hasIntroductions)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; return eligibleAdvisors;&#125; public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; if (advisor instanceof IntroductionAdvisor) &#123; return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); &#125; else if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pca = (PointcutAdvisor) advisor; return canApply(pca.getPointcut(), targetClass, hasIntroductions); &#125; else &#123; // It doesn't have a pointcut so we assume it applies. return true; &#125;&#125; 当前我们分析UserService是否适用于此增强方法，那么当前的advisor就是之前自定义标签解析的BeanFactoryTransactionAttributeSourceAdvisor，这个类间接实现了PointcutAdvisor，然后调用canApply(pca.getPointcut(), targetClass, hasIntroductions)方法，所以现在就将AOP和TX联系起来了 进入canApply(pca.getPointcut(), targetClass, hasIntroductions)方法，这里pca.getPointcut()返回的是TransactionAttributeSourcePointcut，这也是上面解析自定义标签时注入进入的 123456789101112131415161718192021222324252627282930313233public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, \"Pointcut must not be null\"); if (!pc.getClassFilter().matches(targetClass)) &#123; return false; &#125; // TransactionAttributeSourcePointcut里的MethodMatcher MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; // No need to iterate the methods if we're matching any method anyway... return true; &#125; IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;Class&lt;?&gt;&gt;(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); classes.add(targetClass); for (Class&lt;?&gt; clazz : classes) &#123; Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); // 获取对应类的所有接口并连同类本身一起遍历，在遍历过程中又对类中的方法再次遍历，一但匹配成功便认为这个类使用于当前增强器 for (Method method : methods) &#123; if ((introductionAwareMethodMatcher != null &amp;&amp; introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions)) || methodMatcher.matches(method, targetClass)) &#123; return true; &#125; &#125; &#125; return false;&#125; 可以看到先是获取TransactionAttributeSourcePointcut里的MethodMatcher，然后就是获取对应类的所有接口并连同类本身一起遍历，在遍历过程中又对类中的方法再次遍历，一但匹配成功便认为这个类使用于当前增强器，所以关注TransactionAttributeSourcePointcut里的MethodMatcher里的matches(method, targetClass)方法 123456789@Overridepublic boolean matches(Method method, Class&lt;?&gt; targetClass) &#123; if (TransactionalProxy.class.isAssignableFrom(targetClass)) &#123; return false; &#125; // 自定义标签解析时注入，这里tas是AnnotationTransactionAttributeSource TransactionAttributeSource tas = getTransactionAttributeSource(); return (tas == null || tas.getTransactionAttribute(method, targetClass) != null);&#125; 进入tas.getTransactionAttribute()方法，这里跳到org.springframework.transaction.interceptor.AbstractFallbackTransactionAttributeSource#getTransactionAttribute，这里是判断我们的业务方法或者类上是否有@Transactional注解并且做了一下缓存处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 判断我们的业务方法或者类上是否有@Transactional注解 * * Determine the transaction attribute for this method invocation. * &lt;p&gt;Defaults to the class's transaction attribute if no method attribute is found. * @param method the method for the current invocation (never &#123;@code null&#125;) * @param targetClass the target class for this invocation (may be &#123;@code null&#125;) * @return TransactionAttribute for this method, or &#123;@code null&#125; if the method * is not transactional */@Overridepublic TransactionAttribute getTransactionAttribute(Method method, Class&lt;?&gt; targetClass) &#123; if (method.getDeclaringClass() == Object.class) &#123; return null; &#125; // First, see if we have a cached value. Object cacheKey = getCacheKey(method, targetClass); Object cached = this.attributeCache.get(cacheKey); if (cached != null) &#123; // Value will either be canonical value indicating there is no transaction attribute, // or an actual transaction attribute. if (cached == NULL_TRANSACTION_ATTRIBUTE) &#123; return null; &#125; else &#123; return (TransactionAttribute) cached; &#125; &#125; else &#123; // We need to work it out. // 获取事物属性 TransactionAttribute txAttr = computeTransactionAttribute(method, targetClass); // Put it in the cache. if (txAttr == null) &#123; this.attributeCache.put(cacheKey, NULL_TRANSACTION_ATTRIBUTE); &#125; else &#123; String methodIdentification = ClassUtils.getQualifiedMethodName(method, targetClass); if (txAttr instanceof DefaultTransactionAttribute) &#123; ((DefaultTransactionAttribute) txAttr).setDescriptor(methodIdentification); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Adding transactional method '\" + methodIdentification + \"' with attribute: \" + txAttr); &#125; // 存入缓存 this.attributeCache.put(cacheKey, txAttr); &#125; return txAttr; &#125;&#125; 关注computeTransactionAttribute(method, targetClass);，可以看到如果方法中存在事务属性，则使用方法上的事务属性，否则使用方法所在类上的事务属性，如果还是没找到就搜寻接口中的方法的事务属性，再没有就找接口类上的事务属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected TransactionAttribute computeTransactionAttribute(Method method, Class&lt;?&gt; targetClass) &#123; // Don't allow no-public methods as required. if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) &#123; return null; &#125; // Ignore CGLIB subclasses - introspect the actual user class. Class&lt;?&gt; userClass = ClassUtils.getUserClass(targetClass); // The method may be on an interface, but we need attributes from the target class. // If the target class is null, the method will be unchanged. Method specificMethod = ClassUtils.getMostSpecificMethod(method, userClass); // If we are dealing with method with generic parameters, find the original method. specificMethod = BridgeMethodResolver.findBridgedMethod(specificMethod); // First try is the method in the target class. // 查看方法中是否存在事务声明 TransactionAttribute txAttr = findTransactionAttribute(specificMethod); if (txAttr != null) &#123; return txAttr; &#125; // Second try is the transaction attribute on the target class. // 查看方法所在类中是否有事务声明 txAttr = findTransactionAttribute(specificMethod.getDeclaringClass()); if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; if (specificMethod != method) &#123; // Fallback is to look at the original method. // 查看接口方法中是否有事务声明 txAttr = findTransactionAttribute(method); if (txAttr != null) &#123; return txAttr; &#125; // Last fallback is the class of the original method. // 查看接口类中是否有事务声明 txAttr = findTransactionAttribute(method.getDeclaringClass()); if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) &#123; return txAttr; &#125; &#125; return null;&#125; 具体查找逻辑在findTransactionAttribute()方法上 123456789101112131415@Overrideprotected TransactionAttribute findTransactionAttribute(Method method) &#123; return determineTransactionAttribute(method);&#125; protected TransactionAttribute determineTransactionAttribute(AnnotatedElement ae) &#123; if (ae.getAnnotations().length &gt; 0) &#123; for (TransactionAnnotationParser annotationParser : this.annotationParsers) &#123; TransactionAttribute attr = annotationParser.parseTransactionAnnotation(ae); if (attr != null) &#123; return attr; &#125; &#125; &#125; return null;&#125; 然后就是跳到org.springframework.transaction.annotation.SpringTransactionAnnotationParser#parseTransactionAnnotation(java.lang.reflect.AnnotatedElement)方法上，这里的方法就是解析 {@link Transactional} 注解，并封装成TransactionAttribute 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overridepublic TransactionAttribute parseTransactionAnnotation(AnnotatedElement ae) &#123; AnnotationAttributes attributes = AnnotatedElementUtils.getMergedAnnotationAttributes(ae, Transactional.class); if (attributes != null) &#123; return parseTransactionAnnotation(attributes); &#125; else &#123; return null; &#125;&#125;/** * 解析 &#123;@link Transactional&#125; 注解 * * @param attributes * @return */protected TransactionAttribute parseTransactionAnnotation(AnnotationAttributes attributes) &#123; RuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute(); Propagation propagation = attributes.getEnum(\"propagation\"); rbta.setPropagationBehavior(propagation.value()); Isolation isolation = attributes.getEnum(\"isolation\"); rbta.setIsolationLevel(isolation.value()); rbta.setTimeout(attributes.getNumber(\"timeout\").intValue()); rbta.setReadOnly(attributes.getBoolean(\"readOnly\")); rbta.setQualifier(attributes.getString(\"value\")); ArrayList&lt;RollbackRuleAttribute&gt; rollBackRules = new ArrayList&lt;RollbackRuleAttribute&gt;(); Class&lt;?&gt;[] rbf = attributes.getClassArray(\"rollbackFor\"); for (Class&lt;?&gt; rbRule : rbf) &#123; RollbackRuleAttribute rule = new RollbackRuleAttribute(rbRule); rollBackRules.add(rule); &#125; String[] rbfc = attributes.getStringArray(\"rollbackForClassName\"); for (String rbRule : rbfc) &#123; RollbackRuleAttribute rule = new RollbackRuleAttribute(rbRule); rollBackRules.add(rule); &#125; Class&lt;?&gt;[] nrbf = attributes.getClassArray(\"noRollbackFor\"); for (Class&lt;?&gt; rbRule : nrbf) &#123; NoRollbackRuleAttribute rule = new NoRollbackRuleAttribute(rbRule); rollBackRules.add(rule); &#125; String[] nrbfc = attributes.getStringArray(\"noRollbackForClassName\"); for (String rbRule : nrbfc) &#123; NoRollbackRuleAttribute rule = new NoRollbackRuleAttribute(rbRule); rollBackRules.add(rule); &#125; rbta.getRollbackRules().addAll(rollBackRules); return rbta;&#125; 回到AbstractAutoProxyCreator#postProcessAfterInitialization方法，这里是创建AOP代理对象的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445// org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#postProcessAfterInitializationpublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; // 根据给定的bean的class和name构建出个key，格式: beanClassName_beanName Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; // 如果它适合被代理，则需要封装指定的bean return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125;protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 如果已经处理过 if (beanName != null &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; // 无需增强 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // 给定的bean类是否代表一个基础设施类，基础设施类不应代理，或者配置了指定bean不需要自动代理 if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // Create proxy if we have advice. // 如果存在增强方法则创建代理 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); // 如果获取到了增强则需要针对增强创建代理 if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 1、获取增强方法或者增强器 2、根据获取的增强进行代理 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 现在来看看UserService的获取到的增强器，可以看到是获取到了BeanFactoryTransactionAttributeSourceAdvisor，这里是根据该Advisor来创建代理对象，到这里Spring事务自定义标签的解析过程已经介绍完了，可以总结为下面几个步骤： 1、解析事务自定义标签&lt;tx:annotation-driven&gt;，注册InfrastructureAdvisorAutoProxyCreator及BeanFactoryTransactionAttributeSourceAdvisor等bean 2、InfrastructureAdvisorAutoProxyCreator实现了BeanPostProcessor，所以可以遍历所有的bean用于创建代理对象 3、那些类需要创建事务代理对象，则由BeanFactoryTransactionAttributeSourceAdvisor提供实现 编程式事务原理解析 可以看到编程式事务是通过TransactionTemplate及PlatformTransactionManager硬编码的形式来实现的，实际使用起来比声明式事务麻烦，而且侵入性强，因为这个很少使用所以不解析 总结 &lt;tx:annotation-driven&gt;标签是开启事务的开关，配置了这个就可以使用注解@Transactional来开启事务了，解析该标签的过程就是注册bean的过程 注册BeanFactoryTransactionAttributeSourceAdvisor是整个事务功能的基础，这个类是判断这个bean是否需要适用事务增强，如果需要的话就创建AOP代理对象 在解析事务自定义标签时Spring将TransactionInterceptor类注入到了BeanFactoryTransactionAttributeSourceAdvisor，所以在调用事务增强器增强的代理类时会首先执行TransactionInterceptor进行增强，同时其invoke方法完成了整个事务的逻辑 Spring事务的初始化过程的大概逻辑是检查所有的bean是否需要创建AOP代理，判断逻辑是判断所在类及所在类的方法是否有@Transactional注解，如果有的话就创建代理，创建代理之后就是执行代理方法了，下章介绍参考 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(七十)Spring事务之基础概念","slug":"backend/framework/spring/analysis/Spring系列(七十)Spring事务之基础概念","date":"2019-08-01T16:00:00.000Z","updated":"2019-09-16T13:11:04.977Z","comments":true,"path":"2019/08/02/backend/framework/spring/analysis/Spring系列(七十)Spring事务之基础概念/","link":"","permalink":"http://www.songshuiyang.com/2019/08/02/backend/framework/spring/analysis/Spring系列(七十)Spring事务之基础概念/","excerpt":"","text":"前言什么是事务？ 事务就是对一系列的数据库操作（比如插入多条数据）进行统一的提交或回滚操作，如果插入成功，那么一起成功，如果中间有一条出现异常，那么回滚之前的所有操作。 事务的特性ACID1、原子性 Atomicity 一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 2、一致性 Consistency 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器)、级联回滚等。 3、隔离性 Isolation 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 4、持久性 Durability 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 事务的隔离性 MySQL数据库针对这四种特性，为我们提供的四种隔离级别，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五四)AOP源码解析之代理对象方法执行","slug":"backend/framework/spring/analysis/Spring系列(五四)AOP源码解析之代理对象方法执行","date":"2019-07-31T16:00:04.000Z","updated":"2019-09-16T13:11:05.195Z","comments":true,"path":"2019/08/01/backend/framework/spring/analysis/Spring系列(五四)AOP源码解析之代理对象方法执行/","link":"","permalink":"http://www.songshuiyang.com/2019/08/01/backend/framework/spring/analysis/Spring系列(五四)AOP源码解析之代理对象方法执行/","excerpt":"","text":"前言 上一章节介绍了AOP代理对象的创建，那么实际方法的运行是通过代理对象来操作的，本章节将介绍代理对象方法的执行过程 AopProxy它有两个子类，所以不同代理对象方法执行过程是不一样的 JdkDynamicAopProxy是基于 JDK 的 AOP 代理实现类 ObjenesisCglibAopProxy是基于 CGLIB 的 AOP 的代理实现类 解析1、JdkDynamicAopProxy 我们知道JDK的动态代理是通过Proxy,InvocationHandler来实现的，所以抓住这两个点来分析这个JdkDynamicAopProxy 先看一下JdkDynamicAopProxy这个类的继承关系，可以看到这个类实现了InvocationHandler接口，所以关注里面的invoke方法，同时还继承了AopProxy接口，这个接口的作用是返回对应的代理对象 下面是JdkDynamicAopProxy的主体代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; private static final long serialVersionUID = 5531744639992436476L; private static final Log logger = LogFactory.getLog(JdkDynamicAopProxy.class); /** Config used to configure this proxy */ private final AdvisedSupport advised; /** * Is the &#123;@link #equals&#125; method defined on the proxied interfaces? */ private boolean equalsDefined; /** * Is the &#123;@link #hashCode&#125; method defined on the proxied interfaces? */ private boolean hashCodeDefined; /** * Construct a new JdkDynamicAopProxy for the given AOP configuration. * @param config the AOP configuration as AdvisedSupport object * @throws AopConfigException if the config is invalid. We try to throw an informative * exception in this case, rather than let a mysterious failure happen later. */ public JdkDynamicAopProxy(AdvisedSupport config) throws AopConfigException &#123; Assert.notNull(config, \"AdvisedSupport must not be null\"); if (config.getAdvisors().length == 0 &amp;&amp; config.getTargetSource() == AdvisedSupport.EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException(\"No advisors and no TargetSource specified\"); &#125; this.advised = config; &#125; @Override public Object getProxy() &#123; return getProxy(ClassUtils.getDefaultClassLoader()); &#125; @Override public Object getProxy(ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating JDK dynamic proxy: target source is \" + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &#125; /** * Finds any &#123;@link #equals&#125; or &#123;@link #hashCode&#125; method that may be defined * on the supplied set of interfaces. * @param proxiedInterfaces the interfaces to introspect */ private void findDefinedEqualsAndHashCodeMethods(Class&lt;?&gt;[] proxiedInterfaces) &#123; for (Class&lt;?&gt; proxiedInterface : proxiedInterfaces) &#123; Method[] methods = proxiedInterface.getDeclaredMethods(); for (Method method : methods) &#123; if (AopUtils.isEqualsMethod(method)) &#123; this.equalsDefined = true; &#125; if (AopUtils.isHashCodeMethod(method)) &#123; this.hashCodeDefined = true; &#125; if (this.equalsDefined &amp;&amp; this.hashCodeDefined) &#123; return; &#125; &#125; &#125; &#125; /** * Implementation of &#123;@code InvocationHandler.invoke&#125;. * &lt;p&gt;Callers will see exactly the exception thrown by the target, * unless a hook method throws an exception. */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class&lt;?&gt; targetClass = null; Object target = null; try &#123; // 如果被代理的目标对象要执行的方法是equal则执行JdkDynamicAopProxy（即代理对象的equal）方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; // 如果被代理的目标对象要执行的方法是hashCode则执行JdkDynamicAopProxy（即代理对象的hashCode）方法 else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; // 有时候目标对象内部的自我调用将无法实施切面中的增强则需要通过此属性暴露代理 if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // May be null. Get as late as possible to minimize the time we \"own\" the target, // in case it comes from a pool. target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; // Get the interception chain for this method. // 获取当前方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); // 如果没有发现任何拦截器那么直接调用切点方法 retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... // 将拦截器封装在ReflectiveMethodInvocation，以便于使用其proceed进行链接表用拦截器 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. // 执行拦截器链 retVal = invocation.proceed(); &#125; // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned \"this\" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; // 返回结果 else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( \"Null return value from advice does not match primitive return type for: \" + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; ... 关注invoke方法，根据上面代码可以看到如果执行的是equals或者hashCode方法则执行JdkDynamicAopProxy里面对应的内部方法，然后就是获取当前获取当前方法的拦截器链，对于没有拦截器的方法直接调用原有方法，有拦截器的方法会构造ReflectiveMethodInvocation，并沿着拦截器链进行调用。整个调用链的入口在其proceed方法中 1、获取当前方法的拦截器链 this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);方法，这个方法做了一下缓存处理，因为那些方法需要执行代理都是之前写好固定的 12345678910111213public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, Class&lt;?&gt; targetClass) &#123; // 从缓存中寻找该方法的拦截链是否已经获取过（可能被代理对象的某个方法被调用过多次， // 调用第一次就会获取一次，后面多次调用时，则需从缓存中直接获取，无需多次获取， // 这样就会提高性能），如果已经获取过，直接返回 MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object&gt; cached = this.methodCache.get(cacheKey); if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this, method, targetClass); this.methodCache.put(cacheKey, cached); &#125; return cached;&#125; 继续跟进this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice(this, method, targetClass);方法，可以看到这边就是一个拦截器的过滤，可以看到主体逻辑是循环Advisor通过切点匹配MethodMatchers.matches(mm, method, actualClass, hasIntroductions) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 其实这边就是一个拦截器的过滤，我们在生产环境中，我们一般会用正则表达来定义切点（expression）， * 因为并不是每个方法都需要切，会影响性能，所以matches这个方法很重要 * * @param config the AOP configuration in the form of an Advised object * @param method the proxied method * @param targetClass the target class (may be &#123;@code null&#125; to indicate a proxy without * target object, in which case the method's declaring class is the next best option) * @return */@Overridepublic List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice( Advised config, Method method, Class&lt;?&gt; targetClass) &#123; // This is somewhat tricky... We have to process introductions first, // but we need to preserve order in the ultimate list. // 先定义了一个拦截链的List大小最大为我们传入advisor的个数 List&lt;Object&gt; interceptorList = new ArrayList&lt;Object&gt;(config.getAdvisors().length); Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); for (Advisor advisor : config.getAdvisors()) &#123; if (advisor instanceof PointcutAdvisor) &#123; // Add it conditionally. PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; MethodInterceptor[] interceptors = registry.getInterceptors(advisor); MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &#123; if (mm.isRuntime()) &#123; // Creating a new object instance in the getInterceptors() method // isn't a problem as we normally cache created chains. for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList;&#125; 2、对于没有拦截器的方法直接调用原有方法 如果上面获取的chain是isEmpty()，下面就是直接调用method.invoke(target, args);方法 12345678910111213141516171819202122232425262728if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); // 如果没有发现任何拦截器那么直接调用切点方法 retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);&#125; public static Object invokeJoinpointUsingReflection(Object target, Method method, Object[] args) throws Throwable &#123; // 使用反射执行方法 try &#123; ReflectionUtils.makeAccessible(method); return method.invoke(target, args); &#125; catch (InvocationTargetException ex) &#123; // Invoked method threw a checked exception. // We must rethrow it. The client won't see the interceptor. throw ex.getTargetException(); &#125; catch (IllegalArgumentException ex) &#123; throw new AopInvocationException(\"AOP configuration seems to be invalid: tried calling method [\" + method + \"] on target [\" + target + \"]\", ex); &#125; catch (IllegalAccessException ex) &#123; throw new AopInvocationException(\"Could not access method [\" + method + \"]\", ex); &#125;&#125; 3、有拦截器的方法会构造ReflectiveMethodInvocation执行proceed()方法 如果上面获取的chain是isNotEmpty()，就需要执行相应拦截器的方法了，可以看到是封装了一个ReflectiveMethodInvocation对象，然后执行其proceed()方法 12345678else &#123; // We need to create a method invocation... // 将拦截器封装在ReflectiveMethodInvocation，以便于使用其proceed进行链接表用拦截器 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. // 执行拦截器链 retVal = invocation.proceed();&#125; 进入invocation.proceed();方法，可以看到这里使用了一个拦截器链的操作，从索引为-1的拦截器开始，并递增，如果拦截器迭代调用完成，则调用目标方法 123456789101112131415161718192021222324252627282930313233@Overridepublic Object proceed() throws Throwable &#123; // We start with an index of -1 and increment early. // 执行完所有增强后执行切点方法，从索引为-1的拦截器开始，并递增，如果拦截器迭代调用完成，则调用目标方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 获取下一个要执行的拦截器 沿着拦截器链执行 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. // 对方法进行动态匹配，切点的匹配就在这里进行 InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. // 不匹配则跳过这个拦截器调用下一个 return proceed(); &#125; &#125; else &#123; // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. // 这是一个拦截器，直接调用它，将this作为参数传递以保证当前实例中调用链的执行 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125;&#125; 2、ObjenesisCglibAopProxy 先看一下ObjenesisCglibAopProxy这个类的继承关系 Cglib调用方法的核心逻辑在DynamicAdvisedInterceptor的intercept方法中，和jdk方式实现代理的invoke方法大同小异 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable &#123; private final AdvisedSupport advised; public DynamicAdvisedInterceptor(AdvisedSupport advised) &#123; this.advised = advised; &#125; @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Class&lt;?&gt; targetClass = null; Object target = null; try &#123; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // May be null. Get as late as possible to minimize the time we // \"own\" the target, in case it comes from a pool... target = getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; // 获取拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; // We can skip creating a MethodInvocation: just invoke the target directly. // Note that the final invoker must be an InvokerInterceptor, so we know // it does nothing but a reflective operation on the target, and no hot // swapping or fancy proxying. // 拦截器链为空直接激活原方法 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; // We need to create a method invocation... // 进入链 retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null) &#123; releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; 关注retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();这行代码，这里构造了CglibMethodInvocation查看这个类，然后执行proceed()方法，可以发现这个类继承了ReflectiveMethodInvocation这个类，所以这里的proceed()方法和我们上面jdk动态代理执行的proceed()方法是一样的 总结参考 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五三)AOP源码解析之创建AOP代理","slug":"backend/framework/spring/analysis/Spring系列(五三)AOP源码解析之创建AOP代理","date":"2019-07-31T16:00:03.000Z","updated":"2019-09-16T13:11:05.171Z","comments":true,"path":"2019/08/01/backend/framework/spring/analysis/Spring系列(五三)AOP源码解析之创建AOP代理/","link":"","permalink":"http://www.songshuiyang.com/2019/08/01/backend/framework/spring/analysis/Spring系列(五三)AOP源码解析之创建AOP代理/","excerpt":"","text":"前言 上一章节介绍了&lt;aop:aspectj-autoproxy/&gt;的解析过程，最终结果是得到AnnotationAwareAspectJAutoProxyCreator 这个bean，这个类用于创建AOP的代理类，那么这个类到底做了什么工作来完成AOP的功能的呢？ 先看一下AnnotationAwareAspectJAutoProxyCreator 的类继承关系 12345678910111213141516AspectJAwareAdvisorAutoProxyCreator (org.springframework.aop.aspectj.autoproxy) AbstractAdvisorAutoProxyCreator (org.springframework.aop.framework.autoproxy) AbstractAutoProxyCreator (org.springframework.aop.framework.autoproxy) ProxyProcessorSupport (org.springframework.aop.framework) ProxyConfig (org.springframework.aop.framework) Object (java.lang) Serializable (java.io) Ordered (org.springframework.core) BeanClassLoaderAware (org.springframework.beans.factory) Aware (org.springframework.beans.factory) AopInfrastructureBean (org.springframework.aop.framework) SmartInstantiationAwareBeanPostProcessor (org.springframework.beans.factory.config) InstantiationAwareBeanPostProcessor (org.springframework.beans.factory.config) BeanPostProcessor (org.springframework.beans.factory.config) BeanFactoryAware (org.springframework.beans.factory) Aware (org.springframework.beans.factory) 解析 由AnnotationAwareAspectJAutoProxyCreator的继承关系图可以注意到此类实现了 BeanPostProcessor接口，这个接口前面经常看见，实现了这个接口是可以在bean初始化之前和初始化之后添加一些逻辑，到这里，我们大概可以猜出代理类是怎样和目标对象联系在一起的，实现偷天换日 先回顾下doCreateBean方法 123456789101112131415161718192021222324252627// AbstractAutowireCapableBeanFactoryprotected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 1. 创建实例 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; ... // Initialize the bean instance. Object exposedObject = bean; try &#123; // 2. 装载属性 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; // 3. 初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; ...&#125; 在上面第 3 步 initializeBean(...)初始化方法中会调用 BeanPostProcessor 中的方法，如下： 1234567891011121314151617181920protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; ... Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 1. 执行每一个 BeanPostProcessor 的 postProcessBeforeInitialization 方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 激活用户自定义的init方法 1、InitializingBean接口afterPropertiesSet方法 2、bean 定义的init-method=\"\"方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; ... if (mbd == null || !mbd.isSynthetic()) &#123; // 我们关注的重点是这里！！！ // 2. 执行每一个 BeanPostProcessor 的 postProcessAfterInitialization 方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 由上面的代码可以看到Spring AOP 会在 IOC 容器创建 bean 实例的最后对 bean 进行处理，其实就是在这一步进行代理增强。 我们来看一下它是怎么实现 BeanPostProcessor接口的，具体实现在父类AbstractAutoProxyCreator#postProcessAfterInitialization中，下面的代码可以看到先是判断这个bean是否需要被代理，如果要的话就是返回对应的代理类了，具体逻辑在wrapIfNecessary(bean, beanName, cacheKey);方法中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Create a proxy with the configured interceptors if the bean is * identified as one to proxy by the subclass. * @see #getAdvicesAndAdvisorsForBean */@Overridepublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; // 根据给定的bean的class和name构建出个key，格式: beanClassName_beanName Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; // 如果它适合被代理，则需要封装指定的bean return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125;/** * Wrap the given bean if necessary, i.e. if it is eligible for being proxied. * @param bean the raw bean instance * @param beanName the name of the bean * @param cacheKey the cache key for metadata access * @return a proxy wrapping the bean, or the raw bean instance as-is */protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 如果已经处理过 if (beanName != null &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; // 无需增强 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // 给定的bean类是否代表一个基础设施类，基础设施类不应代理，或者配置了指定bean不需要自动代理 if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // Create proxy if we have advice. // 核心方法 如果存在增强方法则创建代理 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); // 如果获取到了增强则需要针对增强创建代理 if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 1、获取增强方法或者增强器 2、根据获取的增强进行代理 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 从上面的代码可以看到代理创建的雏形，主要步骤分为两步 1、获取增强方法或者增强器 2、根据获取的增强进行代理 1、获取增强方法或者增强器 先来看获取增强方法的实现逻辑getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); 1234567891011121314151617181920@Overrideprotected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, TargetSource targetSource) &#123; // 获取所有的增强以及寻找所有增强中适用于bean的增强并应用 List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; &#125; return advisors.toArray();&#125;protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 获取所有增强器 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 从所有增强器中找出适合的增强器 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 可以看到先是获取了所有的增强器，然后在所有增强器中找出适合的增强器并返回 获取所有增强器 当使用注解方式配置AOP的时候并不是丢弃了对XML配置的支持，在这里调用父类方法加载配置文件中的AOP声明，然后再add使用注解配置的Advisor 1234567891011@Overrideprotected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // Add all the Spring advisors found according to superclass rules. // 当使用注解方式配置AOP的时候并不是丢弃了对XML配置的支持 // 在这里调用父类方法加载配置文件中的AOP声明 List&lt;Advisor&gt; advisors = super.findCandidateAdvisors(); // Build Advisors for all AspectJ aspects in the bean factory.// 获取注解配置的Advisor advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); return advisors;&#125; this.aspectJAdvisorsBuilder.buildAspectJAdvisors()方法是获取注解配置的Advisor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public List&lt;Advisor&gt; buildAspectJAdvisors() &#123; List&lt;String&gt; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; synchronized (this) &#123; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;(); aspectNames = new LinkedList&lt;String&gt;(); // 获取所有的beanName String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors( this.beanFactory, Object.class, true, false); // 循环所有的beanName找出对应的增强方法 for (String beanName : beanNames) &#123; // 不合法的bean则略过 if (!isEligibleBean(beanName)) &#123; continue; &#125; // We must be careful not to instantiate beans eagerly as in this case they // would be cached by the Spring conainer but would not have been weaved. // 获取对应的bean的类型 Class&lt;?&gt; beanType = this.beanFactory.getType(beanName); if (beanType == null) &#123; continue; &#125; // 如果存在Aspect注解 if (this.advisorFactory.isAspect(beanType)) &#123; aspectNames.add(beanName); AspectMetadata amd = new AspectMetadata(beanType, beanName); if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) &#123; MetadataAwareAspectInstanceFactory factory = new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName); // TODO 核心 解析标记AspectJ注解中的增强方法 委托 advisorFactory.getAdvisors List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory); if (this.beanFactory.isSingleton(beanName)) &#123; this.advisorsCache.put(beanName, classAdvisors); &#125; else &#123; this.aspectFactoryCache.put(beanName, factory); &#125; advisors.addAll(classAdvisors); &#125; else &#123; // Per target or per this. if (this.beanFactory.isSingleton(beanName)) &#123; throw new IllegalArgumentException(\"Bean with name '\" + beanName + \"' is a singleton, but aspect instantiation model is not singleton\"); &#125; MetadataAwareAspectInstanceFactory factory = new PrototypeAspectInstanceFactory(this.beanFactory, beanName); this.aspectFactoryCache.put(beanName, factory); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; &#125; this.aspectBeanNames = aspectNames; return advisors; &#125; &#125; &#125; if (aspectNames.isEmpty()) &#123; return Collections.emptyList(); &#125; // 记录在缓存中 List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;(); for (String aspectName : aspectNames) &#123; List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName); if (cachedAdvisors != null) &#123; advisors.addAll(cachedAdvisors); &#125; else &#123; MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; return advisors;&#125; 上面的逻辑可以看到先是获取所有的beanName然后遍历，找出声明AspectJ注解的类，并将结果加入到缓存中 this.advisorFactory.getAdvisors(factory);是最为重要及最为复杂的 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) &#123; // 获取标记为AspectJ的类 Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); // 获取标记为AspectJ的name String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName(); // 验证 validate(aspectClass); // We need to wrap the MetadataAwareAspectInstanceFactory with a decorator // so that it will only instantiate once. MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory = new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory); List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;(); for (Method method : getAdvisorMethods(aspectClass)) &#123; // TODO 普通增强器的获取 Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; // If it's a per target aspect, emit the dummy instantiating aspect. // 如果寻找的增强器不为空而且又配置了延迟初始化那么需要在首位加入同步实例化增强器 if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) &#123; Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory); advisors.add(0, instantiationAdvisor); &#125; // Find introduction fields. // 获取DeclaredField注解 for (Field field : aspectClass.getDeclaredFields()) &#123; Advisor advisor = getDeclareParentsAdvisor(field); if (advisor != null) &#123; advisors.add(advisor); &#125; &#125; return advisors;&#125; 关注for (Method method : getAdvisorMethods(aspectClass))方法，循环切点方法，然后调用Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName);获取增强 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Overridepublic Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrderInAspect, String aspectName) &#123; validate(aspectInstanceFactory.getAspectMetadata().getAspectClass()); // 切点信息的获取 AspectJExpressionPointcut expressionPointcut = getPointcut( candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass()); if (expressionPointcut == null) &#123; return null; &#125; // 根据切点信息生成增强器 return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod, this, aspectInstanceFactory, declarationOrderInAspect, aspectName);&#125; private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class&lt;?&gt; candidateAspectClass) &#123; // 获取方法上的注解 AspectJAnnotation&lt;?&gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) &#123; return null; &#125; // 使用AspectJExpressionPointcut实例封装获取的信息 AspectJExpressionPointcut ajexp = new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class&lt;?&gt;[0]); ajexp.setExpression(aspectJAnnotation.getPointcutExpression()); ajexp.setBeanFactory(this.beanFactory); // 提取到的注解中表达式如 @Pointcut(\"execution(* *.*test*(..))\")中的execution(* *.*test*(..) return ajexp;&#125; protected static AspectJAnnotation&lt;?&gt; findAspectJAnnotationOnMethod(Method method) &#123; // 看到了熟悉的注解类 Class&lt;?&gt;[] classesToLookFor = new Class&lt;?&gt;[] &#123; Before.class, Around.class, After.class, AfterReturning.class, AfterThrowing.class, Pointcut.class&#125;; for (Class&lt;?&gt; c : classesToLookFor) &#123; AspectJAnnotation&lt;?&gt; foundAnnotation = findAnnotation(method, (Class&lt;Annotation&gt;) c); if (foundAnnotation != null) &#123; return foundAnnotation; &#125; &#125; return null;&#125; 这里找出了两个List&lt;Advisor&gt; candidateAdvisors，可以看到第二个是serviceAspectj 找出适合的增强器 上面是获取了所有的增强器，但是对应所有增强器来将并不一定都适用于当前的Bean,还要挑取出合适的增强器，也就是满足我们配置的通配符的增强器 1234567891011protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 获取所有增强器 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 从所有增强器中找出适合的增强器 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 执行List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);方法从所有增强器中找出适合的增强器 123456789101112131415161718192021222324252627282930313233343536373839protected List&lt;Advisor&gt; findAdvisorsThatCanApply( List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123; // 过滤已经得到的advisors return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123; ProxyCreationContext.setCurrentProxiedBeanName(null); &#125;&#125; public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) &#123; if (candidateAdvisors.isEmpty()) &#123; return candidateAdvisors; &#125; List&lt;Advisor&gt; eligibleAdvisors = new LinkedList&lt;Advisor&gt;(); // 首先处理引介增强 for (Advisor candidate : candidateAdvisors) &#123; // canApply真正的匹配 if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; boolean hasIntroductions = !eligibleAdvisors.isEmpty(); for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor) &#123; // 引介增强已经处理 // already processed continue; &#125; // 对于普通bean的处理 if (canApply(candidate, clazz, hasIntroductions)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; return eligibleAdvisors;&#125; 真正的匹配在canApply()方法，可以看到使用了MethodMatcher接口的boolean matches(Method method, Class&lt;?&gt; targetClass, boolean hasIntroductions);方法进行匹配 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; if (advisor instanceof IntroductionAdvisor) &#123; return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); &#125; else if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pca = (PointcutAdvisor) advisor; return canApply(pca.getPointcut(), targetClass, hasIntroductions); &#125; else &#123; // It doesn't have a pointcut so we assume it applies. return true; &#125;&#125;public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, \"Pointcut must not be null\"); if (!pc.getClassFilter().matches(targetClass)) &#123; return false; &#125; MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; // No need to iterate the methods if we're matching any method anyway... return true; &#125; IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;Class&lt;?&gt;&gt;(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); classes.add(targetClass); for (Class&lt;?&gt; clazz : classes) &#123; Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); for (Method method : methods) &#123; if ((introductionAwareMethodMatcher != null &amp;&amp; introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions)) || methodMatcher.matches(method, targetClass)) &#123; return true; &#125; &#125; &#125; return false;&#125; 2、根据获取的增强创建代理 获取了所有对应bean的增强器后，便可以进行代理的创建了，对于代理类的创建及处理，Spring委托给了ProxyFactory（创建 Proxy 的工厂类）去处理，下面的函数主要是对ProxyFactory的初始化操作，进而对真正的创建代理做准备 12345678910111213141516171819202122232425262728293031323334353637protected Object createProxy( Class&lt;?&gt; beanClass, String beanName, Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; // 对于代理类的创建及处理，Spring委托给了ProxyFactory去处理 ProxyFactory proxyFactory = new ProxyFactory(); // 获取当前类中相关属性 proxyFactory.copyFrom(this); // 决定对于给定的bean是否应该使用targetClass而不是她的接口代理。检查ProxyTargetClass设置 if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; else &#123; evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; // 将拦截器封装为增强器 Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); for (Advisor advisor : advisors) &#123; // 加入增强器 proxyFactory.addAdvisor(advisor); &#125; // 设置要代理的类 proxyFactory.setTargetSource(targetSource); // 定制dialing customizeProxyFactory(proxyFactory); // 用来控制代理工厂被配置之后是否还允许修改通知 缺省值为false（即在代理被配置之后不允许修改代理的配置） proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; // 创建代理 return proxyFactory.getProxy(getProxyClassLoader());&#125; 继续进入proxyFactory.getProxy(getProxyClassLoader())方法 123public Object getProxy(ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader);&#125; 可以看到先是调用createAopProxy()创建AopProxy，由下图可以看到一个是cglib的代理，一个是jdk的代理 AopProxy 用于生成代理对象的委托类，就俩方法获取代理对象Proxy 12345public interface AopProxy &#123; Object getProxy(); Object getProxy(ClassLoader classLoader);&#125; 进入createAopProxy()方法，这里根据逻辑判断返回ObjenesisCglibAopProxy或者JdkDynamicAopProxy，如果目标对象实现了接口，默认情况下采用jdk的动态代理，也可以强制使用cglib实现aop(设置方式 &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt;) 123456789101112131415161718192021222324252627282930313233343536373839protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; // 创建代理 return getAopProxyFactory().createAopProxy(this);&#125; /** * 如果目标对象实现了接口，默认情况下采用jdk的动态代理，也可以强制使用cglib实现aop * 如果目标对象没有实现了接口，必须采用cglib * @param config the AOP configuration in the form of an * AdvisedSupport object * @return * @throws AopConfigException */ @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; /** * optimize ：用来控制通过cglib创建的代理是否使用激进的优化策略，仅对cglib有效，一般不推荐用户使用这个设置 * proxyTargetClass ：为true时，目标类本身被代理而不是目标类的接口，那么cglib代理将被创建，设置方式 &lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/&gt; * hasNoUserSuppliedProxyInterfaces: 是否存在代理接口 * */ if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125; &#125; 调用createAopProxy()的到AopProxy之后就是调用AopProxy的getProxy(ClassLoader classLoader) 获取代理对象了，AopProxy它有两个子类JdkDynamicAopProxy基于 JDK 的 AOP 代理实现类，ObjenesisCglibAopProxy基于 CGLIB 的 AOP 的代理实现类。 JdkDynamicAopProxy 下面看到了我们熟悉的Proxy.newProxyInstance方法 123456789@Overridepublic Object getProxy(ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating JDK dynamic proxy: target source is \" + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);&#125; 可以看到JdkDynamicAopProxy实现了InvocationHandler接口，那么我们可以推断这一定有一个invoke函数 1final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; JdkDynamicAopProxy的invoke函数最重要的工作就是创建了一个拦截器链，并实现了拦截器链的逐一调用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * Implementation of &#123;@code InvocationHandler.invoke&#125;. * &lt;p&gt;Callers will see exactly the exception thrown by the target, * unless a hook method throws an exception. */@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class&lt;?&gt; targetClass = null; Object target = null; try &#123; // 如果被代理的目标对象要执行的方法是equal则执行JdkDynamicAopProxy（即代理对象的equal）方法 if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; // 如果被代理的目标对象要执行的方法是hashCode则执行JdkDynamicAopProxy（即代理对象的hashCode）方法 else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; // 有时候目标对象内部的自我调用将无法实施切面中的增强则需要通过此属性暴露代理 if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // May be null. Get as late as possible to minimize the time we \"own\" the target, // in case it comes from a pool. target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; // Get the interception chain for this method. // 获取当前方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); // 如果没有发现任何拦截器那么直接调用切点方法 retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... // 将拦截器封装在ReflectiveMethodInvocation，以便于使用其proceed进行链接表用拦截器 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. // 执行拦截器链 retVal = invocation.proceed(); &#125; // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; // Special case: it returned \"this\" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; &#125; // 返回结果 else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( \"Null return value from advice does not match primitive return type for: \" + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; ObjenesisCglibAopProxy Cglib获取代理类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Overridepublic Object getProxy(ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating CGLIB proxy: target source is \" + this.advised.getTargetSource()); &#125; try &#123; Class&lt;?&gt; rootClass = this.advised.getTargetClass(); Assert.state(rootClass != null, \"Target class must be available for creating a CGLIB proxy\"); Class&lt;?&gt; proxySuperClass = rootClass; if (ClassUtils.isCglibProxyClass(rootClass)) &#123; proxySuperClass = rootClass.getSuperclass(); Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces(); for (Class&lt;?&gt; additionalInterface : additionalInterfaces) &#123; this.advised.addInterface(additionalInterface); &#125; &#125; // Validate the class, writing log messages as necessary. validateClassIfNecessary(proxySuperClass, classLoader); // Configure CGLIB Enhancer... Enhancer enhancer = createEnhancer(); if (classLoader != null) &#123; enhancer.setClassLoader(classLoader); if (classLoader instanceof SmartClassLoader &amp;&amp; ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) &#123; enhancer.setUseCache(false); &#125; &#125; enhancer.setSuperclass(proxySuperClass); enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised)); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); enhancer.setStrategy(new ClassLoaderAwareUndeclaredThrowableStrategy(classLoader)); Callback[] callbacks = getCallbacks(rootClass); Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length]; for (int x = 0; x &lt; types.length; x++) &#123; types[x] = callbacks[x].getClass(); &#125; // fixedInterceptorMap only populated at this point, after getCallbacks call above enhancer.setCallbackFilter(new ProxyCallbackFilter( this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset)); enhancer.setCallbackTypes(types); // Generate the proxy class and create a proxy instance. return createProxyClassAndInstance(enhancer, callbacks); &#125; catch (CodeGenerationException ex) &#123; throw new AopConfigException(\"Could not generate CGLIB subclass of class [\" + this.advised.getTargetClass() + \"]: \" + \"Common causes of this problem include using a final class or a non-visible class\", ex); &#125; catch (IllegalArgumentException ex) &#123; throw new AopConfigException(\"Could not generate CGLIB subclass of class [\" + this.advised.getTargetClass() + \"]: \" + \"Common causes of this problem include using a final class or a non-visible class\", ex); &#125; catch (Throwable ex) &#123; // TargetSource.getTarget() failed throw new AopConfigException(\"Unexpected AOP exception\", ex); &#125;&#125; Cglib是一个强大的高性能代码生成包，底层通过使用一个小而快的字节码处理框架ASM，来转化字节码并生成新类 Cglib调用方法的核心逻辑在DynamicAdvisedInterceptor的intercept方法中，和jdk方式实现代理的invoke方法大同小异123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 核心逻辑 * General purpose AOP callback. Used when the target is dynamic or when the * proxy is not frozen. */private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable &#123; private final AdvisedSupport advised; public DynamicAdvisedInterceptor(AdvisedSupport advised) &#123; this.advised = advised; &#125; @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Class&lt;?&gt; targetClass = null; Object target = null; try &#123; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // May be null. Get as late as possible to minimize the time we // \"own\" the target, in case it comes from a pool... target = getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; // 获取拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; // We can skip creating a MethodInvocation: just invoke the target directly. // Note that the final invoker must be an InvokerInterceptor, so we know // it does nothing but a reflective operation on the target, and no hot // swapping or fancy proxying. // 拦截器链为空直接激活原方法 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; // We need to create a method invocation... // 进入链 retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null) &#123; releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; 总结 由AnnotationAwareAspectJAutoProxyCreator的继承关系图可以注意到此类实现了 BeanPostProcessor接口，BeanPostProcessor接口是IOC与AOP连接的桥梁 在研究源码之前可以尝试着自己想象一下解析思路，看看自己的思路和Spring是否有差别 在 Spring 的容器中，我们面向的对象是一个个的 bean 实例，当我们需要bean的时候通过IOC 容器的 getBean(…) 方法从容器中获取 bean 实例，只不过大部分的场景下，我们都用了依赖注入，所以很少手动调用 getBean(...) 方法。借助IOC的话实现AOP就很简单了，只要在getBean(...)返回新的代理类就可以了 Spring使用JDK动态代理和CGLib动态代理技术在运行期织入增强，要使用JDK动态代理，目标类必须实现接口，而CGLib不对目标类作任何限制，他是通过动态生成目标类子类的方式提供代理 JDK在创建代理对象时的性能高于CGLib，但生成的代理对象的运行性能却比CGLib的低，如果无需频繁的创建代理对象比较适合采用CGLib动态代理技术，反之比较适合JDK动态代理技术 参考 《Spring 源码深度解析》 https://www.javadoop.com/post/spring-aop-source","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五二)AOP源码解析之解析AOP自定义标签","slug":"backend/framework/spring/analysis/Spring系列(五二)AOP源码解析之解析AOP自定义标签","date":"2019-07-31T16:00:02.000Z","updated":"2019-09-16T13:11:05.180Z","comments":true,"path":"2019/08/01/backend/framework/spring/analysis/Spring系列(五二)AOP源码解析之解析AOP自定义标签/","link":"","permalink":"http://www.songshuiyang.com/2019/08/01/backend/framework/spring/analysis/Spring系列(五二)AOP源码解析之解析AOP自定义标签/","excerpt":"","text":"前言简单示例 创建切面类ServiceAspectj，这个方法用于定义切面，功能是打印方法的执行前的输入参数及输出结果 1234567891011121314151617181920212223242526@Slf4j@Aspect@Componentpublic class ServiceAspectj &#123; @Pointcut(value = \"execution(* org.springframework.iframe.service..*(..))\") public void pointcut() &#123; &#125; @Around(\"pointcut()\") public Object doAround(ProceedingJoinPoint pjp) throws Throwable &#123; String className = pjp.getSignature().getDeclaringType().getSimpleName(); String methodName = pjp.getSignature().getName(); log.info(\"=&gt; [request method: &#123;&#125;#&#123;&#125;]\",className, methodName); log.info(\"=&gt; [request body: &#123;&#125;]\", JSONObject.toJSONString(pjp.getArgs())); Object result = pjp.proceed(); log.info(\"=&lt; [response method: &#123;&#125;#&#123;&#125;]\",className, methodName); log.info(\"=&lt; [response result: &#123;&#125; ]\", JSONObject.toJSONString(result)); return result; &#125;&#125; 需要切的方法 12345678910111213141516171819202122232425public interface UserService &#123; User findUserByName(String userName);&#125;@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired User user; @Autowired private RoleService roleService; @Override public User findUserByName(String userName) &#123; User user = new User(userName,18); //Role role = roleService.findRoleByUserName(userName); user.setRole(new Role()); return user; &#125;&#125; Spring 配置文件 beans/bean.xml 添加&lt;aop:aspectj-autoproxy/&gt;配置，开启AOP开关 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd\"&gt; &lt;bean class=\"org.springframework.iframe.entity.User\"&gt; &lt;property name=\"userName\" value=\"shop\"/&gt; &lt;/bean&gt; &lt;!-- ComponentScanBeanDefinitionParser--&gt; &lt;context:component-scan base-package = \"org.springframework.iframe.*\"/&gt; &lt;aop:aspectj-autoproxy/&gt;&lt;/beans&gt; 测试类及测试结果 1234567@Testpublic void test1 () &#123; ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(\"beans/bean.xml\"); UserService userService = xmlApplicationContext.getBean(UserService.class); User user1 = userService.findUserByName(\"sd\"); log.info(\"user1:&#123;&#125;\", user1);&#125; 123411:12:06,216 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&gt; [request method: UserService#findUserByName]11:12:06,307 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&gt; [request body: [\"sd\"]]11:12:06,307 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&lt; [response method: UserService#findUserByName]11:12:06,372 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&lt; [response result: &#123;\"age\":18,\"role\":&#123;&#125;,\"userName\":\"sd\"&#125; ] 从上面的例子可以看到已经实现了这个功能，那么是怎么设计呢？ 首先我们知道AOP是实现横切逻辑的增强，比如在方法执行前额外做一些事，方法执行后额外做一些事 那我们是不是需要在一个地方定义好什么人在什么时候做什么事情，ServiceAspectj切面类就是做这个事 什么人：execution(* org.springframework.iframe.service..*(..)) 这里定义了这个包下的所有方法，这些方法就是这些人 什么时候：@Around注解是环绕的意思，也就是做完正常工作之前和之后做一些额外的事情 做什么事情：Object doAround(ProceedingJoinPoint pjp)这个方法就是定义了具体做什么事（打印报告） 上面只是些做了些规划书，还没真正起作用，那么这就需要包工头根据规划书来统一规划了，那些人需要做这些事，那些人不需要做这些事 确认了那些人需要做这些事之后就是通知这些人需要多做一些事了，那么这些人就会执行打印报告的操作 那么Spring究竟是如何实现AOP的呢，以后的几个章节将介绍着一块 解析 beans/bean.xml 配置开启AOP开关 1234567891011// 默认标签&lt;bean class=\"org.springframework.iframe.entity.User\"&gt; &lt;property name=\"userName\" value=\"shop\"/&gt;&lt;/bean&gt;// 自定义标签&lt;!-- ComponentScanBeanDefinitionParser--&gt;&lt;context:component-scan base-package = \"org.springframework.iframe.*\"/&gt;// 自定义标签&lt;aop:aspectj-autoproxy/&gt; 关注上面配置文件 beans/bean.xml 中的 &lt;aop:aspectj-autoproxy/&gt;配置，之前的Spring系列(五)Document读取器BeanDefinitionDocumentReader章节就介绍了Spring的配置文件分为默认标签的解析及自定义标签的解析，我们现在这个&lt;aop:aspectj-autoproxy/&gt;配置和之前扫包的&lt;context:component-scan配置都属于自定义标签 回顾 123456789101112131415161718192021222324252627/** * Parse the elements at the root level in the document: * \"import\", \"alias\", \"bean\". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 如果是默认命名空间 xmlns=\"http://www.springframework.org/schema/beans\" if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; // 默认标签解析 如&lt;bean class=\"\"/&gt; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; // 自定义标签解析 如：&lt;context:component-scan base-package = \"*\"/&gt; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123;// 自定义标签解析 delegate.parseCustomElement(root); &#125;&#125; 进入自定义标签解析方法delegate.parseCustomElement(root); 12345678910111213141516public BeanDefinition parseCustomElement(Element ele) &#123; return parseCustomElement(ele, null);&#125;public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; // 获取xml配置文件中的命名空间http://www.springframework.org/schema/aop String namespaceUri = getNamespaceURI(ele); // 根据命名空间找到命名空间处理类AopNamespaceHandler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; &#125; // 解析命名空间支持的标签 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 这里有个NamespaceHandler这个接口是命名空间处理器，它可以根据需求自己来处理我们设置的标签元素。 主要功能是 通过Element标签找到对于的BeanDefinitionParser，找到之后然后调用BeanDefinitionParser接口的parse方法来解析 NamespaceHandler接口 命名空间处理器，我们就可以根据需求自己来处理我们设置的标签元素。 可能需要配置如&lt;aop:config /&gt;这样的标签, 在配置这个标签之前，通常我们需要在xml中引入这个aop所在的命名空间，xmlns:aop=&quot;http://www.springframework.org/schema/aop 只有通过配置aop的命名空间才会找到AOP标签的处理器org.springframework.aop.config.AopNamespaceHandler，在AOP的jar中的spring.handlers配置文件中配置了命名空间和命名空间处理器之间的关系。1http\\://www.springframework.org/schema/aop=org.springframework.aop.config.AopNamespaceHandler 比如我们这里是&lt;aop:aspectj-autoproxy/&gt;标签，所以得到的命名空间处理类是AopNamespaceHandler，那么是怎么得到的呢，关注this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri);可以看到传入了一个namespaceUri 这里是进入到DefaultNamespaceHandlerResolver#resolve方法，可以看到先是调用了getHandlerMappings() 方法读取spring.handlers配置的命名空间的对应关系，保存到了Map&lt;String, Object&gt; handlerMappings中，然后就是调用NamespaceHandler接口的init()方法注册解析类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 注册handlerMappings * * Locate the &#123;@link NamespaceHandler&#125; for the supplied namespace URI * from the configured mappings. * @param namespaceUri the relevant namespace URI * @return the located &#123;@link NamespaceHandler&#125;, or &#123;@code null&#125; if none found */@Overridepublic NamespaceHandler resolve(String namespaceUri) &#123; Map&lt;String, Object&gt; handlerMappings = getHandlerMappings(); Object handlerOrClassName = handlerMappings.get(namespaceUri); if (handlerOrClassName == null) &#123; return null; &#125; else if (handlerOrClassName instanceof NamespaceHandler) &#123; return (NamespaceHandler) handlerOrClassName; &#125; else &#123; String className = (String) handlerOrClassName; try &#123; Class&lt;?&gt; handlerClass = ClassUtils.forName(className, this.classLoader); if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) &#123; throw new FatalBeanException(\"Class [\" + className + \"] for namespace [\" + namespaceUri + \"] does not implement the [\" + NamespaceHandler.class.getName() + \"] interface\"); &#125; // init方法 NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass); namespaceHandler.init(); handlerMappings.put(namespaceUri, namespaceHandler); return namespaceHandler; &#125; catch (ClassNotFoundException ex) &#123; throw new FatalBeanException(\"NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"] not found\", ex); &#125; catch (LinkageError err) &#123; throw new FatalBeanException(\"Invalid NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]: problem with handler class file or dependent class\", err); &#125; &#125;&#125;/** * Load the specified NamespaceHandler mappings lazily. */private Map&lt;String, Object&gt; getHandlerMappings() &#123; if (this.handlerMappings == null) &#123; synchronized (this) &#123; if (this.handlerMappings == null) &#123; try &#123; // 在 META-INF/spring.handlers配置文件中有配置对应关系 Properties mappings = PropertiesLoaderUtils.loadAllProperties(this.handlerMappingsLocation, this.classLoader); if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded NamespaceHandler mappings: \" + mappings); &#125; Map&lt;String, Object&gt; handlerMappings = new ConcurrentHashMap&lt;String, Object&gt;(mappings.size()); CollectionUtils.mergePropertiesIntoMap(mappings, handlerMappings); // 赋值到 Map&lt;String, Object&gt; handlerMappings中 this.handlerMappings = handlerMappings; &#125; catch (IOException ex) &#123; throw new IllegalStateException( \"Unable to load NamespaceHandler mappings from location [\" + this.handlerMappingsLocation + \"]\", ex); &#125; &#125; &#125; &#125; return this.handlerMappings;&#125; 关注namespaceHandler.init();上下几行代码，这里有执行init()方法，下面的逻辑会调用，这个方法是注册标签与相应解析类对应关系的方法 AopNamespaceHandler.java 123456789101112131415161718public class AopNamespaceHandler extends NamespaceHandlerSupport &#123; /** * Register the &#123;@link BeanDefinitionParser BeanDefinitionParsers&#125; for the * '&#123;@code config&#125;', '&#123;@code spring-configured&#125;', '&#123;@code aspectj-autoproxy&#125;' * and '&#123;@code scoped-proxy&#125;' tags. */ @Override public void init() &#123; // In 2.0 XSD as well as in 2.1 XSD. registerBeanDefinitionParser(\"config\", new ConfigBeanDefinitionParser()); registerBeanDefinitionParser(\"aspectj-autoproxy\", new AspectJAutoProxyBeanDefinitionParser()); registerBeanDefinitionDecorator(\"scoped-proxy\", new ScopedProxyBeanDefinitionDecorator()); // Only in 2.0 XSD: moved to context namespace as of 2.1 registerBeanDefinitionParser(\"spring-configured\", new SpringConfiguredBeanDefinitionParser()); &#125;&#125; 关注registerBeanDefinitionParser(&quot;aspectj-autoproxy&quot;, new AspectJAutoProxyBeanDefinitionParser());这行代码这里注册了标签命名与对应解析类的对应关系，并存放在Map&lt;String, BeanDefinitionParser&gt; parsers 对象中，所以现在 12345private final Map&lt;String, BeanDefinitionParser&gt; parsers = new HashMap&lt;String, BeanDefinitionParser&gt;(); protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) &#123; this.parsers.put(elementName, parser); &#125; 解析配置文件 上面的步骤已经得到了AopNamespaceHandler，然后就是进入handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); 方法开始解析，可以看到逻辑很简单，就是在Map&lt;String, BeanDefinitionParser&gt; parsers中get相应的解析类并调用其parse方法 1234567891011121314151617181920212223242526/** * 先找到对应的BeanDefinitionParser 然后执行parse(element, parserContext)方法 * Parses the supplied &#123;@link Element&#125; by delegating to the &#123;@link BeanDefinitionParser&#125; that is * registered for that &#123;@link Element&#125;. */@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; return findParserForElement(element, parserContext).parse(element, parserContext);&#125;/** * 根据标签名得到相应的解析类，NamespaceHandler这里起到了一个中介的作用 * &#123;@link parsers&#125; Map&lt;String, BeanDefinitionParser&gt; 存放着所有的解析类，这个 * * Locates the &#123;@link BeanDefinitionParser&#125; from the register implementations using * the local name of the supplied &#123;@link Element&#125;. */private BeanDefinitionParser findParserForElement(Element element, ParserContext parserContext) &#123; String localName = parserContext.getDelegate().getLocalName(element); BeanDefinitionParser parser = this.parsers.get(localName); if (parser == null) &#123; parserContext.getReaderContext().fatal( \"Cannot locate BeanDefinitionParser for element [\" + localName + \"]\", element); &#125; return parser;&#125; 我们这里&lt;aop:aspectj-autoproxy/&gt;标签得到的是AspectJAutoProxyBeanDefinitionParser解析类 AspectJAutoProxyBeanDefinitionParser1234567891011121314151617181920212223242526272829303132333435363738class AspectJAutoProxyBeanDefinitionParser implements BeanDefinitionParser &#123; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; // 注册 AnnotationAwareAspectJAutoProxyCreator AOP的实现基本上是靠这个类来完成的 AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element); // 对于注解中子类的处理 extendBeanDefinition(element, parserContext); return null; &#125; private void extendBeanDefinition(Element element, ParserContext parserContext) &#123; BeanDefinition beanDef = parserContext.getRegistry().getBeanDefinition(AopConfigUtils.AUTO_PROXY_CREATOR_BEAN_NAME); if (element.hasChildNodes()) &#123; addIncludePatterns(element, parserContext, beanDef); &#125; &#125; private void addIncludePatterns(Element element, ParserContext parserContext, BeanDefinition beanDef) &#123; ManagedList&lt;TypedStringValue&gt; includePatterns = new ManagedList&lt;TypedStringValue&gt;(); NodeList childNodes = element.getChildNodes(); for (int i = 0; i &lt; childNodes.getLength(); i++) &#123; Node node = childNodes.item(i); if (node instanceof Element) &#123; Element includeElement = (Element) node; TypedStringValue valueHolder = new TypedStringValue(includeElement.getAttribute(\"name\")); valueHolder.setSource(parserContext.extractSource(includeElement)); includePatterns.add(valueHolder); &#125; &#125; if (!includePatterns.isEmpty()) &#123; includePatterns.setSource(parserContext.extractSource(element)); beanDef.getPropertyValues().add(\"includePatterns\", includePatterns); &#125; &#125;&#125; 关注parse方法，可以看到主要逻辑是注册了AnnotationAwareAspectJAutoProxyCreator这个bean 12345678@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; // 注册 AnnotationAwareAspectJAutoProxyCreator 对应AOP的实现基本上是靠这个类来完成的 AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element); // 对于注解中子类的处理 extendBeanDefinition(element, parserContext); return null;&#125; AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element);方法这里是注册了AnnotationAwareAspectJAutoProxyCreator这个bean，RootBeanDefinition beanDefinition = new RootBeanDefinition(cls);这里就把AnnotationAwareAspectJAutoProxyCreator.class给BeanDefinition绑定在一起了，registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition);方法是将BeanDefinition注册到BeanFactory中了 1234567891011121314151617181920212223242526272829303132333435363738394041public static void registerAspectJAnnotationAutoProxyCreatorIfNecessary( ParserContext parserContext, Element sourceElement) &#123; // 关键逻辑 注册或升级AutoProxyCreator定义为beanName为org.springframework.aop.config.internalAutoProxyCreator BeanDefinition beanDefinition = AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary( parserContext.getRegistry(), parserContext.extractSource(sourceElement)); // 对于proxy-target-class(强制使用CGLIB)以及expose-proxy属性的处理 useClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement); // 注册组件并通知，便于监听器做进一步处理 registerComponentIfNecessary(beanDefinition, parserContext);&#125;// AopConfigUtils#registerAspectJAnnotationAutoProxyCreatorIfNecessary(org.springframework.beans.factory.support.BeanDefinitionRegistry, java.lang.Object)public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, Object source) &#123; return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);&#125;private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, Object source) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); // 如果已经存在了自动代理创建器且存在的自动代理创建器与现在的不一致那么需要根据优先级来判断到底需要使用哪个 if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123; BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; // 改变bean最重要的就是改变bean所对应的className属性 apcDefinition.setBeanClassName(cls.getName()); &#125; &#125; // 如果已经存在自动代理创建器并且与将要创建的一致，那么无需再次创建 return null; &#125; RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(\"order\", Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition;&#125; 处理proxy-target-class属性 123456789101112131415private static void useClassProxyingIfNecessary(BeanDefinitionRegistry registry, Element sourceElement) &#123; if (sourceElement != null) &#123; // 对proxy-target-class属性的处理 JDK动态代理或者CGLIB boolean proxyTargetClass = Boolean.valueOf(sourceElement.getAttribute(PROXY_TARGET_CLASS_ATTRIBUTE)); if (proxyTargetClass) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; // 对expose-proxy属性的处理 boolean exposeProxy = Boolean.valueOf(sourceElement.getAttribute(EXPOSE_PROXY_ATTRIBUTE)); if (exposeProxy) &#123; // 强制使用的过程其实也是一个属性设置的过程 AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125;&#125; ConfigBeanDefinitionParser ConfigBeanDefinitionParser用于解析&lt;aop:config&gt;标签，这种方法是Spring之前版本定义增强切面的方法，不过现在都是使用@AspectJ注解的形式来定义了，所以暂不细究 12345678910&lt;aop:config proxy-target-class=\"true\"&gt; &lt;!--使用&lt;aop:aspect&gt;元素标签定义切面, 其内部可以定义多个增强--&gt; &lt;aop:aspect ref=\"adviceMethods\"&gt; &lt;aop:after method=\"afterExecution\" pointcut=\"execution(* com.aop.learn.service.*.*(..))\"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;&lt;!--adviceMethods bean, 该bean是增强方法所在的类--&gt;&lt;bean id=\"adviceMethods\" class=\"com.aop.learn.advice.UserAdvice\"/&gt;&lt;bean id=\"userService\" class=\"com.aop.learn.service.impl.UserServiceImpl\"/&gt; ConfigBeanDefinitionParser 类成员及parse方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class ConfigBeanDefinitionParser implements BeanDefinitionParser &#123; private static final String ASPECT = \"aspect\"; private static final String EXPRESSION = \"expression\"; private static final String ID = \"id\"; private static final String POINTCUT = \"pointcut\"; private static final String ADVICE_BEAN_NAME = \"adviceBeanName\"; private static final String ADVISOR = \"advisor\"; private static final String ADVICE_REF = \"advice-ref\"; private static final String POINTCUT_REF = \"pointcut-ref\"; private static final String REF = \"ref\"; private static final String BEFORE = \"before\"; private static final String DECLARE_PARENTS = \"declare-parents\"; private static final String TYPE_PATTERN = \"types-matching\"; private static final String DEFAULT_IMPL = \"default-impl\"; private static final String DELEGATE_REF = \"delegate-ref\"; private static final String IMPLEMENT_INTERFACE = \"implement-interface\"; private static final String AFTER = \"after\"; private static final String AFTER_RETURNING_ELEMENT = \"after-returning\"; private static final String AFTER_THROWING_ELEMENT = \"after-throwing\"; private static final String AROUND = \"around\"; private static final String RETURNING = \"returning\"; private static final String RETURNING_PROPERTY = \"returningName\"; private static final String THROWING = \"throwing\"; private static final String THROWING_PROPERTY = \"throwingName\"; private static final String ARG_NAMES = \"arg-names\"; private static final String ARG_NAMES_PROPERTY = \"argumentNames\"; private static final String ASPECT_NAME_PROPERTY = \"aspectName\"; private static final String DECLARATION_ORDER_PROPERTY = \"declarationOrder\"; private static final String ORDER_PROPERTY = \"order\"; private static final int METHOD_INDEX = 0; private static final int POINTCUT_INDEX = 1; private static final int ASPECT_INSTANCE_FACTORY_INDEX = 2; private ParseState parseState = new ParseState(); @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), parserContext.extractSource(element)); parserContext.pushContainingComponent(compositeDef); configureAutoProxyCreator(parserContext, element); List&lt;Element&gt; childElts = DomUtils.getChildElements(element); for (Element elt: childElts) &#123; String localName = parserContext.getDelegate().getLocalName(elt); if (POINTCUT.equals(localName)) &#123; parsePointcut(elt, parserContext); &#125; else if (ADVISOR.equals(localName)) &#123; parseAdvisor(elt, parserContext); &#125; else if (ASPECT.equals(localName)) &#123; parseAspect(elt, parserContext); &#125; &#125; parserContext.popAndRegisterContainingComponent(); return null; &#125; 总结 在Spring中如果是用xml的方式配置Spring如果需要使用AOP功能，就需要在配置文件中添加&lt;aop:aspectj-autoproxy/&gt;属性，这个是打开AOP功能的开关，这是标签是自定义标签所以具体的解析工作是给AspectJAutoProxyBeanDefinitionParser来完成的，那么Spring是怎么知道这个&lt;aop:aspectj-autoproxy/&gt;由这个类来解析的呢，NamespaceHandler这个接口设计就发挥作用了，aop对应的命名空间处理器是AopNamespaceHandler（对应关系在aop的炸包里的META-INF/spring.handlers里设置），AopNamespaceHandler里面有配置（init方法）aspectj-autoproxy标签对应的解析类是AspectJAutoProxyBeanDefinitionParser &lt;aop:aspectj-autoproxy/&gt; 的最终结果是注册AnnotationAwareAspectJAutoProxyCreator 这个bean，这个类用于创建AOP的代理类 参考 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五一)AOP切点表达式函数","slug":"backend/framework/spring/analysis/Spring系列(五一)AOP切点表达式函数","date":"2019-07-31T16:00:01.000Z","updated":"2019-09-16T13:11:05.163Z","comments":true,"path":"2019/08/01/backend/framework/spring/analysis/Spring系列(五一)AOP切点表达式函数/","link":"","permalink":"http://www.songshuiyang.com/2019/08/01/backend/framework/spring/analysis/Spring系列(五一)AOP切点表达式函数/","excerpt":"","text":"概述 Spring支持9个@ApsectJ切点表达式函数，它们用不同的方式描述目标类的连接点，根据描述对象的不同，可以将它们大致分为4种类型： 方法切点函数：通过描述目标类方法信息定义连接点； 方法入参切点函数：通过描述目标类方法入参的信息定义连接点； 目标类切点函数：通过描述目标类类型信息定义连接点； 代理类切点函数：通过描述目标类的代理类的信息定义连接点； 这4种类型的切点函数，通过下面的表格进行说明： 类别 函数 入参 说明 方法切点函数 execution() 方法匹配模式串 表示满足某一匹配模式的所有目标类方法连接点。如execution(* greetTo(..))表示所有目标类中的greetTo()方法。 @annotation() 方法注解类名 表示标注了特定注解的目标方法连接点。如@annotation(com.baobaotao.anno.NeedTest)表示任何标注了@NeedTest注解的目标类方法。 方法入参切点函数 args() 类名 通过判别目标类方法运行时入参对象的类型定义指定连接点。如args(com.baobaotao.Waiter)表示所有有且仅有一个按类型匹配于Waiter的入参的方法。 @args() 类型注解类名 通过判别目标方法的运行时入参对象的类是否标注特定注解来指定连接点。如@args(com.baobaotao.Monitorable)表示任何这样的一个目标方法：它有一个入参且入参对象的类标注@Monitorable注解。 目标类切点函数 within() 类名匹配串 表示特定域下的所有连接点。如within(com.baobaotao.service.*)表示com.baobaotao.service包中的所有连接点，也即包中所有类的所有方法，而within(com.baobaotao.service.*Service)表示在com.baobaotao.service包中，所有以Service结尾的类的所有连接点。 target() 类名 假如目标类按类型匹配于指定类，则目标类的所有连接点匹配这个切点。如通过target(com.baobaotao.Waiter)定义的切点，Waiter、以及Waiter实现类NaiveWaiter中所有连接点都匹配该切点。 @within() 类型注解类名 假如目标类按类型匹配于某个类A，且类A标注了特定注解，则目标类的所有连接点匹配这个切点。如@within(com.baobaotao.Monitorable)定义的切点，假如Waiter类标注了@Monitorable注解，则Waiter以及Waiter实现类NaiveWaiter类的所有连接点都匹配。 @target() 类型注解类名 目标类标注了特定注解，则目标类所有连接点匹配该切点。如@target(com.baobaotao.Monitorable)，假如NaiveWaiter标注了@Monitorable，则NaiveWaiter所有连接点匹配切点。 代理类切点函数 this() 类名 代理类按类型匹配于指定类，则被代理的目标类所有连接点匹配切点。限制连接点匹配 AOP 代理的 Bean 引用为指定类型的类 详解execution() execution() 是最常见的切点函数,语法形式为 1excution(&lt;修饰符模式&gt; ? &lt;返回类型模式&gt; &lt;方法名模式&gt;(&lt;参数模式&gt;) &lt;异常模式&gt;?) 切点复合运算 &amp;&amp; 与运算符 &amp; 是特殊运算符，在xml可以使用 &amp;&amp; Spring 提供一个等效的运算符and || 或运算符 Spring 提供一个等效的运算符or ! 非运算符 Spring 提供一个等效的运算符not 示例代码：1234567891011121314151617@Before(\"!target(com.baobaotao.NaiveWaiter) \"+ \"&amp;&amp; execution(* serveTo(..)))\")public void notServeInNaiveWaiter() &#123; System.out.println(\"--notServeInNaiveWaiter() executed!--\");&#125;@After(\"within(com.baobaotao.*) \" + \" &amp;&amp; execution(* greetTo(..)))\")public void greeToFun() &#123; System.out.println(\"--greeToFun() executed!--\");&#125;@AfterReturning(\"target(com.baobaotao.Waiter) || \"+ \" target(com.baobaotao.Seller)\")public void waiterOrSeller()&#123; System.out.println(\"--waiterOrSeller() executed!--\");&#125; 命名切点 运用命名切点，可以实现切点表达式的复用12345678910111213public class TestNamePointcut &#123; // 只能在本切面类中使用 @Pointcut(\"within(com.smart.*)\") private void inPackage()&#123;&#125; // 在切面类、子切面类中使用 @Pointcut(\"execution(* greetTo(..)))\") protected void greetTo()&#123;&#125; // 公共使用 @Pointcut(\"inPackage() and greetTo()\") public void inPkgGreetTo()&#123;&#125;&#125; 访问连接点信息JoinPoint java.lang.Object[] getArgs()：获取连接点方法运行时的入参列表； Signature getSignature() ：获取连接点的方法签名对象； java.lang.Object getTarget() ：获取连接点所在的目标对象； java.lang.Object getThis() ：获取代理对象本身； ProceedingJoinPoint （ProceedingJoinPoint继承JoinPoint子接口，它新增了两个用于执行连接点方法的方法：） java.lang.Object proceed() throws java.lang.Throwable：通过反射执行目标对象的连接点处的方法； java.lang.Object proceed(java.lang.Object[] args) throws java.lang.Throwable：通过反射执行目标对象连接点处的方法，不过使用新的入参替换原来的入参。 切点表达式例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class ExecutionAspect &#123; /** * 匹配所有目标类的public方法 */ @Before(\"execution(public * *(..))\") /** * 匹配所有以To为后缀的方法 */ @Before(\"execution(* *To(..))\") /** * 匹配Waiter接口中的所有方法 */ @Before(\"execution(* com.aop.learn.service.Writer.*(..))\") /** * 匹配Waiter接口中及其实现类的方法 */ @Before(\"execution(* com.aop.learn.service.Writer+.*(..))\") /** * 匹配 com.aop.learn.service 包下所有类的所有方法 */ @Before(\"execution(* com.aop.learn.service.*(..))\") /** * 匹配 com.aop.learn.service 包,子孙包下所有类的所有方法 */ @Before(\"execution(* com.aop.learn.service..*(..))\") /** * 匹配 包名前缀为com的任何包下类名后缀为ive的方法,方法必须以Smart为前缀 */ @Before(\"execution(* com..*.*ive.Smart*(..))\") /** * 匹配 save(String name,int age) 函数 */ @Before(\"execution(* save(String,int))\") /** * 匹配 save(String name,*) 函数 第二个参数为任意类型 */ @Before(\"execution(* save(String,*))\") /** * 匹配 save(String name,..) 函数 除第一个参数固定外,接受后面有任意个入参且入参类型不限 */ @Before(\"execution(* save(String,..))\") /** * 匹配 save(String+) 函数 String+ 表示入参类型是String的子类 */ @Before(\"execution(* save(String+))\") /** * 最详细的切入点表达式 具体到包、类名、方法名、方法返回值、参数个数及类型类型 */ @Before(\"execution(public void com.bwlu.aop.MathCalculator.add(int, int))\") /** * 最模糊的切入点表达式 */ @Before(\"execution (* *.*(..))\") /** * MathCalculator中的任意方法,任意参数列表 */ @Before(\"execution(public void com.bwlu.aop.MathCalculator.*(..))\") /** * MathCalculator中的任意方法,任意参数列表，任意返回值 */ @Before(\"execution(public * com.bwlu.aop.MathCalculator.*(..))\") /** * MathCalculator中的任意方法,任意参数列表，任意返回值，任意访问修饰符 */ @Before(\"execution( * com.bwlu.aop.MathCalculator.*(..))\") 1234567/** * 匹配Controller * @within :使用 “@within(注解类型)” 匹配所以持有指定注解类型内的方法;注解类型也必须是全限定类型名; */@Pointcut(\"@within(org.springframework.stereotype.Controller) || @within(org.springframework.web.bind.annotation.RestController)\")public void excudeService() &#123;&#125; 参考 《精通Spring+4.x++企业应用开发实战》 https://blog.csdn.net/yangshangwei/article/details/77943720","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五十)静态代理及动态代理","slug":"backend/framework/spring/analysis/Spring系列(五十)静态代理及动态代理","date":"2019-07-31T16:00:00.000Z","updated":"2020-01-04T12:21:52.175Z","comments":true,"path":"2019/08/01/backend/framework/spring/analysis/Spring系列(五十)静态代理及动态代理/","link":"","permalink":"http://www.songshuiyang.com/2019/08/01/backend/framework/spring/analysis/Spring系列(五十)静态代理及动态代理/","excerpt":"","text":"前言 代理模式是程序开发中经常使用，使用代理模式可以很方便的满足我们一些特定的需求，代理分为静态代理和动态代理，下面是具体栗子： 静态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105// 明星接口public interface Star &#123; /** * 面谈 */ void confer(); /** * 签合同 */ void signContract(); /** * 订票 */ void bookTicket(); /** * 唱歌 */ void sing(); /** * 收钱 */ void collectMoney();&#125;// 真实明星public class RealStar implements Star &#123; @Override public void bookTicket() &#123; System.out.println(\"RealStar.bookTicket()\"); &#125; @Override public void collectMoney() &#123; System.out.println(\"RealStar.collectMoney()\"); &#125; @Override public void confer() &#123; System.out.println(\"RealStar.confer()\"); &#125; @Override public void signContract() &#123; System.out.println(\"RealStar.signContract()\"); &#125; @Override public void sing() &#123; System.out.println(\"RealStar(周杰伦本人).sing()\"); &#125;&#125;// 明星经纪人public class ProxyStar implements Star &#123; private Star star; public ProxyStar(Star star) &#123; super(); this.star = star; &#125; @Override public void bookTicket() &#123; System.out.println(\"ProxyStar.bookTicket()\"); &#125; @Override public void collectMoney() &#123; System.out.println(\"ProxyStar.collectMoney()\"); &#125; @Override public void confer() &#123; System.out.println(\"ProxyStar.confer()\"); &#125; @Override public void signContract() &#123; System.out.println(\"ProxyStar.signContract()\"); &#125; @Override public void sing() &#123; star.sing(); &#125;&#125;// 商演执行类public class Client &#123; public static void main(String[] args) &#123; // 需要找周杰伦来进行一次商演，直接找他的经纪人处理 Star real = new RealStar(); Star proxy = new ProxyStar(real); proxy.confer(); proxy.signContract(); proxy.bookTicket(); // 经纪人不会唱歌需要他找到周杰伦来唱 proxy.sing(); proxy.collectMoney(); &#125;&#125; 可以看到静态代理实现起来很简单，代理类和被代理类都实现了相同的接口，代理类作为中介提供了对委托资源的访问。 因为代理类和被代理类都实现了相同的接口，所以当接口变化时相应的代理类就需要对应的修改，这样的话维护起来就很繁琐，所以动态代理出现了 动态代理 动态代理的实现有很多种方式： JDK 自带的动态代理 Java assist 字节码操作库实现 Cglib Asm 底层使用指令，可维护性差 我们来看一下JDK自带的动态代理是怎么实现的 JDK动态代理涉及到两个类 Proxy: 此类用来动态生成代理类和对象 InvocationHandler：处理器接口，此类用来定义具体要代理的内容、执行的动作 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public interface Star &#123; /** * 面谈 */ void confer(); /** * 签合同 */ void signContract(); /** * 订票 */ void bookTicket(); /** * 唱歌 */ void sing(); /** * 收钱 */ void collectMoney();&#125;// 周杰伦public class RealStar implements Star &#123; @Override public void bookTicket() &#123; System.out.println(\"RealStar.bookTicket()\"); &#125; @Override public void collectMoney() &#123; System.out.println(\"RealStar.collectMoney()\"); &#125; @Override public void confer() &#123; System.out.println(\"RealStar.confer()\"); &#125; @Override public void signContract() &#123; System.out.println(\"RealStar.signContract()\"); &#125; @Override public void sing() &#123; System.out.println(\"RealStar(周杰伦本人).sing()\"); &#125;&#125;// 增强处理类public class StarHandler implements InvocationHandler &#123; Star realStar; public StarHandler(Star realStar) &#123; super(); this.realStar = realStar; &#125; // 只要调用了被代理的方法都会执行该方法 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object object = null; System.out.println(\"真正的方法执行前！\"); System.out.println(\"面谈，签合同，预付款，订机票\"); if(method.getName().equals(\"sing\"))&#123; object = method.invoke(realStar, args); &#125; System.out.println(\"真正的方法执行后！\"); System.out.println(\"收尾款\"); return object; &#125;&#125;// 演出开始public static void main(String[] args) &#123; Star realStar = new RealStar(); StarHandler handler = new StarHandler(realStar); Star proxy = (Star) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;Star.class&#125;, handler); proxy.sing(); &#125; 从上面的例子可以看到，代理类和被代理类并没有像静态代理那样实现相同接口，但是一样将Star realStar引用通过代理类的构造函数传入具体的实施者（这个是代理类与被代理类能联通的关键），有联系了才能叫人做事嘛 动态代理的代理类StarHandler虽然没有和被代理类实现相同的接口，但它需要实现InvocationHandler接口，这个类就一个对象Star realStar，一个方法invoke()，有了明星引用是不是可以在invoke()直接叫明星唱歌了，而且还可以替明星做额外的事情 总结 静态代理 1.可以做到在不修改目标对象的功能前提下,对目标功能扩展. 2.缺点:因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护. 3.由程序员创建或由特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了所以说是静态代理，而动态代理是程序在运行过程中利用反射生成代理类 动态代理 1.在程序运行时，运用反射机制动态创建而成。由此可见，代理类可以为委托类预处理消息、把消息转发给委托类和事后处理消息等 参考","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五十)面向切面编程AOP","slug":"backend/framework/spring/analysis/Spring系列(五十)面向切面编程AOP","date":"2019-07-31T16:00:00.000Z","updated":"2020-01-04T12:21:52.180Z","comments":true,"path":"2019/08/01/backend/framework/spring/analysis/Spring系列(五十)面向切面编程AOP/","link":"","permalink":"http://www.songshuiyang.com/2019/08/01/backend/framework/spring/analysis/Spring系列(五十)面向切面编程AOP/","excerpt":"概念什么是AOP 在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。 Aop是一种思想而不是一种技术，所以说，如果抛开Spring, 动态代理甚至静态代理的例子也可以算是一种aop。 为什么要用Aop 利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 在不改变原有方法的基础添加一些功能 , 比如: 日志记录 性能统计 安全控制 事务处理 异常处理等等","text":"概念什么是AOP 在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。 Aop是一种思想而不是一种技术，所以说，如果抛开Spring, 动态代理甚至静态代理的例子也可以算是一种aop。 为什么要用Aop 利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 在不改变原有方法的基础添加一些功能 , 比如: 日志记录 性能统计 安全控制 事务处理 异常处理等等 Aop 术语 连接点(JoinPoint) 程序执行到某个特定位置，如类开始初始化前，类初始化后，某个方法调用前/后，方法抛出异常后，一些具有边界性质的特定点就是连接点， Spring 仅支持方法级的连接点(方法执行前，方法完成后，抛出异常后) 切点(Pointcut) 从连接点的基础上引出的概念，是指特定的连接点，一个类有好多方法,每个方法又有多个连接点，则需要切点来限定一个小范围的连接点，在Spring中是使用类和方法作为连接点的查询条件 通知、增强处理(Advice) 就是指你所需要添加的功能及这个功能什么时候(通知)实现 , 比如一个业务方法需要实现日志功能 , 那么就需要专门在一个地方定义好需要做什么，然后定义什么时候执行(方法执行前？，方法完成后？，抛出异常？。。。) Spring 切面可应用的 5 种通知类型： Before——在方法调用之前调用通知 After——在方法完成之后调用通知，无论方法执行成功与否 After-returning——在方法执行成功之后调用通知 After-throwing——在方法抛出异常后进行通知 Around——通知包裹了被通知的方法，在被通知的方法调用之前和调用之后执行自定义的行为 引入(introduction) 特殊的增强，为类添加一些属性和方法，这样即使一个业务类原本没有实现某个接口，通过AOP的引介功能，也可以动态的为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类 切面(Aspect) 切面由切点和增强组成 , 及包括横切逻辑的定义，也包括切点的定义, 目标对象(Target) 增强逻辑的织入目标类 , 如果没有Aop,那么目标对象就要自己实现(日志记录，性能统计，安全控制，事务处理，异常处理)这些功能，那么一个方法就会变成很杂乱 织入(Weaing) 将增强添加到目标对象的具体连接点上, Spring使用动态代理织入 Aop有三种织入方式 编译期织入 类装载期织入 动态代理织入: 在运行期间为目标类添加增强生成子类的方式 Aop 实现 JDK动态代理 CGLib动态代理 代理知识总结 Spring使用JDK动态代理和CGLib动态代理技术在运行期织入增强，要使用JDK动态代理，目标类必须实现接口，而CGLib不对目标类作任何限制，他是通过动态生成目标类子类的方式提供代理 JDK在创建代理对象时的性能高于CGLib，但生成的代理对象的运行性能却比CGLib的低，如果无需频繁的创建代理对象比较适合采用CGLib动态代理技术，反之比较适合JDK动态代理技术 Spring AOP 和 AspectJ AOP 区别 Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单， 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。 AOP示例 创建切面类ServiceAspectj，这个方法用于定义切面，功能是打印方法的执行前的输入参数及输出结果 1234567891011121314151617181920212223242526@Slf4j@Aspect@Componentpublic class ServiceAspectj &#123; @Pointcut(value = \"execution(* org.springframework.iframe.service..*(..))\") public void pointcut() &#123; &#125; @Around(\"pointcut()\") public Object doAround(ProceedingJoinPoint pjp) throws Throwable &#123; String className = pjp.getSignature().getDeclaringType().getSimpleName(); String methodName = pjp.getSignature().getName(); log.info(\"=&gt; [request method: &#123;&#125;#&#123;&#125;]\",className, methodName); log.info(\"=&gt; [request body: &#123;&#125;]\", JSONObject.toJSONString(pjp.getArgs())); Object result = pjp.proceed(); log.info(\"=&lt; [response method: &#123;&#125;#&#123;&#125;]\",className, methodName); log.info(\"=&lt; [response result: &#123;&#125; ]\", JSONObject.toJSONString(result)); return result; &#125;&#125; 需要切的方法 12345678910111213141516171819202122232425public interface UserService &#123; User findUserByName(String userName);&#125;@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired User user; @Autowired private RoleService roleService; @Override public User findUserByName(String userName) &#123; User user = new User(userName,18); //Role role = roleService.findRoleByUserName(userName); user.setRole(new Role()); return user; &#125;&#125; Spring 配置文件 beans/bean.xml 添加&lt;aop:aspectj-autoproxy/&gt;配置，开启AOP开关 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd\"&gt; &lt;bean class=\"org.springframework.iframe.entity.User\"&gt; &lt;property name=\"userName\" value=\"shop\"/&gt; &lt;/bean&gt; &lt;!-- ComponentScanBeanDefinitionParser--&gt; &lt;context:component-scan base-package = \"org.springframework.iframe.*\"/&gt; &lt;aop:aspectj-autoproxy/&gt;&lt;/beans&gt; 测试类及测试结果 1234567@Testpublic void test1 () &#123; ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(\"beans/bean.xml\"); UserService userService = xmlApplicationContext.getBean(UserService.class); User user1 = userService.findUserByName(\"sd\"); log.info(\"user1:&#123;&#125;\", user1);&#125; 123411:12:06,216 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&gt; [request method: UserService#findUserByName]11:12:06,307 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&gt; [request body: [\"sd\"]]11:12:06,307 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&lt; [response method: UserService#findUserByName]11:12:06,372 [INFO ] [org.springframework.iframe.aop.ServiceAspectj] - =&lt; [response result: &#123;\"age\":18,\"role\":&#123;&#125;,\"userName\":\"sd\"&#125; ] 总结 AOP的工作重心就是将增强应用与目标对象的连接点上，这里包括两部分内容： 如何通过切点和增强定位到连接点上 如何在增强中编写切面的逻辑 参考 《精通Spring+4.x++企业应用开发实战》 https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/spring/SpringInterviewQuestions?id=_41-谈谈自己对于-spring-ioc-和-aop-的理解","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(三十)ApplicationContext分析","slug":"backend/framework/spring/analysis/Spring系列(三一)ApplicationContext分析","date":"2019-07-02T14:02:46.000Z","updated":"2019-09-16T13:11:05.001Z","comments":true,"path":"2019/07/02/backend/framework/spring/analysis/Spring系列(三一)ApplicationContext分析/","link":"","permalink":"http://www.songshuiyang.com/2019/07/02/backend/framework/spring/analysis/Spring系列(三一)ApplicationContext分析/","excerpt":"","text":"前言 BeanFactory 是容器的顶级抽象，它并不适用于我们生产环境，在生产环境我们通常会选择 ApplicationContext ，相对于大多数人而言，它才是正规军，相比于 BeanFactory 这个杂牌军而言，它由如下几个区别： 继承 MessageSource，提供国际化的标准访问策略。 继承 ApplicationEventPublisher ，提供强大的事件机制。 扩展 ResourceLoader，可以用来加载多个 Resource，可以灵活访问不同的资源。 对 Web 应用的支持。 ApplicationContext 接口 接口代码 123456789101112131415public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123; String getId(); String getApplicationName(); String getDisplayName(); long getStartupDate(); ApplicationContext getParent(); AutowireCapableBeanFactory getAutowireCapableBeanFactory() throws IllegalStateException;&#125; 类继承关系 BeanFactory Spring 管理 Bean 的顶层接口，我们可以认为他是一个简易版的 Spring 容器。ApplicationContext 继承 BeanFactory 的两个子类：HierarchicalBeanFactory 和 ListableBeanFactory。 HierarchicalBeanFactory 是一个具有层级关系的 BeanFactory，拥有属性 parentBeanFactory 。 ListableBeanFactory 实现了枚举方法可以列举出当前 BeanFactory 中所有的 bean 对象而不必根据 name 一个一个的获取。 ApplicationEventPublisher 用于封装事件发布功能的接口，向事件监听器（Listener）发送事件消息。 ResourceLoader Spring 加载资源的顶层接口，用于从一个源加载资源文件。ApplicationContext 继承 ResourceLoader 的子类 ResourcePatternResolver，该接口是将 location 解析为 Resource 对象的策略接口。 MessageSource 解析 message 的策略接口，用不支撑国际化等功能。 EnvironmentCapable 用于获取 Environment 的接口。 接口方法(包括父类方法) ApplicationContext 常用子类1、 WebApplicationContext 该接口只有一个 #getServletContext() 方法，用于给 Servlet 提供上下文信息。 1234567// WebApplicationContext.javapublic interface WebApplicationContext extends ApplicationContext &#123; ServletContext getServletContext(); &#125; 2、 ClassPathXmlApplicationContext ClassPathXmlApplicationContext 是我们在学习 Spring 过程中用的非常多的一个类 ClassPathXmlApplicationContext 设计的顶级接口 BeanFactory Spring 容器 Bean 的管理 MessageSource 管理 message ，实现国际化等功能 ApplicationEventPublisher 事件发布,用于封装事件发布功能的接口，向事件监听器（Listener）发送事件消息。 ResourcePatternResolver 资源加载 EnvironmentCapable 系统 Environment（profile + Properties） 相关 Lifecycle 管理生命周期 Closable 关闭，释放资源,用于关闭 ApplicationContext 销毁所有 Bean InitializingBean 自定义初始化 BeanNameAware 设置 beanName 的 Aware 接口 3、ConfigurableApplicationContext 接口 ConfigurableApplicationContext 对 ApplicationContext 接口再次进行扩展，提供了生命周期的管理功能。 总结 Spring 真的是一个非常优秀的框架，具有良好的结构设计和接口抽象，它的每一个接口职能单一，且都是具体功能到各个模块的高度抽象，且几乎每套接口都提供了一个默认的实现（defaultXXX）。 抽象类 ApplicationContext 对整套接口提供了大部分的默认实现，将其中“不易变动”的部分进行了封装，通过“组合”的方式将“容易变动”的功能委托给其他类来实现，同时利用模板方法模式将一些方法的实现开放出去由子类实现，从而实现“对扩展开放，对修改封闭”的设计原则。 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(三十)IOC容器技术内幕","slug":"backend/framework/spring/analysis/Spring系列(三十)IOC容器技术内幕","date":"2019-07-02T14:02:45.000Z","updated":"2020-01-04T12:21:52.143Z","comments":true,"path":"2019/07/02/backend/framework/spring/analysis/Spring系列(三十)IOC容器技术内幕/","link":"","permalink":"http://www.songshuiyang.com/2019/07/02/backend/framework/spring/analysis/Spring系列(三十)IOC容器技术内幕/","excerpt":"","text":"前言IOC是什么 Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。在Java开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。如何理解好Ioc呢？理解好Ioc的关键是要明确“谁控制谁，控制什么，为何是反转（有反转就应该有正转了），哪些方面反转了”，那我们来深入分析一下： 谁控制谁，控制什么：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。 为何是反转，哪些方面反转了：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。 用图例说明一下，传统程序设计如图2-1，都是主动去创建相关对象然后再组合起来： 当有了IoC/DI的容器后，在客户端类中不再主动去创建这些对象了，如图2-2所示: IOC和DI Dependency Injection 即“依赖注入”：是组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。 那么IOC和DI这两者又是什么关系呢？ IOC就是一种软件设计思想，DI是这种软件设计思想的一个实现。而Spring中的核心机制就是DI。 IOC注入形式 构造函数注入 通过在其构造方法中声明依赖对象的参数列表，让外部知道它需要哪些依赖对象。 setter 方法注入 当前对象只需要为其所依赖的对象提供相对应的 setter 方法，就可以通过该方法将相应的依赖对象设置到被注入对象中 接口注入 接口方式注入需要被依赖的对象实现不必要的接口，带有侵入性。一般都不推荐这种方式。 Spring支持前两种依赖注入方式 Spring 容器 该图为 ClassPathXmlApplicationContext 的类继承体系结构，虽然只有一部分，但是它基本上包含了 IoC 体系中大部分的核心类和接口。 如果将Spring容器比作一辆车，那么可以将BeanFactory看成汽车的发动机，而ApplicationContext则是一辆完整的汽车，它不但包括发动机，还包括离合器、变速器及底盘、车身、电气设备等其他组件。在ApplicationContext内，各个组件按部就班、有条不絮地完成汽车的各项功能。 内部工作机制Spring 容器启动逻辑 Spring的AbstractApplicationContext是ApplicationContext的抽象实现类，该抽象类的refresh()方法定义了Spring容器在加载配置文件后的各项处理过程，这些处理过程清新地刻画了Spring容器启动时所执行地各项操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 初始化BeanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用工厂后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean， // 并调用其postProcessBeanFactory接口方法 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册Bean后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanPostProcessor接口的bean， // 并将它们注册到容器Bean后处理器的注册表中 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 初始化消息源 初始化容器的国际化消息资源 initMessageSource(); // Initialize event multicaster for this context. // 初始化应用上下文事件广播器 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 初始化其他特殊的bean，由具体子类实现，这是个钩子方法 onRefresh(); // Check for listener beans and register them. // 注册事件监听器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 初始化所有单实例的Bean，使用懒加载模式的bean除外，初始化Bean后将它们放到Spring容器的缓冲池中 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // 完成刷新并发布容器刷新事件 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 处理流程图 Spring容器从加载配置文件到创建一个完整Bean的作业流程及参与的角色 由上图可以得到Spring容器的构造逻辑，如下： 1、ResourceLoader从存储介质中加载Spring配置信息，并使用Resource表示这个配置文件资源； 2、BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中的每个解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中； 3、容器扫描BeanDefintionRegistry中的BeanDefintion，使用Java反射机制自动识别出Bean工厂后处理器(实现BeanFactoryPostProcessor接口的Bean)，然后调用这些Bean工厂后处理对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成一下两项工作: 1). 对使用占位符的&lt; bean &gt;元素标签进行解析，得到最终的配置值。这意味着对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象； 2). 对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean(实现java.beans.PropertyEditor接口的Bean)，并自动将它们注册到Spring容器的属性器注册表中(PropertyEditorRegistry)。 4、Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStarategy着手进行Bean实例化的工作； 5、在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装。BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefintion及容器中的属性编辑器，完成Bean属性注入工作； 6、利用容器中的Bean后处理器(实现BeanPostProcessor接口的Bean)对己经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean；总结 Spring容器堪称一部设计精密的机器，其内部拥有众多的组件和装置。Spring的高明之处在于，它使用众多接口描绘除了所有的装置的协作蓝图，构建好Spring的骨架，继而通过继承体系层层推演、不断丰富，最终让Spring成为有血有肉的完整的框架。所有在查看Spring框架的源码时，有两条清晰可见的脉络： 接口层描述了容器的重要组件及组件间的协作关系 继承体系逐步实现组件的各项功能。 接口层清晰地勾勒出Spring框架地高层功能，框架脉络呼之欲出。有了接口层抽象地描述后，不但Spring自己可以提供具体的实现，任何第三方组织也可以提供不同的实现，可以说Spring完善的接口层使框架的扩展性得到了很好的保证 纵向继承体系的逐步发展，分步骤地实现框架地功能，这种实现方案保证了框架功能不会堆积在某些类身上，从而造成过重地代码逻辑负载，框架的复杂度被完美地分解开了。 Spring可以就像一个餐馆，为顾客提供各种各样的美味佳肴，那么它是怎样做出美味的饭菜呢？ Spring的设计者就是餐馆的老板，统筹规划餐馆的运作 原始食材：xml配置的bean ，高级一点的原始食材注解配置的bean，加工后的食材：Resource BeanDefinition PropertyEditor 采购员：ResourceLoader，择菜员：BeanDefinitionReader，仓库：BeanDefintionRegistry ,厨师就是将准备好的食材烹饪为菜肴其他 在Spring也可以注入List/Map 之前一直使用xml的方式进行Spring配置，对于内部元素为String的List和Map属性的注入一般为如下方式： 123456789101112131415&lt;bean id = \"testBean\" class = \"com.a.b.c.TestBean\"&gt; &lt;property name = \"fieldMap\"&gt; &lt;map&gt; &lt;entry key = \"field1\" value = \"value1\"&gt;&lt;/entry&gt; &lt;entry key = \"field2\" value = \"value2\"&gt;&lt;/entry&gt; &lt;entry key = \"field3\" value = \"value3\"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name = \"fieldList\"&gt; &lt;list&gt; &lt;value&gt;1&lt;/value&gt; &lt;value&gt;2&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 如果内部元素为Bean，则将value替换为value-ref或元素即可。 当然，我们也可以使用Spring提供的schema扩展util来实现List和Map的声明、注入： 123456789101112131415161718&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:util=\"http://www.springframework.org/schema/util\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-2.5.xsd\"&gt; &lt;util:list list-class=\"java.util.ArrayList\"&gt; &lt;value&gt;1&lt;/value&gt; &lt;value&gt;2&lt;/value&gt; &lt;value&gt;3&lt;/value&gt; &lt;/util:list&gt; &lt;util:map map-class=\"java.util.HashMap\"&gt; &lt;entry key=\"Key1\" value=\"1\" /&gt; &lt;entry key=\"Key2\" value=\"2\" /&gt; &lt;entry key=\"Key3\" value=\"3\" /&gt; &lt;/util:map&gt;&lt;/beans&gt; 目前多用注解的方式来注入String类型的List和Map： properties.yml12test.map = &#123;key1:'value1',key2:'value2',key3:'value3'&#125;test.list = value1,value2,value3 在目标Bean中使用@Value注解进行注入： @Value(\"#{'${test.list}'.split(',')}\") private List&lt;String&gt; testList; @Value(\"#{${test.map}}\") private Map&lt;String,String&gt; testMap; 总结参考 《精通Spring+4.x++企业应用开发实战》 https://jinnianshilongnian.iteye.com/blog/1413846 http://www.cnblogs.com/xdp-gacl/p/4249939.html https://blog.csdn.net/li_xiao_dai/article/details/80667246 https://www.cnblogs.com/xiao2/p/7706902.html http://svip.iocoder.cn/Spring/IoC-intro/","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二五)Bean的生命周期","slug":"backend/framework/spring/analysis/Spring系列(二五)Bean的生命周期","date":"2019-07-01T15:02:46.000Z","updated":"2020-01-04T12:21:52.162Z","comments":true,"path":"2019/07/01/backend/framework/spring/analysis/Spring系列(二五)Bean的生命周期/","link":"","permalink":"http://www.songshuiyang.com/2019/07/01/backend/framework/spring/analysis/Spring系列(二五)Bean的生命周期/","excerpt":"","text":"前言Spring Bean 在容器的生命周期是什么样的？ 实例化 Bean 对象 Spring 容器根据配置中的 Bean Definition(定义)中实例化 Bean 对象。Bean Definition 可以通过 XML，Java 注解或 Java Config 代码提供。 进行属性填充 Spring 使用依赖注入填充所有属性，如 Bean 中所定义的配置。 初始化 调用钩子接口函数Aware、BeanPostProcessor、InitializingBean 使用 Bean 对象 销毁 Bean 对象 如果 Bean 实现 DisposableBean 接口，当 spring 容器关闭时，会调用 #destroy() 方法。 如果为 Bean 指定了 destroy 方法（例如 &lt;bean /&gt; 的 destroy-method 属性），那么将调用该方法。 参考","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二四)Spring生命周期之Lifecycle","slug":"backend/framework/spring/analysis/Spring系列(二四)Spring生命周期之Lifecycle","date":"2019-07-01T15:02:46.000Z","updated":"2019-09-16T13:11:05.146Z","comments":true,"path":"2019/07/01/backend/framework/spring/analysis/Spring系列(二四)Spring生命周期之Lifecycle/","link":"","permalink":"http://www.songshuiyang.com/2019/07/01/backend/framework/spring/analysis/Spring系列(二四)Spring生命周期之Lifecycle/","excerpt":"","text":"前言 先看一张图，有了这张图在回顾之前的章节知识就会变了很清晰了 解析### Lifecycle接口，LifeCycle定义Spring容器对象的生命周期，任何Spring管理对象都可以实现该接口。然后，当ApplicationContext本身接收启动和停止信号(例如在运行时停止/重启场景)时，Spring容器将在容器上下文中找出所有实现了LifeCycle及其子类接口的类，并一一调用它们实现的类。Spring是通过委托给生命周期处理器LifecycleProcessor来实现这一点的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * A common interface defining methods for start/stop lifecycle control. * The typical use case for this is to control asynchronous processing. * &lt;b&gt;NOTE: This interface does not imply specific auto-startup semantics. * Consider implementing &#123;@link SmartLifecycle&#125; for that purpose.&lt;/b&gt; * * &lt;p&gt;Can be implemented by both components (typically a Spring bean defined in a * Spring context) and containers (typically a Spring &#123;@link ApplicationContext&#125; * itself). Containers will propagate start/stop signals to all components that * apply within each container, e.g. for a stop/restart scenario at runtime. * * &lt;p&gt;Can be used for direct invocations or for management operations via JMX. * In the latter case, the &#123;@link org.springframework.jmx.export.MBeanExporter&#125; * will typically be defined with an * &#123;@link org.springframework.jmx.export.assembler.InterfaceBasedMBeanInfoAssembler&#125;, * restricting the visibility of activity-controlled components to the Lifecycle * interface. * * &lt;p&gt;Note that the Lifecycle interface is only supported on &lt;b&gt;top-level singleton * beans&lt;/b&gt;. On any other component, the Lifecycle interface will remain undetected * and hence ignored. Also, note that the extended &#123;@link SmartLifecycle&#125; interface * provides integration with the application context's startup and shutdown phases. * * @author Juergen Hoeller * @since 2.0 * @see SmartLifecycle * @see ConfigurableApplicationContext * @see org.springframework.jms.listener.AbstractMessageListenerContainer * @see org.springframework.scheduling.quartz.SchedulerFactoryBean */public interface Lifecycle &#123; /** * Start this component. * &lt;p&gt;Should not throw an exception if the component is already running. * &lt;p&gt;In the case of a container, this will propagate the start signal to all * components that apply. * @see SmartLifecycle#isAutoStartup() */ void start(); /** * Stop this component, typically in a synchronous fashion, such that the component is * fully stopped upon return of this method. Consider implementing &#123;@link SmartLifecycle&#125; * and its &#123;@code stop(Runnable)&#125; variant when asynchronous stop behavior is necessary. * &lt;p&gt;Note that this stop notification is not guaranteed to come before destruction: On * regular shutdown, &#123;@code Lifecycle&#125; beans will first receive a stop notification before * the general destruction callbacks are being propagated; however, on hot refresh during a * context's lifetime or on aborted refresh attempts, only destroy methods will be called. * &lt;p&gt;Should not throw an exception if the component isn't started yet. * &lt;p&gt;In the case of a container, this will propagate the stop signal to all components * that apply. * @see SmartLifecycle#stop(Runnable) * @see org.springframework.beans.factory.DisposableBean#destroy() */ void stop(); /** * Check whether this component is currently running. * &lt;p&gt;In the case of a container, this will return &#123;@code true&#125; only if &lt;i&gt;all&lt;/i&gt; * components that apply are currently running. * @return whether the component is currently running */ boolean isRunning();&#125; Lifecycle 生命周期的不足 常规的LifeCycle接口只是在容器上下文显式的调用start()/stop()方法时，才会去回调LifeCycle的实现类的start stop方法逻辑。并不意味着在上下文刷新时自动启动。 SmartLifecycle 自动的生命周期扩展 那么,如果Spring容器上下文没有显式的调用start和destory(或者close,stop)等方法时，我们也需要做到生命周期回调，怎么做? 于是SmartLifecycle可以做到这一点,它继承自Lifecycle接口，新增了如下几个方法: 123456789101112131415161718192021222324public interface SmartLifecycle extends Lifecycle, Phased &#123; /** * 如果该`Lifecycle`类所在的上下文在调用`refresh`时,希望能够自己自动进行回调，则返回`true`* , * false的值表明组件打算通过显式的start()调用来启动，类似于普通的Lifecycle实现。 */ boolean isAutoStartup(); /** * Indicates that a Lifecycle component must stop if it is currently running. * &lt;p&gt;The provided callback is used by the &#123;@link LifecycleProcessor&#125; to support * an ordered, and potentially concurrent, shutdown of all components having a * common shutdown order value. The callback &lt;b&gt;must&lt;/b&gt; be executed after * the &#123;@code SmartLifecycle&#125; component does indeed stop. * &lt;p&gt;The &#123;@link LifecycleProcessor&#125; will call &lt;i&gt;only&lt;/i&gt; this variant of the * &#123;@code stop&#125; method; i.e. &#123;@link Lifecycle#stop()&#125; will not be called for * &#123;@code SmartLifecycle&#125; implementations unless explicitly delegated to within * the implementation of this method. * @see #stop() * @see #getPhase() */ void stop(Runnable callback);&#125; 容器中实现了Lifecycle的多个类如果希望有顺序的进行回调时，那么启动和关闭调用的顺序可能很重要。如果任何两个对象之间存在依赖关系，那么依赖方将在依赖后开始，在依赖前停止。然而，有时直接依赖关系是未知的。您可能只知道某个类型的对象应该在另一个类型的对象之前开始。在这些情况下，SmartLifecycle接口定义了另一个选项，即在其超接口上定义的getPhase()方法。 总结 Lifecycle接口是为启动或停止生命周期,控制定义方法的通用接口。 参考 https://www.jianshu.com/p/43b65ed2e166","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二三)PropertySource及Environment及Profile接口分析","slug":"backend/framework/spring/analysis/Spring系列(二三)PropertySource及Environment及Profile接口分析","date":"2019-07-01T15:01:46.000Z","updated":"2019-09-16T13:11:05.121Z","comments":true,"path":"2019/07/01/backend/framework/spring/analysis/Spring系列(二三)PropertySource及Environment及Profile接口分析/","link":"","permalink":"http://www.songshuiyang.com/2019/07/01/backend/framework/spring/analysis/Spring系列(二三)PropertySource及Environment及Profile接口分析/","excerpt":"","text":"前言 spring.profiles.active 和 @Profile 这两个我相信各位都熟悉吧，主要功能是可以实现不同环境下（开发、测试、生产）参数配置的切换。 解析 Spring 环境 &amp; 属性由四个部分组成：PropertySource、PropertyResolver、Profile 和 Environment。 PropertySource 属性源，key-value 属性对抽象，用于配置数据。 PropertyResolver 属性解析器，用于解析任何基础源的属性的接口 Profile 剖面，只有激活的剖面的组件/配置才会注册到 Spring 容器，类似于 Spring Boot 中的 profile 。 Environment Environment 对象的作用，是确定哪些配置文件（如果有）当前处于活动状态，以及默认情况下哪些配置文件（如果有）应处于活动状态。properties 在几乎所有应用程序中都发挥着重要作用，并且有多种来源：属性文件，JVM 系统属性，系统环境变量，JNDI，servlet 上下文参数，ad-hoc 属性对象，映射等。同时它继承 PropertyResolver 接口，所以与属性相关的 Environment 对象其主要是为用户提供方便的服务接口，用于配置属性源和从中属性源中解析属性。 123456789101112// Environment.javapublic interface Environment extends PropertyResolver &#123; // 返回此环境下激活的配置文件集 String[] getActiveProfiles(); // 如果未设置激活配置文件，则返回默认的激活的配置文件集 String[] getDefaultProfiles(); boolean acceptsProfiles(String... profiles);&#125; 总结参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二二)BeanFactoryPostProcessor接口分析","slug":"backend/framework/spring/analysis/Spring系列(二二)BeanFactoryPostProcessor接口分析","date":"2019-07-01T14:01:47.000Z","updated":"2020-01-04T12:21:52.157Z","comments":true,"path":"2019/07/01/backend/framework/spring/analysis/Spring系列(二二)BeanFactoryPostProcessor接口分析/","link":"","permalink":"http://www.songshuiyang.com/2019/07/01/backend/framework/spring/analysis/Spring系列(二二)BeanFactoryPostProcessor接口分析/","excerpt":"","text":"前言 前面我们知道BeanPostProcessor是Spring 的一个工厂钩子，使用户可以对Bean创建过程中对 Bean 进行增强处理（前、后置处理），同样在 Spring 容器启动阶段，Spring 也提供了一种容器扩展机制：BeanFactoryPostProcessor，该机制作用于容器启动阶段，允许我们在容器实例化 Bean 之前对注册到该容器的 BeanDefinition 做出修改。 BeanFactoryPostProcessor 的机制，就相当于给了我们在 Bean 实例化之前最后一次修改 BeanDefinition 的机会，我们可以利用这个机会对 BeanDefinition 来进行一些额外的操作，比如更改某些 bean 的一些属性，给某些 Bean 增加一些其他的信息等等操作。 解析BeanFactoryPostProcessor 接口定义 org.springframework.beans.factory.config.BeanFactoryPostProcessor 接口，定义如下： 12345public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 这个方法工作于 BeanDefinition 加载完成之后，Bean实例化之前，其主要作用是对加载 BeanDefinition 进行修改 有一点需要需要注意的是在 #postProcessBeanFactory(...) 方法中千万不能进行 Bean 的实例化工作，因为这样会导致 Bean 过早实例化，会产生严重后果 我们始终需要注意的是 BeanFactoryPostProcessor 是与 BeanDefinition 打交道的，如果想要与 Bean 打交道，请使用 BeanPostProcessor 。 与 BeanPostProcessor 一样，BeanFactoryPostProcessor 同样支持排序，一个容器可以同时拥有多个 BeanFactoryPostProcessor ，这个时候如果我们比较在乎他们的顺序的话，可以实现 Ordered 接口。 BeanFactoryPostProcessor 在哪里调用 回到org.springframework.context.support.AbstractApplicationContext#refresh方法，关注invokeBeanFactoryPostProcessors(beanFactory);方法，见名知其意执行BeanFactoryPostProcessor方法 12345678910111213141516171819202122232425262728@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 准备刷新的上下文环境，例如对系统属性或者环境变量进行准备及验证 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 初始化BeanFactory，并进行XML文件读取，这一步之后ClassPathXmlApplicationContext实际上就已经包含了BeanFactory所提供的功能 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 进入prepareBeanFactory前，Spring已经完成了对配置的解析，而ApplicationContext在功能上的扩展也由此展开 // 对BeanFactory进行各种功能组件填充 @Qualifier @Autowired这两注解功能组件就是在这步骤中增加的支持 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 子类覆盖方法做额外的处理 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用工厂后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean， // 并调用其postProcessBeanFactory接口方法 invokeBeanFactoryPostProcessors(beanFactory); ... 进入invokeBeanFactoryPostProcessors(beanFactory);方法，这里出现了一个新的委托类PostProcessorRegistrationDelegate ，委托执行post processors任务的工具类 1234567891011121314151617/** * 实例化BeanFactoryPostProcessor实例及执行其接口方法 * * Instantiate and invoke all registered BeanFactoryPostProcessor beans, * respecting explicit order if given. * &lt;p&gt;Must be called before singleton instantiation. */protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor) if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125; 进入PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors())方法 12345678910/** * Invoke the given BeanFactoryPostProcessor beans. */private static void invokeBeanFactoryPostProcessors( Collection&lt;? extends BeanFactoryPostProcessor&gt; postProcessors, ConfigurableListableBeanFactory beanFactory) &#123; for (BeanFactoryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanFactory(beanFactory); &#125;&#125; BeanFactoryPostProcessor 子类PropertyPlaceholderConfigurer 允许我们在 XML 配置文件中使用占位符并将这些占位符所代表的资源单独配置到简单的 properties 文件中来加载 总结 我们始终需要注意的是 BeanFactoryPostProcessor 是与 BeanDefinition 打交道的，如果想要与 Bean 打交道，请使用 BeanPostProcessor 。 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn https://blog.csdn.net/andy_zhang2007/article/details/78530137","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二一)BeanPostProcessor接口分析","slug":"backend/framework/spring/analysis/Spring系列(二一)BeanPostProcessor接口分析","date":"2019-07-01T14:01:46.000Z","updated":"2020-01-04T12:21:52.153Z","comments":true,"path":"2019/07/01/backend/framework/spring/analysis/Spring系列(二一)BeanPostProcessor接口分析/","link":"","permalink":"http://www.songshuiyang.com/2019/07/01/backend/framework/spring/analysis/Spring系列(二一)BeanPostProcessor接口分析/","excerpt":"","text":"前言 BeanPostProcessor接口的核心思想是允许 Spring 在创建 bean 阶段对其进行定制化修改 123456public interface BeanPostProcessor &#123; Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; BeanPostProcessor 可以理解为是 Spring 的一个工厂钩子（其实 Spring 提供一系列的钩子，如 Aware 、InitializingBean、DisposableBean），它是 Spring 提供的对象实例化阶段强有力的扩展点，允许 Spring 在实例化 bean 阶段对其进行定制化修改，比较常见的使用场景是处理标记接口实现类或者为当前对象提供代理实现（例如 AOP）。 #postProcessBeforeInitialization(Object bean, String beanName) 和 #postProcessAfterInitialization(Object bean, String beanName) 两个方法，都接收一个 Object 类型的 bean ，一个 String 类型的 beanName ，其中bean 是已经实例化了的 instanceBean ，能拿到这个你是不是可以对它为所欲为了？ 这两个方法是初始化 bean 的前后置处理器，他们应用 #invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd)方法的前后。如下图: 解析BeanPostProcessor接口方法调用 接口的两个方法是哪里调用了呢，又回到回到doCreateBean(...) 方法，这个方法主要用于完成 bean 的创建和初始化工作，我们可以将其分为一下几个过程 createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) 方法，实例化 bean 。 populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法，进行属性填充。 initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，初始化 Bean 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Initialize the given bean instance, applying factory callbacks * as well as init methods and bean post processors. * &lt;p&gt;Called from &#123;@link #createBean&#125; for traditionally defined beans, * and from &#123;@link #initializeBean&#125; for existing bean instances. * @param beanName the bean name in the factory (for debugging purposes) * @param bean the new bean instance we may need to initialize * @param mbd the bean definition that the bean was created with * (can also be &#123;@code null&#125;, if given an existing bean instance) * @return the initialized bean instance (potentially wrapped) * @see BeanNameAware * @see BeanClassLoaderAware * @see BeanFactoryAware * @see #applyBeanPostProcessorsBeforeInitialization * @see #invokeInitMethods * @see #applyBeanPostProcessorsAfterInitialization */protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 对特殊的bean处理 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware invokeAwareMethods(beanName, bean); &#125; /** * 开始三步走： * */ Object wrappedBean = bean; // 第一步： 执行BeanPostProcessor实例化后初始化前处理方法 org.springframework.beans.factory.config.BeanPostProcessor.postProcessBeforeInitialization if (mbd == null || !mbd.isSynthetic()) &#123; // 方法调用前处理方法 /** * 1、会调用下面这些 AwareInterfaces 比如熟悉的 EnvironmentAware ApplicationContextAware * @see org.springframework.context.support.ApplicationContextAwareProcessor#invokeAwareInterfaces(java.lang.Object) * 2、TODO 其他的BeanPostProcessor还没发掘 */ wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 第二步核心：激活用户自定义的init方法 1、InitializingBean接口afterPropertiesSet方法 2、bean 定义的init-method=\"\"方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; // 第三步： 执行BeanPostProcessor实例化后初始化后处理方法 org.springframework.beans.factory.config.BeanPostProcessor.postProcessAfterInitialization if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 重点1：BeanPostProcessor前置处理: 实例化后初始化前处理方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); 12345678910111213@Overridepublic Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessBeforeInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result;&#125; 重点2：BeanPostProcessor后置处理：实例化后初始化后处理方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); 1234567891011121314@Overridepublic Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; // 实现 BeanPostProcessor 接口用户可以根据自己的业务需求进行响应的处理 for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessAfterInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result;&#125; BeanPostProcessor自动检测并注册 上面的逻辑就是就调用BeanPostProcessor接口定义的方法，那么这些BeanPostProcessor类是哪里来的呢？ 关注#getBeanPostProcessors() 方法，返回的是 BeanPostProcessor 集合，该集合里面存放就是我们自定义的 BeanPostProcessor 如果该集合中存在元素则调用相应的方法，否则就直接返回 bean 了。这也是为什么使用 BeanFactory 容器是无法输出自定义 BeanPostProcessor 里面的内容，因为在 BeanFactory#getBean(...) 方法的过程中根本就没有将我们自定义的 BeanPostProcessor 注入进来，所以要想 BeanFactory 容器 的 BeanPostProcessor 生效我们必须手动调用 #addBeanPostProcessor(BeanPostProcessor, beanPostProcessor) 方法，将定义的 BeanPostProcessor 注册到相应的 BeanFactory 中。但是 ApplicationContext 不需要手动，因为 ApplicationContext 会自动检测并完成注册。 ApplicationContext 实现自动注册的原因，在于我们构造一个 ApplicationContext 实例对象的时候会调用 #registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) 方法，将检测到的 BeanPostProcessor 注入到 ApplicationContext 容器中，同时应用到该容器创建的 bean 中。代码如下： 123456789101112131415161718192021222324252627282930313233@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 准备刷新的上下文环境，例如对系统属性或者环境变量进行准备及验证 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 初始化BeanFactory，并进行XML文件读取，这一步之后ClassPathXmlApplicationContext实际上就已经包含了BeanFactory所提供的功能 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 进入prepareBeanFactory前，Spring已经完成了对配置的解析，而ApplicationContext在功能上的扩展也由此展开 // 对BeanFactory进行各种功能组件填充 @Qualifier @Autowired这两注解功能组件就是在这步骤中增加的支持 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 子类覆盖方法做额外的处理 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用工厂后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean， // 并调用其postProcessBeanFactory接口方法 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册Bean后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanPostProcessor接口的bean， // 并将它们注册到容器Bean后处理器的注册表中，这里只是注册，真正的调用在getBean时候 registerBeanPostProcessors(beanFactory); ... 进入registerBeanPostProcessors(beanFactory);方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 实例化并调用已经注入的 BeanPostProcessor 必须在应用中 bean 实例化之前调用 * Instantiate and invoke all registered BeanPostProcessor beans, * respecting explicit order if given. * &lt;p&gt;Must be called before any instantiation of application beans. */protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125;public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; // 获取所有的 BeanPostProcessor 的 beanName // 这些 beanName 都已经全部加载到容器中去，但是没有实例化 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. // 第一步，注册所有实现了 PriorityOrdered 的 BeanPostProcessor // 先排序 sortPostProcessors(beanFactory, priorityOrderedPostProcessors); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. // 第二步，注册所有实现了 Ordered 的 BeanPostProcessor List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(beanFactory, orderedPostProcessors); // 后注册 registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. // 第三步注册所有无序的 BeanPostProcessor List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; // 注册，无需排序 registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. // 最后，注册所有的 MergedBeanDefinitionPostProcessor 类型的 BeanPostProcessor sortPostProcessors(beanFactory, internalPostProcessors); registerBeanPostProcessors(beanFactory, internalPostProcessors); // Re-register post-processor for detecting inner beans as ApplicationListeners, // moving it to the end of the processor chain (for picking up proxies etc). // 加入ApplicationListenerDetector（探测器） // 重新注册 BeanPostProcessor 以检测内部 bean，因为 ApplicationListeners 将其移动到处理器链的末尾 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125; 注册代码如下，可以看到是存放在AbstractBeanFactory类的private final List&lt;BeanPostProcessor&gt; beanPostProcessors属性中 1234567891011121314151617181920212223/** * Register the given BeanPostProcessor beans. */private static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanPostProcessor&gt; postProcessors) &#123; for (BeanPostProcessor postProcessor : postProcessors) &#123; beanFactory.addBeanPostProcessor(postProcessor); &#125;&#125;@Overridepublic void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123; Assert.notNull(beanPostProcessor, \"BeanPostProcessor must not be null\"); this.beanPostProcessors.remove(beanPostProcessor); this.beanPostProcessors.add(beanPostProcessor); if (beanPostProcessor instanceof InstantiationAwareBeanPostProcessor) &#123; this.hasInstantiationAwareBeanPostProcessors = true; &#125; if (beanPostProcessor instanceof DestructionAwareBeanPostProcessor) &#123; this.hasDestructionAwareBeanPostProcessors = true; &#125;&#125; 总结 Spring对对象的可扩展性主要就是依靠BeanPostProcessor来完成的，使用BeanPostProcessor可以对实例化后的bean为所欲为，添加自己的逻辑，不过一般项目开发中很少用到这个类 BeanFactory 和 ApplicationContext 对 BeanPostProcessor 的处理不同，ApplicationContext 会自动检测所有实现了 BeanPostProcessor 接口的 bean，并完成注册，但是使用 BeanFactory 容器时则需要手动调用 AbstractBeanFactory#addBeanPostProcessor(BeanPostProcessor beanPostProcessor) 方法来完成注册 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二十)Aware接口分析","slug":"backend/framework/spring/analysis/Spring系列(二十)Aware接口分析","date":"2019-07-01T14:00:46.000Z","updated":"2020-01-04T12:21:52.166Z","comments":true,"path":"2019/07/01/backend/framework/spring/analysis/Spring系列(二十)Aware接口分析/","link":"","permalink":"http://www.songshuiyang.com/2019/07/01/backend/framework/spring/analysis/Spring系列(二十)Aware接口分析/","excerpt":"","text":"前言 平常开发中会经常用到下面这个工具类，用于获取对应的ApplicationContext容器，然后再根据ApplicationContext获取对应的Bean，那么ApplicationContext applicationContext是怎么被注入进去的呢？ 123456789101112131415161718192021222324252627@Componentpublic class SpringContextUtils implements ApplicationContextAware, DisposableBean&#123; private static ApplicationContext applicationContext; public static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; public static &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) &#123; return applicationContext.getBean(requiredType); &#125; public static Object getBean(String beanName) &#123; return applicationContext.getBean(beanName); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringContextUtils.applicationContext = applicationContext; &#125; @Override public void destroy() throws Exception &#123; applicationContext=null; &#125;&#125; 观察上面的代码可以发现此类是被 @Component修饰的Bean，此外该类还实现了ApplicationContextAware接口，此接口就一个方法，这个方法的作用是获取ApplicationContext容器，下面我们来看看Spring是怎样实现此功能的 12345public interface ApplicationContextAware extends Aware &#123; void setApplicationContext(ApplicationContext applicationContext) throws BeansException;&#125; 解析Aware接口 org.springframework.beans.factory.Aware 接口，定义如下： 123456789101112131415161718192021222324/** * * 标识作用的超级接口，实现了该接口的 bean 是具有被 Spring 容器通知的能力，通知的方式是采用回调的方式。 * * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. * * &lt;p&gt;Note that merely implementing &#123;@link Aware&#125; provides no default * functionality. Rather, processing must be done explicitly, for example * in a &#123;@link org.springframework.beans.factory.config.BeanPostProcessor BeanPostProcessor&#125;. * Refer to &#123;@link org.springframework.context.support.ApplicationContextAwareProcessor&#125; * and &#123;@link org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory&#125; * for examples of processing &#123;@code *Aware&#125; interface callbacks. * * @author Chris Beams * @since 3.1 */public interface Aware &#123;&#125; Aware 接口为 Spring 容器的核心接口，是一个具有标识作用的超级接口，实现了该接口的 bean 是具有被 Spring 容器通知的能力，通知的方式是采用回调的方式 说的简单点就是实现我的Aware 接口的方法，Spring在构造Bean的时候就会调用这些接口方法 Aware 接口是一个空接口，实际的方法签名由各个子接口来确定，且该接口通常只会有一个接收单参数的 set 方法，该 set 方法的命名方式为 set + 去掉接口名中的 Aware 后缀，即 XxxAware 接口，则方法定义为 setXxx()，例如 BeanNameAware（setBeanName），ApplicationContextAware（setApplicationContext）。 Aware接口是如何发挥作用 Aware 的子接口需要提供一个 setXxx 方法，我们知道 set 是设置属性值的方法，即 Aware 类接口的 setXxx 方法其实就是设置 xxx 属性值的。 Aware 的含义是感知的、感应的，那么在 Spring 容器中是如何实现感知并设置属性值得呢？我们可以从初始化 bean 中的激活 Aware 的方法 #invokeAwareMethods(final String beanName, final Object bean) 中看到一点点，代码如下： 回顾doCreateBean(...) 方法，这个方法主要用于完成 bean 的创建和初始化工作，我们可以将其分为一下几个过程 createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) 方法，实例化 bean 。 populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法，进行属性填充。 initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，初始化 Bean 。 Aware接口是怎样发挥作用的呢，进入initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，关注invokeAwareMethods(beanName, bean);方法，见名知其意 12345678910111213141516171819protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 对特殊的bean处理 Aware、BeanClassLoaderAware、BeanFactoryAware invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 应用后处理器 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; 进入invokeAwareMethods(beanName, bean); 可以看到实现逻辑十分简单，首先判断该bean是否实现了Aware，然后就是根据不同的Aware子类调用不同的方法 12345678910111213141516171819/** * 实现了这些Aware接口的bean被初始化之后，可以取得一些相对应的资源 * @param beanName * @param bean */private void invokeAwareMethods(final String beanName, final Object bean) &#123; // 下面都是直接调用接口方法 if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(getBeanClassLoader()); &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125; 上面的只有三种Aware并没有我们的ApplicationContextAware，关注initializeBean()方法里面的 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);这行代码，从这里可以找到答案，下面代码又出现了熟悉的BeanPostProcessor，调用了bean初始化之前的钩子方法 12345678910111213@Overridepublic Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessBeforeInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result;&#125; 这里我们可以的得到ApplicationContextAwareProcessor 这个类，这个类实现了BeanPostProcessor接口，看注释就可以知道这个BeanPostProcessor的作用 12345678910111213141516171819202122232425262728293031323334353637383940/** * &#123;@link org.springframework.beans.factory.config.BeanPostProcessor&#125; * implementation that passes the ApplicationContext to beans that * implement the &#123;@link EnvironmentAware&#125;, &#123;@link EmbeddedValueResolverAware&#125;, * &#123;@link ResourceLoaderAware&#125;, &#123;@link ApplicationEventPublisherAware&#125;, * &#123;@link MessageSourceAware&#125; and/or &#123;@link ApplicationContextAware&#125; interfaces. * * &lt;p&gt;Implemented interfaces are satisfied in order of their mention above. * * &lt;p&gt;Application contexts will automatically register this with their * underlying bean factory. Applications do not use this directly. * * @author Juergen Hoeller * @author Costin Leau * @author Chris Beams * @since 10.10.2003 * @see org.springframework.context.EnvironmentAware * @see org.springframework.context.EmbeddedValueResolverAware * @see org.springframework.context.ResourceLoaderAware * @see org.springframework.context.ApplicationEventPublisherAware * @see org.springframework.context.MessageSourceAware * @see org.springframework.context.ApplicationContextAware * @see org.springframework.context.support.AbstractApplicationContext#refresh() */class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; private final ConfigurableApplicationContext applicationContext; private final StringValueResolver embeddedValueResolver; /** * Create a new ApplicationContextAwareProcessor for the given context. */ public ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; this.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory()); &#125; ... 进入org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization方法，可以看到主要是调用了invokeAwareInterfaces(bean);方法 1234567891011121314151617181920212223242526@Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException &#123; AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) &#123; acc = this.applicationContext.getBeanFactory().getAccessControlContext(); &#125; if (acc != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareInterfaces(bean); return null; &#125; &#125;, acc); &#125; else &#123; invokeAwareInterfaces(bean); &#125; return bean;&#125; 进入invokeAwareInterfaces(bean);方法，这里就看到了Spring对其进行了设置值((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); 12345678910111213141516171819202122private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125;&#125; Aware主要子类 ApplicationContextAware: 加载ApplicationContext LoadTimeWeaverAware：加载Spring Bean时织入第三方模块，如AspectJ BeanClassLoaderAware：加载Spring Bean的类加载器 BootstrapContextAware：资源适配器BootstrapContext，如JCA,CCI ResourceLoaderAware：底层访问资源的加载器 BeanFactoryAware：声明BeanFactory PortletConfigAware：PortletConfig PortletContextAware：PortletContext ServletConfigAware：ServletConfig ServletContextAware：ServletContext MessageSourceAware：国际化 ApplicationEventPublisherAware：应用事件 NotificationPublisherAware：JMX通知 BeanNameAware：声明Spring Bean的名字 总结 Aware 真正的含义是感知，其实是 Spring 容器在初始化主动检测当前 bean 是否实现了 Aware 接口，如果实现了则回调其 set 方法将相应的参数设置给该 bean ，这个时候该 bean 就从 Spring 容器中取得相应的资源。 Aware 接口触发的节点是在1.实例化 2.属性填充 3.初始化第三步触发的 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(十三)Bean初始化initializeBean方法之AbstractAutowireCapableBeanFactory","slug":"backend/framework/spring/analysis/Spring系列(十三)Bean初始化initializeBean方法之AbstractAutowireCapableBeanFactory","date":"2019-06-19T14:01:46.000Z","updated":"2020-01-04T12:21:52.195Z","comments":true,"path":"2019/06/19/backend/framework/spring/analysis/Spring系列(十三)Bean初始化initializeBean方法之AbstractAutowireCapableBeanFactory/","link":"","permalink":"http://www.songshuiyang.com/2019/06/19/backend/framework/spring/analysis/Spring系列(十三)Bean初始化initializeBean方法之AbstractAutowireCapableBeanFactory/","excerpt":"","text":"前言 回到doCreateBean(...) 方法，这个方法主要用于完成 bean 的创建和初始化工作，我们可以将其分为一下几个过程 createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) 方法，实例化 bean 。 populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法，进行属性填充。 initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，初始化 Bean 。 我们关心第三步的initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，这个方法是用来初始化 Bean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117/** * Initialize the given bean instance, applying factory callbacks * as well as init methods and bean post processors. * &lt;p&gt;Called from &#123;@link #createBean&#125; for traditionally defined beans, * and from &#123;@link #initializeBean&#125; for existing bean instances. * @param beanName the bean name in the factory (for debugging purposes) * @param bean the new bean instance we may need to initialize * @param mbd the bean definition that the bean was created with * (can also be &#123;@code null&#125;, if given an existing bean instance) * @return the initialized bean instance (potentially wrapped) * @see BeanNameAware * @see BeanClassLoaderAware * @see BeanFactoryAware * @see #applyBeanPostProcessorsBeforeInitialization * @see #invokeInitMethods * @see #applyBeanPostProcessorsAfterInitialization */protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 对特殊的bean处理 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware invokeAwareMethods(beanName, bean); &#125; /** * 开始三步走： * */ Object wrappedBean = bean; // 第一步： 执行BeanPostProcessor实例化后初始化前处理方法 org.springframework.beans.factory.config.BeanPostProcessor.postProcessBeforeInitialization if (mbd == null || !mbd.isSynthetic()) &#123; // 方法调用前处理方法 /** * 1、会调用下面这些 AwareInterfaces 比如熟悉的 EnvironmentAware ApplicationContextAware * @see org.springframework.context.support.ApplicationContextAwareProcessor#invokeAwareInterfaces(java.lang.Object) * 2、TODO 其他的BeanPostProcessor还没发掘 */ wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 第二步核心：激活用户自定义的init方法 1、InitializingBean接口afterPropertiesSet方法 2、bean 定义的init-method=\"\"方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; // 第三步： 执行BeanPostProcessor实例化后初始化后处理方法 org.springframework.beans.factory.config.BeanPostProcessor.postProcessAfterInitialization if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125;``` * 这个方法主要逻辑： * 1、执行实现了 `BeanNameAware、BeanClassLoaderAware、BeanFactoryAware`的`Bean`的接口方法 * 2、执行`BeanPostProcessor`的前置处理方法 * 3、执行用户自定义的`init`方法，有下面两种类型 * 1、`InitializingBean`接口`afterPropertiesSet`方法 * 2、`bean` 定义的`init-method=\"\"`方法 * 4、执行`BeanPostProcessor`的后置处理方法 * 1、会调用下面这些 AwareInterfaces * 比如熟悉的 EnvironmentAware ApplicationContextAware * @see org.springframework.context.support.ApplicationContextAwareProcessor#invokeAwareInterfaces(java.lang.Object) * 2、TODO 其他的BeanPostProcessor还没发掘* 上面可以看到中间夹了个`invokeInitMethods(beanName, wrappedBean, mbd);`方法，这个方法用于初始化`bean`，也就是用于激活用户自定义的初始化方法 * 进入`invokeInitMethods(beanName, wrappedBean, mbd);`方法，可以看到下面是检测当前 `bean` 对象是否实现了 `InitializingBean`接口。如果是，则会调用其 `#afterPropertiesSet()` 方法，进一步调整 `bean` 实例对象的状态。 ```java protected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd) throws Throwable &#123; // 检测当前 bean 对象是否实现了 InitializingBean 接口。如果是，则会调用其 #afterPropertiesSet() 方法，进一步调整 bean 实例对象的状态。 boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); &#125; if (System.getSecurityManager() != null) &#123; try &#123; // 调用afterPropertiesSet方法 AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123; @Override public Object run() throws Exception &#123; ((InitializingBean) bean).afterPropertiesSet(); return null; &#125; &#125;, getAccessControlContext()); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; // 属性初始化的处理 ((InitializingBean) bean).afterPropertiesSet(); &#125; &#125; if (mbd != null) &#123; String initMethodName = mbd.getInitMethodName(); if (initMethodName != null &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; // 调用自定义初始化方法 invokeCustomInitMethod(beanName, bean, mbd); &#125; &#125; &#125; * 然后，再检查是否也指定了 `init-method`，如果指定了则通过反射机制调用指定的 `init-method` 方法。 * 但是如果真的让我们的业务对象来实现这个`InitializingBean`接口就显得不是那么的友好了，`Spring` 的一个核心理念就是无侵入性，但是如果我们业务类实现这个接口就显得 `Spring` 容器具有侵入性了。所以 Spring 还提供了另外一种实现的方式：`init-method` 方法 * 使用`init-method``完全可以达到和 `InitializingBean` 一样的效果，而且在代码中我们没有看到丝毫 `Spring` 侵入的现象。所以通过 `init-method` 我们可以使用业务对象中定义的任何方法来实现 `bean` 实例对象的初始化定制化，而不再受制于 `InitializingBean的 #afterPropertiesSet()` 方法。同时我们可以使用 `&lt;beans&gt;` 标签的 `default-init-method` 属性来统一指定初始化方法，这样就省了需要在每个 `&lt;bean&gt;` 标签中都设置 `init-method` 这样的繁琐工作了 总结 AbstractAutowireCapableBeanFactory#initializeBean方法用于初始化bean，这时候的对象以及被实例化创建了，也属性填充了，对已经构造好的对象Spring提供了InitializingBean接口afterPropertiesSet方法 及 init-method=&quot;&quot;方法 可以自定义初始化方法，处理一些额外的事情 参考 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(十一)@Autowired注解原理AutowiredAnnotationBeanPostProcessor","slug":"backend/framework/spring/analysis/Spring系列(十一)@Autowired注解原理AutowiredAnnotationBeanPostProcessor","date":"2019-06-19T14:00:46.000Z","updated":"2020-01-04T12:21:52.193Z","comments":true,"path":"2019/06/19/backend/framework/spring/analysis/Spring系列(十一)@Autowired注解原理AutowiredAnnotationBeanPostProcessor/","link":"","permalink":"http://www.songshuiyang.com/2019/06/19/backend/framework/spring/analysis/Spring系列(十一)@Autowired注解原理AutowiredAnnotationBeanPostProcessor/","excerpt":"","text":"前言 @Autowired是一个用来执行依赖注入的注解。每当一个Spring管理的bean发现有这个注解时候，它会直接注入相应的另一个Spring管理的bean。那么具体的解析是怎么实现的呢，AutowiredAnnotationBeanPostProcessor这个类就是做这个事情的 类继承关系 类成员 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class AutowiredAnnotationBeanPostProcessor extends InstantiationAwareBeanPostProcessorAdapter implements MergedBeanDefinitionPostProcessor, PriorityOrdered, BeanFactoryAware &#123; protected final Log logger = LogFactory.getLog(getClass()); private final Set&lt;Class&lt;? extends Annotation&gt;&gt; autowiredAnnotationTypes = new LinkedHashSet&lt;Class&lt;? extends Annotation&gt;&gt;(); private String requiredParameterName = \"required\"; private boolean requiredParameterValue = true; private int order = Ordered.LOWEST_PRECEDENCE - 2; private ConfigurableListableBeanFactory beanFactory; private final Set&lt;String&gt; lookupMethodsChecked = Collections.newSetFromMap(new ConcurrentHashMap&lt;String, Boolean&gt;(256)); private final Map&lt;Class&lt;?&gt;, Constructor&lt;?&gt;[]&gt; candidateConstructorsCache = new ConcurrentHashMap&lt;Class&lt;?&gt;, Constructor&lt;?&gt;[]&gt;(256); private final Map&lt;String, InjectionMetadata&gt; injectionMetadataCache = new ConcurrentHashMap&lt;String, InjectionMetadata&gt;(256); /** * 构造函数中定义要处理的注解 * * Create a new AutowiredAnnotationBeanPostProcessor * for Spring's standard &#123;@link Autowired&#125; annotation. * &lt;p&gt;Also supports JSR-330's &#123;@link javax.inject.Inject&#125; annotation, if available. */ @SuppressWarnings(\"unchecked\") public AutowiredAnnotationBeanPostProcessor() &#123; this.autowiredAnnotationTypes.add(Autowired.class); this.autowiredAnnotationTypes.add(Value.class); try &#123; this.autowiredAnnotationTypes.add((Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.inject.Inject\", AutowiredAnnotationBeanPostProcessor.class.getClassLoader())); logger.info(\"JSR-330 'javax.inject.Inject' annotation found and supported for autowiring\"); &#125; catch (ClassNotFoundException ex) &#123; // JSR-330 API not available - simply skip. &#125; &#125; 解析解析类是怎么注册的 第五章有介绍ComponentScanBeanDefinitionParser是&lt;context:component-scan base-package = &quot;org.springiframe.*&quot;/&gt;这个标签的实现类，我们的AutowiredAnnotationBeanPostProcessor这个类就是在这里注册的，注意这个是会注册成Bean，进入registerComponents(parserContext.getReaderContext(), beanDefinitions, element);方法，关注AnnotationConfigUtils.registerAnnotationConfigProcessors(BeanDefinitionRegistry registry, Object source)方法 Tips：可以看到这里注册了很多解析类，比如我们常用的@Configuration/@Autowired/@Value/@Required解析类，以及JSR规范的@PostConstruct @PreDestroy @Resource注解解析类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Register all relevant annotation post processors in the given registry. * @param registry the registry to operate on * @param source the configuration source element (already extracted) * that this registration was triggered from. May be &#123;@code null&#125;. * @return a Set of BeanDefinitionHolders, containing all bean definitions * that have actually been registered by this call */public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(4); // 注册@Configuration`解析类 if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Autowired/@Value`解析类 if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Required`解析类 if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. // 注册@PostConstruct @PreDestroy @Resource 及JSR-250支持注解解析类 if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. // 注册JPA注解解析类 if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Cannot load optional framework class: \" + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs;&#125; 解析类是在哪里调用的 上一章节介绍了populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw)方法，这个方法是进行属性填充，这里是完成依赖注入的关键 123456789101112131415161718192021222324252627282930...// 后处理器已经初始化boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();// 需要依赖检查boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; // PropertyValue值设置后，Spring会调用getBeanPostProcessor方法遍历Bean工厂中注册的所有InstantiationAwareBeanPostProcessor // 其中就包括AutowiredAnnotationBeanPostProcessor @Autowired注解就是在这里完成的注入 for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 对所有需要依赖检查的属性进行后处理 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; // 依赖检查。对应depends-on属性，3.0已废弃 checkDependencies(beanName, mbd, filteredPds, pvs); &#125;&#125;... 可以看到上面是循环BeanPostProcessor，然后判断是否是InstantiationAwareBeanPostProcessor实例，如果是的话就执行postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName)方法，这里是调用了我们上面注册的AutowiredAnnotationBeanPostProcessor并对其接口方法进行了实现 先看InstantiationAwareBeanPostProcessor接口，这个接口主要作用在于目标对象的实例化过程中需要处理的事情，包括实例化对象的前后过程以及实例的属性设置123456789101112131415161718public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; /** * 是最先执行的方法，它在目标对象实例化之前调用，该方法的返回值类型是Object，我们可以返回任何类型的值。 * 由于这个时候目标对象还未实例化，所以这个返回值可以用来代替原本该生成的目标对象的实例(比如代理对象)。 * 如果该方法的返回值代替原本该生成的目标对象， */ Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException; /** * 在目标对象实例化之后调用，这个时候对象已经被实例化，但是该实例的属性还未被设置都是null，要通过下面那个方法 */ boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException; /** * 对属性值进行修改(这个时候属性值还未被设置，但是我们可以修改原本该设置进去的属性值)。 */ PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException;&#125; 解析类实现依赖注入 进入postProcessPropertyValues方法，可以看到先获取了InjectionMetadata对象，InjectionMetadata对象是注入元数据,包含了目标Bean的Class对象,和注入元素(InjectionElement)集合，先是获取这个bean哪些属性及方法需要依赖注入，然后封装成InjectionMetadata对象，最后执行了其对象的metadata.inject(bean, beanName, pvs);方法完成依赖注入 postProcessPropertyValues方法 1234567891011121314151617@Overridepublic PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; // 调用下面的方法获取InjectionMetadata对象（其实InjectionElement集合） InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); try &#123; // 调用注入方法 metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Injection of autowired dependencies failed\", ex); &#125; return pvs;&#125; InjectionMetadata类 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class InjectionMetadata &#123; private static final Log logger = LogFactory.getLog(InjectionMetadata.class); private final Class&lt;?&gt; targetClass; private final Collection&lt;InjectedElement&gt; injectedElements; private volatile Set&lt;InjectedElement&gt; checkedElements; public InjectionMetadata(Class&lt;?&gt; targetClass, Collection&lt;InjectedElement&gt; elements) &#123; this.targetClass = targetClass; this.injectedElements = elements; &#125; ... public void inject(Object target, String beanName, PropertyValues pvs) throws Throwable &#123; Collection&lt;InjectedElement&gt; elementsToIterate = (this.checkedElements != null ? this.checkedElements : this.injectedElements); if (!elementsToIterate.isEmpty()) &#123; boolean debug = logger.isDebugEnabled(); for (InjectedElement element : elementsToIterate) &#123; if (debug) &#123; logger.debug(\"Processing injected element of bean '\" + beanName + \"': \" + element); &#125; // 依次循环注入 element.inject(target, beanName, pvs); &#125; &#125; &#125; public static abstract class InjectedElement &#123; protected final Member member; protected final boolean isField; protected final PropertyDescriptor pd; protected volatile Boolean skip; ... 1、获取这个bean哪些属性及方法需要依赖注入 进入InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs);方法，因为需要注入的属性基本上都是不变的，所以Spring在这里做了一下缓存 12345678910111213141516171819202122232425262728293031323334/** * 获取注入元数据信息，这里做了一下缓存 * * @param beanName * @param clazz * @param pvs * @return */private InjectionMetadata findAutowiringMetadata(String beanName, Class&lt;?&gt; clazz, PropertyValues pvs) &#123; // Fall back to class name as cache key, for backwards compatibility with custom callers. String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName()); // Quick check on the concurrent map first, with minimal locking. 先找缓存 InjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; synchronized (this.injectionMetadataCache) &#123; metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; if (metadata != null) &#123; metadata.clear(pvs); &#125; try &#123; // 缓存没有，调用buildAutowiringMetadata方法构建 metadata = buildAutowiringMetadata(clazz); this.injectionMetadataCache.put(cacheKey, metadata); &#125; catch (NoClassDefFoundError err) &#123; throw new IllegalStateException(\"Failed to introspect bean class [\" + clazz.getName() + \"] for autowiring metadata: could not find class that it depends on\", err); &#125; &#125; &#125; &#125; return metadata;&#125; 如果缓存没有则调用buildAutowiringMetadata(clazz)方法进行构建，这个方法是找到哪些属性需要被自动装配，也就是查找被@Autowired、@Value、@Inject注解标记的元素，并封装为InjectionMetadata，可以看到是循环了这个类的Field及Method 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 找到哪些属性需要被自动装配，也就是查找被@Autowired、@Value、@Inject注解标记的元素，封装为InjectionMetadata * @param clazz * @return */public InjectionMetadata buildAutowiringMetadata(final Class&lt;?&gt; clazz) &#123; // 存放哪些属性需要被自动装配 LinkedList&lt;InjectionMetadata.InjectedElement&gt; elements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); Class&lt;?&gt; targetClass = clazz; do &#123; // 这里是循环，因为要考虑到父类的字段及方法 final LinkedList&lt;InjectionMetadata.InjectedElement&gt; currElements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); ReflectionUtils.doWithLocalFields(targetClass, new ReflectionUtils.FieldCallback() &#123; @Override public void doWith(Field field) throws IllegalArgumentException, IllegalAccessException &#123; // 遍历每一个field，找到被@Autowired、@Value、@Inject标识的字段 AnnotationAttributes ann = findAutowiredAnnotation(field); if (ann != null) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Autowired annotation is not supported on static fields: \" + field); &#125; return; &#125; boolean required = determineRequiredStatus(ann); // 创建AutowiredFieldElement currElements.add(new AutowiredFieldElement(field, required)); &#125; &#125; &#125;); ReflectionUtils.doWithLocalMethods(targetClass, new ReflectionUtils.MethodCallback() &#123; @Override public void doWith(Method method) throws IllegalArgumentException, IllegalAccessException &#123; // 遍历所有的方法 Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method); if (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) &#123; return; &#125; AnnotationAttributes ann = findAutowiredAnnotation(bridgedMethod); if (ann != null &amp;&amp; method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Autowired annotation is not supported on static methods: \" + method); &#125; return; &#125; if (method.getParameterTypes().length == 0) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Autowired annotation should only be used on methods with parameters: \" + method); &#125; &#125; boolean required = determineRequiredStatus(ann); PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz); // 创建AutowiredFieldElement currElements.add(new AutowiredMethodElement(method, required, pd)); &#125; &#125; &#125;); elements.addAll(0, currElements); targetClass = targetClass.getSuperclass(); &#125; while (targetClass != null &amp;&amp; targetClass != Object.class); // 将InjectedElement集合添加到新建的InjectionMetadata return new InjectionMetadata(clazz, elements);&#125; 关注AnnotationAttributes ann = findAutowiredAnnotation(field\\bridgedMethod);方法，可以看到这里是对this.autowiredAnnotationTypes进行遍历匹配，如果符合就返回 1234567891011private AnnotationAttributes findAutowiredAnnotation(AccessibleObject ao) &#123; if (ao.getAnnotations().length &gt; 0) &#123; for (Class&lt;? extends Annotation&gt; type : this.autowiredAnnotationTypes) &#123; AnnotationAttributes attributes = AnnotatedElementUtils.getMergedAnnotationAttributes(ao, type); if (attributes != null) &#123; return attributes; &#125; &#125; &#125; return null;&#125; this.autowiredAnnotationTypes 属性就是构造函数构建的存放Set&lt;Class&lt;? extends Annotation&gt;&gt; autowiredAnnotationTypes集合 ，默认有@Autowired、@Value、@Inject注解的 2、执行依赖注入 上面的步骤以及获取了这个类哪些属性需要注入，现在就是需要完成依赖注入的操作 123456789101112131415161718192021222324252627282930313233@Overridepublic PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; // 调用下面的方法获取InjectionMetadata对象（其实InjectionElement集合） InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); try &#123; // 调用注入方法 metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Injection of autowired dependencies failed\", ex); &#125; return pvs;&#125;public void inject(Object target, String beanName, PropertyValues pvs) throws Throwable &#123; Collection&lt;InjectedElement&gt; elementsToIterate = (this.checkedElements != null ? this.checkedElements : this.injectedElements); if (!elementsToIterate.isEmpty()) &#123; boolean debug = logger.isDebugEnabled(); for (InjectedElement element : elementsToIterate) &#123; if (debug) &#123; logger.debug(\"Processing injected element of bean '\" + beanName + \"': \" + element); &#125; // 依次循环注入 element.inject(target, beanName, pvs); &#125; &#125;&#125; 关注element.inject(target, beanName, pvs)方法，可以看到是循环Collection&lt;InjectedElement&gt; injectedElements依次对属性进行注入，见下图可以看到Field及Method有不同的注入实现类 注入实现 AutowiredFieldElement#inject() 可以看到 ReflectionUtils.makeAccessible(field); field.set(bean, value); 这里完成了注入操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 @Override protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123; Field field = (Field) this.member; Object value; if (this.cached) &#123; value = resolvedCachedArgument(beanName, this.cachedFieldValue); &#125; else &#123; DependencyDescriptor desc = new DependencyDescriptor(field, this.required); desc.setContainingClass(bean.getClass()); Set&lt;String&gt; autowiredBeanNames = new LinkedHashSet&lt;String&gt;(1); TypeConverter typeConverter = beanFactory.getTypeConverter(); try &#123; // 这里是重中之重，获取真正的属性值。 value = beanFactory.resolveDependency(desc, beanName, autowiredBeanNames, typeConverter); &#125; catch (BeansException ex) &#123; throw new UnsatisfiedDependencyException(null, beanName, new InjectionPoint(field), ex); &#125; synchronized (this) &#123; if (!this.cached) &#123; if (value != null || this.required) &#123; this.cachedFieldValue = desc; registerDependentBeans(beanName, autowiredBeanNames); if (autowiredBeanNames.size() == 1) &#123; String autowiredBeanName = autowiredBeanNames.iterator().next(); if (beanFactory.containsBean(autowiredBeanName)) &#123; if (beanFactory.isTypeMatch(autowiredBeanName, field.getType())) &#123; this.cachedFieldValue = new ShortcutDependencyDescriptor( desc, autowiredBeanName, field.getType()); &#125; &#125; &#125; &#125; else &#123; this.cachedFieldValue = null; &#125; this.cached = true; &#125; &#125; &#125; if (value != null) &#123; // 最终赋值结束。 ReflectionUtils.makeAccessible(field); field.set(bean, value); &#125; &#125;&#125; AutowiredMethodElement#inject()可以看到ReflectionUtils.makeAccessible(method); method.invoke(bean, arguments);这里完成了注入操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123; if (checkPropertySkipping(pvs)) &#123; return; &#125; Method method = (Method) this.member; Object[] arguments; if (this.cached) &#123; // Shortcut for avoiding synchronization... arguments = resolveCachedArguments(beanName); &#125; else &#123; Class&lt;?&gt;[] paramTypes = method.getParameterTypes(); arguments = new Object[paramTypes.length]; DependencyDescriptor[] descriptors = new DependencyDescriptor[paramTypes.length]; Set&lt;String&gt; autowiredBeans = new LinkedHashSet&lt;String&gt;(paramTypes.length); TypeConverter typeConverter = beanFactory.getTypeConverter(); for (int i = 0; i &lt; arguments.length; i++) &#123; MethodParameter methodParam = new MethodParameter(method, i); DependencyDescriptor currDesc = new DependencyDescriptor(methodParam, this.required); currDesc.setContainingClass(bean.getClass()); descriptors[i] = currDesc; try &#123; Object arg = beanFactory.resolveDependency(currDesc, beanName, autowiredBeans, typeConverter); if (arg == null &amp;&amp; !this.required) &#123; arguments = null; break; &#125; arguments[i] = arg; &#125; catch (BeansException ex) &#123; throw new UnsatisfiedDependencyException(null, beanName, new InjectionPoint(methodParam), ex); &#125; &#125; synchronized (this) &#123; if (!this.cached) &#123; if (arguments != null) &#123; this.cachedMethodArguments = new Object[paramTypes.length]; for (int i = 0; i &lt; arguments.length; i++) &#123; this.cachedMethodArguments[i] = descriptors[i]; &#125; registerDependentBeans(beanName, autowiredBeans); if (autowiredBeans.size() == paramTypes.length) &#123; Iterator&lt;String&gt; it = autowiredBeans.iterator(); for (int i = 0; i &lt; paramTypes.length; i++) &#123; String autowiredBeanName = it.next(); if (beanFactory.containsBean(autowiredBeanName)) &#123; if (beanFactory.isTypeMatch(autowiredBeanName, paramTypes[i])) &#123; this.cachedMethodArguments[i] = new ShortcutDependencyDescriptor( descriptors[i], autowiredBeanName, paramTypes[i]); &#125; &#125; &#125; &#125; &#125; else &#123; this.cachedMethodArguments = null; &#125; this.cached = true; &#125; &#125; &#125; if (arguments != null) &#123; try &#123; // 完成注入 ReflectionUtils.makeAccessible(method); method.invoke(bean, arguments); &#125; catch (InvocationTargetException ex)&#123; throw ex.getTargetException(); &#125; &#125; &#125; ``` * `InjectedElement#inject()`可以看到`ReflectionUtils.makeAccessible(method); field.set(target, getResourceToInject(target, requestingBeanName));`这里完成了注入操作 ```java protected void inject(Object target, String requestingBeanName, PropertyValues pvs) throws Throwable &#123; if (this.isField) &#123; Field field = (Field) this.member; ReflectionUtils.makeAccessible(field); field.set(target, getResourceToInject(target, requestingBeanName)); &#125; else &#123; if (checkPropertySkipping(pvs)) &#123; return; &#125; try &#123; Method method = (Method) this.member; ReflectionUtils.makeAccessible(method); method.invoke(target, getResourceToInject(target, requestingBeanName)); &#125; catch (InvocationTargetException ex) &#123; throw ex.getTargetException(); &#125; &#125; &#125; 总结 @Autowired注解的实现原理是通过AutowiredAnnotationBeanPostProcessor此类来实现的，这个类是Spring自带的bean，AutowiredAnnotationBeanPostProcessor实现了InstantiationAwareBeanPostProcessor接口，实现这个接口实现了依赖注入 先看InstantiationAwareBeanPostProcessor接口，这个接口主要作用在于目标对象的实例化过程中需要处理的事情，包括实例化对象的前后过程以及实例的属性设置 123456789101112131415161718public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; /** * 是最先执行的方法，它在目标对象实例化之前调用，该方法的返回值类型是Object，我们可以返回任何类型的值。 * 由于这个时候目标对象还未实例化，所以这个返回值可以用来代替原本该生成的目标对象的实例(比如代理对象)。 * 如果该方法的返回值代替原本该生成的目标对象， */ Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException; /** * 在目标对象实例化之后调用，这个时候对象已经被实例化，但是该实例的属性还未被设置都是null，要通过下面那个方法 */ boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException; /** * 对属性值进行修改(这个时候属性值还未被设置，但是我们可以修改原本该设置进去的属性值)。 */ PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException;&#125; 依赖注入是通过postProcessPropertyValues()方法来实现的，这个方法会在getBean#populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw)的时候会触发调用 @Autowired、@Value、@Inject 注解的实现大体逻辑是先获取哪些需要注入的属性，然后调用反射进行赋值 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(十二)@Resource注解原理CommonAnnotationBeanPostProcessor","slug":"backend/framework/spring/analysis/Spring系列(十二)@Resource注解原理CommonAnnotationBeanPostProcessor","date":"2019-06-19T14:00:46.000Z","updated":"2020-01-04T12:21:52.197Z","comments":true,"path":"2019/06/19/backend/framework/spring/analysis/Spring系列(十二)@Resource注解原理CommonAnnotationBeanPostProcessor/","link":"","permalink":"http://www.songshuiyang.com/2019/06/19/backend/framework/spring/analysis/Spring系列(十二)@Resource注解原理CommonAnnotationBeanPostProcessor/","excerpt":"","text":"前言 上一章节介绍了@Autowired注解的实现原理，本章将介绍和他一样常用的@Resource注解的实现原理，注意这个注解不是Spring的，而是JSR规范定义的注解 还是回到第五章有介绍ComponentScanBeanDefinitionParser是&lt;context:component-scan base-package = &quot;org.springiframe.*&quot;/&gt;这个标签的实现类，哇这个类是万能类呀 查看ComponentScanBeanDefinitionParser类可以看到这里注册了很多解析类，比如我们常用的@Configuration/@Autowired/@Value/@Required注解解析类，以及JSR规范的@PostConstruct @PreDestroy @Resource注解解析类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Register all relevant annotation post processors in the given registry. * @param registry the registry to operate on * @param source the configuration source element (already extracted) * that this registration was triggered from. May be &#123;@code null&#125;. * @return a Set of BeanDefinitionHolders, containing all bean definitions * that have actually been registered by this call */public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(4); // 注册@Configuration`解析类 if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Autowired/@Value`解析类 if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Required`解析类 if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. // 注册@PostConstruct @PreDestroy @Resource 及JSR-250支持注解解析类 if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. // 注册JPA注解解析类 if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Cannot load optional framework class: \" + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs;&#125; 通过上面的代码我们可以定位到CommonAnnotationBeanPostProcessor这个类，下面是这个类的继承关系图，可以看到这个类和AutowiredAnnotationBeanPostProcessor类一样实现了InstantiationAwareBeanPostProcessor接口，所以猜测应该和@Autowired注解的实现差不多 类成员 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132/** * &#123;@link org.springframework.beans.factory.config.BeanPostProcessor&#125; implementation * that supports common Java annotations out of the box, in particular the JSR-250 * annotations in the &#123;@code javax.annotation&#125; package. These common Java * annotations are supported in many Java EE 5 technologies (e.g. JSF 1.2), * as well as in Java 6's JAX-WS. * * &lt;p&gt;This post-processor includes support for the &#123;@link javax.annotation.PostConstruct&#125; * and &#123;@link javax.annotation.PreDestroy&#125; annotations - as init annotation * and destroy annotation, respectively - through inheriting from * &#123;@link InitDestroyAnnotationBeanPostProcessor&#125; with pre-configured annotation types. * * &lt;p&gt;The central element is the &#123;@link javax.annotation.Resource&#125; annotation * for annotation-driven injection of named beans, by default from the containing * Spring BeanFactory, with only &#123;@code mappedName&#125; references resolved in JNDI. * The &#123;@link #setAlwaysUseJndiLookup \"alwaysUseJndiLookup\" flag&#125; enforces JNDI lookups * equivalent to standard Java EE 5 resource injection for &#123;@code name&#125; references * and default names as well. The target beans can be simple POJOs, with no special * requirements other than the type having to match. * * &lt;p&gt;The JAX-WS &#123;@link javax.xml.ws.WebServiceRef&#125; annotation is supported too, * analogous to &#123;@link javax.annotation.Resource&#125; but with the capability of creating * specific JAX-WS service endpoints. This may either point to an explicitly defined * resource by name or operate on a locally specified JAX-WS service class. Finally, * this post-processor also supports the EJB 3 &#123;@link javax.ejb.EJB&#125; annotation, * analogous to &#123;@link javax.annotation.Resource&#125; as well, with the capability to * specify both a local bean name and a global JNDI name for fallback retrieval. * The target beans can be plain POJOs as well as EJB 3 Session Beans in this case. * * &lt;p&gt;The common annotations supported by this post-processor are available in * Java 6 (JDK 1.6) as well as in Java EE 5/6 (which provides a standalone jar for * its common annotations as well, allowing for use in any Java 5 based application). * * &lt;p&gt;For default usage, resolving resource names as Spring bean names, * simply define the following in your application context: * * &lt;pre class=\"code\"&gt; * &amp;lt;bean class=\"org.springframework.context.annotation.CommonAnnotationBeanPostProcessor\"/&amp;gt;&lt;/pre&gt; * * For direct JNDI access, resolving resource names as JNDI resource references * within the Java EE application's \"java:comp/env/\" namespace, use the following: * * &lt;pre class=\"code\"&gt; * &amp;lt;bean class=\"org.springframework.context.annotation.CommonAnnotationBeanPostProcessor\"&amp;gt; * &amp;lt;property name=\"alwaysUseJndiLookup\" value=\"true\"/&amp;gt; * &amp;lt;/bean&amp;gt;&lt;/pre&gt; * * &#123;@code mappedName&#125; references will always be resolved in JNDI, * allowing for global JNDI names (including \"java:\" prefix) as well. The * \"alwaysUseJndiLookup\" flag just affects &#123;@code name&#125; references and * default names (inferred from the field name / property name). * * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; A default CommonAnnotationBeanPostProcessor will be registered * by the \"context:annotation-config\" and \"context:component-scan\" XML tags. * Remove or turn off the default annotation configuration there if you intend * to specify a custom CommonAnnotationBeanPostProcessor bean definition! * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; Annotation injection will be performed &lt;i&gt;before&lt;/i&gt; XML injection; thus * the latter configuration will override the former for properties wired through * both approaches. * * @author Juergen Hoeller * @since 2.5 * @see #setAlwaysUseJndiLookup * @see #setResourceFactory * @see org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor * @see org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor */@SuppressWarnings(\"serial\")public class CommonAnnotationBeanPostProcessor extends InitDestroyAnnotationBeanPostProcessor implements InstantiationAwareBeanPostProcessor, BeanFactoryAware, Serializable &#123; // Common Annotations 1.1 Resource.lookup() available? Not present on JDK 6... private static final Method lookupAttribute = ClassUtils.getMethodIfAvailable(Resource.class, \"lookup\"); private static Class&lt;? extends Annotation&gt; webServiceRefClass = null; private static Class&lt;? extends Annotation&gt; ejbRefClass = null; static &#123; try &#123; @SuppressWarnings(\"unchecked\") Class&lt;? extends Annotation&gt; clazz = (Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.xml.ws.WebServiceRef\", CommonAnnotationBeanPostProcessor.class.getClassLoader()); webServiceRefClass = clazz; &#125; catch (ClassNotFoundException ex) &#123; webServiceRefClass = null; &#125; try &#123; @SuppressWarnings(\"unchecked\") Class&lt;? extends Annotation&gt; clazz = (Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.ejb.EJB\", CommonAnnotationBeanPostProcessor.class.getClassLoader()); ejbRefClass = clazz; &#125; catch (ClassNotFoundException ex) &#123; ejbRefClass = null; &#125; &#125; private final Set&lt;String&gt; ignoredResourceTypes = new HashSet&lt;String&gt;(1); private boolean fallbackToDefaultTypeMatch = true; private boolean alwaysUseJndiLookup = false; private transient BeanFactory jndiFactory = new SimpleJndiBeanFactory(); private transient BeanFactory resourceFactory; private transient BeanFactory beanFactory; private transient StringValueResolver embeddedValueResolver; private transient final Map&lt;String, InjectionMetadata&gt; injectionMetadataCache = new ConcurrentHashMap&lt;String, InjectionMetadata&gt;(256); /** * Create a new CommonAnnotationBeanPostProcessor, * with the init and destroy annotation types set to * &#123;@link javax.annotation.PostConstruct&#125; and &#123;@link javax.annotation.PreDestroy&#125;, * respectively. */ public CommonAnnotationBeanPostProcessor() &#123; setOrder(Ordered.LOWEST_PRECEDENCE - 3); setInitAnnotationType(PostConstruct.class); setDestroyAnnotationType(PreDestroy.class); ignoreResourceType(\"javax.xml.ws.WebServiceContext\"); &#125; ... 解析 此类实现了InstantiationAwareBeanPostProcessor接口，我们看看它是怎么实现的，果然和@Autowired注解注入的实现一样是将需要注入的属性封装成InjectionMetadata，然后调用inject(bean, beanName, pvs)进行注入 12345678910111213@Overridepublic PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; InjectionMetadata metadata = findResourceMetadata(beanName, bean.getClass(), pvs); try &#123; metadata.inject(bean, beanName, pvs); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Injection of resource dependencies failed\", ex); &#125; return pvs;&#125; 下面构造InjectionMetadata对象的逻辑也很简单，就是循环扫描成员变量及成员方法，如果扫到加了符合条件的注解就构造Element对象，我们这关心的是Resource注解修饰的成员被封装为ResourceElement对象了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091private InjectionMetadata buildResourceMetadata(final Class&lt;?&gt; clazz) &#123; LinkedList&lt;InjectionMetadata.InjectedElement&gt; elements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); Class&lt;?&gt; targetClass = clazz; do &#123; final LinkedList&lt;InjectionMetadata.InjectedElement&gt; currElements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); // 扫描成员变量注解 ReflectionUtils.doWithLocalFields(targetClass, new ReflectionUtils.FieldCallback() &#123; @Override public void doWith(Field field) throws IllegalArgumentException, IllegalAccessException &#123; if (webServiceRefClass != null &amp;&amp; field.isAnnotationPresent(webServiceRefClass)) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; throw new IllegalStateException(\"@WebServiceRef annotation is not supported on static fields\"); &#125; // WebService相关注解 currElements.add(new WebServiceRefElement(field, field, null)); &#125; else if (ejbRefClass != null &amp;&amp; field.isAnnotationPresent(ejbRefClass)) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; throw new IllegalStateException(\"@EJB annotation is not supported on static fields\"); &#125; // Ejb相关注解 currElements.add(new EjbRefElement(field, field, null)); &#125; else if (field.isAnnotationPresent(Resource.class)) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; throw new IllegalStateException(\"@Resource annotation is not supported on static fields\"); &#125; // Resource注解 if (!ignoredResourceTypes.contains(field.getType().getName())) &#123; currElements.add(new ResourceElement(field, field, null)); &#125; &#125; &#125; &#125;); // 扫描成员方法注解 ReflectionUtils.doWithLocalMethods(targetClass, new ReflectionUtils.MethodCallback() &#123; @Override public void doWith(Method method) throws IllegalArgumentException, IllegalAccessException &#123; Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method); if (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) &#123; return; &#125; if (method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) &#123; if (webServiceRefClass != null &amp;&amp; bridgedMethod.isAnnotationPresent(webServiceRefClass)) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; throw new IllegalStateException(\"@WebServiceRef annotation is not supported on static methods\"); &#125; if (method.getParameterTypes().length != 1) &#123; throw new IllegalStateException(\"@WebServiceRef annotation requires a single-arg method: \" + method); &#125; PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz); currElements.add(new WebServiceRefElement(method, bridgedMethod, pd)); &#125; else if (ejbRefClass != null &amp;&amp; bridgedMethod.isAnnotationPresent(ejbRefClass)) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; throw new IllegalStateException(\"@EJB annotation is not supported on static methods\"); &#125; if (method.getParameterTypes().length != 1) &#123; throw new IllegalStateException(\"@EJB annotation requires a single-arg method: \" + method); &#125; PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz); currElements.add(new EjbRefElement(method, bridgedMethod, pd)); &#125; else if (bridgedMethod.isAnnotationPresent(Resource.class)) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; throw new IllegalStateException(\"@Resource annotation is not supported on static methods\"); &#125; Class&lt;?&gt;[] paramTypes = method.getParameterTypes(); if (paramTypes.length != 1) &#123; throw new IllegalStateException(\"@Resource annotation requires a single-arg method: \" + method); &#125; if (!ignoredResourceTypes.contains(paramTypes[0].getName())) &#123; PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz); currElements.add(new ResourceElement(method, bridgedMethod, pd)); &#125; &#125; &#125; &#125; &#125;); elements.addAll(0, currElements); targetClass = targetClass.getSuperclass(); &#125; while (targetClass != null &amp;&amp; targetClass != Object.class); return new InjectionMetadata(clazz, elements);&#125; InjectionMetadata#inject(bean, beanName, pvs)方法上一章节也有所介绍 补充 @Resource注解和@Autowired注解的作用差不多，都可以完成依赖注入，但不同的是@Resource注解不是Spring的，而是JSR规范定义的注解，为什么要实现这个注解的注入了，我想这就是Spring包罗万象的做法 @Autowired和@Qualifier一起用，@Resource单独用。当然没有冲突的话@Autowired也可以单独用。值得注意的是Spring官方并不建议直接在类的field上使用@Autowired注解，参考《Why field injection is evil》 @Autowired和@Resource这两个注解是我们开发过程中经常使用的注解 @Autowired默认按类型装配，默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，例如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用 @Resource默认按名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 总结 参考 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(十)加载Bean之AbstractBeanFactory类createBean方法","slug":"backend/framework/spring/analysis/Spring系列(十)加载Bean之AbstractBeanFactory类createBean方法","date":"2019-06-18T14:00:46.000Z","updated":"2020-01-04T12:21:52.190Z","comments":true,"path":"2019/06/18/backend/framework/spring/analysis/Spring系列(十)加载Bean之AbstractBeanFactory类createBean方法/","link":"","permalink":"http://www.songshuiyang.com/2019/06/18/backend/framework/spring/analysis/Spring系列(十)加载Bean之AbstractBeanFactory类createBean方法/","excerpt":"","text":"前言 上一章节介绍了不同作用域下获取Bean的主体逻辑，这些作用域都调用了createBean(String beanName, RootBeanDefinition mbd, Object[] args)方法，这个是AbstractBeanFactory内定义的方法，默认实现是AbstractAutowireCapableBeanFactory，这个方法是创建bean实例的核心方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 创建bean实例的核心方法，填充bean实例 * Central method of this class: creates a bean instance, * populates the bean instance, applies post-processors, etc. * @see #doCreateBean */@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating instance of bean '\" + beanName + \"'\"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. // 锁定class，根据设置的class属性或者根据className来解析Class Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. // 对override属性进行标记及验证 try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 给BeanPostProcessors一个机会来返回代理来替代真正的实例 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); // 当经过前置处理后的返回结果如果不为空，那么会直接略过后续bean的创建二直接返回结果。这一特性虽然很容易被忽略，但是 // 却起着至关重要的作用，我们熟知的AOP功能就是基于这里的判断的 if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &#125; // 核心方法创建bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance;&#125; 上面有两个比较重要的方法，下面将详细介绍 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); Object beanInstance = doCreateBean(beanName, mbdToUse, args); 解析方法一 resolveBeforeInstantiation(…) 解析 查看注释可以得到这个方法是给给BeanPostProcessors一个机会来返回代理来替代真正的实例，注意这里bean还没有实例化还停留在BeanDefinition阶段 1234567891011try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 给BeanPostProcessors一个机会来返回代理来替代真正的实例 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); // 当经过前置处理后的返回结果如果不为空，那么会直接略过后续bean的创建二直接返回结果。这一特性虽然很容易被忽略，但是 // 却起着至关重要的作用 // 注意这里`bean`还没有实例化还停留在`BeanDefinition`阶段 if (bean != null) &#123; return bean; &#125;&#125; 进入Object bean = resolveBeforeInstantiation(beanName, mbdToUse);方法，下面代码可以看到主要逻辑就是循环执行InstantiationAwareBeanPostProcessor接口的postProcessBeforeInstantiation()方法，因为上一层方法会直接return，如果能得到结果然后执行BeanPostProcessor实例化后的后处理器应用方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 在bean实例化之前偷天换日 * @see InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation * * Apply before-instantiation post-processors, resolving whether there is a * before-instantiation shortcut for the specified bean. * @param beanName the name of the bean * @param mbd the bean definition for the bean * @return the shortcut-determined bean instance, or &#123;@code null&#125; if none */protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; // 如果尚未被解析 if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // Make sure bean class is actually resolved at this point. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); if (targetType != null) &#123; // 实例化前的后处理器应用 调用postProcessBeforeInstantiation，给一个子类一个修改BeanDefinition的机会 // 当经过这个方法后，bean可能已经不是我们认为的bean了，而是或许成为了一个经过处理的代理bean，可能是通过cglib生成的 bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); if (bean != null) &#123; // 实例化后的后处理器应用 方法二 调用postProcessAfterInitialization bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean;&#125;protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null;&#125; InstantiationAwareBeanPostProcessor接口也是继承BeanPostProcessor，说明他也是Bean的生命周期的一个钩子，BeanPostProcessor接口定义的方法都是实例化后的执行的方法，InstantiationAwareBeanPostProcessor接口在它的基础上添加了对象未实例化之前调用方法，该方法的返回值类型是Object，我们可以返回任何类型的值。由于这个时候目标对象还未实例化，所以这个返回值可以用来代替原本该生成的目标对象的实例。如果该方法的返回值代替原本该生成的目标对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * * 主要作用在于目标对象的实例化过程中需要处理的事情，包括实例化对象的前后过程以及实例的属性设置 * * Subinterface of &#123;@link BeanPostProcessor&#125; that adds a before-instantiation callback, * and a callback after instantiation but before explicit properties are set or * autowiring occurs. * * &lt;p&gt;Typically used to suppress default instantiation for specific target beans, * for example to create proxies with special TargetSources (pooling targets, * lazily initializing targets, etc), or to implement additional injection strategies * such as field injection. * * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; This interface is a special purpose interface, mainly for * internal use within the framework. It is recommended to implement the plain * &#123;@link BeanPostProcessor&#125; interface as far as possible, or to derive from * &#123;@link InstantiationAwareBeanPostProcessorAdapter&#125; in order to be shielded * from extensions to this interface. * * @author Juergen Hoeller * @author Rod Johnson * @since 1.2 * @see org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#setCustomTargetSourceCreators * @see org.springframework.aop.framework.autoproxy.target.LazyInitTargetSourceCreator */public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; /** * 是最先执行的方法，它在目标对象实例化之前调用，该方法的返回值类型是Object，我们可以返回任何类型的值。 * 由于这个时候目标对象还未实例化，所以这个返回值可以用来代替原本该生成的目标对象的实例(比如AOP代理对象)。 * 如果该方法的返回值代替原本该生成的目标对象， * * Apply this BeanPostProcessor &lt;i&gt;before the target bean gets instantiated&lt;/i&gt;. * The returned bean object may be a proxy to use instead of the target bean, * effectively suppressing default instantiation of the target bean. * &lt;p&gt;If a non-null object is returned by this method, the bean creation process * will be short-circuited. The only further processing applied is the * &#123;@link #postProcessAfterInitialization&#125; callback from the configured * &#123;@link BeanPostProcessor BeanPostProcessors&#125;. * &lt;p&gt;This callback will only be applied to bean definitions with a bean class. * In particular, it will not be applied to beans with a \"factory-method\". * &lt;p&gt;Post-processors may implement the extended * &#123;@link SmartInstantiationAwareBeanPostProcessor&#125; interface in order * to predict the type of the bean object that they are going to return here. * @param beanClass the class of the bean to be instantiated * @param beanName the name of the bean * @return the bean object to expose instead of a default instance of the target bean, * or &#123;@code null&#125; to proceed with default instantiation * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.support.AbstractBeanDefinition#hasBeanClass * @see org.springframework.beans.factory.support.AbstractBeanDefinition#getFactoryMethodName */ Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException; /** * 在目标对象实例化之后调用，这个时候对象已经被实例化，但是该实例的属性还未被设置都是null，要通过下面那个方法 * * * Perform operations after the bean has been instantiated, via a constructor or factory method, * but before Spring property population (from explicit properties or autowiring) occurs. * &lt;p&gt;This is the ideal callback for performing custom field injection on the given bean * instance, right before Spring's autowiring kicks in. * @param bean the bean instance created, with properties not having been set yet * @param beanName the name of the bean * @return &#123;@code true&#125; if properties should be set on the bean; &#123;@code false&#125; * if property population should be skipped. Normal implementations should return &#123;@code true&#125;. * Returning &#123;@code false&#125; will also prevent any subsequent InstantiationAwareBeanPostProcessor * instances being invoked on this bean instance. * @throws org.springframework.beans.BeansException in case of errors */ boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException; /** * 对属性值进行修改(这个时候属性值还未被设置，但是我们可以修改原本该设置进去的属性值)。 * 如果 &#123;@link #postProcessAfterInstantiation(java.lang.Object, java.lang.String)&#125;方法返回false，该方法可能不会被调用。可以在该方法内对属性值进行修改 * * Post-process the given property values before the factory applies them * to the given bean. Allows for checking whether all dependencies have been * satisfied, for example based on a \"Required\" annotation on bean property setters. * &lt;p&gt;Also allows for replacing the property values to apply, typically through * creating a new MutablePropertyValues instance based on the original PropertyValues, * adding or removing specific values. * @param pvs the property values that the factory is about to apply (never &#123;@code null&#125;) * @param pds the relevant property descriptors for the target bean (with ignored * dependency types - which the factory handles specifically - already filtered out) * @param bean the bean instance created, but whose properties have not yet been set * @param beanName the name of the bean * @return the actual property values to apply to the given bean * (can be the passed-in PropertyValues instance), or &#123;@code null&#125; * to skip property population * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.MutablePropertyValues */ PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException;&#125; 方法二 doCreateBean(…) 解析 Object beanInstance = doCreateBean(beanName, mbdToUse, args); 这个方法是核心方法，又是个do开头的方法 该方法接受三个方法参数 bean 的名字 已经合并了父类属性的（如果有的话）BeanDefinition 对象。 用于构造函数或者工厂方法创建 Bean 实例对象的参数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145/** * Actually create the specified bean. Pre-creation processing has already happened * at this point, e.g. checking &#123;@code postProcessBeforeInstantiation&#125; callbacks. * &lt;p&gt;Differentiates between default bean instantiation, use of a * factory method, and autowiring a constructor. * @param beanName the name of the bean * @param mbd the merged bean definition for the bean * @param args explicit arguments to use for constructor or factory method invocation * @return a new instance of the bean * @throws BeanCreationException if the bean could not be created * @see #instantiateBean * @see #instantiateUsingFactoryMethod * @see #autowireConstructor */protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // Instantiate the bean. // BeanWrapper 是对 Bean 的包装，其接口中所定义的功能很简单包括设置获取被包装的对象，获取被包装 bean 的属性描述器 BeanWrapper instanceWrapper = null; // 单例模型，则从未完成的 FactoryBean 缓存中删除 if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; // 开始三步走： // 一：创建对象了 实例化 `bean` 根据指定的bean使用对应的策略创新新的实例，如：工厂方法、构造函数自动注入、简单初始化 if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; // 包装的实例对象 final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null); // 包装的实例对象的类型 Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null); mbd.resolvedTargetType = beanType; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; // 判断是否有后置处理，如果有后置处理，则允许后置处理修改 BeanDefinition if (!mbd.postProcessed) &#123; try &#123; // 应用MergedBeanDefinitionPostProcessors applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. /** * 是否需要提早曝光：单例&amp;允许循环依赖&amp;当前bean正在创建中，检测循环依赖 * * Spring处理循环依赖的解决方法： * 在B中创建依赖A时是通过ObjectFactory提供的实例化方法来中断A中的属性填充，使B中持有的A仅仅是刚初始化并 * 没有填充任何属性的A，而这正初始化A的步骤还是在最开始创建A的时候进行的，但是因为A与B中A所表示的属性地址 * 是一样的，所以在A中创建好的属性填充可以通过B中的A获取，这样就解决了循环依赖的问题 */ boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); &#125; // 为避免后期循环依赖，可以在bean初始化完成前将创建实例的ObjectFactory加入工厂 addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; // 对bean再一次依赖引用，主要应用于SmartInstantiationAware BeanPostProcessor // 其中我们熟知的AOP就是在这里将advice动态织入bean中，若没有直接返回bean，不做任何处理 return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; // 二：属性填充了 // Initialize the bean instance. Object exposedObject = bean; try &#123; // 对bean进行填充，将各个属性值注入，其中，可能存在依赖于其他bean的属性，则会递归初始依赖bean populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; // 三：初始化了 调用初始化方法 比如init-method exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); &#125; &#125; // 循环依赖处理 if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); // 只有在存在循环依赖的情况下，earlySingletonReference 才不会为空 if (earlySingletonReference != null) &#123; // 如果 exposedObject 没有在初始化方法中被改变，也就是没有被增强 if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; // 处理依赖 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" + \"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\"); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; // 根据scope注册bean registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); &#125; return exposedObject;&#125; 这个方法主要用于完成 bean 的创建和初始化工作，我们可以将其分为一下几个过程： createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) 方法，实例化 bean 。 populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法，进行属性填充。 initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，初始化 Bean 。 1、 createBeanInstance(…) 实例化 bean12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * Create a new instance for the specified bean, using an appropriate instantiation strategy: * factory method, constructor autowiring, or simple instantiation. * @param beanName the name of the bean * @param mbd the bean definition for the bean * @param args explicit arguments to use for constructor or factory method invocation * @return BeanWrapper for the new instance * @see #instantiateUsingFactoryMethod * @see #autowireConstructor * @see #instantiateBean */protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123; // Make sure bean class is actually resolved at this point. // 解析 bean ，将 bean 类名解析为 class 引用。 Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName()); &#125; // 如果工厂方法不为空则使用工厂方法初始化策略 if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // Shortcut when re-creating the same bean... boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; // 一个类有多个构造函数，每个构造函数都有不同的参数，所以调用前需要先更具参数锁定构造函数或对应的工厂方法 if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; // 如果已经解析过则使用解析好的构造函数方法不需要再次锁定 if (resolved) &#123; if (autowireNecessary) &#123; // 构造函数自动注入 return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; // 使用默认构造函数构造 return instantiateBean(beanName, mbd); &#125; &#125; // Need to determine the constructor... // 需根据参数解析构造函数 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; // 构造函数自动注入 return autowireConstructor(beanName, mbd, ctors, args); &#125; // No special handling: simply use no-arg constructor. // 使用默认构造函数构造 return instantiateBean(beanName, mbd);&#125; createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) 方法，用于实例化 Bean 对象。它会根据不同情况，选择不同的实例化策略来完成 Bean 的初始化，主要包括 1.1 工厂方法初始化：instantiateUsingFactoryMethod(String beanName, RootBeanDefinition mbd, @Nullable Object[] explicitArgs) 方法。 如果存在工厂方法，则调用此工厂方法完成 bean 的初始化工作 1.2 构造函数自动注入初始化：autowireConstructor(final String beanName, final RootBeanDefinition mbd, Constructor&lt;?&gt;[] chosenCtors, final Object[] explicitArgs) 方法。 这个初始化方法，我们可以简单理解为是带有参数的构造方法，来初始化 bean 对象。 主要是因为构造函数和构造参数的不确定性，Spring 需要花大量的精力来确定构造函数和构造参数，所以比较复杂 1.3 默认构造函数初始化：instantiateBean(final String beanName, final RootBeanDefinition mbd) 方法。 它没有参数，所以不需要确认经过复杂的过来来确定构造器、构造参数 进入getInstantiationStrategy().instantiate(mbd, beanName, parent); 方法，从下面的代码可以得到默认构造函数的初始化比上面的情况更为简单，如果没有什么特殊的直接反射得到ctor.newInstance(args)实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Overridepublic Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) &#123; // Don't override the class with CGLIB if no overrides. // 用户没有使用replace或者lookup的配置方法，那么直接使用反射的方式创建实例 if (bd.getMethodOverrides().isEmpty()) &#123; Constructor&lt;?&gt; constructorToUse; synchronized (bd.constructorArgumentLock) &#123; constructorToUse = (Constructor&lt;?&gt;) bd.resolvedConstructorOrFactoryMethod; if (constructorToUse == null) &#123; final Class&lt;?&gt; clazz = bd.getBeanClass(); if (clazz.isInterface()) &#123; throw new BeanInstantiationException(clazz, \"Specified class is an interface\"); &#125; try &#123; if (System.getSecurityManager() != null) &#123; constructorToUse = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Constructor&lt;?&gt;&gt;() &#123; @Override public Constructor&lt;?&gt; run() throws Exception &#123; return clazz.getDeclaredConstructor((Class[]) null); &#125; &#125;); &#125; else &#123; constructorToUse = clazz.getDeclaredConstructor((Class[]) null); &#125; bd.resolvedConstructorOrFactoryMethod = constructorToUse; &#125; catch (Throwable ex) &#123; throw new BeanInstantiationException(clazz, \"No default constructor found\", ex); &#125; &#125; &#125; // 实例化实体类 return BeanUtils.instantiateClass(constructorToUse); &#125; else &#123; // 需要将replace或者lookup这两个配置的功能（动态代理）切入进去 // Must generate CGLIB subclass. return instantiateWithMethodInjection(bd, beanName, owner); &#125;&#125; public static &lt;T&gt; T instantiateClass(Constructor&lt;T&gt; ctor, Object... args) throws BeanInstantiationException &#123; Assert.notNull(ctor, \"Constructor must not be null\"); try &#123; // 反射构造实例 ReflectionUtils.makeAccessible(ctor); return ctor.newInstance(args); &#125; catch (InstantiationException ex) &#123; throw new BeanInstantiationException(ctor, \"Is it an abstract class?\", ex); &#125; catch (IllegalAccessException ex) &#123; throw new BeanInstantiationException(ctor, \"Is the constructor accessible?\", ex); &#125; catch (IllegalArgumentException ex) &#123; throw new BeanInstantiationException(ctor, \"Illegal arguments for constructor\", ex); &#125; catch (InvocationTargetException ex) &#123; throw new BeanInstantiationException(ctor, \"Constructor threw exception\", ex.getTargetException()); &#125;&#125; 2、 populateBean(…) 进行属性填充，完成依赖注入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * Populate the bean instance in the given BeanWrapper with the property values * from the bean definition. * @param beanName the name of the bean * @param mbd the bean definition for the bean * @param bw BeanWrapper with bean instance */protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; PropertyValues pvs = mbd.getPropertyValues(); if (bw == null) &#123; if (!pvs.isEmpty()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); &#125; else &#123; // Skip property population phase for null instance. // 没有可填充的属性 return; &#125; &#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; /** * 给InstantiationAwareBeanPostProcessors最后一次机会在属性设置前来改变bean * 如：可以用来支持属性注入的类型 */ if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 返回值是否继续填充bean if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; // 终止后续的执行 if (!continueWithPropertyPopulation) &#123; return; &#125; if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; // 存入PropertyValues中 MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. // 根据名称自动注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. // 根据类型自动注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; // 后处理器已经初始化 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); // 需要依赖检查 boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; // PropertyValue值设置后，Spring会调用getBeanPostProcessor方法遍历Bean工厂中注册的所有InstantiationAwareBeanPostProcessor // 其中就包括AutowiredAnnotationBeanPostProcessor @Autowired注解就是在这里完成的注入 for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 对所有需要依赖检查的属性进行后处理 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; // 依赖检查。对应depends-on属性，3.0已废弃 checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; // 将属性应用到bean中 之前的操作是获取所有注入属性，但是获取到的属性是以PropertyValues形式存在的，并没有 // 应用到已经实例化的bean中，下面的方法就是做这个操作的 applyPropertyValues(beanName, mbd, bw, pvs);&#125; populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法，进行属性填充，这里是完成依赖注入的关键，根据上面的代码可以划分 1、获取PropertyValues pvs = mbd.getPropertyValues(); 已定义bean的属性值 比如之前配置的，下面就是userName属性 123&lt;bean class=\"org.springiframe.entity.User\"&gt; &lt;property name=\"userName\" value=\"shop\"/&gt;&lt;/bean&gt; 由下图可以看到已经获取了PropertyValues pvs属性值， 2、给InstantiationAwareBeanPostProcessors最后一次机会在属性设置前来改变bean 看代码可以看到是循环BeanPostProcessor，然后调用postProcessAfterInstantiation(Object bean, String beanName)方法 12345678910111213141516if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 返回值是否继续填充bean if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125;&#125;// 终止后续的执行if (!continueWithPropertyPopulation) &#123; return;&#125; 可以通过postProcessAfterInstantiation(Object bean, String beanName)的返回值来控制 Spring 是否继续进行属性填充。 3、判断自动注入的模式 根据名称自动注入autowireByName(beanName, mbd, bw, newPvs) TODO 根据类型自动注入autowireByType(beanName, mbd, bw, newPvs); TODO 4、依赖检查及依赖注入 @Autowired注解就是在这里完成的注入，遍历InstantiationAwareBeanPostProcessor执行postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName)方法 1234567891011121314151617181920212223242526// 后处理器已经初始化boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();// 需要依赖检查boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; // PropertyValue值设置后，Spring会调用getBeanPostProcessor方法遍历Bean工厂中注册的所有InstantiationAwareBeanPostProcessor // 其中就包括AutowiredAnnotationBeanPostProcessor @Autowired注解就是在这里完成的注入 for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 对所有需要依赖检查的属性进行后处理 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; // 依赖检查。对应depends-on属性，3.0已废弃 checkDependencies(beanName, mbd, filteredPds, pvs); &#125;&#125; 关注postProcessPropertyValues方法，这里是调用的InstantiationAwareBeanPostProcessor接口的方法，这个方法完成了依赖属性的注入，这个接口又是继承BeanPostProcessor，详细说明将在下一章介绍 populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法最后就是调用applyPropertyValues(）将属性应用到已经实例化的bean中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &#123; if (pvs == null || pvs.isEmpty()) &#123; return; &#125; MutablePropertyValues mpvs = null; List&lt;PropertyValue&gt; original; if (System.getSecurityManager() != null) &#123; if (bw instanceof BeanWrapperImpl) &#123; ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); &#125; &#125; if (pvs instanceof MutablePropertyValues) &#123; mpvs = (MutablePropertyValues) pvs; // 如果mpvs中的值已经被转化为对应的类型那么可以直接设置到beanwapper中 if (mpvs.isConverted()) &#123; // Shortcut: use the pre-converted values as-is. try &#123; bw.setPropertyValues(mpvs); return; &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Error setting property values\", ex); &#125; &#125; original = mpvs.getPropertyValueList(); &#125; else &#123; // 如果pvs并不是使用MutablePropertyValues封装的类型，那么直接使用原始的属性获取方法 original = Arrays.asList(pvs.getPropertyValues()); &#125; TypeConverter converter = getCustomTypeConverter(); if (converter == null) &#123; converter = bw; &#125; // 获取对应的解析器 BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // Create a deep copy, resolving any references for values. List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;PropertyValue&gt;(original.size()); boolean resolveNecessary = false; // 遍历属性，将属性转化为对应lei的对应属性的类型 for (PropertyValue pv : original) &#123; if (pv.isConverted()) &#123; deepCopy.add(pv); &#125; else &#123; String propertyName = pv.getName(); Object originalValue = pv.getValue(); // 调用 Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &#123; convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &#125; // Possibly store converted value in merged bean definition, // in order to avoid re-conversion for every created bean instance. if (resolvedValue == originalValue) &#123; if (convertible) &#123; pv.setConvertedValue(convertedValue); &#125; deepCopy.add(pv); &#125; else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123; pv.setConvertedValue(convertedValue); deepCopy.add(pv); &#125; else &#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &#125; &#125; &#125; if (mpvs != null &amp;&amp; !resolveNecessary) &#123; mpvs.setConverted(); &#125; // Set our (possibly massaged) deep copy. try &#123; bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Error setting property values\", ex); &#125;&#125; 3、 initializeBean(…) 初始化 bean 这个方法主要逻辑： 1、执行实现了 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware的Bean的接口方法 2、执行BeanPostProcessor的前置处理方法 3、执行用户自定义的init方法，有下面两种类型 1、InitializingBean接口afterPropertiesSet方法 2、bean 定义的init-method=&quot;&quot;方法 4、执行BeanPostProcessor的后置处理方法 1、会调用下面这些 AwareInterfaces 比如熟悉的 EnvironmentAware ApplicationContextAware @see org.springframework.context.support.ApplicationContextAwareProcessor#invokeAwareInterfaces(java.lang.Object) 2、TODO 其他的BeanPostProcessor还没发掘1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Initialize the given bean instance, applying factory callbacks * as well as init methods and bean post processors. * &lt;p&gt;Called from &#123;@link #createBean&#125; for traditionally defined beans, * and from &#123;@link #initializeBean&#125; for existing bean instances. * @param beanName the bean name in the factory (for debugging purposes) * @param bean the new bean instance we may need to initialize * @param mbd the bean definition that the bean was created with * (can also be &#123;@code null&#125;, if given an existing bean instance) * @return the initialized bean instance (potentially wrapped) * @see BeanNameAware * @see BeanClassLoaderAware * @see BeanFactoryAware * @see #applyBeanPostProcessorsBeforeInitialization * @see #invokeInitMethods * @see #applyBeanPostProcessorsAfterInitialization */protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 对特殊的bean处理 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware invokeAwareMethods(beanName, bean); &#125; /** * 开始三步走： * */ Object wrappedBean = bean; // 第一步： 执行BeanPostProcessor实例化后初始化前处理方法 org.springframework.beans.factory.config.BeanPostProcessor.postProcessBeforeInitialization if (mbd == null || !mbd.isSynthetic()) &#123; // 方法调用前处理方法 /** * 1、会调用下面这些 AwareInterfaces 比如熟悉的 EnvironmentAware ApplicationContextAware * @see org.springframework.context.support.ApplicationContextAwareProcessor#invokeAwareInterfaces(java.lang.Object) * 2、TODO 其他的BeanPostProcessor还没发掘 */ wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 第二步核心：激活用户自定义的init方法 1、InitializingBean接口afterPropertiesSet方法 2、bean 定义的init-method=\"\"方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; // 第三步： 执行BeanPostProcessor实例化后初始化后处理方法 org.springframework.beans.factory.config.BeanPostProcessor.postProcessAfterInitialization if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 将属性应用到已经实例化的bean中applyPropertyValues(beanName, mbd, bw, pvs);，上面只是完成了所有注入属性的获取，将获取的属性封装在 PropertyValues 的实例对象 pvs 中，并没有应用到已经实例化的 bean 中 总结 Object beanInstance = createBean(beanName, mbdToUse, args); 这个方法是核心方法，所有的bean实例的创建，都会委托给该方法实现。 doCreateBean(...) 方法，主要用于完成 bean 的创建和初始化工作，我们可以将其分为一下几个过程： createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) 方法，实例化 bean 。 涉及到下面处理 Constructor.newInstance(args)或者工厂方法来构造对象 populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) 方法，进行属性填充。 涉及到下面接口 InstantiationAwareBeanPostProcessor的#postProcessAfterInstantiation及postProcessPropertyValues 方法，我们使用@Autowired注解是实现就是在这里完成的 initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) 方法，初始化 Bean 。 涉及到下面接口 调用BeanNameAware、BeanClassLoaderAware、BeanFactoryAware（这个是不是很常用）接口方法 调用BeanPostProcessor#postProcessBeforeInitialization() 调用InitializingBean接口afterPropertiesSet方法 、bean 定义的init-method=&quot;&quot;方法 看到上面是不是看到了Spring设计思想的套路了，我在创建对象的过程节点中提供各种各样的接口给你，实现这些接口我就能帮你处理处理一些事情 下面这张图是从其他地方抄过来的getBean 的全流程，画的很详细 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(九)加载Bean之不同作用域下获取Bean","slug":"backend/framework/spring/analysis/Spring系列(九)加载Bean之不同作用域下获取Bean","date":"2019-06-17T15:00:46.000Z","updated":"2020-01-04T12:21:52.148Z","comments":true,"path":"2019/06/17/backend/framework/spring/analysis/Spring系列(九)加载Bean之不同作用域下获取Bean/","link":"","permalink":"http://www.songshuiyang.com/2019/06/17/backend/framework/spring/analysis/Spring系列(九)加载Bean之不同作用域下获取Bean/","excerpt":"","text":"前言 上一章节介绍了从单例缓存中获取单例 Bean，这一章节来介绍不从缓存中获取单例Bean的过程，也就是下面的else分支的代码语句，什么时候会走到else呢，一种情况是该 Bean 的 scope 不是 singleton，另一种情况是该 Bean 的 scope 是 singleton 但是没有初始化完成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138Object sharedInstance = getSingleton(beanName);// 从缓存中获取 Bean 后，若其不为 null 且 args 为空if (sharedInstance != null &amp;&amp; args == null) &#123; ... 第八章已介绍 &#125;else &#123; // 在缓存中没有 // 只有单例情况下才会尝试解决循依赖（如果存在A中有B属性，B中有A属性，那么当依赖注入的时候，就会产生当A还未创建完的时候因为对于B的创建再次创建A，造成循环依赖） // 在原型模式下如果存在循环依赖则会抛出异常。 // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. // 判断工厂中是否含有此Bean的定义，如果没有找到则父类容器里找 BeanFactory parentBeanFactory = getParentBeanFactory(); // 如果beanDefinitionMap中也就是在所有已经加载的类中不包括beanName，则尝试从parentBeanFactory中检测 if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. 如果没有，查询父工厂 String nameToLookup = originalBeanName(name); // 递归到BeanFactory中寻找 递归调用getBean方法 if (args != null) &#123; // Delegation to parent with explicit args. 执行带有args参数的getbean方法 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. 如果没有参数，执行标准的getbean方法 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; // 如果不是仅仅做类型检查则是创建bean，这里要进行记录 if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; // 将存储XML配置文件的GernericBeanDefinition 转换为RootBeanDefinition， // 如果指定BeanName是子Bean的话同时会合并父类的相关属性 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 检查给定的合并的 BeanDefinition checkMergedBeanDefinition(mbd, beanName, args); // 处理所依赖的 bean // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); // 若存在依赖则需要递归实例化依赖的bean，在Spring的加载顺序中，在初始化某一个bean的时候首先会初始化这个bean所对应的依赖 if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; // 缓存依赖调用 registerDependentBean(dep, beanName); /** * 递归处理依赖 Bean * 每个 Bean 都不是单独工作的，它会依赖其他 Bean，其他 Bean 也会依赖它。 * 对于依赖的 Bean ，它会优先加载，所以，在 Spring 的加载顺序中，在初始化某一个 Bean 的时候，首先会初始化这个 Bean 的依赖。 */ getBean(dep); &#125; &#125; // Create bean instance. 重头戏 // 单例模式的实例化bean if (mbd.isSingleton()) &#123; // 获取实例了 sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; // 在getSingleton()方法会调用 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. // 显式从单例缓存中删除 Bean 实例，因为单例模式下为了解决循环依赖，可能他已经存在了，所以销毁它 destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // 原型模式的实例化bean else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; // 指定的scope上实例化bean String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125;&#125; 上面的代码可以分为如下部分： 1、原型模式下循环依赖检查，如果是则抛BeanCurrentlyInCreationException异常 在前面就提过，Spring 只解决单例模式下的循环依赖，对于原型模式的循环依赖则抛异常，单例模式下Spring是通过cache的形式提早曝光创建的对象来处理循环依赖的，但原型模式下的bean都是新建的，所以无法cache 检测逻辑和单例模式一样，一个“集合”存放着正在创建的 Bean ，从该集合中进行判断即可，只不过单例模式下的“集合”为 Set ，而原型模式的则是 ThreadLocal 代码 123456789101112/** Names of beans that are currently in creation */private final ThreadLocal&lt;Object&gt; prototypesCurrentlyInCreation = new NamedThreadLocal&lt;Object&gt;(\"Prototype beans currently in creation\"); if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName);&#125; protected boolean isPrototypeCurrentlyInCreation(String beanName) &#123; Object curVal = this.prototypesCurrentlyInCreation.get(); return (curVal != null &amp;&amp; (curVal.equals(beanName) || (curVal instanceof Set &amp;&amp; ((Set&lt;?&gt;) curVal).contains(beanName))));&#125; 2、判断工厂中是否含有此Bean的定义，如果没有找到则父类容器里找 递归到BeanFactory中寻找 递归调用getBean方法 代码1234567891011121314151617// Check if bean definition exists in this factory.// 判断工厂中是否含有此Bean的定义，如果没有找到则父类容器里找BeanFactory parentBeanFactory = getParentBeanFactory();// 如果beanDefinitionMap中也就是在所有已经加载的类中不包括beanName，则尝试从parentBeanFactory中检测if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. 如果没有，查询父工厂 String nameToLookup = originalBeanName(name); // 递归到BeanFactory中寻找 递归调用getBean方法 if (args != null) &#123; // Delegation to parent with explicit args. 执行带有args参数的getbean方法 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. 如果没有参数，执行标准的getbean方法 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125;&#125; 3、获取RootBeanDefinition，若获取的 BeanDefinition 为子 BeanDefinition，则需要合并父类的相关属性 合并得到RootBeanDefinition 代码12345// 将存储XML配置文件的GernericBeanDefinition 转换为RootBeanDefinition，// 如果指定BeanName是子Bean的话同时会合并父类的相关属性final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);// 检查给定的合并的 BeanDefinitioncheckMergedBeanDefinition(mbd, beanName, args); 4、处理依赖，设及到depends-on属性 适用于表面上看起来两个bean之间没有使用属性之类的强连接的bean，但是两个bean又确实存在前后依赖关系的情况，使用了depends-on的时候，依赖他人的bean是先于被依赖bean销毁的 代码1234567891011121314151617181920// 处理所依赖的 bean// Guarantee initialization of beans that the current bean depends on.String[] dependsOn = mbd.getDependsOn();// 若存在依赖则需要递归实例化依赖的bean，在Spring的加载顺序中，在初始化某一个bean的时候首先会初始化这个bean所对应的依赖if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; // 缓存依赖调用 registerDependentBean(dep, beanName); /** * 递归处理依赖 Bean * 每个 Bean 都不是单独工作的，它会依赖其他 Bean，其他 Bean 也会依赖它。 * 对于依赖的 Bean ，它会优先加载，所以，在 Spring 的加载顺序中，在初始化某一个 Bean 的时候，首先会初始化这个 Bean 的依赖。 */ getBean(dep); &#125;&#125; 5、单例模式的实例化bean 6、原型模式的实例化bean 7、指定的scope上实例化bean解析 1、单例模式的实例化bean 单例模式的实例化bean的动作是在getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory)方法实现的，可以看到两个参数，一个beanName，第二个ObjectFactory的对象，可以看到是直接new了一个ObjectFactory，并重写了getObject()方法，转而调用createBean(beanName, mbd, args);方法 1234567891011121314151617181920212223// Create bean instance. 重头戏// 单例模式的实例化beanif (mbd.isSingleton()) &#123; // 获取实例了 sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; // 在getSingleton()方法会调用 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. // 显式从单例缓存中删除 Bean 实例，因为单例模式下为了解决循环依赖，可能他已经存在了，所以销毁它 destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125; 先进入getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory)方法，可以看到先是从private final Map&lt;String, Object&gt; singletonObjects对象中获取bean，如果没有获取到就是通过singletonFactory.getObject(); 来获取bean 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Return the (raw) singleton object registered under the given name, * creating and registering a new one if none registered yet. * @param beanName the name of the bean * @param singletonFactory the ObjectFactory to lazily create the singleton * with, if necessary * @return the registered singleton object */public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"'beanName' must not be null\"); // 全局变量需要同步 synchronized (this.singletonObjects) &#123; // 首先检查对应的bean是否已经加载过，因为singleton模式其实就是复用以创建的bean。所以这一步是必须的 Object singletonObject = this.singletonObjects.get(beanName); // 如果未空才可以进行singleton的bean的初始化 if (singletonObject == null) &#123; if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, \"Singleton bean creation not allowed while singletons of this factory are in destruction \" + \"(Do not request a bean from a BeanFactory in a destroy method implementation!)\"); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating shared instance of singleton bean '\" + beanName + \"'\"); &#125; // 记录加载状态，将当前正要创建的bean记录在缓存中，这样便可以对循环依赖进行检测 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;Exception&gt;(); &#125; try &#123; // 真正获取单例 bean 的方法 singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch (IllegalStateException ex) &#123; // Has the singleton object implicitly appeared in the meantime -&gt; // if yes, proceed with it since the exception indicates that state. singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; throw ex; &#125; &#125; catch (BeanCreationException ex) &#123; if (recordSuppressedExceptions) &#123; for (Exception suppressedException : this.suppressedExceptions) &#123; ex.addRelatedCause(suppressedException); &#125; &#125; throw ex; &#125; finally &#123; if (recordSuppressedExceptions) &#123; this.suppressedExceptions = null; &#125; // 当bean加载结束后需要移除缓存中对该bean的正在加载状态的记录 afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; // 将结果记录至缓存并删除加载bean过程中所记录的各种辅助状态 addSingleton(beanName, singletonObject); &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null); &#125;&#125; beforeSingletonCreation(beanName); 记录正在创建的bean，使用了一个存放beanName的 Set集合，这样便可以对循环依赖进行检测 1234567891011121314151617/** * Names of beans that are currently in creation * * 记录bean的加载状态 ，在bean开始创建前会将beanName记录在属性中，创建结束会将该beanName从该属性中移除 */private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;String, Boolean&gt;(16));// 记录加载状态，将当前正要创建的bean记录在缓存中，这样便可以对循环依赖进行检测beforeSingletonCreation(beanName);protected void beforeSingletonCreation(String beanName) &#123; // 记录bean的加载状态 if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.add(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125;&#125; singletonObject = singletonFactory.getObject();是真正获取单例 bean 的方法，这个方法在外面AbstractAutowireCapableBeanFactory的createBean(beanName, mbd, args);实现，代码如下可以看到主要是有两个主体方法:1、Object bean = resolveBeforeInstantiation(beanName, mbdToUse); 、2、Object beanInstance = doCreateBean(beanName, mbdToUse, args); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 创建bean实例的核心方法，填充bean实例 * Central method of this class: creates a bean instance, * populates the bean instance, applies post-processors, etc. * @see #doCreateBean */@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating instance of bean '\" + beanName + \"'\"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. // 锁定class，根据设置的class属性或者根据className来解析Class Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. // 对override属性进行标记及验证 try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 给BeanPostProcessors一个机会来返回代理来替代真正的实例 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); // 当经过前置处理后的返回结果如果不为空，那么会直接略过后续bean的创建二直接返回结果。这一特性虽然很容易被忽略，但是 // 却起着至关重要的作用，我们熟知的AOP功能就是基于这里的判断的 if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &#125; // 创建bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance;&#125; 下面来讲解着两个方法 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); 这个方法是给InstantiationAwareBeanPostProcessor一个机会来返回代理来替代真正的实例，这个方法却起着至关重要的作用，我们熟知的AOP功能就是基于这里的判断的，如果不为空直接返回对应的代理类，InstantiationAwareBeanPostProcessor 接口之前也接触过一些，这个接口是定义bean初始化之和初始化之后分别调用的的方法 进入方法，可以看到主要功能是遍历List&lt;BeanPostProcessor&gt; beanPostProcessors，先执行bean初始化之前接口方法postProcessBeforeInstantiation，后执行bean初始化之后接口方法postProcessBeforeInstantiation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; // 如果尚未被解析 if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // Make sure bean class is actually resolved at this point. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); if (targetType != null) &#123; // 实例化前的后处理器应用 调用postProcessBeforeInstantiation，给一个子类一个修改BeanDefinition的机会 // 当经过这个方法后，bean可能已经不是我们认为的bean了，而是或许成为了一个经过处理的代理bean，可能是通过cglib生成的 bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); if (bean != null) &#123; // 实例化后的后处理器应用 方法二 调用postProcessAfterInitialization bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean;&#125; protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null;&#125; public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; // 实现 BeanPostProcessor 接口用户可以根据自己的业务需求进行响应的处理 for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessAfterInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result;&#125; Object beanInstance = doCreateBean(beanName, mbdToUse, args); 这个方法是创建bean的主体方法，篇幅较多所以放到下一章节 得到 Object singletonObject 之后 1、先是移除缓存中对该bean的正在加载状态的记录，与上面的beforeSingletonCreation(beanName)相对应 123456protected void afterSingletonCreation(String beanName) &#123; // 移除bean的加载状态 if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.remove(beanName)) &#123; throw new IllegalStateException(\"Singleton '\" + beanName + \"' isn't currently in creation\"); &#125;&#125; 2、存放到缓存中，可以看到将结果put到Map&lt;String, Object&gt; singletonObjects对象中并记录注册过的单例bean name 放到Set&lt;String&gt; registeredSingletons集合中，然后移除Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories及Map&lt;String, Object&gt; earlySingletonObjects缓存，最终结果:Map&lt;String, Object&gt; singletonObjects 123456789101112131415161718192021if (newSingleton) &#123; // 将结果记录至缓存并删除加载bean过程中所记录的各种辅助状态 addSingleton(beanName, singletonObject); &#125; /** * 将给定的singleton对象添加到此工厂的singleton缓存中。 * * Add the given singleton object to the singleton cache of this factory. * &lt;p&gt;To be called for eager registration of singletons. * @param beanName the name of the bean * @param singletonObject the singleton object */ protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, (singletonObject != null ? singletonObject : NULL_OBJECT)); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; 2、原型模式的实例化bean 上代码 12345678910111213141516// 原型模式的实例化beanelse if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; // 记录加载原型模式 bean 之前的加载状态前置处理 beforePrototypeCreation(beanName); // 直接调用createBean(beanName, mbd, args)创建新bean prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; // 删除原型模式 bean 之前的加载状态，后置处理 afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125; 原型模式下的初始化过程比较简单，与单例模式下的主要区别就是没有在缓存中获取，而是直接调用createBean(beanName, mbd, args)创建新bean，并在创建前记录原型模式下正在创建 bean，使用ThreadLocal&lt;Object&gt; prototypesCurrentlyInCreation进行存放，创建完成之后就销毁，这个变量在isPrototypeCurrentlyInCreation(beanName)方法中使用，检查是否是原型模式下存在循环依赖情况 3、指定的scope上实例化bean 上代码 1234567891011121314151617181920212223242526272829else &#123; // 指定的scope上实例化bean String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125;&#125; 核心流程和原型模式一样，只不过获取 bean 实例是由 Scope#get(String name, ObjectFactory&lt;?&gt; objectFactory) 方法来实现。 指定的scope上实例化bean，分为request（HTTP请求）、session（会话）、global-session（全局会话） 那么可以猜测新建的 bean 实例就是放到对应的request（HTTP请求）、session（会话）、global-session（全局会话）对象中 org.springframework.web.context.request.RequestScope 代码12345678910111213public class RequestScope extends AbstractRequestAttributesScope &#123; @Override protected int getScope() &#123; return RequestAttributes.SCOPE_REQUEST; &#125; @Override public String getConversationId() &#123; return null; &#125;&#125; org.springframework.web.context.request.SessionScope 代码12345678910111213141516171819202122232425262728293031323334353637383940public class SessionScope extends AbstractRequestAttributesScope &#123; private final int scope; public SessionScope() &#123; this.scope = RequestAttributes.SCOPE_SESSION; &#125; public SessionScope(boolean globalSession) &#123; this.scope = (globalSession ? RequestAttributes.SCOPE_GLOBAL_SESSION : RequestAttributes.SCOPE_SESSION); &#125; @Override protected int getScope() &#123; return this.scope; &#125; @Override public String getConversationId() &#123; return RequestContextHolder.currentRequestAttributes().getSessionId(); &#125; @Override public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) &#123; Object mutex = RequestContextHolder.currentRequestAttributes().getSessionMutex(); synchronized (mutex) &#123; return super.get(name, objectFactory); &#125; &#125; @Override public Object remove(String name) &#123; Object mutex = RequestContextHolder.currentRequestAttributes().getSessionMutex(); synchronized (mutex) &#123; return super.remove(name); &#125; &#125;&#125; AbstractRequestAttributesScope是上面两个类的抽象实现类，可以看到里面的操作是通过RequestContextHolder.currentRequestAttributes();来获取当前线程属性集合，之后的操作就是对属性进行get set了，并通过子类实现getScope()方法来区分不同的scope RequestScope就是将把Bean放到HttpServletRequest中，一个Request一个Bean SessionScope和上面同理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public abstract class AbstractRequestAttributesScope implements Scope &#123; @Override public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) &#123; // 获取当前线程属性集合 RequestAttributes attributes = RequestContextHolder.currentRequestAttributes(); Object scopedObject = attributes.getAttribute(name, getScope()); if (scopedObject == null) &#123; // 存放到RequestAttributes中 scopedObject = objectFactory.getObject(); attributes.setAttribute(name, scopedObject, getScope()); // Retrieve object again, registering it for implicit session attribute updates. // As a bonus, we also allow for potential decoration at the getAttribute level. Object retrievedObject = attributes.getAttribute(name, getScope()); if (retrievedObject != null) &#123; // Only proceed with retrieved object if still present (the expected case). // If it disappeared concurrently, we return our locally created instance. scopedObject = retrievedObject; &#125; &#125; // 获取到直接返回 return scopedObject; &#125; @Override public Object remove(String name) &#123; // 获取当前线程属性集合 RequestAttributes attributes = RequestContextHolder.currentRequestAttributes(); Object scopedObject = attributes.getAttribute(name, getScope()); if (scopedObject != null) &#123; // 从RequestAttributes中移除 attributes.removeAttribute(name, getScope()); return scopedObject; &#125; else &#123; return null; &#125; &#125; @Override public void registerDestructionCallback(String name, Runnable callback) &#123; RequestAttributes attributes = RequestContextHolder.currentRequestAttributes(); attributes.registerDestructionCallback(name, callback, getScope()); &#125; @Override public Object resolveContextualObject(String key) &#123; RequestAttributes attributes = RequestContextHolder.currentRequestAttributes(); return attributes.resolveReference(key); &#125; protected abstract int getScope(); &#125; 总结 单例模式的bean是通过一个HashMap缓存来实现的，原型模式下的bean都是每次新建调用的，指定scope模式下的bean是调用Scope接口的get方法来获取的 如果存在循环依赖的情况，单例模式下Spring是通过cache的形式提早曝光创建的对象来处理循环依赖的，但原型模式下的bean都是新建的，所以无法cache 由上面我们自己知道Spring bean作用域 singleton作用域通过缓存的机制来实现的 prototype作用域是每次都创建一个新的Bean request作用域是把Bean放到HttpServletRequest中，一个Request一个Bean session作用域把Bean的放到Session中 global-session作用域把Bean的放到Global Session中 此作用域仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(八)加载Bean之单例缓存中获取单例 Bean","slug":"backend/framework/spring/analysis/Spring系列(八)加载Bean之单例缓存中获取单例 Bean","date":"2019-06-12T15:00:46.000Z","updated":"2019-09-16T13:11:05.268Z","comments":true,"path":"2019/06/12/backend/framework/spring/analysis/Spring系列(八)加载Bean之单例缓存中获取单例 Bean/","link":"","permalink":"http://www.songshuiyang.com/2019/06/12/backend/framework/spring/analysis/Spring系列(八)加载Bean之单例缓存中获取单例 Bean/","excerpt":"","text":"前言 平常开发中我们知道Spring的Bean默认是单例模式，也就是说此Bean只会创建一次，然后每次调用都是获取的同一个Bean，那么Spring是怎么实现的呢？ 解析 回到上一章节的的doGetBean()方法，关注Object sharedInstance = getSingleton(beanName); 方法，sharedInstance 见名知意(共享实例)，这个方法是从缓存中获取 Bean 1234567891011121314151617181920212223242526/** * 检查缓存中或者实例工厂中是否有对应的实例，为什么首先会使用这段代码呢 * * 因为在创建单例bean的时候会存在依赖注入的情况，而在创建依赖的时候为了避免循环依赖 * Spring创建bean的原则是不等bean创建完成就会创建bean的ObjectFactory提早曝光也就是 * 将ObjectFactory加入缓存中，一旦下个bean创建的时候需要依赖上一个bean，则直接使用ObjectFactory */// Eagerly check singleton cache for manually registered singletons.Object sharedInstance = getSingleton(beanName);// 从缓存中获取 Bean 后，若其不为 null 且 args 为空if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &#125; else &#123; logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &#125; &#125; /** * 为什么会有这么一段呢？因为我们从缓存中获取的 bean 是最原始的 Bean ，并不一定使我们最终想要的 Bean * 返回对应的实例，有时候存在诸如BeanFactory的情况并不是直接返回实例本身而是返回指定方法返回的实例 比如工厂bean中定义的factory-method方法中返回的bean */ bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);&#125; 进入getSingleton(beanName)方法，总体逻辑，就是根据 beanNam 依次检测这三个 Map，若为空，从下一个，否则返回，singletonObjects -&gt; earlySingletonObjects -&gt; singletonFactories 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Cache of singleton objects: bean name --&gt; bean instance * 存放的是单例 bean 的映射 一级缓存 * */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);/** * Cache of singleton factories: bean name --&gt; ObjectFactory * 存放的是 ObjectFactory 三级缓存 * */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);/** Cache of early singleton objects: bean name --&gt; bean instance * 提前暴光的单例对象的Cache 二级缓存 * * 1、它与 &#123;@link #singletonFactories&#125; 区别在于 earlySingletonObjects 中存放的 bean 不一定是完整。 * 2、从 &#123;@link #getSingleton(String)&#125; 方法中，我们可以了解，bean 在创建过程中就已经加入到 earlySingletonObjects 中了。 * 所以当在 bean 的创建过程中，就可以通过 getBean() 方法获取。 * 3、这个 Map 也是【循环依赖】的关键所在。 * */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);/** * 根据 beanName 依次检测这三个 Map，若为空，检测下一个，否则返回 * &#123;@link org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#singletonObjects&#125; * &#123;@link org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#earlySingletonObjects&#125; * &#123;@link org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#singletonFactories&#125; * * Return the (raw) singleton object registered under the given name. * &lt;p&gt;Checks already instantiated singletons and also allows for an early * reference to a currently created singleton (resolving a circular reference). * @param beanName the name of the bean to look for * @param allowEarlyReference whether early references should be created or not * @return the registered singleton object, or &#123;@code null&#125; if none found */protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 从单例缓冲中加载 bean Object singletonObject = this.singletonObjects.get(beanName); /** * 缓存中的 bean 为空，且bean正在创建中 * 1、isSingletonCurrentlyInCreation 判断该 beanName 对应的 Bean 是否在创建过程中 * 查看private final Set&lt;String&gt; &#123;@link singletonsCurrentlyInCreation) 是否有，该set记录了正在创建bean的beanName */ if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 从 earlySingletonObjects 获取 singletonObject = this.earlySingletonObjects.get(beanName); // earlySingletonObjects 中没有，且允许提前创建 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 从 singletonFactories 中获取对应的 ObjectFactory ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125; 执行完getSingleton方法之后就是判断如果从缓存里获取到了singletonObjects且没有传入参数，那么就执行getObjectForBeanInstance(sharedInstance, name, beanName, null);方法了，该方法的定义为获取给定 Bean 实例的对象，该对象要么是 Bean 实例本身，要么就是 FactoryBean 创建的 Bean 对象。从下面的方法可以看到首先判断该实例是否实现了FactoryBean接口，如果不是那么直接返回该实例，下面的方法就是获取实现了FactoryBean接口的Bean实例了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 该方法的定义为获取给定 Bean 实例的对象，该对象要么是 bean 实例本身，要么就是 FactoryBean 创建的 Bean 对象。 * * Get the object for the given bean instance, either the bean * instance itself or its created object in case of a FactoryBean. * @param beanInstance the shared bean instance * @param name name that may include factory dereference prefix * @param beanName the canonical bean name * @param mbd the merged bean definition * @return the object to expose for the bean */protected Object getObjectForBeanInstance( Object beanInstance, String name, String beanName, RootBeanDefinition mbd) &#123; // 校验 beanInstance 的正确性 如果指定的name是工厂相关(以&amp;为前缀)且beanInstance又不是FactoryBean类型则验证不通过 // Don't let calling code try to dereference the factory if the bean isn't a factory. if (BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; !(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(transformedBeanName(name), beanInstance.getClass()); &#125; // 如果 beanInstance 不为 FactoryBean 类型或者 name 也不是与工厂相关的，则直接返回 beanInstance 这个 Bean 对象 // 如果是 FactoryBean，我们则创建该 Bean // Now we have the bean instance, which may be a normal bean or a FactoryBean. // If it's a FactoryBean, we use it to create a bean instance, unless the // caller actually wants a reference to the factory. if (!(beanInstance instanceof FactoryBean) || BeanFactoryUtils.isFactoryDereference(name)) &#123; return beanInstance; &#125; // 加载FactoryBean Object object = null; if (mbd == null) &#123; // 尝试从缓存中加载bean object = getCachedObjectForFactoryBean(beanName); &#125; // 若 object 依然为空，则可以确认，beanInstance 一定是 FactoryBean 。从而，使用 FactoryBean 获得 Bean 对象 if (object == null) &#123; // Return bean instance from factory. // 到这里已经明确知道beanInstance一定是FactoryBean类型 FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) beanInstance; // Caches object obtained from FactoryBean if it is a singleton. containsBeanDefinition 检测 beanDefinitionMap 中也就是在所有已经加载的类中 if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) &#123; mbd = getMergedLocalBeanDefinition(beanName); &#125; // 是否是用户定义的，而不是应用程序本身定义的 boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic()); // 核心代码，使用 FactoryBean 获得 Bean 对象 object = getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object;&#125; 使用 FactoryBean 获得 Bean 对象之前先来说明下FactoryBean一些概念 FactoryBean 解析 从下面代码可以看到这个接口只有三个方法，重点是getObject()方法 12345678public interface FactoryBean&lt;T&gt; &#123; T getObject() throws Exception; Class&lt;?&gt; getObjectType(); boolean isSingleton();&#125; 一般情况下，Spring通过反射机制利用&lt;bean&gt;的class属性指定实现类实例化Bean，在某些情况下，实例化Bean过程比较复杂，如果按照传统的方式，则需要在&lt;bean&gt;中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个org.springframework.bean.factory.FactoryBean的工厂类接口，用户可以通过实现该接口定制实例化Bean的逻辑。FactoryBean接口对于Spring框架来说占用重要的地位，Spring自身就提供了70多个FactoryBean的实现。 FactoryBean是一个接口，当在IOC容器中的Bean实现了FactoryBean后，通过getBean(String BeanName)获取到的Bean对象并不是FactoryBean的实现类对象，而是这个实现类中的getObject()方法返回的对象。要想获取FactoryBean的实现类，就要getBean(&amp;BeanName)，在BeanName之前加上&amp;。 由上面可以知道要获取 FactoryBean 实例直接调用getObject()方法就是了，继续跟进方法object = getObjectFromFactoryBean(factory, beanName, !synthetic);，此方法可以看到这里又做了个Map&lt;String, Object&gt; factoryBeanObjectCache缓存的处理，如果有就直接get，如果没有就new然后put 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Obtain an object to expose from the given FactoryBean. * @param factory the FactoryBean instance * @param beanName the name of the bean * @param shouldPostProcess whether the bean is subject to post-processing * @return the object obtained from the FactoryBean * @throws BeanCreationException if FactoryBean object creation failed * @see org.springframework.beans.factory.FactoryBean#getObject() */protected Object getObjectFromFactoryBean(FactoryBean&lt;?&gt; factory, String beanName, boolean shouldPostProcess) &#123; // 如果是单例模式且缓存中存在 if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) &#123; // 同步锁，锁住的对象都是 this.singletonObjects，主要是因为在单例模式中必须要保证全局唯一 synchronized (getSingletonMutex()) &#123; // 从缓存中获取指定的 factoryBean Object object = this.factoryBeanObjectCache.get(beanName); if (object == null) &#123; // 继续跟进，为空，则从 FactoryBean 中获取对象 object = doGetObjectFromFactoryBean(factory, beanName); // Only post-process and store if not put there already during getObject() call above // (e.g. because of circular reference processing triggered by custom getBean calls) Object alreadyThere = this.factoryBeanObjectCache.get(beanName); if (alreadyThere != null) &#123; object = alreadyThere; &#125; else &#123; if (object != null &amp;&amp; shouldPostProcess) &#123; try &#123; // 对从 FactoryBean 获取的对象进行后处理后处理器 object = postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's singleton object failed\", ex); &#125; &#125; // 添加到 factoryBeanObjectCache 中，进行缓存 this.factoryBeanObjectCache.put(beanName, (object != null ? object : NULL_OBJECT)); &#125; &#125; return (object != NULL_OBJECT ? object : null); &#125; &#125; else &#123; // 为空，则从 FactoryBean 中获取对象 Object object = doGetObjectFromFactoryBean(factory, beanName); // 需要后续处理 if (object != null &amp;&amp; shouldPostProcess) &#123; try &#123; // 对从 FactoryBean 获取的对象进行后处理后处理器 object = postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's object failed\", ex); &#125; &#125; return object; &#125;&#125; getObjectFromFactoryBean(factory, beanName, !synthetic) 功能点分析 object = doGetObjectFromFactoryBean(factory, beanName); 从 FactoryBean 中获取对象 看代码，这里是直接调用了object = factory.getObject();方法，是不是很简单123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 如果Bean实现了FactoryBean后，通过getBean(String BeanName) * 获取到的Bean对象并不是FactoryBean的实现类对象，而是这个实现类中的getObject()方法返回的对象。 * * Obtain an object to expose from the given FactoryBean. * @param factory the FactoryBean instance * @param beanName the name of the bean * @return the object obtained from the FactoryBean * @throws BeanCreationException if FactoryBean object creation failed * @see org.springframework.beans.factory.FactoryBean#getObject() */private Object doGetObjectFromFactoryBean(final FactoryBean&lt;?&gt; factory, final String beanName) throws BeanCreationException &#123; Object object; try &#123; // 需要权限验证 if (System.getSecurityManager() != null) &#123; AccessControlContext acc = getAccessControlContext(); try &#123; object = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123; @Override public Object run() throws Exception &#123; return factory.getObject(); &#125; &#125;, acc); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; // 直接调用getObject方法 object = factory.getObject(); &#125; &#125; catch (FactoryBeanNotInitializedException ex) &#123; throw new BeanCurrentlyInCreationException(beanName, ex.toString()); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"FactoryBean threw exception on object creation\", ex); &#125; // Do not accept a null value for a FactoryBean that's not fully // initialized yet: Many FactoryBeans just return null then. if (object == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException( beanName, \"FactoryBean which is currently in creation returned null from getObject\"); &#125; return object;&#125; object = postProcessObjectFromFactoryBean(object, beanName);对从 FactoryBean 获取的对象进行后处理后处理器 看代码，直接调用BeanPostProcessor的postProcessAfterInitialization方法，执行bean初始化后的方法逻辑1234567891011121314@Overridepublic Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; // 实现 BeanPostProcessor 接口用户可以根据自己的业务需求进行响应的处理 for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123; result = beanProcessor.postProcessAfterInitialization(result, beanName); if (result == null) &#123; return result; &#125; &#125; return result;&#125; 我们可以利用这个特性将bean实现BeanPostProcessor接口，实际开发过程中大可以利用这个方法设计自己的业务逻辑。 1234567891011/** * 定义bean初始化之和初始化之后分别调用的的方法 * * BeanFactory钩子，允许对新建的bean进行自定义修改，eg：检查是否有标记接口或者需要代理bean如果有的话做对应的操作 */public interface BeanPostProcessor &#123; Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 至此，从缓存中获取 Bean对象过程已经分析完毕了。 总结 Spring的单例bean是使用HashMap来实现的，用户可以通过实现FactoryBean接口定制实例化Bean的逻辑，又体现了Spring的灵活性 用户可以实现BeanPostProcessor接口进行业务定制化 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(七)加载Bean之doGetBean方法","slug":"backend/framework/spring/analysis/Spring系列(七)加载Bean之doGetBean方法","date":"2019-06-12T14:00:46.000Z","updated":"2020-01-04T12:21:52.139Z","comments":true,"path":"2019/06/12/backend/framework/spring/analysis/Spring系列(七)加载Bean之doGetBean方法/","link":"","permalink":"http://www.songshuiyang.com/2019/06/12/backend/framework/spring/analysis/Spring系列(七)加载Bean之doGetBean方法/","excerpt":"","text":"前言 经过容器初始化阶段后，应用程序中定义的 bean 信息（BeanDefinition ）已经全部加载到系统中了，当我们显示或者隐式地调用 BeanFactory#getBean(...) 方法时，则会触发加载 Bean 阶段。 在这阶段，容器会首先检查所请求的对象是否已经初始化完成了，如果没有，则会根据注册的 Bean 信息实例化请求的对象，并为其注册依赖，然后将其返回给请求方。 下面的章节将会介绍加载Bean的过程，仓库里有货了就应该让它发挥作用 解析 调用 BeanFactory#getBean(...) 方法 123456// AbstractBeanFactory.java@Overridepublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125; 内部调用 org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean(String name, final Class&lt;T&gt; requiredType, Object[] args, boolean typeCheckOnly) 下面是代码主体 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203/** * doGetBean统一入口 * * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve 要获取 Bean 的名字 * @param requiredType the required type of the bean to retrieve 要获取 bean 的类型 * @param args arguments to use when creating a bean instance using explicit arguments 创建 Bean 时传递的参数。这个参数仅限于创建 Bean 时使用。 * (only applied when creating a new instance as opposed to retrieving an existing one) * @param typeCheckOnly whether the instance is obtained for a type check, 是否为类型检查。 * not for actual use * @return an instance of the bean * @throws BeansException if the bean could not be created */@SuppressWarnings(\"unchecked\")protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; /** * 提取对应的beanName， 这里传递的是 name 方法，不一定就是 beanName，可能是 aliasName * 也有可能是 FactoryBean FactoryBean会带上&amp;符号， * 在BeanDefinition阶段时是通过 &#123;@link BeanDefinitionHolder#aliases&#125; 这个字段来向 &#123;@link SimpleAliasRegistry#aliasMap&#125; 注册别名信息的 */ final String beanName = transformedBeanName(name); Object bean; /** * 检查缓存中或者实例工厂中是否有对应的实例，为什么首先会使用这段代码呢 * * 因为在创建单例bean的时候会存在依赖注入的情况，而在创建依赖的时候为了避免循环依赖 * Spring创建bean的原则是不等bean创建完成就会创建bean的ObjectFactory提早曝光也就是 * 将ObjectFactory加入缓存中，一旦下个bean创建的时候需要依赖上一个bean，则直接使用ObjectFactory */ // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); // 从缓存中获取 Bean 后，若其不为 null 且 args 为空 if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &#125; else &#123; logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &#125; &#125; /** * 为什么会有这么一段呢？因为我们从缓存中获取的 bean 是最原始的 Bean ，并不一定使我们最终想要的 Bean * 返回对应的实例，有时候存在诸如BeanFactory的情况并不是直接返回实例本身而是返回指定方法返回的实例 比如工厂bean中定义的factory-method方法中返回的bean */ bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // 在缓存中没有 // 只有单例情况下才会尝试解决循依赖（如果存在A中有B属性，B中有A属性，那么当依赖注入的时候，就会产生当A还未创建完的时候因为对于B的创建再次创建A，造成循环依赖） // 在原型模式下如果存在循环依赖则会抛出异常。 // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. // 判断工厂中是否含有此Bean的定义，如果没有找到则父类容器里找 BeanFactory parentBeanFactory = getParentBeanFactory(); // 如果beanDefinitionMap中也就是在所有已经加载的类中不包括beanName，则尝试从parentBeanFactory中检测 if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. 如果没有，查询父工厂 String nameToLookup = originalBeanName(name); // 递归到BeanFactory中寻找 递归调用getBean方法 if (args != null) &#123; // Delegation to parent with explicit args. 执行带有args参数的getbean方法 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. 如果没有参数，执行标准的getbean方法 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; // 如果不是仅仅做类型检查则是创建bean，这里要进行记录 if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; // 将存储XML配置文件的GernericBeanDefinition 转换为RootBeanDefinition， // 如果指定BeanName是子Bean的话同时会合并父类的相关属性 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 检查给定的合并的 BeanDefinition checkMergedBeanDefinition(mbd, beanName, args); // 处理所依赖的 bean // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); // 若存在依赖则需要递归实例化依赖的bean，在Spring的加载顺序中，在初始化某一个bean的时候首先会初始化这个bean所对应的依赖 if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; // 缓存依赖调用 registerDependentBean(dep, beanName); /** * 递归处理依赖 Bean * 每个 Bean 都不是单独工作的，它会依赖其他 Bean，其他 Bean 也会依赖它。 * 对于依赖的 Bean ，它会优先加载，所以，在 Spring 的加载顺序中，在初始化某一个 Bean 的时候，首先会初始化这个 Bean 的依赖。 */ getBean(dep); &#125; &#125; // Create bean instance. 重头戏 // 单例模式的实例化bean if (mbd.isSingleton()) &#123; // 获取实例了 sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; // 创建bean return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. // 显式从单例缓存中删除 Bean 实例，因为单例模式下为了解决循环依赖，可能他已经存在了，所以销毁它 destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // 原型模式的实例化bean else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; // 指定的scope上实例化bean String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; /** * 检查需要的类型是否符合bean的实际类型 Check if required type matches the type of the actual bean instance. * 当然就一般而言，我们是不需要进行类型转换的，也就是 requiredType 为空（比如 #getBean(String name) 方法）。 * 但有，可能会存在这种情况，比如我们返回的 Bean 类型为 String ，我们在使用的时候需要将其转换为 Integer， * 那么这个时候 requiredType 就有用武之地了。当然我们一般是不需要这样做的。 */ if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; try &#123; // 执行转换 return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Failed to convert bean '\" + name + \"' to required type '\" + ClassUtils.getQualifiedName(requiredType) + \"'\", ex); &#125; // 转换失败，抛出 BeanNotOfRequiredTypeException 异常 throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean;&#125; 总结 上面BeanFactory#getBean(...) 方法是获取Bean的主要逻辑，下面的章节将详细介绍他们 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(六)装载BeanDefinition总结","slug":"backend/framework/spring/analysis/Spring系列(六)装载BeanDefinition总结","date":"2019-06-11T14:00:46.000Z","updated":"2020-01-04T12:21:52.185Z","comments":true,"path":"2019/06/11/backend/framework/spring/analysis/Spring系列(六)装载BeanDefinition总结/","link":"","permalink":"http://www.songshuiyang.com/2019/06/11/backend/framework/spring/analysis/Spring系列(六)装载BeanDefinition总结/","excerpt":"","text":"前言 调试代码 1234567public class ClassPathXmlApplicationContextTest &#123; @Test public void classPathXmlApplicationContext () &#123; ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(\"beans/bean.xml\"); User user = xmlApplicationContext.getBean(User.class); &#125;&#125; 前面的第二节到第五节分析了 IoC BeanDefinition 装载的整个过程，这篇就这些内容做一个总结将其连贯起来。IoC 容器的初始化过程分为三步骤Resource 定位、BeanDefinition 的装载，BeanDefinition解析及注册。 Resource 定位 我们一般用外部资源来描述 Bean 对象，所以在初始化 IoC 容器的第一步就是需要定位这个外部资源。 上面的调试代码new ClassPathXmlApplicationContext(&quot;beans/bean.xml&quot;);中我们传入了配置文件的一个路径，然后Spring就是通过这个路径使用ResourceLoader来找到对应的Resource 123456789101112public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // Resource pattern matching available. try &#123; // 通过`ResourceLoader`来用这个路径找到对应的`Resource` Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); BeanDefinition 的装载 上一步已经得到了Resource了，现在就是装载，这个过程使用XmlBeanDefinitionReader来完成解析，可以看到InputStream inputStream = encodedResource.getResource().getInputStream(); 通过Resource对象直接获取到了InputStream，这个InputStream我们很熟悉，就是读取文件使用的输入流类 1234567891011121314151617181920212223242526public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Loading XML bean definitions from \" + encodedResource.getResource()); &#125; // 通过属性来记录已经加载的资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &#125; try &#123; // 获取输入流 InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; // 构造 InputSource ，此类不是Spring的类 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 逻辑核心部分 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); 得到InputStream之后就是解析了，就是这个方法doLoadBeanDefinitions(inputSource, encodedResource.getResource());来获取到Document doc对象，这个是要下一步需要 BeanDefinition 解析及注册。解析 上一步已经得到了Document doc，现在就是需要将它解析得到BeanDefinition，这个工作由 BeanDefinitionDocumentReader来实现 注册 在 IoC 容器内部维护着一个 BeanDefinition Map 的数据结构，这里的IoC 容器是DefaultListableBeanFactory，在配置文件中每一个bean都对应着一个 BeanDefinition 对象，注册工作就是将BeanDefinition put到容器的map中，这个过程是通过 BeanDefinitionRegistry 接口来实现的。,DefaultListableBeanFactory实现了这个接口 12345678910111213141516171819202122232425262728// DefaultListableBeanFactory.java@Overridepublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; // ...省略校验相关的代码 // 从缓存中获取指定 beanName 的 BeanDefinition BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName); // 如果已经存在 if (existingDefinition != null) &#123; // 如果存在但是不允许覆盖，抛出异常 if (!isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition); &#125; else &#123; // ...省略 logger 打印日志相关的代码 &#125; // 【重点】允许覆盖，直接覆盖原有的 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); // 如果未存在 &#125; else &#123; // ... 省略非核心的代码 // 【重点】添加到 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); &#125; // 重新设置 beanName 对应的缓存 if (existingDefinition != null || containsSingleton(beanName)) &#123; resetBeanDefinition(beanName); &#125;&#125; 在 IoC 容器内部其实是将解析得到的 BeanDefinition 注入到一个HashMap 容器中，IoC 容器就是通过这个 HashMap 来维护这些 BeanDefinition 的。 总结 在这里需要注意的一点是这个过程并没有完成依赖注入Bean创建），Bean 创建是发生在应用第一次调用 #getBean(...) 方法，向容器索要 Bean 时。当然我们可以通过设置预处理，即对某个 Bean 设置 lazyinit = false 属性，那么这个 Bean 的依赖注入就会在容器初始化的时候完成。 整体时序图如下: 红框部分，就是 BeanDefinition 的解析过程 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(五)Document读取器BeanDefinitionDocumentReader","slug":"backend/framework/spring/analysis/Spring系列(五)Document读取器BeanDefinitionDocumentReader","date":"2019-06-09T08:00:46.000Z","updated":"2020-01-04T12:21:52.172Z","comments":true,"path":"2019/06/09/backend/framework/spring/analysis/Spring系列(五)Document读取器BeanDefinitionDocumentReader/","link":"","permalink":"http://www.songshuiyang.com/2019/06/09/backend/framework/spring/analysis/Spring系列(五)Document读取器BeanDefinitionDocumentReader/","excerpt":"","text":"前言 回顾上一章节的内容，在XmlBeanDefinitionReader中已经获取了Document doc，那么需要将Document doc对象解析成BeanDefinition，这里Document读取器BeanDefinitionDocumentReader就开始上场表演了 123456789101112131415161718192021222324252627/** * Register the bean definitions contained in the given DOM document. * Called by &#123;@code loadBeanDefinitions&#125;. * &lt;p&gt;Creates a new instance of the parser class and invokes * &#123;@code registerBeanDefinitions&#125; on it. * @param doc the DOM document * @param resource the resource descriptor (for context information) * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of parsing errors * @see #loadBeanDefinitions * @see #setDocumentReaderClass * @see BeanDefinitionDocumentReader#registerBeanDefinitions */public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; /** * 使用DefaultBeanDefinitionDocumentReader实例化BeanDefinitionDocumentReader，在实例化BeanDefinitionDocumentReader的时候会将 * * @see DefaultBeanDefinitionDocumentReader * */ BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); // 记录统计前的BeanDefinition的加载个数 int countBefore = getRegistry().getBeanDefinitionCount(); // 加载并注册bean documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();这里获取的是DefaultBeanDefinitionDocumentReader类，此类是BeanDefinitionDocumentReader接口的唯一实现类 createReaderContext(resource) 方法将我们的上一章节XmlBeanDefinitionReader对象放在了一个新的对象XmlReaderContext中，注意下面的this指针 1234567/** * Create the &#123;@link XmlReaderContext&#125; to pass over to the document reader. */public XmlReaderContext createReaderContext(Resource resource) &#123; return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver());&#125; BeanDefinitionDocumentReader定义了读取Document 并注册为BeanDefinition功能，里面只有一个方法void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) DefaultBeanDefinitionDocumentReader 属性：可以看到我们熟悉的xml配置标签名 123456789101112131415161718192021222324public class DefaultBeanDefinitionDocumentReader implements BeanDefinitionDocumentReader &#123; public static final String BEAN_ELEMENT = BeanDefinitionParserDelegate.BEAN_ELEMENT; public static final String NESTED_BEANS_ELEMENT = \"beans\"; public static final String ALIAS_ELEMENT = \"alias\"; public static final String NAME_ATTRIBUTE = \"name\"; public static final String ALIAS_ATTRIBUTE = \"alias\"; public static final String IMPORT_ELEMENT = \"import\"; public static final String RESOURCE_ATTRIBUTE = \"resource\"; public static final String PROFILE_ATTRIBUTE = \"profile\"; protected final Log logger = LogFactory.getLog(getClass()); private XmlReaderContext readerContext; private BeanDefinitionParserDelegate delegate; 上面可以看到里面有个BeanDefinitionParserDelegate类，这个类是BeanDefinition解析方法，里面是解析Element的各种方法，从成员变量中可以看到xml标签名及属性名 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169public class BeanDefinitionParserDelegate &#123; public static final String BEANS_NAMESPACE_URI = \"http://www.springframework.org/schema/beans\"; public static final String MULTI_VALUE_ATTRIBUTE_DELIMITERS = \",; \"; /** * Value of a T/F attribute that represents true. * Anything else represents false. Case seNsItive. */ public static final String TRUE_VALUE = \"true\"; public static final String FALSE_VALUE = \"false\"; public static final String DEFAULT_VALUE = \"default\"; public static final String DESCRIPTION_ELEMENT = \"description\"; public static final String AUTOWIRE_NO_VALUE = \"no\"; public static final String AUTOWIRE_BY_NAME_VALUE = \"byName\"; public static final String AUTOWIRE_BY_TYPE_VALUE = \"byType\"; public static final String AUTOWIRE_CONSTRUCTOR_VALUE = \"constructor\"; public static final String AUTOWIRE_AUTODETECT_VALUE = \"autodetect\"; public static final String DEPENDENCY_CHECK_ALL_ATTRIBUTE_VALUE = \"all\"; public static final String DEPENDENCY_CHECK_SIMPLE_ATTRIBUTE_VALUE = \"simple\"; public static final String DEPENDENCY_CHECK_OBJECTS_ATTRIBUTE_VALUE = \"objects\"; public static final String NAME_ATTRIBUTE = \"name\"; public static final String BEAN_ELEMENT = \"bean\"; public static final String META_ELEMENT = \"meta\"; public static final String ID_ATTRIBUTE = \"id\"; public static final String PARENT_ATTRIBUTE = \"parent\"; public static final String CLASS_ATTRIBUTE = \"class\"; public static final String ABSTRACT_ATTRIBUTE = \"abstract\"; public static final String SCOPE_ATTRIBUTE = \"scope\"; private static final String SINGLETON_ATTRIBUTE = \"singleton\"; public static final String LAZY_INIT_ATTRIBUTE = \"lazy-init\"; public static final String AUTOWIRE_ATTRIBUTE = \"autowire\"; public static final String AUTOWIRE_CANDIDATE_ATTRIBUTE = \"autowire-candidate\"; public static final String PRIMARY_ATTRIBUTE = \"primary\"; public static final String DEPENDENCY_CHECK_ATTRIBUTE = \"dependency-check\"; public static final String DEPENDS_ON_ATTRIBUTE = \"depends-on\"; public static final String INIT_METHOD_ATTRIBUTE = \"init-method\"; public static final String DESTROY_METHOD_ATTRIBUTE = \"destroy-method\"; public static final String FACTORY_METHOD_ATTRIBUTE = \"factory-method\"; public static final String FACTORY_BEAN_ATTRIBUTE = \"factory-bean\"; public static final String CONSTRUCTOR_ARG_ELEMENT = \"constructor-arg\"; public static final String INDEX_ATTRIBUTE = \"index\"; public static final String TYPE_ATTRIBUTE = \"type\"; public static final String VALUE_TYPE_ATTRIBUTE = \"value-type\"; public static final String KEY_TYPE_ATTRIBUTE = \"key-type\"; public static final String PROPERTY_ELEMENT = \"property\"; public static final String REF_ATTRIBUTE = \"ref\"; public static final String VALUE_ATTRIBUTE = \"value\"; public static final String LOOKUP_METHOD_ELEMENT = \"lookup-method\"; public static final String REPLACED_METHOD_ELEMENT = \"replaced-method\"; public static final String REPLACER_ATTRIBUTE = \"replacer\"; public static final String ARG_TYPE_ELEMENT = \"arg-type\"; public static final String ARG_TYPE_MATCH_ATTRIBUTE = \"match\"; public static final String REF_ELEMENT = \"ref\"; public static final String IDREF_ELEMENT = \"idref\"; public static final String BEAN_REF_ATTRIBUTE = \"bean\"; public static final String LOCAL_REF_ATTRIBUTE = \"local\"; public static final String PARENT_REF_ATTRIBUTE = \"parent\"; public static final String VALUE_ELEMENT = \"value\"; public static final String NULL_ELEMENT = \"null\"; public static final String ARRAY_ELEMENT = \"array\"; public static final String LIST_ELEMENT = \"list\"; public static final String SET_ELEMENT = \"set\"; public static final String MAP_ELEMENT = \"map\"; public static final String ENTRY_ELEMENT = \"entry\"; public static final String KEY_ELEMENT = \"key\"; public static final String KEY_ATTRIBUTE = \"key\"; public static final String KEY_REF_ATTRIBUTE = \"key-ref\"; public static final String VALUE_REF_ATTRIBUTE = \"value-ref\"; public static final String PROPS_ELEMENT = \"props\"; public static final String PROP_ELEMENT = \"prop\"; public static final String MERGE_ATTRIBUTE = \"merge\"; public static final String QUALIFIER_ELEMENT = \"qualifier\"; public static final String QUALIFIER_ATTRIBUTE_ELEMENT = \"attribute\"; public static final String DEFAULT_LAZY_INIT_ATTRIBUTE = \"default-lazy-init\"; public static final String DEFAULT_MERGE_ATTRIBUTE = \"default-merge\"; public static final String DEFAULT_AUTOWIRE_ATTRIBUTE = \"default-autowire\"; public static final String DEFAULT_DEPENDENCY_CHECK_ATTRIBUTE = \"default-dependency-check\"; public static final String DEFAULT_AUTOWIRE_CANDIDATES_ATTRIBUTE = \"default-autowire-candidates\"; public static final String DEFAULT_INIT_METHOD_ATTRIBUTE = \"default-init-method\"; public static final String DEFAULT_DESTROY_METHOD_ATTRIBUTE = \"default-destroy-method\"; protected final Log logger = LogFactory.getLog(getClass()); private final XmlReaderContext readerContext; private final DocumentDefaultsDefinition defaults = new DocumentDefaultsDefinition(); private final ParseState parseState = new ParseState(); /** * Stores all used bean names so we can enforce uniqueness on a per * beans-element basis. Duplicate bean ids/names may not exist within the * same level of beans element nesting, but may be duplicated across levels. */ private final Set&lt;String&gt; usedNames = new HashSet&lt;String&gt;(); 跟进documentReader.registerBeanDefinitions(doc, createReaderContext(resource));方法，可以看到将XmlReaderContext readerContext对象放到了DefaultBeanDefinitionDocumentReader的 private XmlReaderContext readerContext;成员对象中，这个是BeanDefinitionDocumentReader与XmlBeanDefinitionReader进行互通的纽带 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * This implementation parses bean definitions according to the \"spring-beans\" XSD * (or DTD, historically). * &lt;p&gt;Opens a DOM Document; then initializes the default settings * specified at the &#123;@code &lt;beans/&gt;&#125; level; then parses the contained bean definitions. */@Overridepublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); Element root = doc.getDocumentElement(); // 核心逻辑，真正的开始解析了 doRegisterBeanDefinitions(root);&#125;/** * Register each bean definition within the given root &#123;@code &lt;beans/&gt;&#125; element. */protected void doRegisterBeanDefinitions(Element root) &#123; // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; // 检查是否定义了profile属性，如果定义了需要到环境变量中找，利用这个特性我们可以在配置文件中部署不同的环境 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; // 解析前处理，留给子类实现 preProcessXml(root); // 解析并注册BeBeanDefinitions parseBeanDefinitions(root, this.delegate); // 解析后处理，留给子类实现 postProcessXml(root); this.delegate = parent;&#125; 进入parseBeanDefinitions(root, this.delegate);方法，这里分为默认标签解析及自定义标签解析 123456789101112131415161718192021222324252627/** * Parse the elements at the root level in the document: * \"import\", \"alias\", \"bean\". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 如果是默认命名空间 xmlns=\"http://www.springframework.org/schema/beans\" if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; // 默认标签解析 如&lt;bean class=\"\"/&gt; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; // 自定义标签解析 如：&lt;context:component-scan base-package = \"*\"/&gt; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123;// 自定义标签解析 delegate.parseCustomElement(root); &#125;&#125; delegate.isDefaultNamespace(root) 方法用于区分是使用默认标签解析还是自定义标签解析，由下面代码可以看到是获取了Node标签的命名间URI然后再与&quot;http://www.springframework.org/schema/beans&quot;字符串进行比较，可以看到如果相等的话就是默认标签了 isDefaultNamespace(root)方法 12345678public static final String BEANS_NAMESPACE_URI = \"http://www.springframework.org/schema/beans\";public boolean isDefaultNamespace(Node node) &#123; return isDefaultNamespace(getNamespaceURI(node));&#125;public boolean isDefaultNamespace(String namespaceUri) &#123; return (!StringUtils.hasLength(namespaceUri) || BEANS_NAMESPACE_URI.equals(namespaceUri));&#125; 访问 http://www.springframework.org/schema/beans 得到的是beans的XSD定义文件 12345678910111213Index of /schema/beansIcon Name Last modified Size Description[PARENTDIR] Parent Directory - [TXT] spring-beans-2.0.xsd 2019-05-09 08:43 38K [TXT] spring-beans-2.5.xsd 2019-05-09 08:43 41K [TXT] spring-beans-3.0.xsd 2019-05-09 08:43 41K [TXT] spring-beans-3.1.xsd 2019-05-09 08:43 42K [TXT] spring-beans-3.2.xsd 2019-05-09 08:43 43K [TXT] spring-beans-4.0.xsd 2019-05-09 08:43 42K [TXT] spring-beans-4.1.xsd 2019-05-09 08:43 43K [TXT] spring-beans-4.2.xsd 2019-05-09 08:43 43K [TXT] spring-beans-4.3.xsd 2019-05-09 08:43 43K [TXT] spring-beans.xsd 2019-05-09 08:43 43K 默认标签解析parseDefaultElement(ele, delegate) 可以看到这些是Spring默认的一些标签 12345678910111213141516171819202122232425/** * 默认标签解析 * * @param ele * @param delegate */private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 解析import if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; // 解析alias else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; // 解析bean 最为复杂最为重要 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; // 解析beans else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125;&#125; 进入processBeanDefinition(ele, delegate);我们这里查看bean标签是怎么解析的，毕竟是Spring的主力军，可以看到下面的方法先是获取了BeanDefinitionHolder，这个是BeanDefinition的一个容器，在BeanDefinition内容的基础上添加了beanName及aliases属性，然后标签的解析工作是由BeanDefinitionParserDelegate类的registerBeanDefinition方法来执行的，这个类在上面的内容中简单提过一次，BeanDefinitionParserDelegate类提供了解析spring配置文件功能，对于默认空间下的元素在该类内部实现，如果是其它命名空间下的元素可以通过绑定NamespaceHandler的方式来实现,针对每个命名空间下的元素提供不同BeanDefinitionParser来实现. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Process the given bean element, parsing the bean definition * and registering it with the registry. */protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; /** * 委托BeanDefinitionParserDelegate的parseBeanDefinitionElement方法进行元素解析 * * bdHolder 实例已经包含我们配置文件中配置的各个属性了，例如class、name、id、alias */ BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; /** * 对解析后的bdHolder进行注册 * Register the final decorated instance. */ BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125;/** * * BeanDefinitionHolder 实例已经包含我们配置文件中配置的各个属性了， * 有beanDefinition及beanName和aliases,为注册做准备 * * Holder for a BeanDefinition with name and aliases. * Can be registered as a placeholder for an inner bean. * * &lt;p&gt;Can also be used for programmatic registration of inner bean * definitions. If you don't care about BeanNameAware and the like, * registering RootBeanDefinition or ChildBeanDefinition is good enough. * * @author Juergen Hoeller * @since 1.0.2 * @see org.springframework.beans.factory.BeanNameAware * @see org.springframework.beans.factory.support.RootBeanDefinition * @see org.springframework.beans.factory.support.ChildBeanDefinition */ public class BeanDefinitionHolder implements BeanMetadataElement &#123; private final BeanDefinition beanDefinition; private final String beanName; private final String[] aliases; 进入delegate.parseBeanDefinitionElement(ele)，可以看到一些基础代码String id = ele.getAttribute(ID_ATTRIBUTE); 获取id呀，获取name属性呀 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Parses the supplied &#123;@code &lt;bean&gt;&#125; element. May return &#123;@code null&#125; * if there were errors during parse. Errors are reported to the * &#123;@link org.springframework.beans.factory.parsing.ProblemReporter&#125;. */public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) &#123; // 获取id属性 String id = ele.getAttribute(ID_ATTRIBUTE); // 获取name属性 String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); // 分割name属性 这里是实现了多个name配置的解析，可以是`,; `作为分割 List&lt;String&gt; aliases = new ArrayList&lt;String&gt;(); if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; String beanName = id; if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &#123; logger.debug(\"No XML 'id' specified - using '\" + beanName + \"' as bean name and \" + aliases + \" as aliases\"); &#125; &#125; if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); if (beanDefinition != null) &#123; if (!StringUtils.hasText(beanName)) &#123; try &#123; // 如果不存在beanName那么根据Spring中提供的命名规则为当前的bean生成对应的beanName if (containingBean != null) &#123; beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); // Register an alias for the plain bean class name, if still possible, // if the generator returned the class name plus a suffix. // This is expected for Spring 1.2/2.0 backwards compatibility. String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Neither XML 'id' nor 'name' specified - \" + \"using generated bean name [\" + beanName + \"]\"); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; return null;&#125; parseBeanDefinitionElement(ele, beanName, containingBean) 这个方法构造了BeanDefinition，在这里是AbstractBeanDefinition对象，通过下面的代码可以很清晰的与&lt;bean&gt;标签的一些属性对应在一起，这些xml标签在Spring中就是转化成BeanDefinition 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Parse the bean definition itself, without regard to name or aliases. May return * &#123;@code null&#125; if problems occurred during the parsing of the bean definition. */public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; // 获取class属性 if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; try &#123; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; // 创建用于承载属性的AbstractBeanDefinition类型的GenericBeanDefinition AbstractBeanDefinition bd = createBeanDefinition(className, parent); // 硬编码解析默认bean的各种属性 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); // 提取description bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); // 解析元数据 parseMetaElements(ele, bd); // 解析lookup-method parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); // 解析replaced-method parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); // 解析构造函数参数 parseConstructorArgElements(ele, bd); // 解析property子元素 parsePropertyElements(ele, bd); // 解析qualifier子元素 parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error(\"Bean class [\" + className + \"] not found\", ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err); &#125; catch (Throwable ex) &#123; error(\"Unexpected failure during bean definition parsing\", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null;&#125; 回到protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate)方法，在这里我们已经得到了BeanDefinitionHolder，下面就是需要将解析后的结果注册存放起来了，下面的BeanDefinitionReaderUtils.registerBeanDefinition方法就是做的这个任务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Process the given bean element, parsing the bean definition * and registering it with the registry. */protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; /** * 委托BeanDefinitionParserDelegate的parseBeanDefinitionElement方法进行元素解析 * * bdHolder 实例已经包含我们配置文件中配置的各个属性了，例如class、name、id、alias */ BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; /** * 对解析后的bdHolder进行注册 * Register the final decorated instance. */ BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; ``` * 进入`BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());`方法，关注`getReaderContext().getRegistry()`方法，由上面可以知道`XmlReaderContext`存放着`XmlBeanDefinitionReader`，而`XmlBeanDefinitionReader`存放着`private final BeanDefinitionRegistry registry;`我们的`beanFactory` private XmlReaderContext readerContext; ```java/** * Return the descriptor for the XML resource that this parser works on. */protected final XmlReaderContext getReaderContext() &#123; return this.readerContext;&#125;// org.springframework.beans.factory.xml.XmlReaderContext#getRegistrypublic class XmlReaderContext extends ReaderContext &#123; private final XmlBeanDefinitionReader reader; private final NamespaceHandlerResolver namespaceHandlerResolver; public XmlReaderContext( Resource resource, ProblemReporter problemReporter, ReaderEventListener eventListener, SourceExtractor sourceExtractor, XmlBeanDefinitionReader reader, NamespaceHandlerResolver namespaceHandlerResolver) &#123; super(resource, problemReporter, eventListener, sourceExtractor); this.reader = reader; this.namespaceHandlerResolver = namespaceHandlerResolver; &#125; public final XmlBeanDefinitionReader getReader() &#123; return this.reader; &#125; public final BeanDefinitionRegistry getRegistry() &#123; return this.reader.getRegistry(); &#125; 下面的代码可以看到第二参数是看到传入了BeanDefinitionRegistry对象，下面的方法就是根据BeanDefinitionHolder信息调用BeanDefinitionRegistry类的方法注册BeanDefinition及Aliases 1234567891011121314151617181920212223/** * Register the given bean definition with the given bean factory. * @param definitionHolder the bean definition including name and aliases * @param registry the bean factory to register with * @throws BeanDefinitionStoreException if registration failed */public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. 使用beanName做唯一标识注册 String beanName = definitionHolder.getBeanName(); // 核心代码 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. 注册所有的别名 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125;&#125; 进入核心方法registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());，关注this.beanDefinitionMap.put(beanName, beanDefinition); 可以看到将我们得到的beanDefinition存放到了一个private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap中，到这一个&lt;bean&gt;标签已经是解析完成了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394@Overridepublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; // 校验 beanName 与 beanDefinition 非空 Assert.hasText(beanName, \"Bean name must not be empty\"); Assert.notNull(beanDefinition, \"BeanDefinition must not be null\"); // 校验 BeanDefinition 这是注册前的最后一次校验了，主要是对 AbstractBeanDefinition 的 methodOverrides 属性进行校验。 if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \"Validation of bean definition failed\", ex); &#125; &#125; BeanDefinition oldBeanDefinition; // 从缓存中获取指定 beanName 的 BeanDefinition oldBeanDefinition = this.beanDefinitionMap.get(beanName); // 如果已经存在 if (oldBeanDefinition != null) &#123; // 如果存在但是不允许覆盖，抛出异常 if (!isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \"Cannot register bean definition [\" + beanDefinition + \"] for bean '\" + beanName + \"': There is already [\" + oldBeanDefinition + \"] bound.\"); &#125; // 覆盖 beanDefinition 大于 被覆盖的 beanDefinition 的 ROLE ，打印 info 日志 else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123; // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE if (this.logger.isWarnEnabled()) &#123; this.logger.warn(\"Overriding user-defined bean definition for bean '\" + beanName + \"' with a framework-generated bean definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &#125; &#125; // 覆盖 beanDefinition 与 被覆盖的 beanDefinition 不相同，打印 debug 日志 else if (!beanDefinition.equals(oldBeanDefinition)) &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info(\"Overriding bean definition for bean '\" + beanName + \"' with a different definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &#125; &#125; // 其它，打印 debug 日志 else &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Overriding bean definition for bean '\" + beanName + \"' with an equivalent definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &#125; &#125; // 允许覆盖，直接覆盖原有的 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); &#125; else &#123; // 检测创建 Bean 阶段是否已经开启，如果开启了则需要对 beanDefinitionMap 进行并发控制 if (hasBeanCreationStarted()) &#123; // Cannot modify startup-time collection elements anymore (for stable iteration) // beanDefinitionMap 为全局变量，避免并发情况 synchronized (this.beanDefinitionMap) &#123; // 添加到 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;String&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); // 添加 beanName 到 beanDefinitionNames 中 this.beanDefinitionNames = updatedDefinitions; // 从 manualSingletonNames 移除 beanName if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;String&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; // Still in startup registration phase // 添加到 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); // 添加 beanName 到 beanDefinitionNames 中 this.beanDefinitionNames.add(beanName); // 从 manualSingletonNames 移除 beanName this.manualSingletonNames.remove(beanName); &#125; this.frozenBeanDefinitionNames = null; &#125; // 重新设置 beanName 对应的缓存 if (oldBeanDefinition != null || containsSingleton(beanName)) &#123; resetBeanDefinition(beanName); &#125;&#125; 自定义标签解析delegate.parseCustomElement(ele) 与默认标签解析的操作不同，它是通过调用BeanDefinitionParser接口的parse方法来解析 12345678910111213141516public BeanDefinition parseCustomElement(Element ele) &#123; return parseCustomElement(ele, null);&#125;public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; // 获取xml配置文件中的命名空间http://www.springframework.org/schema/context String namespaceUri = getNamespaceURI(ele); // 根据命名空间找到命名空间处理类 比如ContextNamespaceHandler AopNamespaceHandler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; &#125; // 解析命名空间支持的标签 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 这里有个NamespaceHandler这个接口主要功能是通过Element标签找到对于的BeanDefinitionParser，找到之后然后调用BeanDefinitionParser接口的parse方法来解析 NamespaceHandler接口 命名空间处理器，我们就可以根据需求自己来处理我们设置的标签元素。 可能需要配置如&lt;aop:config /&gt;这样的标签, 在配置这个标签之前，通常我们需要在xml中引入这个aop所在的命名空间，xmlns:aop=&quot;http://www.springframework.org/schema/aop 只有通过配置aop的命名空间才会找到AOP标签的处理器{@link org.springframework.aop.config.AopNamespaceHandler}，在AOP的jar中的spring.handlers配置文件中配置了命名空间和命名空间处理器之间的关系。 比如我们这里是&lt;context:component-scan/&gt;标签，所以得到的命名空间处理类是ContextNamespaceHandler 123456789101112131415public class ContextNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser(\"property-placeholder\", new PropertyPlaceholderBeanDefinitionParser()); registerBeanDefinitionParser(\"property-override\", new PropertyOverrideBeanDefinitionParser()); registerBeanDefinitionParser(\"annotation-config\", new AnnotationConfigBeanDefinitionParser()); registerBeanDefinitionParser(\"component-scan\", new ComponentScanBeanDefinitionParser()); registerBeanDefinitionParser(\"load-time-weaver\", new LoadTimeWeaverBeanDefinitionParser()); registerBeanDefinitionParser(\"spring-configured\", new SpringConfiguredBeanDefinitionParser()); registerBeanDefinitionParser(\"mbean-export\", new MBeanExportBeanDefinitionParser()); registerBeanDefinitionParser(\"mbean-server\", new MBeanServerBeanDefinitionParser()); &#125;&#125; 关注registerBeanDefinitionParser(&quot;component-scan&quot;, new ComponentScanBeanDefinitionParser());这行代码这里注册了标签命名与对应解析类的对应关系，找到ContextNamespaceHandler之后就是调用对应解析类的对应方法了，调用ComponentScanBeanDefinitionParser的parse方法，此类实现了BeanDefinitionParser 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Parser for the &#123;@code &lt;context:component-scan/&gt;&#125; element. * * @author Mark Fisher * @author Ramnivas Laddad * @author Juergen Hoeller * @since 2.5 */public class ComponentScanBeanDefinitionParser implements BeanDefinitionParser &#123; private static final String BASE_PACKAGE_ATTRIBUTE = \"base-package\"; private static final String RESOURCE_PATTERN_ATTRIBUTE = \"resource-pattern\"; private static final String USE_DEFAULT_FILTERS_ATTRIBUTE = \"use-default-filters\"; private static final String ANNOTATION_CONFIG_ATTRIBUTE = \"annotation-config\"; private static final String NAME_GENERATOR_ATTRIBUTE = \"name-generator\"; private static final String SCOPE_RESOLVER_ATTRIBUTE = \"scope-resolver\"; private static final String SCOPED_PROXY_ATTRIBUTE = \"scoped-proxy\"; private static final String EXCLUDE_FILTER_ELEMENT = \"exclude-filter\"; private static final String INCLUDE_FILTER_ELEMENT = \"include-filter\"; private static final String FILTER_TYPE_ATTRIBUTE = \"type\"; private static final String FILTER_EXPRESSION_ATTRIBUTE = \"expression\"; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; String basePackage = element.getAttribute(BASE_PACKAGE_ATTRIBUTE); basePackage = parserContext.getReaderContext().getEnvironment().resolvePlaceholders(basePackage); // 解析base-package属性值，扫描的包可以,;分隔 String[] basePackages = StringUtils.tokenizeToStringArray(basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); // Actually scan for bean definitions and register them. // 构建类路径的BeanDefinition扫描器 ClassPathBeanDefinitionScanner scanner = configureScanner(parserContext, element); // 在指定的基础包中执行扫描 base-package = \"org.springiframe.*\" 找出该包下所有的bean注册为beanDefinition Set&lt;BeanDefinitionHolder&gt; beanDefinitions = scanner.doScan(basePackages); // 注册组件 registerComponents(parserContext.getReaderContext(), beanDefinitions, element); return null; &#125; 进入configureScanner(parserContext, element);方法，这里是构建了ClassPathBeanDefinitionScanner对象，并解析标签元素 123456789101112131415161718192021222324252627282930313233343536373839protected ClassPathBeanDefinitionScanner configureScanner(ParserContext parserContext, Element element) &#123; // 默认使用spring自带的注解过滤 boolean useDefaultFilters = true; // 解析`use-default-filters`，类型为boolean if (element.hasAttribute(USE_DEFAULT_FILTERS_ATTRIBUTE)) &#123; useDefaultFilters = Boolean.valueOf(element.getAttribute(USE_DEFAULT_FILTERS_ATTRIBUTE)); &#125; // Delegate bean definition registration to scanner class. // 此处如果`use-default-filters`为true，则添加`@Component`、`@Service`、`@Controller`、`@Repository`、`@ManagedBean`、`@Named`添加到includeFilters的集合过滤 ClassPathBeanDefinitionScanner scanner = createScanner(parserContext.getReaderContext(), useDefaultFilters); scanner.setBeanDefinitionDefaults(parserContext.getDelegate().getBeanDefinitionDefaults()); scanner.setAutowireCandidatePatterns(parserContext.getDelegate().getAutowireCandidatePatterns()); // 设置`resource-pattern`属性，扫描资源的模式匹配，支持正则表达式 if (element.hasAttribute(RESOURCE_PATTERN_ATTRIBUTE)) &#123; scanner.setResourcePattern(element.getAttribute(RESOURCE_PATTERN_ATTRIBUTE)); &#125; try &#123; // 解析name-generator属性 beanName生成器 parseBeanNameGenerator(element, scanner); &#125; catch (Exception ex) &#123; parserContext.getReaderContext().error(ex.getMessage(), parserContext.extractSource(element), ex.getCause()); &#125; try &#123; // 解析scope-resolver属性和scoped-proxy属性，但两者只可存在其一 后者值为targetClass：cglib代理、interfaces：JDK代理、no：不使用代理 parseScope(element, scanner); &#125; catch (Exception ex) &#123; parserContext.getReaderContext().error(ex.getMessage(), parserContext.extractSource(element), ex.getCause()); &#125; // 解析子节点`context:include-filter`、`context:exclude-filter`主要用于对扫描class类的过滤 parseTypeFilters(element, scanner, parserContext); return scanner;&#125; 进入createScanner(parserContext.getReaderContext(), useDefaultFilters); 方法里面的registerDefaultFilters();方法，可以看到默认是注册了@Component,@ManagedBean,@Named过滤器到this.includeFilters中 1234567891011121314151617181920protected void registerDefaultFilters() &#123; this.includeFilters.add(new AnnotationTypeFilter(Component.class)); ClassLoader cl = ClassPathScanningCandidateComponentProvider.class.getClassLoader(); try &#123; this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.annotation.ManagedBean\", cl)), false)); logger.debug(\"JSR-250 'javax.annotation.ManagedBean' found and supported for component scanning\"); &#125; catch (ClassNotFoundException ex) &#123; // JSR-250 1.1 API (as included in Java EE 6) not available - simply skip. &#125; try &#123; this.includeFilters.add(new AnnotationTypeFilter( ((Class&lt;? extends Annotation&gt;) ClassUtils.forName(\"javax.inject.Named\", cl)), false)); logger.debug(\"JSR-330 'javax.inject.Named' annotation found and supported for component scanning\"); &#125; catch (ClassNotFoundException ex) &#123; // JSR-330 API not available - simply skip. &#125;&#125; 从上面可以看到Spring支持如下三种注解 Spring自带的@Component注解及扩展@Repository、@Service、@Controller JSR-250 1.1版本中中定义的@ManagedBean注解，是Java EE 6标准规范之一，不包括在JDK中，需要在应用服务器环境使用（如Jboss） JSR-330的@Named注解 回到Set&lt;BeanDefinitionHolder&gt; beanDefinitions = scanner.doScan(basePackages);方法，这个方法就是在指定的基础包中执行扫描基础包下的所有符合条件的class 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 在指定的基础包中执行扫描基础包下的所有符合条件的class * * Perform a scan within the specified base packages, * returning the registered bean definitions. * &lt;p&gt;This method does &lt;i&gt;not&lt;/i&gt; register an annotation config processor * but rather leaves this up to the caller. * @param basePackages the packages to check for annotated classes * @return set of beans registered if any for tooling registration purposes (never &#123;@code null&#125;) */protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; // base-package属性必须要有 Assert.notEmpty(basePackages, \"At least one base package must be specified\"); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(); // 对每个基础包都进行扫描寻找并且对基础包下的所有符合条件的class注册为BeanDefinition for (String basePackage : basePackages) &#123; // 核心方法 并对得到的candidates集合进行过滤，此处便用到include-filters和exclude-filters Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) &#123; // 设置lazy-init/autowire-code默认属性，从spring配置的&lt;beans&gt;节点属性读取 postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; if (candidate instanceof AnnotatedBeanDefinition) &#123; // 读取bean上的注解，比如`@Lazy`、`@Dependson`的值设置相应的属性 AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; // 查看是否已注册 if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); // 默认采取cglib来做代理 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); // 注册bean信息到工厂中 registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions;&#125; findCandidateComponents(String basePackage)方法可以看到是遍历了class文件，一个个找符合条件的class并构造成BeanDefinition对象 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Scan the class path for candidate components. * @param basePackage the package to check for annotated classes * @return a corresponding Set of autodetected bean definitions */public Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) &#123; Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;BeanDefinition&gt;(); try &#123; String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + resolveBasePackage(basePackage) + '/' + this.resourcePattern; Resource[] resources = this.resourcePatternResolver.getResources(packageSearchPath); boolean traceEnabled = logger.isTraceEnabled(); boolean debugEnabled = logger.isDebugEnabled(); // 遍历class文件 for (Resource resource : resources) &#123; if (traceEnabled) &#123; logger.trace(\"Scanning \" + resource); &#125; if (resource.isReadable()) &#123; try &#123; MetadataReader metadataReader = this.metadataReaderFactory.getMetadataReader(resource); // 这里进行匹配 if (isCandidateComponent(metadataReader)) &#123; ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader); sbd.setResource(resource); sbd.setSource(resource); if (isCandidateComponent(sbd)) &#123; if (debugEnabled) &#123; logger.debug(\"Identified candidate component class: \" + resource); &#125; candidates.add(sbd); &#125; else &#123; if (debugEnabled) &#123; logger.debug(\"Ignored because not a concrete top-level class: \" + resource); &#125; &#125; &#125; else &#123; if (traceEnabled) &#123; logger.trace(\"Ignored because not matching any filter: \" + resource); &#125; &#125; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( \"Failed to read candidate component class: \" + resource, ex); &#125; &#125; else &#123; if (traceEnabled) &#123; logger.trace(\"Ignored because not readable: \" + resource); &#125; &#125; &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"I/O failure during classpath scanning\", ex); &#125; return candidates;&#125; isCandidateComponent(MetadataReader metadataReader) 方法就是进行匹配的主体方法，上面默认注册的this.includeFilters就派上作用了 123456789101112131415161718192021/** * Determine whether the given class does not match any exclude filter * and does match at least one include filter. * @param metadataReader the ASM ClassReader for the class * @return whether the class qualifies as a candidate component */protected boolean isCandidateComponent(MetadataReader metadataReader) throws IOException &#123; for (TypeFilter tf : this.excludeFilters) &#123; // 排除过滤器 if (tf.match(metadataReader, this.metadataReaderFactory)) &#123; return false; &#125; &#125; for (TypeFilter tf : this.includeFilters) &#123; // 筛选过滤器 if (tf.match(metadataReader, this.metadataReaderFactory)) &#123; return isConditionMatch(metadataReader); &#125; &#125; return false;&#125; 获得BeanDefinition之后就是通过registerBeanDefinition(definitionHolder, this.registry);注册，和之前默认标签的BeanDefinition的注册调用的是同一个方法 1234567891011121314151617181920212223/** * Register the given bean definition with the given bean factory. * @param definitionHolder the bean definition including name and aliases * @param registry the bean factory to register with * @throws BeanDefinitionStoreException if registration failed */public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. 使用beanName做唯一标识注册 String beanName = definitionHolder.getBeanName(); // 核心代码 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. 注册所有的别名 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125;&#125; 回到registerComponents(parserContext.getReaderContext(), beanDefinitions, element);，此处的目的主要是注册多个BeanPostProcessor接口实现类，供后续Spring调用统一接口进行解析 1234567891011121314151617181920212223242526272829protected void registerComponents(XmlReaderContext readerContext, Set&lt;BeanDefinitionHolder&gt; beanDefinitions, Element element) &#123; Object source = readerContext.extractSource(element); // 包装为CompositeComponentDefinition对象，内置多ComponentDefinition对象 CompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(), source); // 将已注册的所有beanDefinitionHolder对象放到上述对象中 for (BeanDefinitionHolder beanDefHolder : beanDefinitions) &#123; compositeDef.addNestedComponent(new BeanComponentDefinition(beanDefHolder)); &#125; // Register annotation config processors, if necessary. boolean annotationConfig = true; // 获取annotation-config的属性值，默认为true if (element.hasAttribute(ANNOTATION_CONFIG_ATTRIBUTE)) &#123; annotationConfig = Boolean.valueOf(element.getAttribute(ANNOTATION_CONFIG_ATTRIBUTE)); &#125; if (annotationConfig) &#123; // 注册多个BeanPostProcessor接口，具体什么可自行查看，返回的是包含BeanPostProcessor接口的beanDefinitionHolder对象集合 // 我们的@Autowired注解解析类AutowiredAnnotationBeanPostProcessor就是在这里默认导入的 Set&lt;BeanDefinitionHolder&gt; processorDefinitions = AnnotationConfigUtils.registerAnnotationConfigProcessors(readerContext.getRegistry(), source); // 继续装入CompositeComponentDefinition对象 for (BeanDefinitionHolder processorDefinition : processorDefinitions) &#123; compositeDef.addNestedComponent(new BeanComponentDefinition(processorDefinition)); &#125; &#125; readerContext.fireComponentRegistered(compositeDef);&#125; 关注registerAnnotationConfigProcessors(BeanDefinitionRegistry registry, Object source)方法，可以看到默认注册了一些我们常用注解的解析器 ConfigurationClassPostProcessor解析@Configuration注解类 AutowiredAnnotationBeanPostProcessor解析@Autowired/@Value注解 RequiredAnnotationBeanPostProcessor解析@Required注解 CommonAnnotationBeanPostProcessor解析@PostConstruct @PreDestroy @Resource注解 PersistenceAnnotationBeanPostProcessor解析JPA注解，持久层123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Register all relevant annotation post processors in the given registry. * @param registry the registry to operate on * @param source the configuration source element (already extracted) * that this registration was triggered from. May be &#123;@code null&#125;. * @return a Set of BeanDefinitionHolders, containing all bean definitions * that have actually been registered by this call */public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(4); // 注册@Configuration`解析类 if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Autowired/@Value`解析类 if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Required`解析类 if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. // 注册@PostConstruct @PreDestroy @Resource 及JSR-250支持注解解析类 if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. // 注册JPA注解解析类 if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Cannot load optional framework class: \" + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs;&#125; 总结 回顾上一章节中XmlBeanDefinitionReader的总体功能是 XML Resource =&gt; XML Document =&gt; Bean Definition 的转化过程。由Resource得到Document对象，再由Document对象得到BeanDefinition对象，本章的BeanDefinitionDocumentReader对象就是替XmlBeanDefinitionReader完成XML Document =&gt; Bean Definition的功能 XML Document标签的解析分为默认标签的解析及自定义标签解析，默认标签的解析主要是通过BeanDefinitionParserDelegate类来实现，默认标签的解析比较固定所以直接是一个解析类就能完成，而自定义标签的实现是通过绑定NamespaceHandler的方式来实现,针对每个命名空间下的元素提供不同BeanDefinitionParser来实现，可以看到Spring考虑的十分全面 ComponentScanBeanDefinitionParser这个类是&lt;context:component-scan base-package = &quot;org.springiframe.*&quot;/&gt;这个标签的实现类，用于解析该包下所有的bean注册为beanDefinition 使用了这个标签默认会注册如下这些Bean，看名字是不是很熟悉，我们能够使用这些注解功能就是靠下面这些BeanPostProcessor来实现的 ConfigurationClassPostProcessor解析@Configuration注解类 AutowiredAnnotationBeanPostProcessor解析@Autowired/@Value注解 RequiredAnnotationBeanPostProcessor解析@Required注解 CommonAnnotationBeanPostProcessor解析@PostConstruct @PreDestroy @Resource注解 PersistenceAnnotationBeanPostProcessor解析JPA注解，持久层参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(四)BeanDefinition读取器XmlBeanDefinitionReader","slug":"backend/framework/spring/analysis/Spring系列(四)BeanDefinition读取器XmlBeanDefinitionReader","date":"2019-06-09T07:00:46.000Z","updated":"2020-01-04T12:21:52.202Z","comments":true,"path":"2019/06/09/backend/framework/spring/analysis/Spring系列(四)BeanDefinition读取器XmlBeanDefinitionReader/","link":"","permalink":"http://www.songshuiyang.com/2019/06/09/backend/framework/spring/analysis/Spring系列(四)BeanDefinition读取器XmlBeanDefinitionReader/","excerpt":"","text":"前言 上一章节介绍了Resource的获取，这一章节来介绍BeanDefinitionReader功能， 它的作用是读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中的每个解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中； 下图是Spring容器从加载配置文件到创建一个完整Bean的作业流程及参与的角色 BeanDefinitionReader 读取、解析 Resource 资源，也就是将用户定义的 Bean 表示成 IoC 容器的内部数据结构：BeanDefinition 。 在 IoC 容器内部维护着一个 BeanDefinition Map 的数据结构 在配置文件中每一个 都对应着一个 BeanDefinition 对象。 向 IoC 容器注册在第二步解析好的 BeanDefinition，这个过程是通过 BeanDefinitionRegistry 接口来实现的。在 IoC 容器内部其实是将第二个过程解析得到的 BeanDefinition 注入到一个 HashMap 容器中，IoC 容器就是通过这个 HashMap 来维护这些 BeanDefinition 的。 在这里需要注意的一点是这个过程并没有完成依赖注入（Bean 创建），Bean 创建是发生在应用第一次调用 #getBean(…) 方法，向容器索要 Bean 时。 当然我们可以通过设置预处理，即对某个 Bean 设置 lazyinit = false 属性，那么这个 Bean 的依赖注入就会在容器初始化的时候完成。 解析 XmlBeanDefinitionReader的继承结构比较简单，上面就一个顶级接口及一个默认抽象实现类，还有个获取Environment的接口 BeanDefinitionReader 顶级接口，关注loadBeanDefinitions方法，这些是定义解析BeanDefinitions的方法，可以看到支持Resource资源类型的解析，还支持location指定文件路径资源的解析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * 主要定义了资源文件读取并转换为BeanDefinition的各个功能 * * Simple interface for bean definition readers. * Specifies load methods with Resource and String location parameters. * * &lt;p&gt;Concrete bean definition readers can of course add additional * load and register methods for bean definitions, specific to * their bean definition format. * * &lt;p&gt;Note that a bean definition reader does not have to implement * this interface. It only serves as suggestion for bean definition * readers that want to follow standard naming conventions. * * @author Juergen Hoeller * @since 1.1 * @see org.springframework.core.io.Resource */public interface BeanDefinitionReader &#123; /** * Return the bean factory to register the bean definitions with. * &lt;p&gt;The factory is exposed through the BeanDefinitionRegistry interface, * encapsulating the methods that are relevant for bean definition handling. */ BeanDefinitionRegistry getRegistry(); /** * Return the resource loader to use for resource locations. * Can be checked for the &lt;b&gt;ResourcePatternResolver&lt;/b&gt; interface and cast * accordingly, for loading multiple resources for a given resource pattern. * &lt;p&gt;Null suggests that absolute resource loading is not available * for this bean definition reader. * &lt;p&gt;This is mainly meant to be used for importing further resources * from within a bean definition resource, for example via the \"import\" * tag in XML bean definitions. It is recommended, however, to apply * such imports relative to the defining resource; only explicit full * resource locations will trigger absolute resource loading. * &lt;p&gt;There is also a &#123;@code loadBeanDefinitions(String)&#125; method available, * for loading bean definitions from a resource location (or location pattern). * This is a convenience to avoid explicit ResourceLoader handling. * @see #loadBeanDefinitions(String) * @see org.springframework.core.io.support.ResourcePatternResolver */ ResourceLoader getResourceLoader(); /** * Return the class loader to use for bean classes. * &lt;p&gt;&#123;@code null&#125; suggests to not load bean classes eagerly * but rather to just register bean definitions with class names, * with the corresponding Classes to be resolved later (or never). */ ClassLoader getBeanClassLoader(); /** * Return the BeanNameGenerator to use for anonymous beans * (without explicit bean name specified). */ BeanNameGenerator getBeanNameGenerator(); /** * Load bean definitions from the specified resource. * @param resource the resource descriptor * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */ int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException; /** * Load bean definitions from the specified resources. * @param resources the resource descriptors * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */ int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException; /** * Load bean definitions from the specified resource location. * &lt;p&gt;The location can also be a location pattern, provided that the * ResourceLoader of this bean definition reader is a ResourcePatternResolver. * @param location the resource location, to be loaded with the ResourceLoader * (or ResourcePatternResolver) of this bean definition reader * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #getResourceLoader() * @see #loadBeanDefinitions(org.springframework.core.io.Resource) * @see #loadBeanDefinitions(org.springframework.core.io.Resource[]) */ int loadBeanDefinitions(String location) throws BeanDefinitionStoreException; /** * Load bean definitions from the specified resource locations. * @param locations the resource locations, to be loaded with the ResourceLoader * (or ResourcePatternResolver) of this bean definition reader * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */ int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException;&#125; AbstractBeanDefinitionReader 抽象类是BeanDefinitionReader接口的默认抽象实现，关注private final BeanDefinitionRegistry registry;属性，上一章节介绍的DefaultListableBeanFactory类型的beanFactory就是存放在这，之后解析后的BeanDefinition也是存放在这 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * BeanDefinitionReader的抽象实现 * 对 EnvironmentCapable、BeanDefinitionReader定义的功能进行实现 * * Abstract base class for bean definition readers which implement * the &#123;@link BeanDefinitionReader&#125; interface. * * &lt;p&gt;Provides common properties like the bean factory to work on * and the class loader to use for loading bean classes. * * @author Juergen Hoeller * @author Chris Beams * @since 11.12.2003 * @see BeanDefinitionReaderUtils */public abstract class AbstractBeanDefinitionReader implements EnvironmentCapable, BeanDefinitionReader &#123; /** Logger available to subclasses */ protected final Log logger = LogFactory.getLog(getClass()); private final BeanDefinitionRegistry registry; private ResourceLoader resourceLoader; private ClassLoader beanClassLoader; private Environment environment; private BeanNameGenerator beanNameGenerator = new DefaultBeanNameGenerator(); /** * Create a new AbstractBeanDefinitionReader for the given bean factory. * &lt;p&gt;If the passed-in bean factory does not only implement the BeanDefinitionRegistry * interface but also the ResourceLoader interface, it will be used as default * ResourceLoader as well. This will usually be the case for * &#123;@link org.springframework.context.ApplicationContext&#125; implementations. * &lt;p&gt;If given a plain BeanDefinitionRegistry, the default ResourceLoader will be a * &#123;@link org.springframework.core.io.support.PathMatchingResourcePatternResolver&#125;. * &lt;p&gt;If the passed-in bean factory also implements &#123;@link EnvironmentCapable&#125; its * environment will be used by this reader. Otherwise, the reader will initialize and * use a &#123;@link StandardEnvironment&#125;. All ApplicationContext implementations are * EnvironmentCapable, while normal BeanFactory implementations are not. * @param registry the BeanFactory to load bean definitions into, * in the form of a BeanDefinitionRegistry * @see #setResourceLoader * @see #setEnvironment */ protected AbstractBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); this.registry = registry; // Determine ResourceLoader to use. if (this.registry instanceof ResourceLoader) &#123; this.resourceLoader = (ResourceLoader) this.registry; &#125; else &#123; this.resourceLoader = new PathMatchingResourcePatternResolver(); &#125; // Inherit Environment if possible if (this.registry instanceof EnvironmentCapable) &#123; this.environment = ((EnvironmentCapable) this.registry).getEnvironment(); &#125; else &#123; this.environment = new StandardEnvironment(); &#125; &#125; XmlBeanDefinitionReader.java 可以看到就一个构造方法public XmlBeanDefinitionReader(BeanDefinitionRegistry registry) 我们之前构造的DefaultListableBeanFactory是实现了BeanDefinitionRegistry这个接口的，这个接口定义了对 BeanDefinition 的各种增删改查方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192/** * 用于XML bean定义的Bean定义读取器。 * * Bean definition reader for XML bean definitions. * Delegates the actual XML document reading to an implementation * of the &#123;@link BeanDefinitionDocumentReader&#125; interface. * * &lt;p&gt;Typically applied to a * &#123;@link org.springframework.beans.factory.support.DefaultListableBeanFactory&#125; * or a &#123;@link org.springframework.context.support.GenericApplicationContext&#125;. * * &lt;p&gt;This class loads a DOM document and applies the BeanDefinitionDocumentReader to it. * The document reader will register each bean definition with the given bean factory, * talking to the latter's implementation of the * &#123;@link org.springframework.beans.factory.support.BeanDefinitionRegistry&#125; interface. * * @author Juergen Hoeller * @author Rob Harrop * @author Chris Beams * @since 26.11.2003 * @see #setDocumentReaderClass * @see BeanDefinitionDocumentReader * @see DefaultBeanDefinitionDocumentReader * @see BeanDefinitionRegistry * @see org.springframework.beans.factory.support.DefaultListableBeanFactory * @see org.springframework.context.support.GenericApplicationContext */public class XmlBeanDefinitionReader extends AbstractBeanDefinitionReader &#123; /** * Indicates that the validation should be disabled. */ public static final int VALIDATION_NONE = XmlValidationModeDetector.VALIDATION_NONE; /** * Indicates that the validation mode should be detected automatically. */ public static final int VALIDATION_AUTO = XmlValidationModeDetector.VALIDATION_AUTO; /** * Indicates that DTD validation should be used. */ public static final int VALIDATION_DTD = XmlValidationModeDetector.VALIDATION_DTD; /** * Indicates that XSD validation should be used. */ public static final int VALIDATION_XSD = XmlValidationModeDetector.VALIDATION_XSD; /** Constants instance for this class */ private static final Constants constants = new Constants(XmlBeanDefinitionReader.class); private int validationMode = VALIDATION_AUTO; private boolean namespaceAware = false; private Class&lt;?&gt; documentReaderClass = DefaultBeanDefinitionDocumentReader.class; private ProblemReporter problemReporter = new FailFastProblemReporter(); private ReaderEventListener eventListener = new EmptyReaderEventListener(); private SourceExtractor sourceExtractor = new NullSourceExtractor(); private NamespaceHandlerResolver namespaceHandlerResolver; private DocumentLoader documentLoader = new DefaultDocumentLoader(); /** * 解析XML,SAX首先会读取xml文档上的声明，根据声明去寻找相应的DTD定义，以便对文档进行一个验证， * 默认的寻找规则即通过网络，通过网络的话有可能出现网络中断或不可用的情况，所以提供该接口来实 * 现寻找DTD声明的过程，可以把这个文件放到项目中，这样就可以避免网络出错而导致无法启动项目的情况 */ private EntityResolver entityResolver; private ErrorHandler errorHandler = new SimpleSaxErrorHandler(logger); private final XmlValidationModeDetector validationModeDetector = new XmlValidationModeDetector(); private final ThreadLocal&lt;Set&lt;EncodedResource&gt;&gt; resourcesCurrentlyBeingLoaded = new NamedThreadLocal&lt;Set&lt;EncodedResource&gt;&gt;(\"XML bean definition resources currently being loaded\"); /** * Create new XmlBeanDefinitionReader for the given bean factory. * @param registry the BeanFactory to load bean definitions into, * in the form of a BeanDefinitionRegistry */ public XmlBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; super(registry); &#125; 代码跟进 上一章节介绍了 Resource[] resources 的获取，得到resources之后就是调用loadBeanDefinitions(resources);方法了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Load bean definitions from the specified resource location. * &lt;p&gt;The location can also be a location pattern, provided that the * ResourceLoader of this bean definition reader is a ResourcePatternResolver. * @param location the resource location, to be loaded with the ResourceLoader * (or ResourcePatternResolver) of this bean definition reader * @param actualResources a Set to be filled with the actual Resource objects * that have been resolved during the loading process. May be &#123;@code null&#125; * to indicate that the caller is not interested in those Resource objects. * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #getResourceLoader() * @see #loadBeanDefinitions(org.springframework.core.io.Resource) * @see #loadBeanDefinitions(org.springframework.core.io.Resource[]) */public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // Resource pattern matching available. try &#123; Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); // 解析BeanDefinition int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location pattern [\" + location + \"]\"); &#125; return loadCount; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex); &#125; &#125; else &#123; // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location [\" + location + \"]\"); &#125; return loadCount; &#125;&#125; loadBeanDefinitions(Resource resource)是XmlBeanDefinitionReader类的方法 1234567891011/** * Load bean definitions from the specified XML file. * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */@Overridepublic int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; // 对参数使用EncodedResource类进行封装，对资源文件的编码进行处理，考虑到Resource可能存在编码要求的情况 return loadBeanDefinitions(new EncodedResource(resource));&#125; 再跟进loadBeanDefinitions(new EncodedResource(resource));，可以看到我们熟悉的代码InputStream inputStream = encodedResource.getResource().getInputStream(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Load bean definitions from the specified XML file. * @param encodedResource the resource descriptor for the XML file, * allowing to specify an encoding to use for parsing the file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Loading XML bean definitions from \" + encodedResource.getResource()); &#125; // 通过属性来记录已经加载的资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &#125; try &#123; // 获取输入流 InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; // 构造 InputSource ，此类不是Spring的类 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 逻辑核心部分 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"IOException parsing XML document from \" + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; 进入核心代码doLoadBeanDefinitions(inputSource, encodedResource.getResource());，下面的方法得到了Document doc，Document对象是 org.w3c.dom包下的对象，是xml文件在Java中的表示 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Actually load bean definitions from the specified XML file. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #doLoadDocument * @see #registerBeanDefinitions */protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; // 加载XML文件得到Document Document doc = doLoadDocument(inputSource, resource); // 根据得到的Document注册Bean信息 return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &#125;&#125; 进入doLoadDocument(inputSource, resource);方法，此方法完成了 XML Resource =&gt; XML Document 的转化过程 12345678910111213141516171819/** * Actually load the specified document using the configured DocumentLoader. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the DOM Document * @throws Exception when thrown from the DocumentLoader * @see #setDocumentLoader * @see DocumentLoader#loadDocument */protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; /** * 委托了DocumentLoader来加载Document，具体实现: * @see DefaultDocumentLoader#loadDocument(org.xml.sax.InputSource, org.xml.sax.EntityResolver, org.xml.sax.ErrorHandler, int, boolean) * * getValidationModeForResource方法来获取对应资源的验证模式 */ return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware());&#125; getEntityResolver() 方法，返回指定的解析器，如果没有指定，则构造一个未指定的默认解析器。 何为EntityResolver？官网这样解释：如果 SAX 应用程序需要实现自定义处理外部实体，则必须实现此接口并使用 setEntityResolver 方法向SAX 驱动器注册一个实例。也就是说，对于解析一个XML，SAX 首先读取该 XML 文档上的声明，根据声明去寻找相应的 DTD 定义，以便对文档进行一个验证。默认的寻找规则，即通过网络（实现上就是声明的DTD的URI地址）来下载相应的DTD声明，并进行认证。下载的过程是一个漫长的过程，而且当网络中断或不可用时，这里会报错，就是因为相应的DTD声明没有被找到的原因。 EntityResolver 的作用是项目本身就可以提供一个如何寻找 DTD 声明的方法，即由程序来实现寻找 DTD 声明的过程，比如我们将 DTD 文件放到项目中某处，在实现时直接将此文档读取并返回给 SAX 即可。这样就避免了通过网络来寻找相应的声明。 getValidationModeForResource(resource)方法是来获取对应XML资源的验证模式，我们知道XML使用了DTD 与 XSD验证模式保证了 XML 文件的正确性 DTD 与 XSD 的区别 DTD (Document Type Definition)即文档类型 一个DTD文档包含：（1）元素的定义规则；（2）元素间关系的定义规则；（3）元素可使用的属性，可使用的实体或符号规则 .dtd文件，DTD基本语法：&lt;!ELEMENT NAME CONTENT&gt; 123456&lt;!ELEMENT 班级 (学生+)&gt;&lt;!ELEMENT 学生 (名字,年龄,介绍)&gt;&lt;!ELEMENT 名字 (#PCDATA)&gt;&lt;!ELEMENT 年龄 (#PCDATA)&gt;&lt;!ELEMENT 介绍 (#PCDATA)&gt; 使用DTD验证模式需要在XML文件的头部声明 12345678910&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!-- 引入dtd文件，约束这个xml --&gt;&lt;!DOCTYPE 班级 SYSTEM \"myclass.dtd\"&gt;&lt;班级&gt; &lt;学生&gt; &lt;名字&gt;周小星&lt;/名字&gt; &lt;年龄&gt;23&lt;/年龄&gt; &lt;介绍&gt;学习刻苦&lt;/介绍&gt; &lt;/学生&gt;&lt;/班级&gt; XSD (XML Schema)描述了XML文档的结构，可以用一个指定的XML Schema来验证某个XML XML Schema的优点: 1) XML Schema基于XML,没有专门的语法 2) XML Schema可以象其他XML文件一样解析和处理 3) XML Schema比DTD提供了更丰富的数据类型. 4) XML Schema提供可扩充的数据模型。 5) XML Schema支持综合命名空间 6) XML Schema支持属性组 XSD定义 1234567891011121314151617&lt;?xml version=\"1.0\"?&gt; &lt;xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"//在schema中用到的数据类型和元素来自此命名空间，并且来自此命名空间的元素以xs开头targetNamespace=\"http://www.w3school.com.cn\"//此shema定义的元素（note等）来自此命名空间xmlns=\"http://www.w3school.com.cn\"//默认的命名空间elementFormDefault=\"qualified\"&gt; &lt;xs:element name=\"note\"&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=\"to\" type=\"xs:string\"/&gt; &lt;xs:element name=\"from\" type=\"xs:string\"/&gt; &lt;xs:element name=\"heading\" type=\"xs:string\"/&gt; &lt;xs:element name=\"body\" type=\"xs:string\"/&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt;&lt;/xs:schema&gt; XSD使用 1234567891011&lt;?xml version=\"1.0\"?&gt;&lt;note xmlns=\"http://www.w3school.com.cn\" //默认命名空间xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" //可用的XML SCHEMAL实例命名空间 ---&gt;可以使用schemaLocationxsi:schemaLocation=\"http://www.w3school.com.cn note.xsd\"&gt; //schemaLacation两个属性：需要使用的命名空间 ；供命名空间使用的 XML schema 的位置&lt;to&gt;George&lt;/to&gt;&lt;from&gt;John&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Don't forget the meeting!&lt;/body&gt;&lt;/note&gt; registerBeanDefinitions(doc, resource);这行代码完成XML Document =&gt; Bean Definition的转化过程，这里涉及到另一个类BeanDefinitionDocumentReader，所以放到下一个章节介绍 /** * Register the bean definitions contained in the given DOM document. * Called by {@code loadBeanDefinitions}. * &lt;p&gt;Creates a new instance of the parser class and invokes * {@code registerBeanDefinitions} on it. * @param doc the DOM document * @param resource the resource descriptor (for context information) * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of parsing errors * @see #loadBeanDefinitions * @see #setDocumentReaderClass * @see BeanDefinitionDocumentReader#registerBeanDefinitions */ public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { /** * 使用DefaultBeanDefinitionDocumentReader实例化BeanDefinitionDocumentReader，在实例化BeanDefinitionDocumentReader的时候会将 * * @see DefaultBeanDefinitionDocumentReader * */ BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); // 记录统计前的BeanDefinition的加载个数 int countBefore = getRegistry().getBeanDefinitionCount(); // 加载并注册bean documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore; } 总结 XmlBeanDefinitionReader的总体功能是 XML Resource =&gt; XML Document =&gt; Bean Definition 的转化过程。由Resource得到Document对象，再由Document对象得到BeanDefinition对象 参考 https://blog.csdn.net/qq_17037733/article/details/80503560 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(三)Bean标签BeanDefinition","slug":"backend/framework/spring/analysis/Spring系列(三)Bean标签BeanDefinition","date":"2019-06-08T08:00:46.000Z","updated":"2019-09-16T13:11:04.994Z","comments":true,"path":"2019/06/08/backend/framework/spring/analysis/Spring系列(三)Bean标签BeanDefinition/","link":"","permalink":"http://www.songshuiyang.com/2019/06/08/backend/framework/spring/analysis/Spring系列(三)Bean标签BeanDefinition/","excerpt":"","text":"前言 解析 bean 标签的过程其实就是构造一个 BeanDefinition 对象的过程， 元素标签拥有的配置属性，BeanDefinition 均提供了相应的属性，与之一一对应。所以，我们有必要对 BeanDefinition 先有一个整体的认识。 BeanDefinition 的继承关系图 BeanDefinition123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253/** * 配置文件&lt;bean&gt;元素标签在容器中的内部表示形式 * * A BeanDefinition describes a bean instance, which has property values, * constructor argument values, and further information supplied by * concrete implementations. * * &lt;p&gt;This is just a minimal interface: The main intention is to allow a * &#123;@link BeanFactoryPostProcessor&#125; such as &#123;@link PropertyPlaceholderConfigurer&#125; * to introspect and modify property values and other bean metadata. * * @author Juergen Hoeller * @author Rob Harrop * @since 19.03.2004 * @see ConfigurableListableBeanFactory#getBeanDefinition * @see org.springframework.beans.factory.support.RootBeanDefinition * @see org.springframework.beans.factory.support.ChildBeanDefinition */public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement &#123; /** * Scope identifier for the standard singleton scope: \"singleton\". * &lt;p&gt;Note that extended bean factories might support further scopes. * @see #setScope */ String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; /** * Scope identifier for the standard prototype scope: \"prototype\". * &lt;p&gt;Note that extended bean factories might support further scopes. * @see #setScope */ String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; /** * Role hint indicating that a &#123;@code BeanDefinition&#125; is a major part * of the application. Typically corresponds to a user-defined bean. */ int ROLE_APPLICATION = 0; /** * Role hint indicating that a &#123;@code BeanDefinition&#125; is a supporting * part of some larger configuration, typically an outer * &#123;@link org.springframework.beans.factory.parsing.ComponentDefinition&#125;. * &#123;@code SUPPORT&#125; beans are considered important enough to be aware * of when looking more closely at a particular * &#123;@link org.springframework.beans.factory.parsing.ComponentDefinition&#125;, * but not when looking at the overall configuration of an application. */ int ROLE_SUPPORT = 1; /** * Role hint indicating that a &#123;@code BeanDefinition&#125; is providing an * entirely background role and has no relevance to the end-user. This hint is * used when registering beans that are completely part of the internal workings * of a &#123;@link org.springframework.beans.factory.parsing.ComponentDefinition&#125;. */ int ROLE_INFRASTRUCTURE = 2; // Modifiable attributes /** * Set the name of the parent definition of this bean definition, if any. */ void setParentName(String parentName); /** * Return the name of the parent definition of this bean definition, if any. */ String getParentName(); /** * Specify the bean class name of this bean definition. * &lt;p&gt;The class name can be modified during bean factory post-processing, * typically replacing the original class name with a parsed variant of it. * @see #setParentName * @see #setFactoryBeanName * @see #setFactoryMethodName */ void setBeanClassName(String beanClassName); /** * Return the current bean class name of this bean definition. * &lt;p&gt;Note that this does not have to be the actual class name used at runtime, in * case of a child definition overriding/inheriting the class name from its parent. * Also, this may just be the class that a factory method is called on, or it may * even be empty in case of a factory bean reference that a method is called on. * Hence, do &lt;i&gt;not&lt;/i&gt; consider this to be the definitive bean type at runtime but * rather only use it for parsing purposes at the individual bean definition level. * @see #getParentName() * @see #getFactoryBeanName() * @see #getFactoryMethodName() */ String getBeanClassName(); /** * Override the target scope of this bean, specifying a new scope name. * @see #SCOPE_SINGLETON * @see #SCOPE_PROTOTYPE */ void setScope(String scope); /** * Return the name of the current target scope for this bean, * or &#123;@code null&#125; if not known yet. */ String getScope(); /** * Set whether this bean should be lazily initialized. * &lt;p&gt;If &#123;@code false&#125;, the bean will get instantiated on startup by bean * factories that perform eager initialization of singletons. */ void setLazyInit(boolean lazyInit); /** * Return whether this bean should be lazily initialized, i.e. not * eagerly instantiated on startup. Only applicable to a singleton bean. */ boolean isLazyInit(); /** * Set the names of the beans that this bean depends on being initialized. * The bean factory will guarantee that these beans get initialized first. */ void setDependsOn(String... dependsOn); /** * Return the bean names that this bean depends on. */ String[] getDependsOn(); /** * Set whether this bean is a candidate for getting autowired into some other bean. * &lt;p&gt;Note that this flag is designed to only affect type-based autowiring. * It does not affect explicit references by name, which will get resolved even * if the specified bean is not marked as an autowire candidate. As a consequence, * autowiring by name will nevertheless inject a bean if the name matches. */ void setAutowireCandidate(boolean autowireCandidate); /** * Return whether this bean is a candidate for getting autowired into some other bean. */ boolean isAutowireCandidate(); /** * Set whether this bean is a primary autowire candidate. * &lt;p&gt;If this value is &#123;@code true&#125; for exactly one bean among multiple * matching candidates, it will serve as a tie-breaker. */ void setPrimary(boolean primary); /** * Return whether this bean is a primary autowire candidate. */ boolean isPrimary(); /** * Specify the factory bean to use, if any. * This the name of the bean to call the specified factory method on. * @see #setFactoryMethodName */ void setFactoryBeanName(String factoryBeanName); /** * Return the factory bean name, if any. */ String getFactoryBeanName(); /** * Specify a factory method, if any. This method will be invoked with * constructor arguments, or with no arguments if none are specified. * The method will be invoked on the specified factory bean, if any, * or otherwise as a static method on the local bean class. * @see #setFactoryBeanName * @see #setBeanClassName */ void setFactoryMethodName(String factoryMethodName); /** * Return a factory method, if any. */ String getFactoryMethodName(); /** * Return the constructor argument values for this bean. * &lt;p&gt;The returned instance can be modified during bean factory post-processing. * @return the ConstructorArgumentValues object (never &#123;@code null&#125;) */ ConstructorArgumentValues getConstructorArgumentValues(); /** * Return the property values to be applied to a new instance of the bean. * &lt;p&gt;The returned instance can be modified during bean factory post-processing. * @return the MutablePropertyValues object (never &#123;@code null&#125;) */ MutablePropertyValues getPropertyValues(); // Read-only attributes /** * Return whether this a &lt;b&gt;Singleton&lt;/b&gt;, with a single, shared instance * returned on all calls. * @see #SCOPE_SINGLETON */ boolean isSingleton(); /** * Return whether this a &lt;b&gt;Prototype&lt;/b&gt;, with an independent instance * returned for each call. * @see #SCOPE_PROTOTYPE */ boolean isPrototype(); /** * Return whether this bean is \"abstract\", that is, not meant to be instantiated. */ boolean isAbstract(); /** * Get the role hint for this &#123;@code BeanDefinition&#125;. The role hint * provides the frameworks as well as tools with an indication of * the role and importance of a particular &#123;@code BeanDefinition&#125;. * @see #ROLE_APPLICATION * @see #ROLE_SUPPORT * @see #ROLE_INFRASTRUCTURE */ int getRole(); /** * Return a human-readable description of this bean definition. */ String getDescription(); /** * Return a description of the resource that this bean definition * came from (for the purpose of showing context in case of errors). */ String getResourceDescription(); /** * Return the originating BeanDefinition, or &#123;@code null&#125; if none. * Allows for retrieving the decorated bean definition, if any. * &lt;p&gt;Note that this method returns the immediate originator. Iterate through the * originator chain to find the original BeanDefinition as defined by the user. */ BeanDefinition getOriginatingBeanDefinition();&#125; BeanDefinition 的父类 BeanDefinition 继承 AttributeAccessor 和 BeanMetadataElement 接口。两个接口定义如下： AttributeAccessor 定义了与其它对象的（元数据）进行连接和访问的约定，即对属性的修改，包括获取、设置、删除。 代码如下：123456789101112131415public interface AttributeAccessor &#123; void setAttribute(String name, @Nullable Object value); @Nullable Object getAttribute(String name); @Nullable Object removeAttribute(String name); boolean hasAttribute(String name); String[] attributeNames();&#125; BeanMetadataElement Bean 元对象持有的配置元素可以通过 #getSource() 方法来获取。 * 代码如下：123456public interface BeanMetadataElement &#123; @Nullable Object getSource();&#125; BeanDefinition 的子类 常用的三个实现类有： 123org.springframework.beans.factory.support.ChildBeanDefinitionorg.springframework.beans.factory.support.RootBeanDefinitionorg.springframework.beans.factory.support.GenericBeanDefinition ChildBeanDefinition、RootBeanDefinition、GenericBeanDefinition 三者都继承 AbstractBeanDefinition 抽象类，即 AbstractBeanDefinition 对三个子类的共同的类信息进行抽象。 AbstractBeanDefinition 是BeanDefinition的抽象基类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229/** * BeanDefinition的抽象基类 * * Base class for concrete, full-fledged &#123;@link BeanDefinition&#125; classes, * factoring out common properties of &#123;@link GenericBeanDefinition&#125;, * &#123;@link RootBeanDefinition&#125;, and &#123;@link ChildBeanDefinition&#125;. * * &lt;p&gt;The autowire constants match the ones defined in the * &#123;@link org.springframework.beans.factory.config.AutowireCapableBeanFactory&#125; * interface. * * @author Rod Johnson * @author Juergen Hoeller * @author Rob Harrop * @author Mark Fisher * @see GenericBeanDefinition * @see RootBeanDefinition * @see ChildBeanDefinition */@SuppressWarnings(\"serial\")public abstract class AbstractBeanDefinition extends BeanMetadataAttributeAccessor implements BeanDefinition, Cloneable &#123; /** * Constant for the default scope name: &#123;@code \"\"&#125;, equivalent to singleton * status unless overridden from a parent bean definition (if applicable). */ public static final String SCOPE_DEFAULT = \"\"; /** * Constant that indicates no autowiring at all. * @see #setAutowireMode */ public static final int AUTOWIRE_NO = AutowireCapableBeanFactory.AUTOWIRE_NO; /** * Constant that indicates autowiring bean properties by name. * @see #setAutowireMode */ public static final int AUTOWIRE_BY_NAME = AutowireCapableBeanFactory.AUTOWIRE_BY_NAME; /** * Constant that indicates autowiring bean properties by type. * @see #setAutowireMode */ public static final int AUTOWIRE_BY_TYPE = AutowireCapableBeanFactory.AUTOWIRE_BY_TYPE; /** * Constant that indicates autowiring a constructor. * @see #setAutowireMode */ public static final int AUTOWIRE_CONSTRUCTOR = AutowireCapableBeanFactory.AUTOWIRE_CONSTRUCTOR; /** * Constant that indicates determining an appropriate autowire strategy * through introspection of the bean class. * @see #setAutowireMode * @deprecated as of Spring 3.0: If you are using mixed autowiring strategies, * use annotation-based autowiring for clearer demarcation of autowiring needs. */ @Deprecated public static final int AUTOWIRE_AUTODETECT = AutowireCapableBeanFactory.AUTOWIRE_AUTODETECT; /** * Constant that indicates no dependency check at all. * @see #setDependencyCheck */ public static final int DEPENDENCY_CHECK_NONE = 0; /** * Constant that indicates dependency checking for object references. * @see #setDependencyCheck */ public static final int DEPENDENCY_CHECK_OBJECTS = 1; /** * Constant that indicates dependency checking for \"simple\" properties. * @see #setDependencyCheck * @see org.springframework.beans.BeanUtils#isSimpleProperty */ public static final int DEPENDENCY_CHECK_SIMPLE = 2; /** * Constant that indicates dependency checking for all properties * (object references as well as \"simple\" properties). * @see #setDependencyCheck */ public static final int DEPENDENCY_CHECK_ALL = 3; /** * Constant that indicates the container should attempt to infer the * &#123;@link #setDestroyMethodName destroy method name&#125; for a bean as opposed to * explicit specification of a method name. The value &#123;@value&#125; is specifically * designed to include characters otherwise illegal in a method name, ensuring * no possibility of collisions with legitimately named methods having the same * name. * &lt;p&gt;Currently, the method names detected during destroy method inference * are \"close\" and \"shutdown\", if present on the specific bean class. */ public static final String INFER_METHOD = \"(inferred)\"; private volatile Object beanClass; /** * bean属性scope */ private String scope = SCOPE_DEFAULT; /** * 是否是抽奖 */ private boolean abstractFlag = false; /** * 是否延迟加载 */ private boolean lazyInit = false; /** * 自动注入模式，对应bean属性autowire */ private int autowireMode = AUTOWIRE_NO; /** * 依赖检查 */ private int dependencyCheck = DEPENDENCY_CHECK_NONE; /** * 用来表示一个bean的实例化依靠另一个bean先实例化，对应bean属性depend-on */ private String[] dependsOn; private boolean autowireCandidate = true; /** * 首选bean */ private boolean primary = false; private final Map&lt;String, AutowireCandidateQualifier&gt; qualifiers = new LinkedHashMap&lt;String, AutowireCandidateQualifier&gt;(0); private boolean nonPublicAccessAllowed = true; private boolean lenientConstructorResolution = true; private String factoryBeanName; private String factoryMethodName; private ConstructorArgumentValues constructorArgumentValues; private MutablePropertyValues propertyValues; private MethodOverrides methodOverrides = new MethodOverrides(); private String initMethodName; private String destroyMethodName; private boolean enforceInitMethod = true; private boolean enforceDestroyMethod = true; private boolean synthetic = false; private int role = BeanDefinition.ROLE_APPLICATION; private String description; private Resource resource; /** * Create a new AbstractBeanDefinition with default settings. */ protected AbstractBeanDefinition() &#123; this(null, null); &#125; /** * Create a new AbstractBeanDefinition with the given * constructor argument values and property values. */ protected AbstractBeanDefinition(ConstructorArgumentValues cargs, MutablePropertyValues pvs) &#123; setConstructorArgumentValues(cargs); setPropertyValues(pvs); &#125; /** * Create a new AbstractBeanDefinition as a deep copy of the given * bean definition. * @param original the original bean definition to copy from */ protected AbstractBeanDefinition(BeanDefinition original) &#123; setParentName(original.getParentName()); setBeanClassName(original.getBeanClassName()); setScope(original.getScope()); setAbstract(original.isAbstract()); setLazyInit(original.isLazyInit()); setFactoryBeanName(original.getFactoryBeanName()); setFactoryMethodName(original.getFactoryMethodName()); setConstructorArgumentValues(new ConstructorArgumentValues(original.getConstructorArgumentValues())); setPropertyValues(new MutablePropertyValues(original.getPropertyValues())); setRole(original.getRole()); setSource(original.getSource()); copyAttributesFrom(original); if (original instanceof AbstractBeanDefinition) &#123; AbstractBeanDefinition originalAbd = (AbstractBeanDefinition) original; if (originalAbd.hasBeanClass()) &#123; setBeanClass(originalAbd.getBeanClass()); &#125; setAutowireMode(originalAbd.getAutowireMode()); setDependencyCheck(originalAbd.getDependencyCheck()); setDependsOn(originalAbd.getDependsOn()); setAutowireCandidate(originalAbd.isAutowireCandidate()); setPrimary(originalAbd.isPrimary()); copyQualifiersFrom(originalAbd); setNonPublicAccessAllowed(originalAbd.isNonPublicAccessAllowed()); setLenientConstructorResolution(originalAbd.isLenientConstructorResolution()); setMethodOverrides(new MethodOverrides(originalAbd.getMethodOverrides())); setInitMethodName(originalAbd.getInitMethodName()); setEnforceInitMethod(originalAbd.isEnforceInitMethod()); setDestroyMethodName(originalAbd.getDestroyMethodName()); setEnforceDestroyMethod(originalAbd.isEnforceDestroyMethod()); setSynthetic(originalAbd.isSynthetic()); setResource(originalAbd.getResource()); &#125; else &#123; setResourceDescription(original.getResourceDescription()); &#125; &#125; 如果配置文件中定义了父bean 和 子bean ，则父bean用 RootBeanDefinition 表示，子bean用 ChildBeanDefinition 表示，而没有父bean的就使用RootBeanDefinition 表示。 GenericBeanDefinition 为一站式服务类。 BeanDefinition 注册表：BeanDefinitionRegistry 将Bean 的资源文件解析成 BeanDefinition 后需要将其注入容器中，这个过程由 BeanDefinitionRegistry 来完成。 BeanDefinitionRegistry 接口 12345678910111213141516171819202122/** * 定义了对 BeanDefinition 的各种增删改查操作 * Spring bean配置信息的内存数据库，以map的形式保存 * */public interface BeanDefinitionRegistry extends AliasRegistry &#123; void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException; void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; BeanDefinition getBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; boolean containsBeanDefinition(String beanName); String[] getBeanDefinitionNames(); int getBeanDefinitionCount(); boolean isBeanNameInUse(String beanName);&#125; 下图是 BeanDefinitionRegistry 类结构图 子类 SimpleBeanDefinitionRegistry SimpleBeanDefinitionRegistry 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 对BeanDefinitionRegistry的基本实现，提供了beanDefinitionMap Map作为BeanDefinition的容器 * 下面的方法就是对map的增删改查 * * Simple implementation of the &#123;@link BeanDefinitionRegistry&#125; interface. * Provides registry capabilities only, with no factory capabilities built in. * Can for example be used for testing bean definition readers. * * @author Juergen Hoeller * @since 2.5.2 */public class SimpleBeanDefinitionRegistry extends SimpleAliasRegistry implements BeanDefinitionRegistry &#123; /** Map of bean definition objects, keyed by bean name */ private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;(64); @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, \"'beanName' must not be empty\"); Assert.notNull(beanDefinition, \"BeanDefinition must not be null\"); this.beanDefinitionMap.put(beanName, beanDefinition); &#125; @Override public void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException &#123; if (this.beanDefinitionMap.remove(beanName) == null) &#123; throw new NoSuchBeanDefinitionException(beanName); &#125; &#125; @Override public BeanDefinition getBeanDefinition(String beanName) throws NoSuchBeanDefinitionException &#123; BeanDefinition bd = this.beanDefinitionMap.get(beanName); if (bd == null) &#123; throw new NoSuchBeanDefinitionException(beanName); &#125; return bd; &#125; @Override public boolean containsBeanDefinition(String beanName) &#123; return this.beanDefinitionMap.containsKey(beanName); &#125; @Override public String[] getBeanDefinitionNames() &#123; return StringUtils.toStringArray(this.beanDefinitionMap.keySet()); &#125; @Override public int getBeanDefinitionCount() &#123; return this.beanDefinitionMap.size(); &#125; @Override public boolean isBeanNameInUse(String beanName) &#123; return isAlias(beanName) || containsBeanDefinition(beanName); &#125;&#125; 总结 类名、scope、属性、构造函数参数列表、依赖的bean、是否是单例类、是否是懒加载等，其实就是将Bean的定义信息存储到这个BeanDefinition相应的属性中，后面对Bean的操作就直接对BeanDefinition进行 拿到这个BeanDefinition后，可以根据里面的类名、构造函数、构造函数参数，使用反射进行对象创建。 下面的章节将介绍BeanDefinition的构建 参考 《Spring 源码深度解析》 芋道源码 http://www.iocoder.cn","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(二)装载配置文件Resource","slug":"backend/framework/spring/analysis/Spring系列(二)装载配置文件Resource","date":"2019-05-12T15:00:44.000Z","updated":"2019-09-16T13:11:05.043Z","comments":true,"path":"2019/05/12/backend/framework/spring/analysis/Spring系列(二)装载配置文件Resource/","link":"","permalink":"http://www.songshuiyang.com/2019/05/12/backend/framework/spring/analysis/Spring系列(二)装载配置文件Resource/","excerpt":"","text":"前言 测试类 12345678public class ClassPathXmlApplicationContextTest &#123; @Test public void classPathXmlApplicationContext () &#123; ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(\"beans/bean.xml\"); User user = xmlApplicationContext.getBean(User.class); &#125;&#125; 关注ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(&quot;beans/bean.xml&quot;); 这行代码可以看到是传入了一个文件的相对路径地址，我们可以猜到里面的逻辑是读取配置文件beans/bean.xml，解析并构造成需要的对象 那么Spring是怎样加载配置文件的呢，本章内容就是介绍Spring的资源加载设计及实现的一些知识，然后再通过断点调试来跟进上面这行代码是怎么实现资源加载的 在学Java SE的时候，我们学习了一个标准类 java.net.URL，该类在 Java SE 中的定位为统一资源定位器（Uniform Resource Locator） 我们知道它的实现基本只限于网络形式发布的资源的查找和定位 然而，实际上资源的定义比较广泛，除了网络形式的资源，还有以二进制形式存在的、以文件形式存在的、以字节流形式存在的等等,而且它可以存在于任何场所，比如网络、文件系统、应用程序中 所以 java.net.URL 的局限性迫使 Spring 必须实现自己的资源加载策略 Jdk没有轮子那么Spring自己造 Spring 提供了 Resource 和 ResourceLoader 来统一抽象整个资源及其定位。使得资源与资源的定位有了一个更加清晰的界限，并且提供了合适的 Default 类，使得自定义实现更加方便和清晰。 资源的定义Resource Spring 定义了一个 org.springframework.core.io.Resource 接口，Resource 接口是为了统一各种类型不同的资源而定义的，Spring 提供了若干 Resource 接口的实现类， 由子类 AbstractResource 提供统一的默认实现，这些实现类可以轻松地加载不同类型的底层资源，并提供了获取文件名、URL 地址以及资源内容的操作方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public interface Resource extends InputStreamSource &#123; /** * 资源是否存在 */ boolean exists(); /** * 资源是否可读 */ default boolean isReadable() &#123; return true; &#125; /** * 资源所代表的句柄是否被一个 stream 打开了 */ default boolean isOpen() &#123; return false; &#125; /** * 是否为 File */ default boolean isFile() &#123; return false; &#125; /** * 返回资源的 URL 的句柄 */ URL getURL() throws IOException; /** * 返回资源的 URI 的句柄 */ URI getURI() throws IOException; /** * 返回资源的 File 的句柄 */ File getFile() throws IOException; /** * 返回 ReadableByteChannel */ default ReadableByteChannel readableChannel() throws IOException &#123; return java.nio.channels.Channels.newChannel(getInputStream()); &#125; /** * 资源内容的长度 */ long contentLength() throws IOException; /** * 资源最后的修改时间 */ long lastModified() throws IOException; /** * 根据资源的相对路径创建新资源 */ Resource createRelative(String relativePath) throws IOException; /** * 资源的文件名 */ @Nullable String getFilename(); /** * 资源的描述 */ String getDescription();&#125; Resource 根据资源的不同类型提供不同子类的具体实现，如下: 抽象基类 AbstractResource 这个类是Resource 接口的默认抽象实现，如果我们想自定义Resource，继承该接口重写对应的方法就可以很方便自定义 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207/** * Convenience base class for &#123;@link Resource&#125; implementations, * pre-implementing typical behavior. * * &lt;p&gt;The \"exists\" method will check whether a File or InputStream can * be opened; \"isOpen\" will always return false; \"getURL\" and \"getFile\" * throw an exception; and \"toString\" will return the description. * * @author Juergen Hoeller * @since 28.12.2003 */public abstract class AbstractResource implements Resource &#123; /** * 判断文件是否存在，若判断过程产生异常（因为会调用SecurityManager来判断），就关闭对应的流 * * This implementation checks whether a File can be opened, * falling back to whether an InputStream can be opened. * This will cover both directories and content resources. */ @Override public boolean exists() &#123; // Try file existence: can we find the file in the file system? 基于 File 进行判断 try &#123; return getFile().exists(); &#125; catch (IOException ex) &#123; // Fall back to stream existence: can we open the stream? 基于 InputStream 进行判断 try &#123; InputStream is = getInputStream(); is.close(); return true; &#125; catch (Throwable isEx) &#123; return false; &#125; &#125; &#125; /** * 直接返回true，表示可读 * This implementation always returns &#123;@code true&#125;. */ @Override public boolean isReadable() &#123; return true; &#125; /** * 直接返回 false，表示未被打开 * This implementation always returns &#123;@code false&#125;. */ @Override public boolean isOpen() &#123; return false; &#125; /** * 抛出 FileNotFoundException 异常，交给子类实现 * * This implementation throws a FileNotFoundException, assuming * that the resource cannot be resolved to a URL. */ @Override public URL getURL() throws IOException &#123; throw new FileNotFoundException(getDescription() + \" cannot be resolved to URL\"); &#125; /** * 基于 getURL() 返回的 URL 构建 URI * * This implementation builds a URI based on the URL returned * by &#123;@link #getURL()&#125;. */ @Override public URI getURI() throws IOException &#123; URL url = getURL(); try &#123; return ResourceUtils.toURI(url); &#125; catch (URISyntaxException ex) &#123; throw new NestedIOException(\"Invalid URI [\" + url + \"]\", ex); &#125; &#125; /** * 直接返回false，表示不为 File * * This implementation throws a FileNotFoundException, assuming * that the resource cannot be resolved to an absolute file path. */ @Override public File getFile() throws IOException &#123; throw new FileNotFoundException(getDescription() + \" cannot be resolved to absolute file path\"); &#125; /** * 获取资源的长度 * * 这个资源内容长度实际就是资源的字节长度，通过全部读取一遍来判断 * * This implementation reads the entire InputStream to calculate the * content length. Subclasses will almost always be able to provide * a more optimal version of this, e.g. checking a File length. * @see #getInputStream() */ @Override public long contentLength() throws IOException &#123; InputStream is = getInputStream(); Assert.state(is != null, \"Resource InputStream must not be null\"); try &#123; long size = 0; byte[] buf = new byte[255]; int read; while ((read = is.read(buf)) != -1) &#123; size += read; &#125; return size; &#125; finally &#123; try &#123; is.close(); &#125; catch (IOException ex) &#123; &#125; &#125; &#125; /** * 返回资源最后的修改时间 * * This implementation checks the timestamp of the underlying File, * if available. * @see #getFileForLastModifiedCheck() */ @Override public long lastModified() throws IOException &#123; long lastModified = getFileForLastModifiedCheck().lastModified(); if (lastModified == 0L) &#123; throw new FileNotFoundException(getDescription() + \" cannot be resolved in the file system for resolving its last-modified timestamp\"); &#125; return lastModified; &#125; /** * Determine the File to use for timestamp checking. * &lt;p&gt;The default implementation delegates to &#123;@link #getFile()&#125;. * @return the File to use for timestamp checking (never &#123;@code null&#125;) * @throws FileNotFoundException if the resource cannot be resolved as * an absolute file path, i.e. is not available in a file system * @throws IOException in case of general resolution/reading failures */ protected File getFileForLastModifiedCheck() throws IOException &#123; return getFile(); &#125; /** * 抛出 FileNotFoundException 异常，交给子类实现 * * This implementation throws a FileNotFoundException, assuming * that relative resources cannot be created for this resource. */ @Override public Resource createRelative(String relativePath) throws IOException &#123; throw new FileNotFoundException(\"Cannot create a relative resource for \" + getDescription()); &#125; /** * 获取资源名称，默认返回 null ，交给子类实现 * * This implementation always returns &#123;@code null&#125;, * assuming that this resource type does not have a filename. */ @Override public String getFilename() &#123; return null; &#125; /** * This implementation returns the description of this resource. * @see #getDescription() */ @Override public String toString() &#123; return getDescription(); &#125; /** * This implementation compares description strings. * @see #getDescription() */ @Override public boolean equals(Object obj) &#123; return (obj == this || (obj instanceof Resource &amp;&amp; ((Resource) obj).getDescription().equals(getDescription()))); &#125; /** * This implementation returns the description's hash code. * @see #getDescription() */ @Override public int hashCode() &#123; return getDescription().hashCode(); &#125; 子类解析 通过 FileSystemResource 以文件系统绝对路径的方式进行访问，对 java.io.File 类型资源的封装，只要是跟 File 打交道的，基本上与 FileSystemResource 也可以打交道； 成员变量及构造方法12345678910111213141516public class FileSystemResource extends AbstractResource implements WritableResource &#123; private final File file; private final String path; public FileSystemResource(File file) &#123; Assert.notNull(file, \"File must not be null\"); this.file = file; this.path = StringUtils.cleanPath(file.getPath()); &#125; public FileSystemResource(String path) &#123; Assert.notNull(path, \"Path must not be null\"); this.file = new File(path); this.path = StringUtils.cleanPath(path); &#125; 通过 ByteArrayResource 对字节数组提供的数据的封装。如果通过 InputStream 形式访问该类型的资源，该实现会根据字节数组的数据构造一个相应的 ByteArrayInputStream。 成员变量及构造方法1234567891011121314151617public class ByteArrayResource extends AbstractResource &#123; private final byte[] byteArray; private final String description; public ByteArrayResource(byte[] byteArray) &#123; this(byteArray, \"resource loaded from byte array\"); &#125; public ByteArrayResource(byte[] byteArray, String description) &#123; if (byteArray == null) &#123; throw new IllegalArgumentException(\"Byte array must not be null\"); &#125; this.byteArray = byteArray; this.description = (description != null ? description : \"\"); &#125; 通过 UrlResource 对 java.net.URL类型资源的封装。内部委派 URL 进行具体的资源操作。 成员变量及构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445public class UrlResource extends AbstractFileResolvingResource &#123; private final URI uri; private final URL url; private final URL cleanedUrl; public UrlResource(URI uri) throws MalformedURLException &#123; Assert.notNull(uri, \"URI must not be null\"); this.uri = uri; this.url = uri.toURL(); this.cleanedUrl = getCleanedUrl(this.url, uri.toString()); &#125; public UrlResource(URL url) &#123; Assert.notNull(url, \"URL must not be null\"); this.url = url; this.cleanedUrl = getCleanedUrl(this.url, url.toString()); this.uri = null; &#125; public UrlResource(String path) throws MalformedURLException &#123; Assert.notNull(path, \"Path must not be null\"); this.uri = null; this.url = new URL(path); this.cleanedUrl = getCleanedUrl(this.url, path); &#125; public UrlResource(String protocol, String location) throws MalformedURLException &#123; this(protocol, location, null); &#125; public UrlResource(String protocol, String location, String fragment) throws MalformedURLException &#123; try &#123; this.uri = new URI(protocol, location, fragment); this.url = this.uri.toURL(); this.cleanedUrl = getCleanedUrl(this.url, this.uri.toString()); &#125; catch (URISyntaxException ex) &#123; MalformedURLException exToThrow = new MalformedURLException(ex.getMessage()); exToThrow.initCause(ex); throw exToThrow; &#125; &#125; 通过 ClassPathResource 以类路径的方式进行访问,class path 类型资源的实现。使用给定的 ClassLoader 或者给定的 Class 来加载资源。 成员变量及构造方法123456789101112131415161718192021222324252627282930313233public class ClassPathResource extends AbstractFileResolvingResource &#123; private final String path; private ClassLoader classLoader; private Class&lt;?&gt; clazz; public ClassPathResource(String path) &#123; this(path, (ClassLoader) null); &#125; public ClassPathResource(String path, ClassLoader classLoader) &#123; Assert.notNull(path, \"Path must not be null\"); String pathToUse = StringUtils.cleanPath(path); if (pathToUse.startsWith(\"/\")) &#123; pathToUse = pathToUse.substring(1); &#125; this.path = pathToUse; this.classLoader = (classLoader != null ? classLoader : ClassUtils.getDefaultClassLoader()); &#125; public ClassPathResource(String path, Class&lt;?&gt; clazz) &#123; Assert.notNull(path, \"Path must not be null\"); this.path = StringUtils.cleanPath(path); this.clazz = clazz; &#125; protected ClassPathResource(String path, ClassLoader classLoader, Class&lt;?&gt; clazz) &#123; this.path = StringUtils.cleanPath(path); this.classLoader = classLoader; this.clazz = clazz; &#125; 通过 InputStreamResource 将给定的 InputStream 作为一种资源的 Resource 的实现类。 成员变量及构造方法12345678910111213141516171819public class InputStreamResource extends AbstractResource &#123; private final InputStream inputStream; private final String description; private boolean read = false; public InputStreamResource(InputStream inputStream) &#123; this(inputStream, \"resource loaded through InputStream\"); &#125; public InputStreamResource(InputStream inputStream, String description) &#123; if (inputStream == null) &#123; throw new IllegalArgumentException(\"InputStream must not be null\"); &#125; this.inputStream = inputStream; this.description = (description != null ? description : \"\"); &#125; 通过 ServletContextResource 以相对于 Web 应用根目录的方式进行访问。 成员变量及构造方法12345678910111213141516171819public class ServletContextResource extends AbstractFileResolvingResource implements ContextResource &#123; private final ServletContext servletContext; private final String path; public ServletContextResource(ServletContext servletContext, String path) &#123; // check ServletContext Assert.notNull(servletContext, \"Cannot resolve ServletContextResource without ServletContext\"); this.servletContext = servletContext; // check path Assert.notNull(path, \"Path is required\"); String pathToUse = StringUtils.cleanPath(path); if (!pathToUse.startsWith(\"/\")) &#123; pathToUse = \"/\" + pathToUse; &#125; this.path = pathToUse; &#125; 示例代码 1234567891011121314@Testpublic void createFileSystemResourceByFile() throws Exception &#123; File file = new File(\"D://1.txt\"); FileSystemResource fileSystemResource = new FileSystemResource(file);&#125;@Testpublic void createFileSystemResourceByPath() throws Exception &#123; FileSystemResource fileSystemResource = new FileSystemResource(\"D://1.txt\");&#125;@Testpublic void createClassPathResourceByFile() throws Exception &#123; ClassPathResource classPathResource = new ClassPathResource(\"beans/bean.xml\");&#125; 统一资源定位 ResourceLoader 一开始就说了 Spring 将资源的定义和资源的加载区分开了，Resource 定义了统一的资源，那资源的加载则由 ResourceLoader 来统一定义。 org.springframework.core.io.ResourceLoader 为 Spring 资源加载的统一抽象，具体的资源加载则由相应的实现类来完成，所以我们可以将 ResourceLoader 称作为统一资源定位器 ,主要应用于根据给定的资源文件地址，返回对应的 Resource 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * 定义资源加载器，主要应用于根据给定的资源文件地址返回对应的 Resource * * Strategy interface for loading resources (e.. class path or file system * resources). An &#123;@link org.springframework.context.ApplicationContext&#125; * is required to provide this functionality, plus extended * &#123;@link org.springframework.core.io.support.ResourcePatternResolver&#125; support. * * &lt;p&gt;&#123;@link DefaultResourceLoader&#125; is a standalone implementation that is * usable outside an ApplicationContext, also used by &#123;@link ResourceEditor&#125;. * * &lt;p&gt;Bean properties of type Resource and Resource array can be populated * from Strings when running in an ApplicationContext, using the particular * context's resource loading strategy. * * @author Juergen Hoeller * @since 10.03.2004 * @see Resource * @see org.springframework.core.io.support.ResourcePatternResolver * @see org.springframework.context.ApplicationContext * @see org.springframework.context.ResourceLoaderAware */public interface ResourceLoader &#123; /** Pseudo URL prefix for loading from the class path: \"classpath:\" */ String CLASSPATH_URL_PREFIX = ResourceUtils.CLASSPATH_URL_PREFIX; /** * 据所提供资源的路径 location 返回 Resource 实例，但是它不确保该 Resource 一定存在，需要调用 Resource#exist() 方法来判断。 * 该方法支持以下模式的资源加载： * URL位置资源，如 \"file:C:/test.dat\" * ClassPath位置资源，如 \"classpath:test.dat\". * 相对路径资源，如 \"WEB-INF/test.dat\" * Return a Resource handle for the specified resource location. * &lt;p&gt;The handle should always be a reusable resource descriptor, * allowing for multiple &#123;@link Resource#getInputStream()&#125; calls. * &lt;p&gt;&lt;ul&gt; * &lt;li&gt;Must support fully qualified URLs, e.g. \"file:C:/test.dat\". * &lt;li&gt;Must support classpath pseudo-URLs, e.g. \"classpath:test.dat\". * &lt;li&gt;Should support relative file paths, e.g. \"WEB-INF/test.dat\". * (This will be implementation-specific, typically provided by an * ApplicationContext implementation.) * &lt;/ul&gt; * &lt;p&gt;Note that a Resource handle does not imply an existing resource; * you need to invoke &#123;@link Resource#exists&#125; to check for existence. * @param location the resource location * @return a corresponding Resource handle (never &#123;@code null&#125;) * @see #CLASSPATH_URL_PREFIX * @see Resource#exists() * @see Resource#getInputStream() */ Resource getResource(String location); /** * 返回 ClassLoader 实例，对于想要获取 ResourceLoader 使用的 ClassLoader 用户来说，可以直接调用该方法来获取。 * * Expose the ClassLoader used by this ResourceLoader. * &lt;p&gt;Clients which need to access the ClassLoader directly can do so * in a uniform manner with the ResourceLoader, rather than relying * on the thread context ClassLoader. * @return the ClassLoader (only &#123;@code null&#125; if even the system * ClassLoader isn't accessible) * @see org.springframework.util.ClassUtils#getDefaultClassLoader() */ ClassLoader getClassLoader();&#125; ResourceLoader.java 类继承结构 子类结构 DefaultResourceLoader 与 AbstractResource 相似，org.springframework.core.io.DefaultResourceLoader 是 ResourceLoader 的默认实现。 getResource 方法 ResourceLoader 中最核心的方法为 #getResource(String location) ，它根据提供的 location 返回相应的 Resource 。而 DefaultResourceLoader 对该方法提供了核心实现（因为，它的两个子类都没有提供覆盖该方法，所以可以断定 ResourceLoader 的资源加载策略就封装在 DefaultResourceLoader 中)，12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 可以看到Resource的加载获取是有顺序的，谁先获得就先返回 * 1、首先，通过 ProtocolResolver 来加载资源，为什么要这个呢，它允许用户自定义资源加载协议， * 而不需要继承 ResourceLoader 的子类。ProtocolResolver 接口，仅有一个方法resolve，实现该方法 * 就可以自己实现资源加载， * 2、以 / 开头，返回 ClassPathContextResource 类型的资源 * 3、以 classpath: 开头，返回 ClassPathResource 类型的资源 * 4、加载URL资源文件 * 5、上一步没有找到，抛异常 ，就是返回 ClassPathContextResource 类型的资源 * @param location the resource location * @return */@Overridepublic Resource getResource(String location) &#123; Assert.notNull(location, \"Location must not be null\"); /** * 首先，通过 ProtocolResolver 来加载资源， * @see #protocolResolvers * 调用方法 &#123;@link DefaultResourceLoader#addProtocolResolver(ProtocolResolver)&#125; 即可添加 */ for (ProtocolResolver protocolResolver : this.protocolResolvers) &#123; Resource resource = protocolResolver.resolve(location, this); if (resource != null) &#123; return resource; &#125; &#125; // 其次，以 / 开头，返回 ClassPathContextResource 类型的资源 if (location.startsWith(\"/\")) &#123; return getResourceByPath(location); &#125; // 再次，以 classpath: 开头，返回 ClassPathResource 类型的资源 else if (location.startsWith(CLASSPATH_URL_PREFIX)) &#123; return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); &#125; else &#123; // 然后，根据是否为文件 URL ，是则返回 FileUrlResource 类型的资源，否则返回 UrlResource 类型的资源 try &#123; // Try to parse the location as a URL... URL url = new URL(location); return new UrlResource(url); &#125; catch (MalformedURLException ex) &#123; // No URL -&gt; resolve as resource path. 最后，返回 ClassPathContextResource 类型的资源 return getResourceByPath(location); &#125; &#125;&#125; FileSystemResourceLoader 它继承 DefaultResourceLoader ，且覆写了 #getResourceByPath(String) 方法，使之从文件系统加载资源并以 FileSystemResource 类型返回，这样我们就可以得到想要的资源类型 ClassRelativeResourceLoader ClassRelativeResourceLoader 扩展的功能是，可以根据给定的class 所在包或者所在包的子包下加载资源。 是 DefaultResourceLoader 的另一个子类的实现。和 FileSystemResourceLoader 类似，在实现代码的结构上类似，也是覆写 #getResourceByPath(String path) 方法，并返回其对应的 ClassRelativeContextResource 的资源类型。 ResourcePatternResolver ResourceLoader 的 Resource getResource(String location) 方法，每次只能根据 location 返回一个 Resource 。当需要加载多个资源时，我们除了多次调用 #getResource(String location) 方法外，别无他法 ResourcePatternResolver 是 ResourceLoader 的扩展，它支持根据指定的资源路径匹配模式每次返回多个 Resource 实例，其定义如下： 123456789101112131415161718192021 public interface ResourcePatternResolver extends ResourceLoader &#123; String CLASSPATH_ALL_URL_PREFIX = \"classpath*:\"; Resource[] getResources(String locationPattern) throws IOException; &#125; ``` * ResourcePatternResolver 在 ResourceLoader 的基础上增加了 #getResources(String locationPattern) 方法，以支持根据路径匹配模式返回多个 Resource 实例。 * 同时，也新增了一种新的协议前缀 \"classpath*:\"，该协议前缀由其子类负责实现。* PathMatchingResourcePatternResolver * 为 ResourcePatternResolver 最常用的子类，它除了支持 ResourceLoader 和 ResourcePatternResolver 新增的 \"classpath*:\" 前缀外，还支持 Ant 风格的路径匹配模式（类似于 \"**/*.xml\"）。 * getResource() 该方法，直接委托给相应的 ResourceLoader 来实现。所以，如果我们在实例化的 PathMatchingResourcePatternResolver 的时候，如果未指定 ResourceLoader 参数的情况下，那么在加载资源时，其实就是 DefaultResourceLoader 的过程。 ```java @Override public Resource getResource(String location) &#123; return getResourceLoader().getResource(location); &#125; public ResourceLoader getResourceLoader() &#123; return this.resourceLoader; &#125; getResources() 方法，返回的资源是多个 非 “classpath*:” 开头，且路径不包含通配符，直接委托给相应的 ResourceLoader 来实现，只能加载找到的第一个文件 其他情况，调用 #findAllClassPathResources(…)、或 #findPathMatchingResources(…) 方法，返回多个 Resource 使用classpath*:与classpath:加载资源的结果是不一样的，如果有通配符的话更复杂 123456789101112131415161718192021222324252627282930313233343536373839/** * Spring可以通过指定classpath*:与classpath:前缀加路径的方式从classpath加载文件, * 如bean的定义文件.classpath*:的出现是为了从多个jar文件中加载相同的文件，.classpath:只能加载找到的第一个文件. * @param locationPattern the location pattern to resolve * @return * @throws IOException */@Overridepublic Resource[] getResources(String locationPattern) throws IOException &#123; Assert.notNull(locationPattern, \"Location pattern must not be null\"); // 以 \"classpath*:\" 开头 if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) &#123; // 路径包含通配符 // a class path resource (multiple resources for same name possible) if (getPathMatcher().isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) &#123; // a class path resource pattern return findPathMatchingResources(locationPattern); &#125; else &#123; // 路径不包含通配符，该方法返回 classes 路径下和所有 jar 包中的所有相匹配的资源。 // all class path resources with the given name return findAllClassPathResources(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length())); &#125; &#125; // 不以 \"classpath*:\" 开头 else &#123; // Generally only look for a pattern after a prefix here, // and on Tomcat only after the \"*/\" separator for its \"war:\" protocol. int prefixEnd = (locationPattern.startsWith(\"war:\") ? locationPattern.indexOf(\"*/\") + 1 : locationPattern.indexOf(\":\") + 1); if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) &#123; // a file pattern return findPathMatchingResources(locationPattern); &#125; else &#123; // a single resource with the given name return new Resource[] &#123;getResourceLoader().getResource(locationPattern)&#125;; &#125; &#125;&#125; 方法讲解 findPathMatchingResources 方法 当 locationPattern 中包含了通配符，则调用该方法进行资源加载1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 确定目录，获取该目录下得所有资源。在所获得的所有资源后，进行迭代匹配获取我们想要的资源。 * * Find all resources that match the given location pattern via the * Ant-style PathMatcher. Supports resources in jar files and zip files * and in the file system. * @param locationPattern the location pattern to match * @return the result as Resource array * @throws IOException in case of I/O errors * @see #doFindPathMatchingJarResources * @see #doFindPathMatchingFileResources * @see org.springframework.util.PathMatcher */protected Resource[] findPathMatchingResources(String locationPattern) throws IOException &#123; // 确定根路径、子路径 String rootDirPath = determineRootDir(locationPattern); String subPattern = locationPattern.substring(rootDirPath.length()); // 获取根据路径下的资源 Resource[] rootDirResources = getResources(rootDirPath); // 遍历，迭代 Set&lt;Resource&gt; result = new LinkedHashSet&lt;Resource&gt;(16); for (Resource rootDirResource : rootDirResources) &#123; rootDirResource = resolveRootDirResource(rootDirResource); URL rootDirURL = rootDirResource.getURL(); // bundle 资源类型 if (equinoxResolveMethod != null) &#123; if (rootDirURL.getProtocol().startsWith(\"bundle\")) &#123; rootDirURL = (URL) ReflectionUtils.invokeMethod(equinoxResolveMethod, null, rootDirURL); rootDirResource = new UrlResource(rootDirURL); &#125; &#125; // vfs 资源类型 if (rootDirURL.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) &#123; result.addAll(VfsResourceMatchingDelegate.findMatchingResources(rootDirURL, subPattern, getPathMatcher())); &#125; // jar 资源类型 else if (ResourceUtils.isJarURL(rootDirURL) || isJarResource(rootDirResource)) &#123; result.addAll(doFindPathMatchingJarResources(rootDirResource, rootDirURL, subPattern)); &#125; // 其它资源类型 else &#123; result.addAll(doFindPathMatchingFileResources(rootDirResource, subPattern)); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Resolved location pattern [\" + locationPattern + \"] to resources \" + result); &#125; // 转换成 Resource 数组返回 return result.toArray(new Resource[result.size()]);&#125; findAllClassPathResources 方法 当 locationPattern 以 “classpath*:” 开头但是不包含通配符则调用此方法，该方法返回 classes 路径下和所有 jar 包中的所有相匹配的资源。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Find all class location resources with the given location via the ClassLoader. * Delegates to &#123;@link #doFindAllClassPathResources(String)&#125;. * @param location the absolute path within the classpath * @return the result as Resource array * @throws IOException in case of I/O errors * @see java.lang.ClassLoader#getResources * @see #convertClassLoaderURL */protected Resource[] findAllClassPathResources(String location) throws IOException &#123; // 去除首个 / String path = location; if (path.startsWith(\"/\")) &#123; path = path.substring(1); &#125; // 真正执行加载所有 classpath 资源 Set&lt;Resource&gt; result = doFindAllClassPathResources(path); if (logger.isDebugEnabled()) &#123; logger.debug(\"Resolved classpath location [\" + location + \"] to resources \" + result); &#125; // 转换成 Resource 数组返回 return result.toArray(new Resource[result.size()]);&#125;/** * Find all class location resources with the given path via the ClassLoader. * Called by &#123;@link #findAllClassPathResources(String)&#125;. * @param path the absolute path within the classpath (never a leading slash) * @return a mutable Set of matching Resource instances * @since 4.1.1 */protected Set&lt;Resource&gt; doFindAllClassPathResources(String path) throws IOException &#123; Set&lt;Resource&gt; result = new LinkedHashSet&lt;Resource&gt;(16); ClassLoader cl = getClassLoader(); // 根据 ClassLoader 加载路径下的所有资源 Enumeration&lt;URL&gt; resourceUrls = (cl != null ? cl.getResources(path) : ClassLoader.getSystemResources(path)); while (resourceUrls.hasMoreElements()) &#123; URL url = resourceUrls.nextElement(); // 将 URL 转换成 UrlResource result.add(convertClassLoaderURL(url)); &#125; // &lt;3&gt; 加载路径下得所有 jar 包 if (\"\".equals(path)) &#123; // The above result is likely to be incomplete, i.e. only containing file system references. // We need to have pointers to each of the jar files on the classpath as well... addAllClassLoaderJarRoots(cl, result); &#125; return result;&#125; 通过上面的分析，我们知道 #findAllClassPathResources(…) 方法，其实就是利用 ClassLoader 来加载指定路径下的资源，不论它是在 class 路径下还是在 jar 包中。如果我们传入的路径为空或者 /，则会调用 #addAllClassLoaderJarRoots(…) 方法，加载所有的 jar 包。 处理的流程图: 代码跟进 有了上面的知识储备，我们就知道一些皮毛概念了，下面的内容就是打好断点一步步调试了 关注ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(&quot;beans/bean.xml&quot;); 这行代码可以看到是传入了一个文件的相对路径地址，我们可以猜到里面的逻辑是读取配置文件beans/bean.xml，解析并构造成需要的对象 进入new ClassPathXmlApplicationContext(&quot;beans/bean.xml&quot;)构造方法，可以看到参数是支持数组形式传入的 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Create a new ClassPathXmlApplicationContext, loading the definitions * from the given XML file and automatically refreshing the context. * @param configLocation resource location * @throws BeansException if context creation failed */public ClassPathXmlApplicationContext(String configLocation) throws BeansException &#123; this(new String[] &#123;configLocation&#125;, true, null);&#125;/** * Create a new ClassPathXmlApplicationContext, loading the definitions * from the given XML files and automatically refreshing the context. * @param configLocations array of resource locations * @throws BeansException if context creation failed */public ClassPathXmlApplicationContext(String... configLocations) throws BeansException &#123; this(configLocations, true, null);&#125;/** * Create a new ClassPathXmlApplicationContext with the given parent, * loading the definitions from the given XML files. * @param configLocations array of resource locations * @param refresh whether to automatically refresh the context, * loading all bean definitions and creating all singletons. * Alternatively, call refresh manually after further configuring the context. * @param parent the parent context * @throws BeansException if context creation failed * @see #refresh() */public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; super(parent); // 可以将配置文件路径以数组的方式传入 setConfigLocations(configLocations); if (refresh) &#123; // 重点 refresh(); &#125;&#125; 进入setConfigLocations方法，可以看到直接解析参数并设置到private String[] configLocations 对象中 1234567891011121314151617/** * Set the config locations for this application context. * &lt;p&gt;If not set, the implementation may use a default as appropriate. */public void setConfigLocations(String... locations) &#123; if (locations != null) &#123; Assert.noNullElements(locations, \"Config locations must not be null\"); this.configLocations = new String[locations.length]; for (int i = 0; i &lt; locations.length; i++) &#123; // 解析给定的路径 this.configLocations[i] = resolvePath(locations[i]).trim(); &#125; &#125; else &#123; this.configLocations = null; &#125;&#125; 进入refresh()此方法是容器构建的主体方法，以后的章节也是以这个方法为主线，逐步分析Spring 容器构造的过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 准备刷新的上下文环境，例如对系统属性或者环境变量进行准备及验证 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 初始化BeanFactory，并进行XML文件读取，这一步之后ClassPathXmlApplicationContext实际上就已经包含了BeanFactory所提供的功能 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 进入prepareBeanFactory前，Spring已经完成了对配置的解析，而ApplicationContext在功能上的扩展也由此展开 // 对BeanFactory进行各种功能组件填充 @Qualifier @Autowired这两注解功能组件就是在这步骤中增加的支持 prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 子类覆盖方法做额外的处理 postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // 调用工厂后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanFactoryPostProcessor接口的bean， // 并调用其postProcessBeanFactory接口方法 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册Bean后处理器 根据反射机制从BeanDefinitionRegistry中找出所有实现了BeanPostProcessor接口的bean， // 并将它们注册到容器Bean后处理器的注册表中，这里只是注册，真正的调用在getBean时候 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 初始化消息源 初始化容器的国际化消息资源 initMessageSource(); // Initialize event multicaster for this context. // 初始化应用上下文事件广播器 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 初始化其他特殊的bean，由具体子类实现，这是个钩子方法 onRefresh(); // Check for listener beans and register them. // 注册事件监听器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 重点：初始化所有单实例的Bean，使用懒加载模式的bean除外，初始化Bean后将它们放到Spring容器的缓冲池中 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // 完成刷新并发布容器刷新事件 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 在这里我们关心的是配置文件的装载，所以进入ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); ，此方法的功能是构造BeanFactory 12345678910111213141516/** * Tell the subclass to refresh the internal bean factory. * @return the fresh BeanFactory instance * @see #refreshBeanFactory() * @see #getBeanFactory() */protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // 刷新BeanFactory 子类实现，创建DefaultListableBeanFactory refreshBeanFactory(); // 将配置文件的信息装入容器Bean定义注册表(BeanDefinitionRegistry)中，Bean未初始化 子类实现 ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Bean factory for \" + getDisplayName() + \": \" + beanFactory); &#125; return beanFactory;&#125; 关注refreshBeanFactory();方法 ，下面是构造了一个DefaultListableBeanFactory一个默认的BeanFactory然后就是一些赋值操作 12345678910111213141516171819202122232425262728/** * This implementation performs an actual refresh of this context's underlying * bean factory, shutting down the previous bean factory (if any) and * initializing a fresh bean factory for the next phase of the context's lifecycle. */@Overrideprotected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; // 创建DefaultListableBeanFactory DefaultListableBeanFactory beanFactory = createBeanFactory(); // 为了序列化指定id，如果需要的话，让这个BeanFactory从id反序列化到BeanFactory对象 beanFactory.setSerializationId(getId()); // 定制beanFactory：设置相关属性，包括是否允许覆盖同名称的不同定义的对象以及循环依赖 customizeBeanFactory(beanFactory); // 核心方法 初始化DodumentReader，并进行XML文件读取及解析 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); &#125;&#125; 进入核心方法loadBeanDefinitions(beanFactory); 这里传入了构造的DefaultListableBeanFactory，通过下面的代码可以看到是用beanFactory构建了一个XmlBeanDefinitionReader，这里的befaultListableBeanFactory会存放在XmlBeanDefinitionReader的private final BeanDefinitionRegistry registry;属性中，我们的&lt;bean&gt;信息解析后会存放在这，XmlBeanDefinitionReader就是做这个功能 ，这个类将会在下一章节中介绍 1234567891011121314151617181920212223242526/** * Loads the bean definitions via an XmlBeanDefinitionReader. * @see org.springframework.beans.factory.xml.XmlBeanDefinitionReader * @see #initBeanDefinitionReader * @see #loadBeanDefinitions */@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. // 为指定beanFactory创建XmlBeanDefinitionReader XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. // 对beanDefinitionReader进行环境变量的设置 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. // 对BeanDefinitionReader进行初始设置，可以被子类覆盖，这里只是设置了一个validationMode值 initBeanDefinitionReader(beanDefinitionReader); // 配置文件的读取 loadBeanDefinitions(beanDefinitionReader);&#125; 我们进入loadBeanDefinitions(beanDefinitionReader);方法，这里是对配置文件的读取，下面的代码看到了我们之前传入的String[] configLocations，得到之后然后使用XmlBeanDefinitionReader解析 12345678910111213141516171819202122/** * Load the bean definitions with the given XmlBeanDefinitionReader. * &lt;p&gt;The lifecycle of the bean factory is handled by the &#123;@link #refreshBeanFactory&#125; * method; hence this method is just supposed to load and/or register bean definitions. * @param reader the XmlBeanDefinitionReader to use * @throws BeansException in case of bean registration errors * @throws IOException if the required XML document isn't found * @see #refreshBeanFactory * @see #getConfigLocations * @see #getResources * @see #getResourcePatternResolver */protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; Resource[] configResources = getConfigResources(); if (configResources != null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; reader.loadBeanDefinitions(configLocations); &#125;&#125; 继续跟进到了loadBeanDefinitions(location, null)方法，是不是看到了我们的 Resource[] resources 及 ResourceLoader，看到这里下面的逻辑就是通过ResourceLoader的getResources方法来获取Resource[]了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Load bean definitions from the specified resource location. * &lt;p&gt;The location can also be a location pattern, provided that the * ResourceLoader of this bean definition reader is a ResourcePatternResolver. * @param location the resource location, to be loaded with the ResourceLoader * (or ResourcePatternResolver) of this bean definition reader * @param actualResources a Set to be filled with the actual Resource objects * that have been resolved during the loading process. May be &#123;@code null&#125; * to indicate that the caller is not interested in those Resource objects. * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #getResourceLoader() * @see #loadBeanDefinitions(org.springframework.core.io.Resource) * @see #loadBeanDefinitions(org.springframework.core.io.Resource[]) */public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // Resource pattern matching available. try &#123; Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); // 解析BeanDefinition int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location pattern [\" + location + \"]\"); &#125; return loadCount; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex); &#125; &#125; else &#123; // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location [\" + location + \"]\"); &#125; return loadCount; &#125;&#125; 跟进ResourceLoader resourceLoader = getResourceLoader();，因为ClassPathXmlApplicationContext实现了ResourceLoader接口，我们看下ClassPathXmlApplicationContext是怎么实现ResourceLoader接口的，下面重写getResources代码可以看到委托了ResourcePatternResolver类来操作的 getResources() 方法 1234567/** ResourcePatternResolver used by this context */private ResourcePatternResolver resourcePatternResolver;@Overridepublic Resource[] getResources(String locationPattern) throws IOException &#123; return this.resourcePatternResolver.getResources(locationPattern);&#125; ResourcePatternResolver 是个接口，也是继承自ResourceLoader接口 1234567891011121314151617181920212223public interface ResourcePatternResolver extends ResourceLoader &#123; /** * Pseudo URL prefix for all matching resources from the class path: \"classpath*:\" * This differs from ResourceLoader's classpath URL prefix in that it * retrieves all matching resources for a given name (e.g. \"/beans.xml\"), * for example in the root of all deployed JAR files. * @see org.springframework.core.io.ResourceLoader#CLASSPATH_URL_PREFIX */ String CLASSPATH_ALL_URL_PREFIX = \"classpath*:\"; /** * Resolve the given location pattern into Resource objects. * &lt;p&gt;Overlapping resource entries that point to the same physical * resource should be avoided, as far as possible. The result should * have set semantics. * @param locationPattern the location pattern to resolve * @return the corresponding Resource objects * @throws IOException in case of I/O errors */ Resource[] getResources(String locationPattern) throws IOException;&#125; 那ResourcePatternResolver是怎么获得呢，查看resourcePatternResolver引用，可以看到在默认构造函数赋值，下面的代码可以看到直接构造了PathMatchingResourcePatternResolver，没错此类就是我们上面的已经讲解过的 12345678910 /** * Create a new AbstractApplicationContext with no parent. */ public AbstractApplicationContext() &#123; this.resourcePatternResolver = getResourcePatternResolver(); &#125; protected ResourcePatternResolver getResourcePatternResolver() &#123; return new PathMatchingResourcePatternResolver(this);&#125; 到了这里我们的beans/bean.xml配置文件已经通过ResourceLoader获取到了Resource，得到Resource之后就是需要解析了，这个之后的章节会介绍 总结 Spring 提供了 Resource 和 ResourceLoader 来统一抽象整个资源及其定位。使得资源与资源的定位有了一个更加清晰的界限，并且提供了合适的 Default 类，使得自定义实现更加方便和清晰。 Resource接口使资源的定义更广泛，网络形式的资源，还有以二进制形式存在的、以文件形式存在的、以字节流形式存在的等等,而且它可以存在于任何场所，比如网络、文件系统、应用程序中，我们可以选择不同Resource实现类或者自定义Resource从而定义不同的资源 参考 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列(一)为什么要学习Spring","slug":"backend/framework/spring/analysis/Spring系列(一)为什么要学习Spring","date":"2019-05-11T15:02:44.000Z","updated":"2020-01-04T12:22:45.268Z","comments":true,"path":"2019/05/11/backend/framework/spring/analysis/Spring系列(一)为什么要学习Spring/","link":"","permalink":"http://www.songshuiyang.com/2019/05/11/backend/framework/spring/analysis/Spring系列(一)为什么要学习Spring/","excerpt":"","text":"前言 作为一名从事JavaWeb开发方向的程序猿，Spring在项目开发中的地位是十分重要的（个人感觉地位仅次于jdk），现在基本上的项目都有使用它，之前的日常开发中对Spring的掌握程度也只是在使用层面上，对其实现的底层不是很清楚，所以特地开此系列博文来记录自己学习Spring的一些笔记及总结 好记性不如烂笔头，Java开发设及的技术太多太杂，有些知识点没有总结记录过了许久又会忘记，所以论笔记的重要性 Spring 的宗旨：简化开发 为什么要阅读源码 站在巨人的肩膀上看世界，看看大佬们是怎么写代码的，一些写代码的模式或者技巧是否可以运用到实际项目中 许多东西不能只停留在使用层面，更要知其所以然，提高自己知识的深度 可以融会贯通，看得越多，知识的互通性的愈发明显，比如一些设计思想，设计模式这些在其他框架也是大量的运用 面试官会问呀 下载并导入源码 源码地址 https://github.com/spring-projects/spring-framework 选择合适的版本 配置gradle环境 详情可见源码父目录下的import-into-idea.md说明文档来将源码导入到IDEA环境中，执行import-into-eclipse.bat脚本将源码可导入至eclipse环境中 导入到IDEA环境中操作步骤 进入 spring-framework 文件夹下，打开cmd，输入 gradlew :spring-oxm:compileTestJava ，spring-oxm 应该预编译，因为它使用重新打包的依赖项，被其他包依赖 排除 spring-aspects 模块 1、Exclude(Go to File-&gt;Project Structure-&gt;Modules) 2、右键unmark as sources root让idea不认为此目录是源代码文件夹，不然此模块不然在本地编译不过 执行gradlew.bat 问题记录 执行gradle命令报错 尝试更换gradle版本，多下几个版本的gradle 执行gradle命令报错误: 找不到或无法加载主类 org.gradle.wrapper.GradleWrapperMain 检查源码目录下是否有 gradle/wrapper/gradle-wrapper.jar，如果没有从其他项目中copy一份 执行gradle命令报taskdef class jdiff.JDiffAntTask cannot be found 注释该文件的下面代码1234ant.taskdef( name: \"jdiff\", classname: \"jdiff.JDiffAntTask\", classpath: \"$&#123;jdiffHome&#125;/antjdiff.jar\") 有些类GroovyBeanDefinitionReader GroovyBeanDefinitionReader编译报错说是找不到 找到对应GroovyBeanDefinitionReader的模块是spring-beans-groovy 然后在找到build.gradle文件将compile(project(&quot;:spring-beans-groovy&quot;))依赖添加到对于报错的模块中 123456789project(\"spring-context\") &#123; description = \"Spring Context\" apply plugin: \"groovy\" dependencies &#123; compile(project(\":spring-aop\")) compile(project(\":spring-beans\")) compile(project(\":spring-beans-groovy\")) 下面的代码是已经可以在idea编译使用的源码文件 https://github.com/songshuiyang/spring-framework-4.3.10.RELEASE ，clone一下按照上面的步骤说明即可在本地调试源码 设置测试类不编译，修改文件build.gradle，不然每次点击方法在哪里调用都会冒出一堆测试类供你选择 12345678910111213141516sourceSets &#123; test &#123; java.srcDirs = ['src/排除test目录'] &#125;&#125;test &#123; systemProperty(\"java.awt.headless\", \"true\") systemProperty(\"testGroups\", project.properties.get(\"testGroups\")) scanForTestClasses = false include([\"**/*Tests.class\", \"**/*Test.class\"]) // Since we set scanForTestClasses to false, we need to filter out inner // classes with the \"$\" pattern; otherwise, using -Dtest.single=MyTests to // run MyTests by itself will fail if MyTests contains any inner classes. exclude '*'&#125; 坚持 这个世界上从来没有一蹴而就的成功，只有经过踏实的努力，点滴的积累，这样机会降临在你头上的时候你才有能力去掌握它 下面的章节将会以最基础的Spring示例代码来学习Spring 4.3.10.RELEASE，下面只有几行代码，但Spring却做了很多逻辑，所以以这几行代码为入口，开始吧 org.springiframe.entity.User.java 1234567891011121314151617181920212223public class User &#123; private String userName; private Integer age; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; beans/bean.xml 123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean class=\"org.springiframe.entity.User\"&gt; &lt;property name=\"userName\" value=\"shop\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 测试类 12345678public class ClassPathXmlApplicationContextTest &#123; @Test public void classPathXmlApplicationContext () &#123; ClassPathXmlApplicationContext xmlApplicationContext = new ClassPathXmlApplicationContext(\"beans/bean.xml\"); User user = xmlApplicationContext.getBean(User.class); &#125;&#125; 上面的代码主要是做了几件事 读取配置文件beans/bean.xml 根据配置文件实例化org.springiframe.entity.User.java 实例化完成之后就可以使用该对象了 这些过程看似很简单，但跟入代码查看可以发现Spring还是做了挺多事情的 参考 http://cmsblogs.com/?cat=206 《Spring 源码深度解析》","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列()工具类Assert断言","slug":"backend/framework/spring/Spring系列()工具类Assert断言","date":"2019-05-09T16:00:00.000Z","updated":"2019-09-16T13:11:04.920Z","comments":true,"path":"2019/05/10/backend/framework/spring/Spring系列()工具类Assert断言/","link":"","permalink":"http://www.songshuiyang.com/2019/05/10/backend/framework/spring/Spring系列()工具类Assert断言/","excerpt":"","text":"Assert（当要判断一个方法传入的参数时，我们就可以使用断言。） package org.springframework.util 1. notNull(Object object)当 object 不为 null 时抛出异常，notNull(Object object, String message) 方法允许您通过 message 定制异常信息。和 notNull() 方法断言规则相反的方法是 isNull(Object object)/isNull(Object object, String message)，它要求入参一定是 null； 2. isTrue(boolean expression) / isTrue(boolean expression, String message)当 expression 不为 true 抛出异常； 3. notEmpty(Collection collection) / notEmpty(Collection collection, String message)当集合未包含元素时抛出异常。 notEmpty(Map map) / notEmpty(Map map, String message) 和 notEmpty(Object[] array, String message) / notEmpty(Object[] array, String message) 分别对 Map 和 Object[] 类型的入参进行判断； 4. hasLength(String text) / hasLength(String text, String message)当 text 为 null 或长度为 0 时抛出异常； 5. hasText(String text) / hasText(String text, String message)text 不能为 null 且必须至少包含一个非空格的字符，否则抛出异常； 6. isInstanceOf(Class clazz, Object obj) / isInstanceOf(Class type, Object obj, String message)如果 obj 不能被正确造型为 clazz 指定的类将抛出异常； 7. isAssignable(Class superType, Class subType) / isAssignable(Class superType, Class subType, String message)subType 必须可以按类型匹配于 superType，否则将抛出异常；","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列()Aop面向切面编程","slug":"backend/framework/spring/Spring系列()Aop面向切面编程","date":"2019-05-09T16:00:00.000Z","updated":"2019-12-05T12:51:15.541Z","comments":true,"path":"2019/05/10/backend/framework/spring/Spring系列()Aop面向切面编程/","link":"","permalink":"http://www.songshuiyang.com/2019/05/10/backend/framework/spring/Spring系列()Aop面向切面编程/","excerpt":"Spring Aop一: 概念1. 什么是AOP在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。 2. 为什么要用Aop利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。在不改变原有方法的基础添加一些功能 , 比如:日志记录，性能统计，安全控制，事务处理，异常处理等等。","text":"Spring Aop一: 概念1. 什么是AOP在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。 2. 为什么要用Aop利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。在不改变原有方法的基础添加一些功能 , 比如:日志记录，性能统计，安全控制，事务处理，异常处理等等。 3. Aop 术语 连接点(JoinPoint) 程序执行到某个特定位置 , Spring 仅支持方法级的连接点(方法执行前，方法完成后，抛出异常后) 切点(Pointcut) 从连接点的基础上引出的概念，是指特定的连接点，一个类有好多方法,每个方法又有多个连接点，则需要切点来限定一个小范围的连接点 通知、增强处理(Advice) 就是指你所需要添加的功能及这个功能什么时候(通知)实现 , 比如一个业务方法需要实现日志功能 , 那么就需要专门在一个地方定义好需要做什么，然后定义什么时候执行(方法执行前？，方法完成后？，抛出异常？。。。) Spring 切面可应用的 5 种通知类型： Before——在方法调用之前调用通知 After——在方法完成之后调用通知，无论方法执行成功与否 After-returning——在方法执行成功之后调用通知 After-throwing——在方法抛出异常后进行通知 Around——通知包裹了被通知的方法，在被通知的方法调用之前和调用之后执行自定义的行为 引入(introduction) 特殊的增强，为类添加一些属性和方法 切面(Aspect) 切面由切点和增强组成 , 及包括横切逻辑的定义，也包括切点的定义, 目标对象(Target) 增强逻辑的织入目标类 , 如果没有Aop,那么目标对象就要自己实现(日志记录，性能统计，安全控制，事务处理，异常处理)这些功能，那么一个方法就会变成很杂乱 织入(Weaing) 将增强添加到目标对象的具体连接点上, Spring使用动态代理织入 Aop有三种织入方式 编译期织入 类装载期织入 动态代理织入: 在运行期间为目标类添加增强生成子类的方式 二: Spring Aop 的应用 Spring Aop的使用一般通过俩种方式:第一种是通过注解的，第二种是通过xml配置 通过注解的方式实现Aop 第一步 Maven 导包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;parent&gt; &lt;groupId&gt;ecut&lt;/groupId&gt; &lt;artifactId&gt;spring-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;ecut&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-aop&lt;/name&gt; &lt;dependencies&gt; &lt;!-- spring 核心 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring aop --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;spring-aop&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--@Override is not allowed when implementing interface method--&gt; &lt;!-- 编码和编译和JDK版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;utf8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 第二步 编写一个基于 @AspectJ 的切面 12345678910111213141516171819202122232425262728293031package com.aop.learn.aspectj;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;/** * @author songshuiyang * @title: @Aspect * @description: * @date 2017/11/15 */@Component@Aspect // 通过该注解将该类标识为一个切面public class PreGreetingAspect &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 前置增强, greetTo方法执行前触发此方法 * */ @Before(\"execution(* greetTo(..))\") // 定义切点和增强类型（前置增强,可以带任何参数，和任意的返回值） public void beforeGreeting() &#123; // 增强的横切逻辑 logger.info(\"How are you Aspect 使用了前置增强\"); &#125; &#125; 3: 编写目标对象 Writer.java 接口 12345678910111213package com.aop.learn.service;/** * @author songshuiyang * @title: * @description: * @date 2017/11/15 */public interface Writer &#123; public void greetTo();&#125; NativeWaiter.java 实现方法12345678910111213141516171819202122232425package com.aop.learn.service.impl;import com.aop.learn.annotation.NeedTest;import com.aop.learn.service.Writer;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Service;/** * @author songshuiyang * @title: * @description: * @date 2017/11/15 */@Servicepublic class NativeWaiter implements Writer &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public void greetTo() &#123; logger.info(\"执行方法体: \"); &#125; &#125; 4：Spring配置文件 applicationContext.xml12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;context:component-scan base-package=\"com.aop.learn\"/&gt; &lt;!--基于@AspectJ切面的驱动器,自动为Spring容器中匹配@AspectJ切面的Bean创建代理，完成切面织入--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--&lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/&gt; 表示使用CGLib动态代理技术织入增强--&gt;&lt;/beans&gt; 5: 测试类 测试基类 BaseTest.java123456789101112131415161718192021package com.aop.test;import org.junit.runner.RunWith;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.AbstractJUnit4SpringContextTests;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;/** * @author songshuiyang * @title: * @description: * @date 2017/11/15 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(\"classpath:/spring/applicationContext.xml\")public class BaseTest extends AbstractJUnit4SpringContextTests &#123; public Logger logger = LoggerFactory.getLogger(this.getClass());&#125; 测试类 AspectTest.java 12345678910111213141516171819202122232425262728293031package com.aop.test.service;import com.aop.learn.service.AgentWriter;import com.aop.learn.service.Seller;import com.aop.learn.service.Writer;import com.aop.test.BaseTest;import org.junit.Test;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;/** * @author songshuiyang * @title: 基于spring配置使用@AspectJ切面 * @description: * @date 2017/11/15 */public class AspectTest extends BaseTest &#123; @Autowired private Writer writer; /** * 基于spring配置使用@AspectJ切面 */ @Test public void test1() &#123; writer.greetTo(); &#125;&#125; 6: 效果图,完成 aop增强 logo 通过xml schema的方式实现Aop applicationContext-schema.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- aop:config 配置一个基于Schema的切面，aop:config 可以定义多个切面--&gt; &lt;aop:config proxy-target-class=\"true\"&gt; &lt;!--aop:pointcut 配置命名切点,可以被其他增强引用--&gt; &lt;aop:pointcut id=\"greetToPointcut\" expression=\"target(com.aop.learn.service.impl.NativeWaiter) and execution (* greetTo(..))\"/&gt; &lt;aop:pointcut id=\"bindParmPointcut\" expression=\"target(com.aop.learn.service.impl.NativeWaiter) and execution (* greetTo(..)) and args(clientName)\"/&gt; &lt;!-- aop:advisor 是切点和增强的复合体,仅包含一个切点和增强--&gt; &lt;aop:advisor advice-ref=\"advisorMethods\" pointcut=\"target(com.aop.learn.service.impl.NativeWaiter) and execution (* serveTo(..))\"/&gt; &lt;!--aop:aspect 元素标签定义切面,其内部可以定义多个增强--&gt; &lt;aop:aspect ref=\"adviceMethods\"&gt; &lt;!-- aop:before前置增强 method 增强方法， pointcut 切点表达式--&gt; &lt;aop:before method=\"preGreeting\" pointcut-ref=\"greetToPointcut\"/&gt; &lt;!-- aop:before后置增强--&gt; &lt;aop:after-returning method=\"afterGreeting\" pointcut=\"target(com.aop.learn.service.impl.NativeWaiter) and execution (* name(..))\" returning=\"retVal\"/&gt; &lt;!-- 测试绑定连接点信息--&gt; &lt;aop:after method=\"bindParmGreet\" pointcut-ref=\"bindParmPointcut\"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; &lt;!--增强方法所在的Bean--&gt; &lt;bean id=\"adviceMethods\" class=\"com.aop.learn.schema.AdviceMethods\"/&gt; &lt;bean id=\"nativeWaiter\" class=\"com.aop.learn.service.impl.NativeWaiter\"/&gt; &lt;bean id=\"advisorMethods\" class=\"com.aop.learn.schema.AdvisorMethods\"/&gt;&lt;/beans&gt; AdviceMethods.java123456789101112131415161718192021222324252627282930313233343536package com.aop.learn.schema;/** * @author songshuiyang * @title: Schema 用作增强的方法 * @description: * @date 2017/11/18 */public class AdviceMethods &#123; /** * 前置增强 */ public void preGreeting() &#123; System.out.println(\"-------------前置增强\"); &#125; /** * 后置增强 * * @param retVal */ public void afterGreeting(String retVal) &#123; System.out.println(\"-------------后置增强,返回的参数\" + retVal); &#125; /** * 绑定连接点信息 * * @param clientName */ public void bindParmGreet(String clientName) &#123; System.out.println(\"-------------绑定连接点信息 的参数\" + clientName); &#125;&#125; NativeWaiter.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.aop.learn.service.impl;import com.aop.learn.annotation.NeedTest;import com.aop.learn.service.Writer;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Service;/** * @author songshuiyang * @title: * @description: * @date 2017/11/15 */@Servicepublic class NativeWaiter implements Writer &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public void greetTo(String clientName) &#123; logger.info(\"-------------greetTo \" + clientName); &#125; @Override public void greetTo(String clientName, Integer age) &#123; logger.info(\"-------------greetTo \" + clientName + \" \" + age + \"岁\"); &#125; @Override public void serveTo(String clientName) &#123; logger.info(\"-------------serveTo \" + clientName); &#125; @Override @NeedTest() public void nestTo() &#123; logger.info(\"开始执行 nestTo() 函数\"); &#125; @Override public String name() &#123; return \"宋水阳\"; &#125; @Override public void throwExcetion() &#123; throw new IllegalArgumentException(\"抛出异常了\"); &#125;&#125; AdvisorMethods.java1234567891011121314151617181920package com.aop.learn.schema;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;/** * @author songshuiyang * @title: aop:advisor 是切点和增强的复合体,仅包含一个切点和增强 * @description: * @date 2017/11/18 */public class AdvisorMethods implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] args, Object taget) throws Throwable &#123; System.out.println(\"--------------执行aop:advisor增强----------------\"); System.out.println(\"获取的参数\" + args[0]); &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列()注解Value","slug":"backend/framework/spring/Spring系列()注解Value","date":"2019-05-09T16:00:00.000Z","updated":"2019-09-16T13:11:04.927Z","comments":true,"path":"2019/05/10/backend/framework/spring/Spring系列()注解Value/","link":"","permalink":"http://www.songshuiyang.com/2019/05/10/backend/framework/spring/Spring系列()注解Value/","excerpt":"@Value用法及配合Spring EL使用spring支持@Value注解获取一些配置信息及加载资源 ELConfig.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.smart.boot.el;import org.apache.commons.io.IOUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.env.Environment;import org.springframework.core.io.Resource;@Configuration@ComponentScan(\"com.smart.boot.el\")@PropertySource(\"classpath:el.properties\")public class ELConfig &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 注入普通字符串 */ @Value(\"songsy\") private String str; /** * 通过el注入操作系统属性 */ @Value(\"# &#123;systemProperties['os.name']&#125;\") private String osName; /** * 表达式结果 */ @Value(\"#&#123; T(java.lang.Math).random() * 100.0 &#125;\") private double randomNumber; /** * 注入其他Bean属性 */ @Value(\"#&#123;eLService.another&#125;\") public String fromAnothor; /** * 注入文件资源 */ @Value(\"classpath:el.properties\") private Resource testFile; /** * 注入网站资源 */ @Value(\"http://www.baidu.com\") private Resource testUrl; /** * 注入配置文件 */ @Value(\"$&#123;book.name&#125;\") private String bookName; /** * 环境配置 * 环境在容器中是一个抽象的集合，是指应用环境的2个方面: profiles和 properties. * profile: * 配置是一个被命名的，bean定义的逻辑组，这些bean只有在给定的profile配置激活时才会注册到容器。不管是XML还是注解， * Beans都有可能指派给profile配置。Environment环境对象的作用，对于profiles配置来说，它能决定当前激活的是哪个profile配置，和哪个profile是默认。 * Properties: * 扮演一个非常重要的角色,可能来源于一下源码变量:properties文件，JVM properties,system环境变量，JNDI, servlet context parameters上下文参数, * 专门的Properties对象，Maps等等。Environment对象的作用，对于properties来说，是提供给用户方便的服务接口，方便撰写配置、方便解析配置。 * 作者：不迷失 * 链接：https://www.jianshu.com/p/49e950b0b008 * 來源：简书 * 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 */ @Autowired private Environment environment; /** * 若使用@Value注入, 则要配置一个PropertySourcesPlaceholderConfigurer * * @return */ @Bean public static PropertySourcesPlaceholderConfigurer placeholderConfigurer() &#123; return new PropertySourcesPlaceholderConfigurer(); &#125; public void print() throws Exception &#123; logger.info(\"str: \" + str); logger.info(\"osName: \" + osName); logger.info(\"randomNumber: \" + String.valueOf(randomNumber)); logger.info(\"fromAnothor: \" + fromAnothor); logger.info(\"testFile: \" + IOUtils.toString(testFile.getInputStream())); logger.info(\"testUrl: \" + IOUtils.toString(testUrl.getInputStream())); logger.info(\"bookName: \" + bookName); logger.info(\"environment: \" + environment.getProperty(\"book.author\")); &#125;&#125;","text":"@Value用法及配合Spring EL使用spring支持@Value注解获取一些配置信息及加载资源 ELConfig.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.smart.boot.el;import org.apache.commons.io.IOUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.env.Environment;import org.springframework.core.io.Resource;@Configuration@ComponentScan(\"com.smart.boot.el\")@PropertySource(\"classpath:el.properties\")public class ELConfig &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 注入普通字符串 */ @Value(\"songsy\") private String str; /** * 通过el注入操作系统属性 */ @Value(\"# &#123;systemProperties['os.name']&#125;\") private String osName; /** * 表达式结果 */ @Value(\"#&#123; T(java.lang.Math).random() * 100.0 &#125;\") private double randomNumber; /** * 注入其他Bean属性 */ @Value(\"#&#123;eLService.another&#125;\") public String fromAnothor; /** * 注入文件资源 */ @Value(\"classpath:el.properties\") private Resource testFile; /** * 注入网站资源 */ @Value(\"http://www.baidu.com\") private Resource testUrl; /** * 注入配置文件 */ @Value(\"$&#123;book.name&#125;\") private String bookName; /** * 环境配置 * 环境在容器中是一个抽象的集合，是指应用环境的2个方面: profiles和 properties. * profile: * 配置是一个被命名的，bean定义的逻辑组，这些bean只有在给定的profile配置激活时才会注册到容器。不管是XML还是注解， * Beans都有可能指派给profile配置。Environment环境对象的作用，对于profiles配置来说，它能决定当前激活的是哪个profile配置，和哪个profile是默认。 * Properties: * 扮演一个非常重要的角色,可能来源于一下源码变量:properties文件，JVM properties,system环境变量，JNDI, servlet context parameters上下文参数, * 专门的Properties对象，Maps等等。Environment对象的作用，对于properties来说，是提供给用户方便的服务接口，方便撰写配置、方便解析配置。 * 作者：不迷失 * 链接：https://www.jianshu.com/p/49e950b0b008 * 來源：简书 * 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 */ @Autowired private Environment environment; /** * 若使用@Value注入, 则要配置一个PropertySourcesPlaceholderConfigurer * * @return */ @Bean public static PropertySourcesPlaceholderConfigurer placeholderConfigurer() &#123; return new PropertySourcesPlaceholderConfigurer(); &#125; public void print() throws Exception &#123; logger.info(\"str: \" + str); logger.info(\"osName: \" + osName); logger.info(\"randomNumber: \" + String.valueOf(randomNumber)); logger.info(\"fromAnothor: \" + fromAnothor); logger.info(\"testFile: \" + IOUtils.toString(testFile.getInputStream())); logger.info(\"testUrl: \" + IOUtils.toString(testUrl.getInputStream())); logger.info(\"bookName: \" + bookName); logger.info(\"environment: \" + environment.getProperty(\"book.author\")); &#125;&#125; ELService.java12345678910111213141516171819package com.smart.boot.el;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Service(\"eLService\")public class ELService &#123; public String another; public String getAnother() &#123; return another; &#125; @Autowired public void setAnother() &#123; this.another = \"ELService 自动注入\"; &#125;&#125; ELMain.java123456789101112package com.smart.boot.el;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class ELMain &#123; public static void main(String[] args) throws Exception &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ELConfig.class); ELConfig elConfig = context.getBean(ELConfig.class); elConfig.print(); context.close(); &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列()异步方法Async","slug":"backend/framework/spring/Spring系列()异步方法Async","date":"2019-05-09T16:00:00.000Z","updated":"2020-01-04T12:21:52.134Z","comments":true,"path":"2019/05/10/backend/framework/spring/Spring系列()异步方法Async/","link":"","permalink":"http://www.songshuiyang.com/2019/05/10/backend/framework/spring/Spring系列()异步方法Async/","excerpt":"","text":"异步方法 加入@Async注解可以让普通方法变为异步方法 AsyncTaskService.java 12345678910111213141516171819202122package com.smart.boot.asyn;import org.springframework.scheduling.annotation.Async;import org.springframework.stereotype.Service;@Servicepublic class AsyncTaskService &#123; /** * 异步方法 * * @param i */ @Async public void task1(Integer i) &#123; System.out.println(\"执行异步任务\" + i); &#125; @Async public void task2(Integer i) &#123; System.out.println(\"执行异步任务+1 \" + (i + 1)); &#125;&#125; Config.java 1234567891011121314151617181920212223242526272829303132333435package com.smart.boot.asyn;import org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.AsyncConfigurer;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.concurrent.Executor;@Configuration@ComponentScan(\"com.smart.boot.asyn\")@EnableAsync // 开启异步任务支持public class Config implements AsyncConfigurer &#123; /** * 获得一个基于线程池的 taskExecutor * * @return */ @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); taskExecutor.setCorePoolSize(5); taskExecutor.setMaxPoolSize(10); taskExecutor.setQueueCapacity(25); taskExecutor.initialize(); return taskExecutor; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return null; &#125;&#125; Application.java123456789101112131415package com.smart.boot.asyn;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class Application &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(Config.class); AsyncTaskService asyncTaskService = context.getBean(AsyncTaskService.class); for (int i = 0; i &lt; 10; i++) &#123; asyncTaskService.task1(i); asyncTaskService.task2(i); &#125; context.close(); &#125;&#125; 补充 在@SpringBootApplication启动类 添加注解@EnableAsync 异步方法使用注解@Async ,返回值为void或者Future 切记一点 ,异步方法和调用方法一定要 写在不同的类中 ,如果写在一个类中,是没有效果的 参考 https://blog.csdn.net/qq_34545192/article/details/80484780","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列()定时任务SpringTask","slug":"backend/framework/spring/Spring系列()定时任务SpringTask","date":"2019-05-09T16:00:00.000Z","updated":"2019-09-16T13:11:04.916Z","comments":true,"path":"2019/05/10/backend/framework/spring/Spring系列()定时任务SpringTask/","link":"","permalink":"http://www.songshuiyang.com/2019/05/10/backend/framework/spring/Spring系列()定时任务SpringTask/","excerpt":"Spring Task spring task作为定时任务的处理,是Spring自带的一个设定时间自动任务调度,提供了两种方式进行配置，一种是注解的方式，而另外一种就是XML配置方式了。","text":"Spring Task spring task作为定时任务的处理,是Spring自带的一个设定时间自动任务调度,提供了两种方式进行配置，一种是注解的方式，而另外一种就是XML配置方式了。 基于XML配置文件的方式 applicationContext.xml12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:task=\"http://www.springframework.org/schema/task\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd\"&gt; &lt;!--使用配置文件的方式,注册 xmlTaskJob bean中的job1方法,每隔一秒执行 --&gt; &lt;task:scheduled-tasks&gt; &lt;task:scheduled ref=\"xmlTaskJob\" method=\"job1\" cron=\"*/1 * * * * ?\"/&gt; &lt;/task:scheduled-tasks&gt; &lt;context:component-scan base-package=\"com.learn.schedule.service\"/&gt;&lt;/beans&gt; XmlTaskJob.Java12345678910111213141516171819202122package com.learn.schedule.service;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Service;/** * @author songshuiyang * @title: 基于xml文件配置的定时任务 * @description: * @date 2017/11/7 22:20 */@Servicepublic class XmlTaskJob &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); public void job1() &#123; logger.info(\"基于xml文件配置的定时任务，每隔一秒执行\"); &#125;&#125; Test.java1234567891011/** * @author songshuiyang * @title: * @description: * @date 2017/11/7 22:45 */public class Test &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:/spring/applicationContext.xml\"); &#125;&#125; 基于注解配置文件的方式更简单 applicationContext.xml1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:task=\"http://www.springframework.org/schema/task\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd\"&gt; &lt;!-- 启动定时器 基于注解--&gt; &lt;task:annotation-driven/&gt; &lt;context:component-scan base-package=\"com.learn.schedule.service\"/&gt;&lt;/beans&gt; AnnotationTaskJob.Java12345678910111213141516171819202122package com.learn.schedule.service;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;/** * @author songshuiyang * @title: 基于注解配置的定时任务 * @description: * @date 2017/11/7 22:42 */@Componentpublic class AnnotationTaskJob &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Scheduled(cron = \"*/2 * * * * ?\") //每2秒执行一次 public void job() &#123; logger.info(\"基于注解配置的定时任务，每隔俩秒执行\"); &#125;&#125; 效果: logo","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"Spring系列()事件监听","slug":"backend/framework/spring/Spring系列()事件监听","date":"2019-05-09T16:00:00.000Z","updated":"2019-09-16T13:11:04.901Z","comments":true,"path":"2019/05/10/backend/framework/spring/Spring系列()事件监听/","link":"","permalink":"http://www.songshuiyang.com/2019/05/10/backend/framework/spring/Spring系列()事件监听/","excerpt":"Spring 事件监听spring的事件(Application Event)为Bean与Bean之间的消息通信提供了支持, 当第一个Bean处理完一件事之后, 需要另外一个Bean知道并能做出相应的处理, 这时可以通过事件监听来讲一个Bean监听另一个Bean 观察者模式 Spring 事件监听是观察者模式的一种实现 意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 事件驱动模型简介 事件驱动模型也就是我们常说的观察者，或者发布-订阅模型；理解它的几个关键点： 首先是一种对象间的一对多的关系；最简单的如交通信号灯，信号灯是目标（一方），行人注视着信号灯（多方）； 当目标发送改变（发布），观察者（订阅者）就可以接收到改变； 观察者如何处理（如行人如何走，是快走/慢走/不走，目标不会管的），目标无需干涉；所以就松散耦合了它们之间的关系。","text":"Spring 事件监听spring的事件(Application Event)为Bean与Bean之间的消息通信提供了支持, 当第一个Bean处理完一件事之后, 需要另外一个Bean知道并能做出相应的处理, 这时可以通过事件监听来讲一个Bean监听另一个Bean 观察者模式 Spring 事件监听是观察者模式的一种实现 意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 事件驱动模型简介 事件驱动模型也就是我们常说的观察者，或者发布-订阅模型；理解它的几个关键点： 首先是一种对象间的一对多的关系；最简单的如交通信号灯，信号灯是目标（一方），行人注视着信号灯（多方）； 当目标发送改变（发布），观察者（订阅者）就可以接收到改变； 观察者如何处理（如行人如何走，是快走/慢走/不走，目标不会管的），目标无需干涉；所以就松散耦合了它们之间的关系。 实现流程1.自定义事件12345678910111213141516171819202122232425262728package com.smart.boot.event;import org.springframework.context.ApplicationEvent;public class DemoEvent extends ApplicationEvent &#123; private String msg; public DemoEvent(Object source, String msg) &#123; super(source); this.msg = msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; /** * 去做一些事 */ public void todoSomethings() &#123; System.out.println(\"正在做第一件事 , 做完需要做第二件事\"); &#125;&#125; 2.定义事件监听器12345678910111213141516171819package com.smart.boot.event;import org.springframework.context.ApplicationListener;import org.springframework.stereotype.Component;@Componentpublic class DemoListener implements ApplicationListener&lt;DemoEvent&gt; &#123; /** * 对消息进行接受处理 * @param event */ @Override public void onApplicationEvent(DemoEvent event) &#123; String msg = event.getMsg(); System.out.println(\"DemoListener 接受到了消息\" + msg ); event.todoSomethings(); System.out.println(\"正在做第二件事\"); &#125;&#125; 3.发布事件12345678910111213141516171819202122package com.smart.boot.event;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.ApplicationContext;import org.springframework.stereotype.Component;@Componentpublic class DemoPublisher &#123; /** * 注入ApplicationContext来发布事件 */ @Autowired ApplicationContext context; /** * 发布事件 * @param msg */ public void publish(String msg) &#123; context.publishEvent(new DemoEvent(this,msg)); &#125;&#125; 4.定义配置类123456789package com.smart.boot.event;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;@Configuration@ComponentScan(\"com.smart.boot.event\")public class Config &#123;&#125; 5.运行123456789101112package com.smart.boot.event;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class Application &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(Config.class); DemoPublisher demoPublisher = context.getBean(DemoPublisher.class); demoPublisher.publish(\"hello songshuiyang\"); context.close(); &#125;&#125; 6.实现结果123DemoListener 接受到了消息hello songshuiyang正在做第一件事 , 做完需要做第二件事正在做第二件事 总结 实现事件监听可以使业务解耦, 每个模块做好自己的事情即可, 可用在用户注册功能, eg: http://jinnianshilongnian.iteye.com/blog/1902886","categories":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"}]},{"title":"并发多线程(十五)CountDownLatch计数器","slug":"backend/java/concurrent/并发多线程(十五)CountDownLatch计数器","date":"2019-05-02T16:01:00.000Z","updated":"2020-03-16T11:43:55.464Z","comments":true,"path":"2019/05/03/backend/java/concurrent/并发多线程(十五)CountDownLatch计数器/","link":"","permalink":"http://www.songshuiyang.com/2019/05/03/backend/java/concurrent/并发多线程(十五)CountDownLatch计数器/","excerpt":"","text":"概述 CountDownLatch 是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行 CountDownLatch 使用一个计数器进行实现。计数器初始值为线程的数量。当每一个线程完成自己任务后，计数器的值就会减一。当计数器的值为0时，表示所有的线程都已经完成一些任务，然后在CountDownLatch上等待的线程就可以恢复执行接下来的任务。 介绍使用场景三种典型用法 1、某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减 1 countdownlatch.countDown()，当计数器的值变为 0 时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 2、实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。 3、死锁检测：一个非常方便的使用场景是，你可以使用 n 个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。 使用示例 下面的代码可以看到使用了一个线程池来执行550个线程处理，当所有请求都处理完成之后才打印finish 12345678910111213141516171819202122232425262728293031323334353637public class CountDownLatchTest &#123; // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException &#123; // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadnum = i; threadPool.execute(() -&gt; &#123;// Lambda 表达式的运用 try &#123; test(threadnum); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; // 表示一个请求已经被完成 countDownLatch.countDown(); &#125; &#125;); &#125; // 主线程必须在启动其他线程后立即调用 CountDownLatch.await()方法 // 这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。 countDownLatch.await(); threadPool.shutdown(); System.out.println(\"finish\"); &#125; public static void test(int threadnum) throws InterruptedException &#123; Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println(\"threadnum:\" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 &#125;&#125; 解析 下面是CountDownLatch的源码，可以发现里面逻辑很简单，只有一个成员Sync sync，Sync是个内部类继承了AbstractQueuedSynchronizer，这不和ReentrantLock类的实现差不多吗 观察CountDownLatch的内部方法实际上调用的是其sync成员方法，在这里可以看到AQS是构建锁或者其他同步组件的基础框架，AQS的内容回顾本系列的第七章节 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160public class CountDownLatch &#123; /** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */ private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; &#125; private final Sync sync; /** * Constructs a &#123;@code CountDownLatch&#125; initialized with the given count. * * @param count the number of times &#123;@link #countDown&#125; must be invoked * before threads can pass through &#123;@link #await&#125; * @throws IllegalArgumentException if &#123;@code count&#125; is negative */ public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count); &#125; /** * Causes the current thread to wait until the latch has counted down to * zero, unless the thread is &#123;@linkplain Thread#interrupt interrupted&#125;. * * &lt;p&gt;If the current count is zero then this method returns immediately. * * &lt;p&gt;If the current count is greater than zero then the current * thread becomes disabled for thread scheduling purposes and lies * dormant until one of two things happen: * &lt;ul&gt; * &lt;li&gt;The count reaches zero due to invocations of the * &#123;@link #countDown&#125; method; or * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt interrupts&#125; * the current thread. * &lt;/ul&gt; * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is &#123;@linkplain Thread#interrupt interrupted&#125; while waiting, * &lt;/ul&gt; * then &#123;@link InterruptedException&#125; is thrown and the current thread's * interrupted status is cleared. * * @throws InterruptedException if the current thread is interrupted * while waiting */ public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; /** * Causes the current thread to wait until the latch has counted down to * zero, unless the thread is &#123;@linkplain Thread#interrupt interrupted&#125;, * or the specified waiting time elapses. * * &lt;p&gt;If the current count is zero then this method returns immediately * with the value &#123;@code true&#125;. * * &lt;p&gt;If the current count is greater than zero then the current * thread becomes disabled for thread scheduling purposes and lies * dormant until one of three things happen: * &lt;ul&gt; * &lt;li&gt;The count reaches zero due to invocations of the * &#123;@link #countDown&#125; method; or * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt interrupts&#125; * the current thread; or * &lt;li&gt;The specified waiting time elapses. * &lt;/ul&gt; * * &lt;p&gt;If the count reaches zero then the method returns with the * value &#123;@code true&#125;. * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is &#123;@linkplain Thread#interrupt interrupted&#125; while waiting, * &lt;/ul&gt; * then &#123;@link InterruptedException&#125; is thrown and the current thread's * interrupted status is cleared. * * &lt;p&gt;If the specified waiting time elapses then the value &#123;@code false&#125; * is returned. If the time is less than or equal to zero, the method * will not wait at all. * * @param timeout the maximum time to wait * @param unit the time unit of the &#123;@code timeout&#125; argument * @return &#123;@code true&#125; if the count reached zero and &#123;@code false&#125; * if the waiting time elapsed before the count reached zero * @throws InterruptedException if the current thread is interrupted * while waiting */ public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; /** * Decrements the count of the latch, releasing all waiting threads if * the count reaches zero. * * &lt;p&gt;If the current count is greater than zero then it is decremented. * If the new count is zero then all waiting threads are re-enabled for * thread scheduling purposes. * * &lt;p&gt;If the current count equals zero then nothing happens. */ public void countDown() &#123; sync.releaseShared(1); &#125; /** * Returns the current count. * * &lt;p&gt;This method is typically used for debugging and testing purposes. * * @return the current count */ public long getCount() &#123; return sync.getCount(); &#125; /** * Returns a string identifying this latch, as well as its state. * The state, in brackets, includes the String &#123;@code \"Count =\"&#125; * followed by the current count. * * @return a string identifying this latch, as well as its state */ public String toString() &#123; return super.toString() + \"[Count = \" + sync.getCount() + \"]\"; &#125;&#125; 其他CyclicBarrier(循环栅栏) CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。 CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 CyclicBarrier 的应用场景 CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。 CyclicBarrier 的使用示例123456789101112131415161718192021222324252627282930313233343536373839404142public class CyclicBarrierExample1 &#123; // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) throws InterruptedException &#123; // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public static void test(int threadnum) throws InterruptedException, BrokenBarrierException &#123; System.out.println(\"threadnum:\" + threadnum + \"is ready\"); try &#123; /** * 等待60秒，保证子线程完全执行结束 * 当线程数量也就是请求数量达到我们定义的 5 个的时候， await方法之后的方法才被执行。 * */ cyclicBarrier.await(60, TimeUnit.SECONDS); &#125; catch (Exception e) &#123; System.out.println(\"-----CyclicBarrierException------\"); &#125; System.out.println(\"threadnum:\" + threadnum + \"is finish\"); &#125;&#125; 输出 12345678910111213141516171819202122232425262728293031323334threadnum:0is readythreadnum:1is readythreadnum:2is readythreadnum:3is readythreadnum:4is readythreadnum:4is finishthreadnum:0is finishthreadnum:1is finishthreadnum:3is finishthreadnum:2is finishthreadnum:5is readythreadnum:6is readythreadnum:7is readythreadnum:8is readythreadnum:9is readythreadnum:9is finishthreadnum:5is finishthreadnum:7is finishthreadnum:6is finishthreadnum:8is finishthreadnum:10is readythreadnum:11is readythreadnum:12is readythreadnum:13is readythreadnum:14is readythreadnum:14is finishthreadnum:10is finishthreadnum:11is finishthreadnum:12is finishthreadnum:13is finishthreadnum:15is readythreadnum:16is readythreadnum:17is readythreadnum:18is ready 总结 CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。 CyclicBarrier 和 CountDownLatch 的区别 CountDownLatch 是计数器，线程完成一个记录一个，只不过计数不是递增而是递减 而 CyclicBarrier 更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行 参考 https://snailclimb.gitee.io/javaguide/#/docs/java/Multithread/AQS?id=_4-countdownlatch-（倒计时器）","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(十四)JUC包中的原子类","slug":"backend/java/concurrent/并发多线程(十四)JUC包中的原子类","date":"2019-05-02T16:00:00.000Z","updated":"2020-03-16T11:43:55.466Z","comments":true,"path":"2019/05/03/backend/java/concurrent/并发多线程(十四)JUC包中的原子类/","link":"","permalink":"http://www.songshuiyang.com/2019/05/03/backend/java/concurrent/并发多线程(十四)JUC包中的原子类/","excerpt":"","text":"概述4大类型 基本类型：使用原子的方式更新基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 数组类型：使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新引用类型里的字段原子类 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 解析AtomicInteger 的使用 AtomicInteger 类常用方法 1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 AtomicInteger 类的使用示例 使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全 1234567891011class AtomicIntegerTest &#123; private AtomicInteger count = new AtomicInteger(); //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。 public void increment() &#123; count.incrementAndGet(); &#125; public int getCount() &#123; return count.get(); &#125;&#125; AtomicInteger线程安全原理123456789101112131415161718192021222324public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates （更新操作时提供“比较并替换”的作用） private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; /** * Creates a new AtomicInteger with the given initial value. * * @param initialValue the initial value */ public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 总结参考 https://snailclimb.gitee.io/javaguide/#/docs/java/Multithread/JavaConcurrencyAdvancedCommonInterviewQuestions","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(十三)ConcurrentLinkedQueue并发容器","slug":"backend/java/concurrent/并发多线程(十三)ConcurrentLinkedQueue并发容器","date":"2019-05-02T15:02:44.000Z","updated":"2019-09-19T12:25:24.396Z","comments":true,"path":"2019/05/02/backend/java/concurrent/并发多线程(十三)ConcurrentLinkedQueue并发容器/","link":"","permalink":"http://www.songshuiyang.com/2019/05/02/backend/java/concurrent/并发多线程(十三)ConcurrentLinkedQueue并发容器/","excerpt":"","text":"概述 要实现一个线程安全的队列有两种方式：阻塞和非阻塞。阻塞队列无非就是锁的应用，而非阻塞则是CAS算法的应用。下面我们就开始一个非阻塞算法的研究：CoucurrentLinkedQueue。解析 ConcurrentLinkedQueue是一个基于链接节点的无边界的线程安全队列，它采用FIFO原则对元素进行排序。采用“wait-free”算法（即CAS算法）来实现的。 CoucurrentLinkedQueue的结构由head节点和tail节点组成，每个节点由节点元素item和指向下一个节点的next引用组成，而节点与节点之间的关系就是通过该next关联起来的，从而组成一张链表的队列。节点Node为ConcurrentLinkedQueue的内部类，定义如下123456789101112131415161718192021222324252627282930313233343536373839404142434445private static class Node&lt;E&gt; &#123; /** 节点元素域 */ volatile E item; volatile Node&lt;E&gt; next; //初始化,获得item 和 next 的偏移量,为后期的CAS做准备 Node(E item) &#123; UNSAFE.putObject(this, itemOffset, item); &#125; boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; void lazySetNext(Node&lt;E&gt; val) &#123; UNSAFE.putOrderedObject(this, nextOffset, val); &#125; boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; /** 偏移量 */ private static final long itemOffset; /** 下一个元素的偏移量 */ private static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = Node.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"item\")); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"next\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 总结参考 http://www.iocoder.cn/JUC/sike/ConcurrentLinkedQueue/","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(十二)ConcurrentHashMap并发容器","slug":"backend/java/concurrent/并发多线程(十二)ConcurrentHashMap并发容器","date":"2019-05-02T15:01:44.000Z","updated":"2020-03-21T14:52:42.891Z","comments":true,"path":"2019/05/02/backend/java/concurrent/并发多线程(十二)ConcurrentHashMap并发容器/","link":"","permalink":"http://www.songshuiyang.com/2019/05/02/backend/java/concurrent/并发多线程(十二)ConcurrentHashMap并发容器/","excerpt":"","text":"概述 HashMap是我们用得非常频繁的一个集合，但是由于它是非线程安全的，在多线程环境下，put操作是有可能产生死循环的，导致CPU利用率接近100%。为了解决该问题，提供了Hashtable和Collections.synchronizedMap(hashMap)两种解决方案，但是这两种方案都是对读写加锁，独占式，一个线程在读时其他线程必须等待，吞吐量较低，性能较为低下。故而Doug Lea大神给我们提供了高性能的线程安全HashMap：ConcurrentHashMap。 解析ConcurrentHashMap的实现 ConcurrentHashMap作为Concurrent一族，其有着高效地并发操作，相比Hashtable的笨重，ConcurrentHashMap则更胜一筹了。 在1.8版本以前，ConcurrentHashMap采用分段锁的概念，使锁更加细化，但是1.8已经改变了这种思路，而是利用CAS+Synchronized来保证并发更新的安全，当然底层采用数组+链表+红黑树的存储结构。 我们先用一个示意图来描述下其结构： 结构上和 Java8 的 HashMap 基本上一样，不过它要保证线程安全性，所以在源码上确实要复杂一些。 初始化1234567891011// 这构造函数里，什么都不干public ConcurrentHashMap() &#123;&#125;public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; put 过程分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // key、value均不能为null if (key == null || value == null) throw new NullPointerException(); // 得到 hash 值 int hash = spread(key.hashCode()); // 用于记录相应链表的长度 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 如果数组\"空\"，进行数组初始化 if (tab == null || (n = tab.length) == 0) // 初始化数组，后面会详细介绍 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 如果数组该位置为空， // 用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了 // 如果 CAS 失败，那就是有并发操作，进到下一个循环就好了 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容 else if ((fh = f.hash) == MOVED) // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了 tab = helpTransfer(tab, f); else &#123; // 到这里就是说，f 是该位置的头结点，而且不为空 V oldVal = null; // 获取数组该位置的头结点的监视器锁 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; // 头结点的 hash 值大于 0，说明是链表 // 用于累加，记录链表的长度 binCount = 1; // 遍历链表 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 如果发现了\"相等\"的 key，判断是否要进行值覆盖，然后也就可以 break 了 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; // 到了链表的最末端，将这个新值放到链表的最后面 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // 红黑树 Node&lt;K,V&gt; p; binCount = 2; // 调用红黑树的插值方法插入新节点 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // binCount != 0 说明上面在做链表操作 if (binCount != 0) &#123; // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8 if (binCount &gt;= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 // 具体源码我们就不看了，扩容部分后面说 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // addCount(1L, binCount); return null;&#125; get 过程分析123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 判断头结点是否就是我们需要的节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 如果头结点的 hash 小于 0，说明 正在扩容，或者该位置是红黑树 else if (eh &lt; 0) // 参考 ForwardingNode.find(int h, Object k) 和 TreeBin.find(int h, Object k) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; get 方法从来都是最简单的，这里也不例外： 计算 hash 值 根据 hash 值找到数组对应位置: (n – 1) &amp; h 根据该位置处结点性质进行相应查找 总结其他 何为同步容器？可以简单地理解为通过 synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。 比如 Vector，Hashtable，以及 Collections#synchronizedSet()，Collections#synchronizedList() 等方法返回的容器。 可以通过查看 Vector，Hashtable 等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字 synchronized 。并发容器，使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性。 例如在 ConcurrentHashMap 中采用了一种粒度更细的加锁机制，可以称为分段锁。在这种锁机制下，允许任意数量的读线程并发地访问 map ，并且执行读操作的线程和写操作的线程也可以并发的访问 map ，同时允许一定数量的写操作线程并发地修改 map ，所以它可以在并发环境下实现更高的吞吐量。 SynchronizedMap 和 ConcurrentHashMap 有什么区别？ SynchronizedMap 一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为 map 。 ConcurrentHashMap * 参考 http://www.iocoder.cn/JUC/sike/ConcurrentHashMap/ http://svip.iocoder.cn/Java/Concurrent/Interview/ http://www.importnew.com/28263.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(十一)CompareAndSwap(CAS)","slug":"backend/java/concurrent/并发多线程(十一)CompareAndSwap(CAS)","date":"2019-05-02T15:00:44.000Z","updated":"2019-09-19T12:25:24.388Z","comments":true,"path":"2019/05/02/backend/java/concurrent/并发多线程(十一)CompareAndSwap(CAS)/","link":"","permalink":"http://www.songshuiyang.com/2019/05/02/backend/java/concurrent/并发多线程(十一)CompareAndSwap(CAS)/","excerpt":"","text":"概述 CAS ，Compare And Swap ，即比较并交换。Doug Lea 大神在实现同步组件时，大量使用CAS 技术，鬼斧神工地实现了Java 多线程的并发操作。整个 AQS 同步组件、Atomic 原子类操作等等都是基 CAS 实现的 CAS分析 在 CAS 中有三个参数：内存值 V、旧的预期值 A、要更新的值 B ，当且仅当内存值 V 的值等于旧的预期值 A 时，才会将内存值V的值修改为 B ，否则就再次尝试。其伪代码如下： 123456if (this.value == A) &#123; this.value = B return true;&#125; else &#123; return false;&#125; 这样说或许有些抽象，我们来看一个例子： 1.在内存地址V当中，存储着值为10的变量。 2.此时线程1想要把变量的值增加1。对线程1来说，旧的预期值A=10，要修改的新值B=11。 3.在线程1要提交更新之前，另一个线程2抢先一步，把内存地址V中的变量值率先更新成了11。 4.线程1开始提交更新，首先进行A和地址V的实际值比较（Compare），发现A不等于V的实际值，提交失败。 5.线程1重新获取内存地址V的当前值，并重新计算想要修改的新值。此时对线程1来说，A=11，B=12。这个重新尝试的过程被称为自旋。 6.这一次比较幸运，没有其他线程改变地址V的值。线程1进行Compare，发现A和地址V的实际值是相等的。 7.线程1进行SWAP，把地址V的值替换为B，也就是12。 * 由于CAS操作属于乐观派，它总认为自己可以成功完成操作，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作，这点从图中也可以看出来。基于这样的原理，CAS操作即使没有锁，同样知道其他线程对共享资源操作影响，并执行相应的处理措施。 J.U.C 下的 Atomic 类，都是通过 CAS 来实现的。下面就以 AtomicInteger 为例，来阐述 CAS 的实现。如下： 我们就以 AtomicInteger 的 #addAndGet() 方法来做说明，先看源代码： 1234567891011121314// AtomicInteger.javapublic final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta;&#125;// Unsafe.javapublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 关注 public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 12 对象 对象的地址 预期值 修改值public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); CPU指令对CAS的支持 或许我们可能会有这样的疑问，假设存在多个线程执行CAS操作并且CAS的步骤很多，有没有可能在判断V和E相同后，正要赋值时，切换了线程，更改了值。造成了数据不一致呢？答案是否定的， 因为CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 鲜为人知的指针: Unsafe类 Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，单从名称看来就可以知道该类是非安全的，毕竟Unsafe拥有着类似于C的指针操作，因此总是不应该首先使用Unsafe类，Java官方也不建议直接使用的Unsafe类，但我们还是很有必要了解该类，因为Java中CAS操作的执行依赖于Unsafe类的方法，注意Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的方法都直接调用操作系统底层资源执行相应任务，关于Unsafe类的主要功能点如下： 内存管理，Unsafe类中存在直接操作内存的方法； 1234567891011121314151617181920212223242526// 分配内存指定大小的内存public native long allocateMemory(long bytes);// 根据给定的内存地址address设置重新分配指定大小的内存public native long reallocateMemory(long address, long bytes);// 用于释放allocateMemory和reallocateMemory申请的内存public native void freeMemory(long address);// 将指定对象的给定offset偏移量内存块中的所有字节设置为固定值public native void setMemory(Object o, long offset, long bytes, byte value);//设置给定内存地址的值public native void putAddress(long address, long x);// 获取指定内存地址的值public native long getAddress(long address);// 设置给定内存地址的long值public native void putLong(long address, long x);// 获取指定内存地址的long值public native long getLong(long address);// 设置或获取指定内存的byte值// 其他基本数据类型(long,char,float,double,short等)的操作与putByte及getByte相同public native byte getByte(long address);public native void putByte(long address, byte x); CAS是一些CPU直接支持的指令，也就是我们前面分析的无锁操作，在Java中无锁操作CAS基于以下3个方法实现 12345678//第一个参数o为给定对象，offset为对象内存的偏移量，通过这个偏移量迅速定位字段并设置或获取该字段的值，//expected表示期望值，x表示要设置的值，下面3个方法都通过CAS原子指令执行操作。public final native boolean compareAndSwapObject(Object o, long offset,Object expected, Object x); public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x); public final native boolean compareAndSwapLong(Object o, long offset,long expected,long x); CAS缺陷 CAS 虽然高效地解决了原子操作，但是还是存在一些缺陷的，主要表现在三个方面： 循环时间太长 如果CAS一直不成功呢？这种情况绝对有可能发生，如果自旋 CAS 长时间地不成功，则会给 CPU 带来非常大的开销。在 J.U.C 中，有些地方就限制了 CAS 自旋的次数，例如： BlockingQueue 的 SynchronousQueue 。 只能保证一个共享变量原子操作 看了 CAS 的实现就知道这只能针对一个共享变量，如果是多个共享变量就只能使用锁了，当然如果你有办法把多个变量整成一个变量，利用 CAS 也不错。例如读写锁中 state 的高低位。 ABA 问题 CAS 需要检查操作值有没有发生改变，如果没有发生改变则更新。但是存在这样一种情况：如果一个值原来是 A，变成了 B，然后又变成了 A，那么在 CAS 检查的时候会发现没有改变，但是实质上它已经发生了改变，这就是所谓的ABA问题。对于 ABA 问题其解决方案是加上版本号，即在每个变量都加上一个版本号，每次改变时加 1 ，即 A —&gt; B —&gt; A ，变成1A —&gt; 2B —&gt; 3A 。 总结： 从思想上来说，Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。 参考 http://www.iocoder.cn/JUC/sike/CAS/ https://blog.csdn.net/mmoren/article/details/79185862","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(十)Condition","slug":"backend/java/concurrent/并发多线程(十)Condition","date":"2019-05-02T14:59:44.000Z","updated":"2019-09-19T12:25:24.380Z","comments":true,"path":"2019/05/02/backend/java/concurrent/并发多线程(十)Condition/","link":"","permalink":"http://www.songshuiyang.com/2019/05/02/backend/java/concurrent/并发多线程(十)Condition/","excerpt":"","text":"简介 Condition 在没有 Lock 之前，我们使用 synchronized 来控制同步，配合 Object 的 #wait()、#notify() 等一系列方法可以实现等待 / 通知模式。在 Java SE 5 后，Java 提供了 Lock 接口，相对于 synchronized 而言，Lock 提供了条件 Condition ，对线程的等待、唤醒操作更加详细和灵活。下图是 Condition 与 Object 的监视器方法的对比（摘自《Java并发编程的艺术》）： java.util.concurrent.locks.Condition 条件 Condition 接口，定义了一系列的方法，来对阻塞和唤醒线程： 12345678910// ========== 阻塞 ==========void await() throws InterruptedException; // 造成当前线程在接到信号或被中断之前一直处于等待状态。void awaitUninterruptibly(); // 造成当前线程在接到信号之前一直处于等待状态。【注意：该方法对中断不敏感】。long awaitNanos(long nanosTimeout) throws InterruptedException; // 造成当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。返回值表示剩余时间，如果在`nanosTimeout` 之前唤醒，那么返回值 `= nanosTimeout - 消耗时间` ，如果返回值 `&lt;= 0` ,则可以认定它已经超时了。boolean await(long time, TimeUnit unit) throws InterruptedException; // 造成当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。boolean awaitUntil(Date deadline) throws InterruptedException; // 造成当前线程在接到信号、被中断或到达指定最后期限之前一直处于等待状态。如果没有到指定时间就被通知，则返回 true ，否则表示到了指定时间，返回返回 false 。// ========== 唤醒 ==========void signal(); // 唤醒一个等待线程。该线程从等待方法返回前必须获得与Condition相关的锁。void signalAll(); // 唤醒所有等待线程。能够从等待方法返回的线程必须获得与Condition相关的锁。 Condition是个接口，基本的方法就是await()和signal()方法； Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition() 调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock之间才可以使用 Conditon中的await()对应Object的wait()； Condition中的signal()对应Object的notify()； Condition中的signalAll()对应Object的notifyAll()。 示例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ConditionTest &#123; final Lock lock = new ReentrantLock(); // 获取的是ConditionObject final Condition condition = lock.newCondition(); public static void main(String[] args) &#123; ConditionTest conditionTest = new ConditionTest(); Consumer consumer = conditionTest.new Consumer(); Producer producer = conditionTest.new Producer(); consumer.start(); producer.start(); &#125; class Consumer extends Thread &#123; @Override public void run() &#123; try &#123; lock.lock(); System.out.println(\"消费者：我在等一个新信号\" + currentThread().getName()); condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"消费者：拿到一个信号\" + currentThread().getName()); lock.unlock(); &#125; &#125; &#125; class Producer extends Thread &#123; @Override public void run() &#123; try &#123; lock.lock(); System.out.println(\"生产者：我拿到了锁\" + currentThread().getName()); condition.signalAll(); System.out.println(\"生产者：我发出了一个信号\" + currentThread().getName()); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; 运行结果 1234567\"C:\\Program Files\\Java\\jdk1.7.0_80\\bin\\java\" \"-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2017.2.1\\lib\\idea_rt.jar=54974:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2017.2.1\\bin\" -Dfile.encoding=UTF-8 -classpath \"C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\charsets.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\deploy.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\access-bridge-64.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\dnsns.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\jaccess.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\localedata.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\sunec.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\sunjce_provider.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\sunmscapi.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\ext\\zipfs.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\javaws.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\jce.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\jfr.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\jfxrt.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\jsse.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\management-agent.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\plugin.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\resources.jar;C:\\Program Files\\Java\\jdk1.7.0_80\\jre\\lib\\rt.jar;D:\\workspace-github\\jvm\\target\\production\\jvm\" com.songsy.jdk.concurrent.ConditionTest消费者：我在等一个新信号Thread-0生产者：我拿到了锁Thread-1生产者：我发出了一个信号Thread-1消费者：拿到一个信号Thread-0Process finished with exit code 0 Condition的执行方式，是当在线程Consumer中调用await方法后，线程Consumer将释放锁，并且将自己沉睡，等待唤醒，线程Producer获取到锁后，开始做事，完毕后，调用Condition的signalall方法，唤醒线程Consumer，线程Consumer恢复执行。 以上说明Condition是一个多线程间协调通信的工具类，使得某个，或者某些线程一起等待某个条件（Condition）,只有当该条件具备( signal 或者 signalAll方法被带调用)时 ，这些等待线程才会被唤醒，从而重新争夺锁。 ConditionObject 获取一个 Condition 必须要通过 Lock 的 #newCondition() 方法。该方法定义在接口 Lock 下面，返回的结果是绑定到此 Lock 实例的新 Condition 实例。Condition 为一个接口，其下仅有一个实现类 ConditionObject ，由于 Condition 的操作需要获取相关的锁，而 AQS则是同步锁的实现基础，所以 ConditionObject 则定义为 AQS 的内部类。代码如下： 123456789101112131415public class ConditionObject implements Condition, java.io.Serializable &#123; /** * 我们知道一个Condition可以在多个地方被await()，那么就需要一个FIFO的结构将这些Condition串联起来， * 然后根据需要唤醒一个或者多个（通常是所有）。所以在Condition内部就需要一个FIFO的队列。 */ /** First node of condition queue. */ private transient Node firstWaiter; // 头节点 /** Last node of condition queue. */ private transient Node lastWaiter; // 尾节点 public ConditionObject() &#123; &#125; // ... 省略内部代码&#125; 从代码中可以看出ConditionObject 拥有首节点（firstWaiter），尾节点（lastWaiter）。当前线程调用 #await()方法时，将会以当前线程构造成一个节点（Node），并将节点加入到该队列的尾部 Node 里面包含了当前线程的引用。Node 定义与 AQS 的 CLH 同步队列的节点使用的都是同一个类（AbstractQueuedSynchronized 的 Node 静态内部类）。 大体实现流程 AQS等待队列与Condition队列是两个相互独立的队列 await()就是在当前线程持有锁的基础上释放锁资源，并新建Condition节点加入到Condition的队列尾部，阻塞当前线程 signal()就是将Condition的头节点移动到AQS等待节点尾部，让其等待再次获取锁 以下是AQS队列和Condition队列的出入结点的示意图，可以通过这几张图看出线程结点在两个队列中的出入关系和条件。 一：AQS等待队列有3个Node，Condition队列有1个Node(也有可能1个都没有)，节点1执行Condition.await() 1.将head后移 2.释放节点1的锁并从AQS等待队列中移除 3.将节点1加入到Condition的等待队列中 4.更新lastWaiter为节点1 二：节点2执行signal()操作 5.将firstWaiter后移 6.将节点4移出Condition队列 7.将节点4加入到AQS的等待队列中去 8.更新AQS的等待队列的tail await 调用 Condition 的 #await() 方法，会使当前线程进入等待状态，同时会加入到 Condition 等待队列，并且同时释放锁。当从 #await() 方法结束时，当前线程一定是获取了Condition 相关联的锁。 signal 调用 ConditionObject的 #signal() 方法，将会唤醒在等待队列中等待最长时间的节点（条件队列里的首节点），在唤醒节点前，会将节点移到CLH同步队列中。 示例 生产者和消费者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class ConsumerProducer &#123; private int storage; private int putCounter; private int getCounter; private Lock lock = new ReentrantLock(); private Condition putCondition = lock.newCondition(); private Condition getCondition = lock.newCondition(); public void put() throws InterruptedException &#123; try &#123; lock.lock(); if (storage &gt; 0) &#123; putCondition.await(); &#125; storage++; System.out.println(\"put =&gt; \" + ++putCounter ); getCondition.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void get() throws InterruptedException &#123; try &#123; lock.lock(); lock.lock(); if (storage &lt;= 0) &#123; getCondition.await(); &#125; storage--; System.out.println(\"get =&gt; \" + ++getCounter); putCondition.signal(); &#125; finally &#123; lock.unlock(); lock.unlock(); &#125; &#125; public class PutThread extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; try &#123; put(); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; &#125; public class GetThread extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; try &#123; get(); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; final ConsumerProducer test = new ConsumerProducer(); Thread put = test.new PutThread(); Thread get = test.new GetThread(); put.start(); get.start(); &#125;&#125; 总结： 一个线程获取锁后，通过调用 Condition 的 #await() 方法，会将当前线程先加入到条件队列中，然后释放锁，最后通过 #isOnSyncQueue(Node node) 方法，不断自检看节点是否已经在 CLH 同步队列了，如果是则尝试获取锁，否则一直挂起。 当线程调用 #signal() 方法后，程序首先检查当前线程是否获取了锁，然后通过#doSignal(Node first) 方法唤醒CLH同步队列的首节点。被唤醒的线程，将从 #await() 方法中的 while 循环中退出来，然后调用 #acquireQueued(Node node, int arg) 方法竞争同步状态。 参考 http://www.iocoder.cn/JUC/sike/Condition/ https://blog.csdn.net/coslay/article/details/45217069","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(九)ReadWriteLock与ReentrantReadWriteLock","slug":"backend/java/concurrent/并发多线程(九)ReadWriteLock与ReentrantReadWriteLock","date":"2019-04-29T14:59:50.000Z","updated":"2019-12-03T12:17:09.368Z","comments":true,"path":"2019/04/29/backend/java/concurrent/并发多线程(九)ReadWriteLock与ReentrantReadWriteLock/","link":"","permalink":"http://www.songshuiyang.com/2019/04/29/backend/java/concurrent/并发多线程(九)ReadWriteLock与ReentrantReadWriteLock/","excerpt":"","text":"简介 重入锁 ReentrantLock 是排他锁，排他锁在同一时刻仅有一个线程可以进行访问，但是在大多数场景下，大部分时间都是提供读服务，而写服务占有的时间较少。然而，读服务不存在数据竞争问题，如果一个线程在读时禁止其他线程读势必会导致性能降低。所以就提供了读写锁。 读写锁维护着一对锁，一个读锁和一个写锁。通过分离读锁和写锁，使得并发性比一般的排他锁有了较大的提升： 在同一时间，可以允许多个读线程同时访问。 是，在写线程访问时，所有读线程和写线程都会被阻塞。 读写锁的主要特性： 公平性：支持公平性和非公平性。 重入性：支持重入。读写锁最多支持 65535 个递归写入锁和 65535 个递归读取锁。 锁降级：遵循获取写锁，再获取读锁，最后释放写锁的次序，如此写锁能够降级成为读锁。 示例 ReadWriteLock ReadWriteLock也是一个接口，在它里面只定义了两个方法： 123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading. */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing. */ Lock writeLock();&#125; 一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。 4.ReentrantReadWriteLock ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。 下面通过几个例子来看一下ReentrantReadWriteLock具体用法。 假如有多个线程要同时进行读操作的话，先看一下synchronized达到的效果： 12345678910111213141516171819202122232425262728public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public synchronized void get(Thread thread) &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+\"正在进行读操作\"); &#125; System.out.println(thread.getName()+\"读操作完毕\"); &#125;&#125; 这段程序的输出结果会是，直到thread1执行完读操作之后，才会打印thread2执行读操作的信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0读操作完毕Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1读操作完毕 而改成用读写锁的话： 12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void get(Thread thread) &#123; rwl.readLock().lock(); try &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+\"正在进行读操作\"); &#125; System.out.println(thread.getName()+\"读操作完毕\"); &#125; finally &#123; rwl.readLock().unlock(); &#125; &#125;&#125; 此时打印的结果为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0读操作完毕Thread-1读操作完毕 说明thread1和thread2在同时进行读操作。这样就大大提升了读操作的效率。不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。 四.总结参考转载 https://www.cnblogs.com/dolphin0520/p/3932921.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(八)Reentrantlock重入锁","slug":"backend/java/concurrent/并发多线程(八)Reentrantlock重入锁","date":"2019-04-29T14:59:48.000Z","updated":"2020-01-04T12:21:52.249Z","comments":true,"path":"2019/04/29/backend/java/concurrent/并发多线程(八)Reentrantlock重入锁/","link":"","permalink":"http://www.songshuiyang.com/2019/04/29/backend/java/concurrent/并发多线程(八)Reentrantlock重入锁/","excerpt":"","text":"简介 ReentrantLock，可重入锁，是一种递归无阻塞的同步机制。它可以等同于 synchronized 的使用，但是 ReentrantLock 提供了比 synchronized 更强大、灵活的锁机制，可以减少死锁发生的概率。 一个可重入的互斥锁定 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁定相同的一些基本行为和语义，但功能更强大。 示例 ReentrantLock，意思是“可重入锁”，ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。下面通过一些实例看具体看一下如何使用ReentrantLock。 lock()的错误使用方法 代码 12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; Lock lock = new ReentrantLock(); //注意这个地方 lock.lock(); try &#123; System.out.println(thread.getName()+\"得到了锁\"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+\"释放了锁\"); lock.unlock(); &#125; &#125;&#125; 各位朋友先想一下这段代码的输出结果是什么？ 1234Thread-0得到了锁Thread-1得到了锁Thread-0释放了锁Thread-1释放了锁 也许有朋友会问，怎么会输出这个结果？第二个线程怎么会在第一个线程释放锁之前得到了锁？原因在于，在insert方法中的lock变量是局部变量，每个线程执行该方法时都会保存一个副本，那么理所当然每个线程执行到lock.lock()处获取的是不同的锁，所以就不会发生冲突。 知道了原因改起来就比较容易了，只需要将lock声明为类的属性即可。 12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; lock.lock(); try &#123; System.out.println(thread.getName()+\"得到了锁\"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+\"释放了锁\"); lock.unlock(); &#125; &#125;&#125; 这样就是正确地使用Lock的方法了。 tryLock()的使用方法 代码 12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; if(lock.tryLock()) &#123; try &#123; System.out.println(thread.getName()+\"得到了锁\"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+\"释放了锁\"); lock.unlock(); &#125; &#125; else &#123; System.out.println(thread.getName()+\"获取锁失败\"); &#125; &#125;&#125; 输出结果： 123Thread-0得到了锁Thread-1获取锁失败Thread-0释放了锁 lockInterruptibly()响应中断的使用方法： 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Test &#123; private Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; Test test = new Test(); MyThread thread1 = new MyThread(test); MyThread thread2 = new MyThread(test); thread1.start(); thread2.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread2.interrupt(); &#125; public void insert(Thread thread) throws InterruptedException&#123; lock.lockInterruptibly(); //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出 try &#123; System.out.println(thread.getName()+\"得到了锁\"); long startTime = System.currentTimeMillis(); for( ; ;) &#123; if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE) break; //插入数据 &#125; &#125; finally &#123; System.out.println(Thread.currentThread().getName()+\"执行finally\"); lock.unlock(); System.out.println(thread.getName()+\"释放了锁\"); &#125; &#125;&#125; class MyThread extends Thread &#123; private Test test = null; public MyThread(Test test) &#123; this.test = test; &#125; @Override public void run() &#123; try &#123; test.insert(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+\"被中断\"); &#125; &#125;&#125; 运行之后，发现thread2能够被正确中断 12Thread-0得到了锁Thread-1被中断 补充synchronized与ReentrantLock两者的性能 在 JDK1.6 之前，synchronized 的性能是比 ReentrantLock 差很多。具体表示为：synchronized 关键字吞吐量岁线程数的增加，下降得非常严重。而 ReentrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点， 了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReentrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReentrantLock 的文章都是错的！ JDK1.6 之后，性能已经不是选择 synchronized 和 ReentrantLock 的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的 synchronized，所以还是提倡在 synchronized 能满足你的需求的情况下，优先考虑使用 synchronized 关键字来进行同步！优化后的 synchronized 和 ReentrantLock 一样，在很多地方都是用到了 CAS 操作。 总结 与 synchronized 相比，ReentrantLock提供了更多，更加全面的功能，具备更强的扩展性。例如：时间锁等候，可中断锁等候，锁投票。 ReentrantLock 还提供了条件 Condition ，对线程的等待、唤醒操作更加详细和灵活，所以在多个条件变量和高度竞争锁的地方，ReentrantLock 更加适合（以后会阐述Condition）。 ReentrantLock 提供了可轮询的锁请求。它会尝试着去获取锁，如果成功则继续，否则可以等到下次运行时处理，而 synchronized 则一旦进入锁请求要么成功要么阻塞，所以相比 synchronized 而言，ReentrantLock会不容易产生死锁些。 ReentrantLock 支持更加灵活的同步代码块，但是使用 synchronized 时，只能在同一个 synchronized 块结构中获取和释放。注意，ReentrantLock 的锁释放一定要在 finally 中处理，否则可能会产生严重的后果。 ReentrantLock 支持中断处理，且性能较 synchronized 会好些。 获取锁方法 lock() 阻塞式地获取锁，只有在获取到锁后才处理interrupt信息 lockInterruptibly()阻塞式地获取锁，立即处理interrupt信息，并抛出异常 lockInterruptibly()方法能够中断等待获取锁的线程。当两个线程同时通过lock.lockInterruptibly()获取某个锁时，假若此时线程A获取到了锁，而线程B只有等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 tryLock() 尝试获取一次锁，不管成功失败，都立即返回true、false tryLock(long timeout, TimeUnit unit)在timeout时间内阻塞式地获取锁，成功返回true，超时返回false，同时立即处理interrupt信息，并抛出异常 公平锁与非公平锁 ReentrantLock 默认采用非公平锁，除非在构造方法中传入参数 true ，所谓非公平锁，就是不管执行顺序，每个线程获取锁的几率都是相同的 参考转载 http://www.iocoder.cn/JUC/sike/ReentrantLock/https://blog.csdn.net/yangcheng33/article/details/47708631","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(七)AbstractQueuedSynchronizer","slug":"backend/java/concurrent/并发多线程(七)AbstractQueuedSynchronizer","date":"2019-04-29T14:59:44.000Z","updated":"2020-03-16T11:43:55.429Z","comments":true,"path":"2019/04/29/backend/java/concurrent/并发多线程(七)AbstractQueuedSynchronizer/","link":"","permalink":"http://www.songshuiyang.com/2019/04/29/backend/java/concurrent/并发多线程(七)AbstractQueuedSynchronizer/","excerpt":"","text":"简介 AbstractQueuedSynchronizer(AQS ) 即队列同步器。它是构建锁或者其他同步组件的基础框架（如 ReentrantLock、ReentrantReadWriteLock、Semaphore 等），它使用了一个int成员变量表示同步状态，通过内置的FIFO队列完成资源获取线程的派对工作 J.U.C 并发包的作者（Doug Lea）期望它能够成为实现大部分同步需求的基础。它是 J.U.C 并发包中的核心基础组件。 原理概览 AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 优势 AQS 解决了在实现同步器时涉及当的大量细节问题，例如获取同步状态、FIFO 同步队列。基于 AQS 来构建同步器可以带来很多好处。它不仅能够极大地减少实现工作，而且也不必处理在多个位置上发生的竞争问题。 在基于 AQS 构建的同步器中，只能在一个时刻发生阻塞，从而降低上下文切换的开销，提高了吞吐量。同时在设计 AQS 时充分考虑了可伸缩性，因此 J.U.C 中，所有基于 AQS 构建的同步器均可以获得这个优势。 同步状态 AQS 的主要使用方式是继承，子类通过继承同步器，并实现它的抽象方法来管理同步状态。 AQS 使用一个 int 类型的成员变量 state 来表示同步状态： 当 state &gt; 0 时，表示已经获取了锁。 当 state = 0 时，表示释放了锁。 它提供了三个方法，来对同步状态 state 进行操作，并且 AQS 可以确保对 state 的操作是安全的： getState() setState(int newState) compareAndSetState(int expect, int update) 同步队列 AQS 通过内置的 FIFO 同步队列来完成资源获取线程的排队工作： 如果当前线程获取同步状态失败（锁）时，AQS 则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程 当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。 同步器的开始提到了其实现依赖于一个FIFO队列，该队列就是 CLH 同步队列，那么队列中的元素Node就是保存着线程引用和线程状态的容器，每个线程对同步器的访问，都可以看做是队列中的一个节点。 Node 是 AbstractQueuedSynchronizer 的内部静态类，Node的主要包含以下成员变量： 属性名称 描述 int waitStatus 表示节点的状态。其中包含的状态有：1. CANCELLED，值为1，由于在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待表示当前的线程被取消；2. SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，将会通知后继节点，使后继节点的线程得以运行；3. CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中；4. PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行； 5. 值为0，表示当前节点在sync队列中，等待着获取锁。 Node prev 前驱节点，比如当前节点被取消，那就需要前驱节点和后继节点来完成连接。 Node next 后继节点。 Node nextWaiter 存储condition队列中的后继节点。 Thread thread 入队列时的当前线程。 入列 学了数据结构的我们，CLH 队列入列是再简单不过了 tail 指向新节点。 新节点的 prev 指向当前最后的节点。 当前最后一个节点的 next 指向当前节点。 过程图如下： 实际上，入队逻辑实现的 #addWaiter(Node) 方法，需要考虑并发的情况。它通过 CAS 的方式，来保证正确的添加 Node 。代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Creates and enqueues node for current thread and given mode. * * mode 方法参数，传递获取同步状态的模式。 * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */private Node addWaiter(Node mode) &#123; // 新建节点 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 记录原尾节点 Node pred = tail; // 快速尝试，添加新节点为尾节点 if (pred != null) &#123; // 设置新 Node 节点的尾节点为原尾节点 node.prev = pred; // CAS 设置新的尾节点 if (compareAndSetTail(pred, node)) &#123; // 成功，原尾节点的下一个节点为新节点 pred.next = node; return node; &#125; &#125; // 失败，多次尝试，直到成功 enq(node); return node;&#125; /** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */private Node enq(final Node node) &#123; // 死循环，多次尝试，直到成功添加为止 for (;;) &#123; // 记录原尾节点 Node t = tail; // 原尾节点不存在，创建首尾节点都为 new Node() if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 原尾节点存在，添加新节点为尾节点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 出队 CLH 同步队列遵循 FIFO，首节点的线程释放同步状态后，将会唤醒它的下一个节点（Node.next）。而后继节点将会在获取同步状态成功时，将自己设置为首节点( head )。 这个过程非常简单，head 执行该节点并断开原首节点的 next 和当前节点的 prev 即可。注意，在这个过程是不需要使用 CAS 来保证的，因为只有一个线程，能够成功获取到同步状态。 过程图如下： setHead(Node node) 方法，实现上述的出列逻辑。代码如下：12345private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; API说明 实现自定义同步器时，需要使用同步器提供的getState()、setState()和compareAndSetState()方法来操纵状态的变迁。 方法名称 描述 getState() 返回同步状态的当前值。 setState(int newState) 设置当前同步状态。 compareAndSetState(int expect, int update) 使用 CAS 设置当前状态，该方法能够保证状态设置的原子性。 protected boolean tryAcquire(int arg) 【可重写】排它的获取这个状态。这个方法的实现需要查询当前状态是否允许获取，然后再进行获取（使用compareAndSetState来做）状态。 protected boolean tryRelease(int arg) 【可重写】释放状态。 protected int tryAcquireShared(int arg) 【可重写】共享的模式下获取状态。 protected boolean tryReleaseShared(int arg) 【可重写】共享的模式下释放状态。 protected boolean isHeldExclusively() 【可重写】在排它模式下，状态是否被占用。 acquire(int arg) 独占式获取同步状态。如果当前线程获取同步状态成功，则由该方法返回；否则，将会进入同步队列等待。该方法将会调用可重写的 #tryAcquire(int arg) 方法； acquireInterruptibly(int arg) 与 acquire(int arg) 相同，但是该方法响应中断。当前线程为获取到同步状态而进入到同步队列中，如果当前线程被中断，则该方法会抛出InterruptedException 异常并返回。 tryAcquireNanos(int arg, long nanos) 超时获取同步状态。如果当前线程在 nanos 时间内没有获取到同步状态，那么将会返回 false ，已经获取则返回 true 。 acquireShared(int arg) 共享式获取同步状态，如果当前线程未获取到同步状态，将会进入同步队列等待，与独占式的主要区别是在同一时刻可以有多个线程获取到同步状态； acquireSharedInterruptibly(int arg) 共享式获取同步状态，响应中断。 tryAcquireSharedNanos(int arg, long nanosTimeout) 共享式获取同步状态，增加超时限制。 release(int arg) 独占式释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒。 releaseShared(int arg) 共享式释放同步状态。 同步状态的获取与释放 AQS 的设计模式采用的模板方法模式，子类通过继承的方式，实现它的抽象方法来管理同步状态。对于子类而言，它并没有太多的活要做，AQS 已经提供了大量的模板方法来实现同步，主要是分为三类： 独占式获取和释放同步状态 共享式获取和释放同步状态 查询同步队列中的等待线程情况。 独占式: 同一时刻，仅有一个线程持有同步状态。 共享式: 共享式与独占式的最主要区别在于，同一时刻：1、独占式只能有一个线程获取同步状态。2、共享式可以有多个线程获取同步状态。 总结： 等待队列是FIFO先进先出。 加入同步队列后，并不是立即挂起，而是再次进行获取同步状态, 到挂起之前都是在自旋（无限循环尝试），因为同步状态的变化很快，线程上下文的切换比较耗时，所以用短暂的自旋来换取时间开销，当然如果一直自旋，那么开销反而大于了线程切换。所以把自旋时间（次数）控制在一定范围有利于提高性能。 参考 https://snailclimb.gitee.io/javaguide/#/docs/java/Multithread/AQS http://www.iocoder.cn/JUC/sike/aqs-0-intro/ https://blog.csdn.net/u014634338/article/details/77168608","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(六)ThreadLocal","slug":"backend/java/concurrent/并发多线程(六)ThreadLocal","date":"2019-04-20T14:59:44.000Z","updated":"2020-03-16T11:43:55.463Z","comments":true,"path":"2019/04/20/backend/java/concurrent/并发多线程(六)ThreadLocal/","link":"","permalink":"http://www.songshuiyang.com/2019/04/20/backend/java/concurrent/并发多线程(六)ThreadLocal/","excerpt":"","text":"ThreadLocal 作用在并发编程中时常有这样一种需求：每条线程都需要存取一个同名变量，但每条线程中该变量的值均不相同。 如果是你，该如何实现上述功能？常规的思路如下：使用一个线程共享的Map，Map中的key为线程对象，value即为需要存储的值。那么，我们只需要通过map.get(Thread.currentThread())即可获取本线程中该变量的值。 这种方式确实可以实现我们的需求，但它有何缺点呢？——答案就是：需要同步，效率低！ 由于这个map对象需要被所有线程共享，因此需要加锁来保证线程安全性。当然我们可以使用java.util.concurrent.*包下的ConcurrentHashMap提高并发效率，但这种方法只能降低锁的粒度，不能从根本上避免同步锁。而JDK提供的ThreadLocal就能很好地解决这一问题。下面来看看ThreadLocal是如何高效地实现这一需求的。 ThreadLocal 是什么 ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，其实意思差不多。可能很多朋友都知道ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量，个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。 ThreadLocal 解析 ThreadLocal的内部结构图 threadLocal 从上面的结构图，我们已经窥见ThreadLocal的核心机制： 每个Thread线程内部都有一个Map。 Map里面存储线程本地对象（key）和线程的变量副本（value） 但是，Thread内部的Map是由ThreadLocal维护的，由ThreadLocal负责向map获取和设置线程的变量值。 所以对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰。 Thread线程内部的Map在类中描述如下:123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal类提供如下几个核心方法： get()方法用于获取当前线程的副本变量值。 set()方法用于保存当前线程的副本变量值。 initialValue()为当前线程初始副本变量值。 remove()方法移除当前前程的副本变量值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/** * 返回当前线程的副本变量 * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */public T get() &#123; Thread t = Thread.currentThread(); // 返回Thread 对象中的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; // 如果没有值的话调用默认setInitialValue()方法 return setInitialValue();&#125;/** * 存放在Thread的 threadLocals * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;/** * 设置初始值 * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;// map为空的话返回初始值null，即线程变量副本为null，在使用时需要注意判断NullPointerException。protected T initialValue() &#123; return null;&#125;/** * 赋值 * Sets the current thread's copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of * this thread-local. */public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;/** * Removes the current thread's value for this thread-local * variable. If this thread-local variable is subsequently * &#123;@linkplain #get read&#125; by the current thread, its value will be * reinitialized by invoking its &#123;@link #initialValue&#125; method, * unless its value is &#123;@linkplain #set set&#125; by the current thread * in the interim. This may result in multiple invocations of the * &#123;@code initialValue&#125; method in the current thread. * * @since 1.5 */ public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; ThreadLocalMap ThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部的Entry也独立实现:12345678910111213141516171819202122static class ThreadLocalMap &#123; /** * 在ThreadLocalMap中，也是用Entry来保存K-V结构数据的。但是Entry中key只能是ThreadLocal对象 * * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as \"stale entries\" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; // Entry继承自WeakReference（弱引用，生命周期只能存活到下次GC前），但只有Key是弱引用类型的，Value并非弱引用。 super(k); value = v; &#125; &#125;&#125; ThreadLocalMap的问题由于ThreadLocalMap的key是弱引用，而Value是强引用。这就导致了一个问题，ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，而Value不会回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。 Java的四种引用方式前言 Java的数据类型分为两类：基本数据类型、引用数据类型。 基本数据类型的值存储在栈内存中 引用数据类型需要开辟两块存储空间，一块在堆内存中，用于存储该类型的对象；另一块在栈内存中，用于存储堆内存中该对象的引用。 Java对象的引用类型包括: 强引用，软引用，弱引用，虚引用，详情见Java基础-强引用-软引用-弱引用-虚引用章节 Java中提供这四种引用类型主要有两个目的： 第一是可以让程序员通过代码的方式决定某些对象的生命周期，随着 java.lang.ref这个包下的类的引进，程序员拥有了一点点控制你创建的对象何时释放，销毁的权利 第二是有利于JVM进行垃圾回收 介绍如何避免泄漏既然Key是弱引用，那么我们要做的事，就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots分析后就变成不可达了，下次GC的时候就可以被回收。 如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。 ThreadLocal 应用场景 Hibernate的session获取场景：每个线程访问数据库都应当是一个独立的Session会话，如果多个线程共享同一个Session会话，有可能其他线程关闭连接了，当前线程再执行提交时就会出现会话已关闭的异常，导致系统异常。此方式能避免线程争抢Session，提高并发下的安全性。 12345678910111213141516171819202122private static final ThreadLocal&lt;Session&gt; threadLocal = new ThreadLocal&lt;Session&gt;();// 获取Sessionpublic static Session getCurrentSession()&#123; Session session = threadLocal.get(); // 判断Session是否为空，如果为空，将创建一个session，并设置到本地线程变量中 try &#123; if(session == null &amp;&amp; !session.isOpen())&#123; if(sessionFactory == null)&#123; // 创建Hibernate的SessionFactory rbuildSessionFactory(); &#125;else&#123; session = sessionFactory.openSession(); &#125; &#125; threadLocal.set(session); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return session;&#125; 总结： 每个ThreadLocal只能保存一个变量副本，如果想要上线一个线程能够保存多个副本以上，就需要创建多个ThreadLocal。 ThreadLocal内部的ThreadLocalMap键为弱引用，会有内存泄漏的风险。 适用于无状态，副本变量独立后不影响业务逻辑的高并发场景。如果如果业务逻辑强依赖于副本变量，则不适合用ThreadLocal解决，需要另寻解决方案。 参考 https://www.jianshu.com/p/98b68c97df9b https://www.jianshu.com/p/3f3620f9011d https://blog.csdn.net/rodbate/article/details/72857447 https://www.cnblogs.com/dolphin0520/p/3784171.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"RabbitMQ-与Spring集成-问题记录","slug":"backend/framework/mq/RabbitMQ-与Spring集成-问题记录","date":"2019-04-14T16:05:02.000Z","updated":"2020-04-12T06:18:27.545Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-与Spring集成-问题记录/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-与Spring集成-问题记录/","excerpt":"","text":"整理1、使用错误的交换器或者路由key发送消息不报错 测试发现如果生产者在发送消息的时候如果是错误的交换器或者路由key则不会报错，这个需要注意下，这样如果粗心的话很容易造成以为生产者发送消息正常，但队列里面没有消息 123456@Testpublic void test1() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"0\"); rabbitMessagingTemplate.convertAndSend(\"错误exchange_submit_order\", \"错误routingKey\", orderMO);&#125; 2、消息处理异常导致RabbitMQ不断重试 第一次使用Spring RabbitMQ时发现如果消费者的处理方法抛出异常的话，这个消息通知会一直触发，后台log也会一直打 原因： RabbitMQ消息监听程序异常时，消费者会向rabbitmq server发送Basic.Reject，表示消息拒绝接受 由于Spring默认requeue-rejected配置为true，消息会重新入队，然后rabbitmq server重新投递，造成了程序一直异常的情况 所以我们通过rabbitmq监听消息的时候，程序一定要添加try…catch语句!!!当然你也可以根据实际情况，选择设置requeue-rejected为false来丢弃消息。 3、消费端反序列化异常 下面场景会出现反序列化异常: OrderMO orderMO = JSON.parseObject(message.getBody(), OrderMO.class); orderMO对象解析后为null导致程序报错 查看 String messageString = new String(message.getBody()); 解析后发现是下面这种格式 1�� \u0005sr -com.songsy.springboot.rabbitmq.entity.OrderMO�\u0013�b+�*\u0010\u0002 \u0001L \u0007orderNot \u0012Ljava/lang/String;xpt \u00010 生产者代码 12345678@Datapublic class OrderMO implements Serializable &#123; private static final long serialVersionUID = -7128203829971899888L; private String orderNo;&#125; 123OrderMO orderMO = new OrderMO();orderMO.setOrderNo(\"0\");rabbitMessagingTemplate.convertAndSend(\"exchange_submit_order\", \"routing_key_submit_order\", orderMO); 消费者代码 123456789@RabbitListener(bindings = @QueueBinding( value = @Queue(value = \"queue_submit_order\", durable = \"true\"), exchange = @Exchange(value = \"exchange_submit_order\", type = ExchangeTypes.DIRECT, durable = \"true\"), key = \"routing_key_submit_order\"))public void rabbitMessageProcess1(Channel channel, Message message, OrderMO orderMO, @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag) throws IOException &#123; String messageString = new String(message.getBody()); log.info(\"收到提交订单mq消息:&#123;&#125; deliveryTag:&#123;&#125; \", messageString, deliveryTag);&#125; 一开始猜测是OrderMO没有实现Serializable接口导致的，加上之后测试了下发现还是不行 最后跟进消费者端代码发现org.springframework.amqp.support.converter.MessagingMessageConverter#fromMessage解析message默认使用的是SimpleMessageConverter，看到这个名字就发现和SpringMVC的HttpMessageConverter好像，查看此接口的涉及的子类，和HttpMessageConverter如出一辙 1234567891011121314public Object fromMessage(Message message) throws MessageConversionException &#123; if (message == null) &#123; return null; &#125; else &#123; Map&lt;String, Object&gt; mappedHeaders = this.headerMapper.toHeaders(message.getMessageProperties()); Object convertedObject = this.extractPayload(message); MessageBuilder&lt;Object&gt; builder = convertedObject instanceof org.springframework.messaging.Message ? MessageBuilder.fromMessage((org.springframework.messaging.Message)convertedObject) : MessageBuilder.withPayload(convertedObject); return builder.copyHeadersIfAbsent(mappedHeaders).build(); &#125;&#125;protected Object extractPayload(Message message) &#123; return this.payloadConverter.fromMessage(message);&#125; 解决方法，添加下面的bean，这样才可以将message.getBody()字节流转化为json串，并通过JSON.parseObject反序列化 1234@Beanpublic MessageConverter messageConverter()&#123; return new Jackson2JsonMessageConverter();&#125; 这里发现MessageConverter的套路和HttpMessageConverter的套路一样，消息格式转化都是通过MessageConverter接口定义，不同的格式转化对应不同的转换类 4、队列配置更新了导致报错 启动时报如下错误 1ERROR 5624 --- [ 127.0.0.1:5672] o.s.a.r.c.CachingConnectionFactory : Channel shutdown: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=406, reply-text=PRECONDITION_FAILED - inequivalent arg 'x-message-ttl' for queue 'jishufeng' in vhost '/': received the value '1000' of type 'signedint' but current is none, class-id=50, method-id=10) 原因： 是现启动的队列配置与后台已有的配置不一致导致的。 解决：进入后台，删除已有配置即可，删除前要关闭已有连接程序。 5、弃用 QueueingConsumer QueueingConsumer RabbitMQ 客户端 3.x 版本中用得如火如荼 但是在 4.x 版本开始就被标记为@Deprecated，使用此类有可能会导致内存溢出问题 参考 RabbitMQ实战指南 https://my.oschina.net/jzgycq/blog/1576288 https://www.jianshu.com/p/da8e2ab6591d","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-与Spring集成","slug":"backend/framework/mq/RabbitMQ-与Spring集成","date":"2019-04-14T16:05:01.000Z","updated":"2020-04-11T15:19:44.118Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-与Spring集成/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-与Spring集成/","excerpt":"","text":"前言 在SpringBoot项目中使用RabbitMQ是很简单的，只要几步就可以 pom文件添加 starter依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 下面可以看到这个starter又依赖了其他两个包 消费者代码方式一12345678910111213141516171819202122232425262728293031323334/** * 声明队列 * @return */@Beanpublic Queue queue() &#123; return new Queue(\"queue_submit_order\", true);&#125;/** * 声明Direct交换器 * @return */@Beanpublic DirectExchange directExchange() &#123; return new DirectExchange(\"exchange_submit_order\");&#125;/** * 绑定Exchange和queue 正确地将消息路由到指定的Queue */@Beanpublic Binding binding() &#123; return BindingBuilder.bind(queue()).to(directExchange()).with(\"routing_key_submit_order\");&#125;..../** * 消费者 * @param message */@RabbitListener(queues = \"queue_submit_order\")public void receive(String message) &#123; // log.info(\"receive queue message: \" + message);&#125; 方式二 方式二的使用方式更为简洁，直接通过一个@RabbitListener全搞定 deliveryTag 可以看作消息的编号 123456789101112131415161718192021222324252627282930313233@RabbitListener(bindings = @QueueBinding( value = @Queue(value = \"queue_submit_order\", durable = \"true\"), exchange = @Exchange(value = \"exchange_submit_order\", type = ExchangeTypes.DIRECT, durable = \"true\"), key = \"routing_key_submit_order\"))public void rabbitMessageProcess1(Channel channel, Message message, OrderMO orderMO, @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag) throws IOException &#123; String messageString = new String(message.getBody()); log.info(\"收到提交订单mq消息:&#123;&#125; deliveryTag:&#123;&#125; \", messageString, deliveryTag); // 添加Jackson2JsonMessageConverter bean后直接在方法参数上可以实现反序列化操作，而不用下面这种方式 // OrderMO orderMO = JSON.parseObject(message.getBody(), OrderMO.class); try &#123; // 提交订单的处理 模拟异常场景 if (\"1\".equals(orderMO.getOrderNo())) &#123; throw new IllegalArgumentException(\"参数异常\"); &#125; else if (\"2\".equals(orderMO.getOrderNo())) &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // MessageProperties messageProperties = message.getMessageProperties(); // 消息手动确认 channel.basicAck(deliveryTag, false); &#125; catch (Exception e) &#123; log.error(\"[通知]-处理异常:&#123;&#125;\", e.getMessage()); // 转发到重试队列 后续处理 rabbitMessagingTemplate.convertAndSend(\"exchange_submit_order\",\"routing_key_submit_order_retry\", orderMO); // channel.basicReject(deliveryTag,false); // 消息拒绝 channel.basicNack(deliveryTag,false,false); // 和basicReject效果一样不过可以批量拒绝消息 &#125;&#125; 生产者代码 指定好交换器名及路由键即可发送消息到对应队列中去 1234567@Testpublic void test2() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"0\"); // String payload = JSON.toJSONString(orderMO); rabbitMessagingTemplate.convertAndSend(\"exchange_submit_order\", \"routing_key_submit_order\", orderMO);&#125; 补充RabbitMQ 自建的Exchange 如下图所示RabbitMQ会建direct、fanout、topic、headers默认的一些交换器，默认新建的这些交换器有什么好处呢，那就是可以不用指定交换器了，直接使用RabbitMQ Broker默认的交换器 上面的示例代码可以看到一个消息的发送及接受需要声明队列、声明交换器、声明绑定，还是挺繁琐的，如果使用默认的交换器就不需要这些，下面通过一个例子来说明 direct Exchange是RabbitMQ Broker的默认Exchange 它有一个特别的属性对一些简单的应用来说是非常有用的，在使用这个类型的Exchange时，可以不必指定routing key的名字，在此类型下创建的Queue有一个默认的routing key，这个routing key一般同Queue同名。 所以不需要将Exchange进行任何绑定(binding)操作 。消息传递时，RouteKey必须完全匹配，才会被队列接收，否则该消息会被抛弃。 示例如下，下面的代码只声明了一个队列就完成了一个消息的发送及接受123456789101112131415161718192021222324/** * 声明队列 * routing key和Queue都是`only_one_queue` * @return */@Beanpublic Queue onlyOneQqueue() &#123; return new Queue(\"only_one_queue\", true);&#125;/** * 消费者 */@RabbitListener(queues = \"only_one_queue\")public void receive(String message) &#123; logger.info(\"receive:&#123;&#125;\", message);&#125;/** * 生产者 */@Testpublic void test0() &#123; rabbitMessagingTemplate.convertAndSend(\"only_one_queue\", \"发送一条only_one_queue消息\");&#125; 参考 RabbitMQ实战指南","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-分布式部署","slug":"backend/framework/mq/RabbitMQ-分布式部署","date":"2019-04-14T16:05:00.000Z","updated":"2020-04-11T12:23:47.852Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-分布式部署/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-分布式部署/","excerpt":"","text":"前言集群 RabbitMQ 集群允许消费者和生产者在 RabbitMQ 单个节点崩惯的情况下继续运行，它可以通过添加更多的节点来线性地扩展消息通信的吞吐量。当失去一个 RabbitMQ 节点时 客户端能够重新连接到集群中的任何其他节点并继续生产或者消费。 不过 RabbitMQ 集群不能保证消息的万无一失 即将消息、队列、交换器等都设置为可持久化，生产端和消费端都正确地使用了确认方式。当集群中一个 RabbitMQ 节点崩溃时，该节点上的所有队列中的消息也会丢失。 RabbitM 集群中 的所有节点都会备份所有的元数据信息，包括以下内容。 但是不会备份消息，可以通过特殊的配置比如镜像队列可以解决这个问题 基于存储空间和性能的考虑 RabbitMQ 集群中创建队列，集群只会在单个节点而不是在所有节点上创建队列的进程井包含完整的队列信息(元数据 、状态、内容)。这样只有队列的宿主节点，即所有者节点知道队列的所有信息，所有其他非所有者节点只知道队列的元数据和指向该队列存在的那个节点的指针。因此当集群节点崩溃时，该节点的队列进程和关联的绑定都会消失。附加在那些队列上的消费者 会丢失其所订阅的信息 井且任何匹配该队列绑定信息的新消息也都会消失。 RabbitMQ 集群对延迟非常敏感，应当只在本地局域网内使用。在广域网中不应该使用集群，而应该使用 Federation 或者 Shove1 来代替。 在集群中创建队列、交换器或者绑定关系的时候，这些操作直到所有集群节点都成功提交元数据变更后才会返回 Federation Federation 插件的设计目标是使 RabbitMQ 在不同的 Broker 节点之间进行消息传递而无须建立集群， Shovel参考 RabbitMQ实战指南","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-配置管理","slug":"backend/framework/mq/RabbitMQ-配置管理","date":"2019-04-14T16:04:00.000Z","updated":"2020-04-11T12:23:47.861Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-配置管理/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-配置管理/","excerpt":"","text":"前言管理用户管理123456789101112131415161718192021# 创建songsy2用户，密码songsy2[root@VM_0_8_centos ~]# rabbitmqctl add_user songsy2 songsy2Creating user \"songsy2\" ...# 修改密码[root@VM_0_8_centos ~]# rabbitmqctl change_password songsy2 songsy21# 删除用户[root@VM_0_8_centos ~]# rabbitmqctl delete_user songsy2Deleting user \"songsy2\" ...# 查看用户及角色（tag）[root@VM_0_8_centos ~]# rabbitmqctl list_usersListing users ...songsy2 []songsy1 []songsy [administrator]# 用户授权[root@VM_0_8_centos ~]# rabbitmqctl set_user_tags songsy2 managementSetting tags for user \"songsy2\" to [management] ... 角色分类 1、其他(none) 无法登陆管理控制台，通常就是普通的生产者和消费者，新建用户默认就是这个 2、普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 3、策略制定者(policymaker) 包含management所有权限，可以管理策略(policy)和参数(parameter) 4、监控者(monitoring) 包含management所有权限，可以看到所有连接、信道及节点相关信息 5、超级管理员(administrator) 最高权限 虚拟主机（vhost） 每一个RabbitMQ都能创建虚拟消息服务器，我们称之为虚拟主机（vhost），每一个vhost本质上是一个mini版的RabbitMQ服务器，拥有自己的交换器、队列和绑定……更重要的是他有自己的权限机制 实例 12345678910111213# 添加一个名为vhost1的虚拟主机[root@VM_0_8_centos ~]# rabbitmqctl add_vhost vhost1Creating vhost \"vhost1\" ...# 查看有哪些虚拟主机（/是默认的）[root@VM_0_8_centos ~]# rabbitmqctl list_vhostsListing vhosts ...vhost1/# 授权songsy1用户可以访问vhost1并在所有资源上都具备可配置可读写的权限[root@VM_0_8_centos ~]# rabbitmqctl set_permissions -p vhost1 songsy1 \".*\" \".*\" \".*\"Setting permissions for user \"songsy1\" in vhost \"vhost1\" ... HTTP API接口 HTTP API接口通常用来方便客户端的调用，采用RESTful协议的接口形式 内存及磁盘告警 内存告警 默认情况下vm_memory_high_watermark 的值为0.4，即内存阑值为0.4 表示当 RabbitMQ 使用的内存超过 40%时，就会产生内存告警井阻塞所有生产者的连接。 一旦告警被解除(有消息被消费或者从内存转储到磁盘等情况的发生)， 一切都会恢复正常。 磁盘告警 默认情况下，磁盘阑值为 50MB，这意味着当磁盘剩余空间低于50MB 时会阻塞生产者井停止内存中消息的换页动作 参考 RabbitMQ实战指南 https://pdf-lib.org/Home/Details/10901 https://blog.csdn.net/w893932747/java/article/details/81018591","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-使用-死信队列及延迟队列","slug":"backend/framework/mq/RabbitMQ-使用-死信队列及延迟队列","date":"2019-04-14T16:03:02.000Z","updated":"2020-04-12T05:53:21.620Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-使用-死信队列及延迟队列/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-使用-死信队列及延迟队列/","excerpt":"","text":"前言死信队列 DLX(Dead-Letter-Exchange)，当消息在一个队列中变成死信之后，它能被重新被发送到另一个交换器中，这个交换器叫做DLX，而绑定DLX的队列叫死信队列 消息变成死信有下面几种情况 消息被拒绝(Basic.Reject/Basic.Nack) ，井且设置 requeue 参数为 false; 消息过期 队列达到最大长度 对于 RabbitMQ 来说， DLX 个非常有用的特性，它可以处理异常情况下，消息不能够被消费者正确消费(消费者调用了 Basic.Nack 或者 Basic.Reject) 而被置入死信队列中的情况，后续分析程序可以通过消费这个死信队列中的内容来分析当时所遇到的异常情况，进而可以改善和优化系统。 DLX 配合 TTL 使用还可以实现延迟队列的功能， 实例介绍 下面代码配置了两套交换器及队列【测试死信队列-正常队列、测试死信队列-死信队列】，同时通过参数配置将队列【测试死信队列-死信队列】设置为【测试死信队列-正常队列】死信队列 12345678910111213141516171819202122232425262728293031323334353637@Beanpublic Queue receiveDeadQueue() &#123; return new Queue(\"测试死信队列-死信队列\", true);&#125;@Beanpublic Queue receiveNormalQueue() &#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 绑定死信队列 通过队列属性设置，队列中所有消息都有相同的过期时间。 // map.put(\"x-message-ttl\", 20000); map.put(\"x-dead-letter-exchange\",\"测试死信队列-dead-exchange\"); map.put(\"x-dead-letter-routing-key\", \"测试死信队列-dead-routing-key\"); // return new Queue(\"\",true,false,false,map); return QueueBuilder.durable(\"测试死信队列-正常队列\") .withArguments(map).build();&#125;@Beanpublic DirectExchange receiveNormalExchange()&#123; return new DirectExchange(\"测试死信队列-normal-exchange\");&#125;@Beanpublic DirectExchange receiveDeadExchange()&#123; return new DirectExchange(\"测试死信队列-dead-exchange\");&#125;@Beanpublic Binding receiveDeadBinding() &#123; return BindingBuilder.bind(receiveDeadQueue()).to(receiveDeadExchange()).with(\"测试死信队列-dead-routing-key\");&#125;@Beanpublic Binding receiveNormalBinding() &#123; return BindingBuilder.bind(receiveNormalQueue()).to(receiveNormalExchange()).with(\"测试死信队列-normal-routing-key\");&#125; 下面通过两个场景来介绍死信队列 1、消息被拒绝(Basic.Reject/Basic.Nack)场景进入死信队列 消费者代码 12345678910111213141516171819202122232425@RabbitListener(queues = \"测试死信队列-正常队列\")public void rabbitMessageProcess1(Channel channel, Message message, OrderMO orderMO, @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag) throws IOException &#123; String messageString = new String(message.getBody()); logger.info(\"收到测试死信队列-正常队列mq消息:&#123;&#125; deliveryTag:&#123;&#125; \", messageString, deliveryTag); try &#123; // 提交订单的处理 模拟异常场景 if (\"1\".equals(orderMO.getOrderNo())) &#123; throw new IllegalArgumentException(\"参数异常\"); &#125; else if (\"2\".equals(orderMO.getOrderNo())) &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // MessageProperties messageProperties = message.getMessageProperties(); // 消息手动确认 channel.basicAck(deliveryTag, false); &#125; catch (Exception e) &#123; logger.error(\"异常\", e); channel.basicReject(deliveryTag,false); // 消息拒绝 //channel.basicNack(deliveryTag,false,false); // 和basicReject效果一样不过可以批量拒绝消息 &#125;&#125; 生产者代码 12345678910111213/** * 向队列中发送消息 抛异常 */ @Test public void sendDelayMessage2() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"1\"); rabbitTemplate.convertAndSend( \"测试死信队列-normal-exchange\", \"测试死信队列-normal-routing-key\", orderMO ); &#125; 运行上面的测试类，消费者代码会抛异常然后走catch逻辑，之后将消息channel.basicReject(deliveryTag,false)拒绝 结果可以看到消息进到死信队列了 2、消息过期场景进入死信队列 将上面队列配置的这行map.put(&quot;x-message-ttl&quot;, 20000);注释给去掉，这里的意思是如果队列【测试死信队列-正常队列】收到消息后20秒之后没有消费，就会把这个消息转发到队列【测试死信队列-死信队列】中 123456789101112@Beanpublic Queue receiveNormalQueue() &#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 绑定死信队列 通过队列属性设置，队列中所有消息都有相同的过期时间。 // map.put(\"x-message-ttl\", 20000); map.put(\"x-dead-letter-exchange\",\"测试死信队列-dead-exchange\"); map.put(\"x-dead-letter-routing-key\", \"测试死信队列-dead-routing-key\"); // return new Queue(\"\",true,false,false,map); return QueueBuilder.durable(\"测试死信队列-正常队列\") .withArguments(map).build();&#125; 注释消费者代码，等20秒后结果 延迟队列TTL1、设置消息的TTL 是对消息本身进行单独设置，每条消息的 TTL 可以不同 2、设置队列的TTL 针对队列来说，可以使用x-message-ttl参数设置当前队列中所有消息的过期时间，即当前队列中所有的消息过期时间都一样； 上面有示例代码 优先级队列 可通过x-max-priority参数来设置队列的优先级，具有优先级别高的队列具有高的优先权，优先级高的消息具体优先被消费的特权 如果在消费者的消费数据大于生产者消费的速度且Broker中没有消息堆积的情况下，对于发送的消息设置优先级并没有什么实际意义，一条消息怎么判断优先级 补充但是基于TTL的延时队列存在一个问题，就是同一个队列里的消息延时时间最好一致，比如说队列里的延时时间都是1小时，千万不能队列里的消息延时时间乱七八糟多久的都有，这样的话先入队的消息如果延时时间过长会堵着后入队延时时间小的消息，导致后面的消息到时也无法变成死信转发出去，很坑！！！举个栗子：延时队列里先后进入A,B,C三条消息，存活时间是3h,2h,1h，结果到了1小时C不会死，到了2hB不会死，到了3小时A死了，同时B,C也死了，意味着3h后A,B,C才能消费，很坑！！！我本来使用时候以为会像redis的存活时间一样，内部维护一个定时器去扫描死亡时间然后变成死信转发，结果不是。。。至于怎么解决这个问题，一个队列里可以放不同死亡时间的消息，还能够异步死亡转发，请看下回分解:springboot整合rabbitmq实现延时队列之rabbitmq_delayed_messageexchange插件方式————————————————版权声明：本文为CSDN博主「是guava不是瓜娃啊」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/eumenides/java/article/details/86025773 参考 RabbitMQ实战指南 https://www.cnblogs.com/vipstone/p/9295625.html","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-使用-消息发送确认及消息接收确认","slug":"backend/framework/mq/RabbitMQ-使用-消息发送确认及消息接收确认","date":"2019-04-14T16:03:01.000Z","updated":"2020-04-12T06:06:07.690Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-使用-消息发送确认及消息接收确认/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-使用-消息发送确认及消息接收确认/","excerpt":"","text":"前言消息发送确认 在默认情况下生产者是不知道消息有没有正确的到达服务器，如果消息到达服务器之前已经丢失，持久化操作也解决不了这个问题，针对这个问题，RabbitMQ提供了两种解决方法： 1、通过事务机制实现 这种模式下是通过channel txSelect、channel txCommit、channel txRollback3个事务控制方法来实现的 事务确实能够解决消息发送方和 RabbitMQ 之间消息确认的问题，只有消息成功被RabbitMQ 接收，事务才能提交成功，否则便可在捕获异常之后进行事务回滚 ，与此同时可以进行消息重发 但这种模式下回严重影响性能，所以RabbitMQ 提供了下面这种改进方案 2、 通过发送方确认（publisher confirm） 这个是轻量级解决方法，异步处理 如果不知道消息有没有正确的到达服务器，那么就需要一个确认操作，RabbitMQ提供了ConfirmCallback和ReturnCallback来检测消息是否已经到达对应队列 例子说明： 先自定义配置RabbitTemplateConfig confrim回调能检测到消息是否到达 broker，通过ack变量来判断，但不能保证消息准确投递到目标 queue return回调能检测到消息是否到达 queue，如果没有到达指定队列就会触发下面的逻辑 代码: 123456789101112131415161718192021222324252627282930313233343536373839404142@Configurationpublic class RabbitTemplateConfig &#123; private Logger log = LoggerFactory.getLogger(RabbitTemplateConfig.class); /** * confrim回调能检测到消息是否到达 broker，通过ack变量来判断，但不能保证消息准确投递到目标 queue * */ final RabbitTemplate.ConfirmCallback confirmCallback= new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; log.info(\"ConfirmCallback &gt;&gt; correlationData:&#123;&#125;, ack:&#123;&#125;, cause:&#123;&#125;\", correlationData , ack, cause); if(!ack)&#123; log.info(\"异常处理....\"); &#125; &#125; &#125;; /** * return回调能检测到消息是否到达 queue，如果没有到达指定队列就会触发下面的逻辑 */ final RabbitTemplate.ReturnCallback returnCallback = new RabbitTemplate.ReturnCallback() &#123; @Override public void returnedMessage(org.springframework.amqp.core.Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; log.info(\"ReturnCallback &gt;&gt; return exchange: &#123;&#125;, routingKey: &#123;&#125;, replyCode: &#123;&#125;, replyText: &#123;&#125;\", exchange, routingKey, replyCode, replyText); &#125; &#125;; @Bean(name = \"rabbitTemplate\") public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &#123; RabbitTemplate template = new RabbitTemplate(connectionFactory); // 开启 mandatory template.setMandatory(true); template.setConfirmCallback(confirmCallback); template.setReturnCallback(returnCallback); template.setMessageConverter(new Jackson2JsonMessageConverter()); return template; &#125;&#125; 测试类 12345678910111213141516171819202122232425262728293031323334353637383940/** * 给错误的交换器及路由键发消息 */@Testpublic void test1() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"给错误的交换器及路由键发消息\"); rabbitTemplate.convertAndSend(\"错误exchange_submit_order\", \"错误routing_key_submit_order\", orderMO);&#125;/** * 给错误的交换器发消息 */@Testpublic void test2() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"给错误的交换器发消息\"); rabbitTemplate.convertAndSend(\"错误exchange_submit_order\", \"routing_key_submit_order\", orderMO);&#125;/** * 给错误的路由键发消息 */@Testpublic void test3() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"给错误的路由键发消息\"); rabbitTemplate.convertAndSend(\"exchange_submit_order\", \"错误routing_key_submit_order\", orderMO);&#125;/** * 给正确的路由键发消息 */@Testpublic void test4() &#123; OrderMO orderMO = new OrderMO(); orderMO.setOrderNo(\"给正确的路由键发消息\"); rabbitTemplate.convertAndSend(\"exchange_submit_order\", \"routing_key_submit_order\", orderMO);&#125; 消息接收确认 为了保证消息从队列可靠地达到消费者， RabbitMQ 提供了消息确认机制 如果 RabbitMQ 一直没有收到消费者的确认信号，并且消费此消息的消费者己经断开连接，则RabbitMQ 会安排该消息重新进入队列，等待投递给下一个消费者 方法参数说明 deliveryTag 可以看作消息的编号 multiple 参数设置为 true 则表示对 deliveryTag 编号之前所有的消息未被ack都有效 如果 requeue 参数设置为 true ，则 RabbitMQ 会重新将这条消息存入队列，以便可以发送给下 个订阅的消费者12345678// 消息确认 void basicAck(long deliveryTag, boolean multiple)// 消息拒绝void basicReject(long deliveryTag, boolean requeue)// 消息拒绝 和basicReject效果一样不过可以批量拒绝序号为deliveryTag之前消息，void basicNack(long deliveryTag, boolean multiple, boolean requeue) 总结 RabbitMQ 提供了消息发送确认机制及消息接受机制来保证消息传递的可靠性 参考 RabbitMQ实战指南 https://www.cnblogs.com/vipstone/p/9295625.html","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-使用","slug":"backend/framework/mq/RabbitMQ-使用-消费信息模式","date":"2019-04-14T16:03:00.000Z","updated":"2020-04-12T06:15:22.107Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-使用-消费信息模式/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-使用-消费信息模式/","excerpt":"","text":"前言概念消费信息模式 RabbitMQ的消费模式分两种： 推模式 Basic.Consume 通过持续订阅的方式来消费消息 拉模式 Basic.Get 如果只想从队列获得单条消息而不是持续订阅，建议还是使用 Basic.Get 进行消费.但是不能将 Basic.Get 放在一个循环里来代替 Basic.Consume ，这样做会严重影响 RabbitMQ的性能 如果要实现高吞吐量，消费者理应使用 Basic.Consume 方法。 消费者要点1、消息分发 如果有多个消费者时，队列收到的消息将以轮询的方式发给消费者 如果有的消费者吃的比较慢，来不及消费那么多消息，那么就会一直累呀累呀，那么该如何处理这种情况呢，可以使用channel.basicQos(int prefetchCount) 如果是设置了这个就是限制信道上消费者所能保持的最大未确认消息的数量 对于拉模式无效 消息顺序 如果正常情况下如果生产者发布的消息分别为 msgl msg2 msg3 ，那么消费者必然也是按照 msgl msg2 msg3 的顺序进行消费的。 但是下面这些场景会导致消息不一定是按预期顺序消费的 有多个生产者的情况，因为你不知道那个先发完 有多个消费者的情况，是轮询消费的，而且每个消费者胃口不一样导致有的消费者吃的很多 如果使用了事务机制，万一出现回滚情况 设置了延迟队列 如果要保证消息的顺序性，需要业务方使用 RabbitMQ 之后做进一步的处理，比如在消息体内添加全局有序标识(类似 Sequence ID) 来实现 2、持久化 RabbitMQ的持久化分为三个部分: 交换器的持久化 队列的持久化 消息的持久化 在选择是否要将消息持久化时，需要在可靠性和吞吐量之间做一个权衡，因为持久化涉及到IO操作会影响性能 参考 RabbitMQ实战指南 https://www.cnblogs.com/vipstone/p/9295625.html","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RocketMQ-基础概念","slug":"backend/framework/mq/RocketMQ-基础概念","date":"2019-04-14T16:02:02.000Z","updated":"2020-01-04T12:21:52.125Z","comments":true,"path":"2019/04/15/backend/framework/mq/RocketMQ-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RocketMQ-基础概念/","excerpt":"","text":"前言RocketMQ 角色 如下图所示： 生产者（Producer）：负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。 消费者（Consumer）：负责消费消息，消费者从消息服务器拉取信息并将其输入用户应用程序。 消息服务器（Broker）：是消息存储中心，主要作用是接收来自 Producer 的消息并存储， Consumer 从这里取得消息。 名称服务器（NameServer）：用来保存 Broker 相关 Topic 等元信息并给 Producer ，提供 Consumer 查找 Broker 信息，感觉是个协调者 RocketMQ 的启动流程图 下面是RocketMQ启动流程图 1、启动 Namesrv Namesrv起 来后监听端口，等待 Broker、Producer、Consumer 连上来，相当于一个路由控制中心。 2、Broker 启动 Broker 跟所有的 Namesrv 保持长连接，定时发送心跳包。 心跳包中，包含当前 Broker 信息(IP+端口等)以及存储所有 Topic 信息。 注册成功后，Namesrv 集群中就有 Topic 跟 Broker 的映射关系。 3、收发消息前，先创建 Topic 创建 Topic 时，需要指定该 Topic 要存储在 哪些 Broker上。也可以在发送消息时自动创建Topic。 4、Producer 发送消息 启动时，先跟 Namesrv 集群中的其中一台建立长连接，并从Namesrv 中获取当前发送的 Topic 存在哪些 Broker 上，然后跟对应的 Broker 建立长连接，直接向 Broker 发消息。 5、Consumer 消费消息 Consumer 跟 Producer 类似。跟其中一台 Namesrv 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始消费消息。 Namesrv 1、Namesrv 用于存储 Topic、Broker关系信息，功能简单，稳定性高。 多个 Namesrv 之间相互没有通信，单台 Namesrv 宕机不影响其它 Namesrv 与集群，多个 Namesrv 之间的信息共享，通过 Broker 主动向多个 Namesrv 都发起心跳。正如上文所说，Broker 需要跟所有 Namesrv 连接。 即使整个 Namesrv集群宕机，已经正常工作的 Producer、Consumer、Broker 仍然能正常工作，但新起的Producer、Consumer、Broker 就无法工作，这点和 Dubbo 有些不同，不会缓存 Topic 等元信息到本地文件。 2、Namesrv 压力不会太大，平时主要开销是在维持心跳和提供 Topic-Broker 的关系数据。 但有一点需要注意，Broker 向 Namesr 发心跳时，会带上当前自己所负责的所有 Topic 信息，如果 Topic 个数太多（万级别），会导致一次心跳中，就 Topic 的数据就几十 M，网络情况差的话，网络传输失败，心跳失败，导致 Namesrv 误认为 Broker 心跳失败。 当然，一般公司，很难达到过万级的 Topic ，因为一方面体量达不到，另一方面 RocketMQ 提供了 Tag 属性。 另外，内网环境网络相对是比较稳定的，传输几十 M 问题不大。同时，如果真的要优化，Broker可以把心跳包做压缩，再发送给 Namesrv 。不过，这样也会带来 CPU 的占用率的提升。 Broker 1、 高并发读写服务。Broker的高并发读写主要是依靠以下两点： 消息顺序写，所有 Topic数据同时只会写一个文件，一个文件满1G ，再写新文件，真正的顺序写盘，使得发消息 TPS 大幅提高。 消息随机读，RocketMQ 尽可能让读命中系统Pagecache ，因为操作系统访问 Pagecache 时，即使只访问 1K 的消息，系统也会提前预读出更多的数据，在下次读时就可能命中 Pagecache ，减少 IO 操作。 2、 负载均衡与动态伸缩。 负载均衡：Broker 上存 Topic信息，Topic由多个队列组成，队列会平均分散在多个 Broker上，而 Producer 的发送机制保证消息尽量平均分布到所有队列中，最终效果就是所有消息都平均落在每个 Broker 上。 动态伸缩能力（非顺序消息）：Broker 的伸缩性体现在两个维度：Topic、Broker Topic 维度：假如一个 Topic的消息量特别大，但集群水位压力还是很低，就可以扩大该 Topic 的队列数， Topic 的队列数跟发送、消费速度成正比。 Broker 维度：如果集群水位很高了，需要扩容，直接加机器部署 Broker 就可以。Broker 启动后向 Namesrv 注册，Producer、Consumer 通过 Namesrv 发现新Broker，立即跟该 Broker 直连，收发消息。 3、 高可用 &amp; 高可靠。 高可用：集群部署时一般都为主备，备机实时从主机同步消息，如果其中一个主机宕机，备机提供消费服务，但不提供写服务。 高可靠：所有发往 Broker 的消息，有同步刷盘和异步刷盘机制。 同步刷盘时，消息写入物理文件才会返回成功。 异步刷盘时，只有机器宕机，才会产生消息丢失，Broker 挂掉可能会发生，但是机器宕机崩溃是很少发生的，除非突然断电。 如果 Broker 挂掉，未同步到硬盘的消息，还在 Pagecache 中呆着。 4、 Broker 与 Namesrv 的心跳机制。 单个 Broker 跟所有 Namesrv 保持心跳请求，心跳间隔为30秒，心跳请求中包括当前 Broker 所有的 Topic 信息。 Namesrv 会反查 Broker 的心跳信息，如果某个 Broker 在 2 分钟之内都没有心跳，则认为该 Broker 下线，调整 Topic 跟 Broker 的对应关系。但此时 Namesrv 不会主动通知Producer、Consumer 有 Broker 宕机。也就说，只能等 Producer、Consumer下次定时拉取 Topic 信息的时候，才会发现有 Broker 宕机。 Producer 1、获得 Topic-Broker 的映射关系。 Producer 启动时，也需要指定 Namesrv 的地址，从 Namesrv 集群中选一台建立长连接。如果该 Namesrv 宕机，会自动连其他 Namesrv ，直到有可用的 Namesrv为止。 生产者每 30 秒从 Namesrv 获取 Topic 跟 Broker 的映射关系，更新到本地内存中。然后再跟 Topic 涉及的所有 Broker 建立长连接，每隔 30 秒发一次心跳。 在 Broker 端也会每 10 秒扫描一次当前注册的 Producer ，如果发现某个 Producer 超过 2 分钟都没有发心跳，则断开连接。 2、生产者端的负载均衡。 生产者发送时，会自动轮询当前所有可发送的broker，一条消息发送成功，下次换另外一个broker发送，以达到消息平均落到所有的broker上。 这里需要注意一点：假如某个Broker 宕机，意味生产者最长需要 30 秒才能感知到。在这期间会向宕机的Broker 发送消息。当一条消息发送到某个Broker 失败后，会自动再重发 2 次，假如还是发送失败，则抛出发送失败异常。客户端里会自动轮询另外一个 Broker 重新发送，这个对于用户是透明的。 3、发送消息有几种方式 同步方式 异步方式 Oneway 方式 Consumer 1、获得 Topic-Broker 的映射关系。 Consumer 启动时需要指定 Namesrv 地址，与其中一个 Namesrv 建立长连接。消费者每隔 30 秒从 Namesrv 获取所有Topic 的最新队列情况，这意味着某个 Broker 如果宕机，客户端最多要 30 秒才能感知。连接建立后，从 Namesrv 中获取当前消费 Topic 所涉及的 Broker，直连 Broker 。 Consumer 跟 Broker 是长连接，会每隔 30 秒发心跳信息到Broker 。Broker 端每 10 秒检查一次当前存活的 Consumer ，若发现某个 Consumer 2 分钟内没有心跳，就断开与该 Consumer 的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡。 2、消费者端的负载均衡。根据消费者的消费模式不同，负载均衡方式也不同。 3、消费者有两种消费模式：集群消费和广播消费。 集群消费（几个人分6块肉）：一个 Topic 可以由同一个消费这分组( Consumer Group )下所有消费者平摊消费。 具体例子：假如 TopicA 有 6 个队列，某个消费者分组起了 2 个消费者实例，那么每个消费者负责消费 3 个队列。如果再增加一个消费者分组相同消费者实例，即当前共有 3 个消费者同时消费 6 个队列，那每个消费者负责 2 个队列的消费。 广播消费（每个人都有6块肉）：每个消费者消费 Topic 下的所有队列。 4、消费者获取消息有两种模式 PushConsumer 推送模式 推送模式（虽然 RocketMQ 使用的是长轮询push + pull 模式结合的方式））的消费者，消息的能及时被消费 使用非常简单，内部已处理如线程池消费、流控、负载均衡、异常处理等等的各种场景。 PullConsumer 拉取模式 拉取模式的消费者。应用主动控制拉取的时机，怎么拉取，怎么消费等。主动权更高。但要自己处理各种场景。 决绝绝大多数场景下，我们只会使用 PushConsumer 推送模式 其他多次消费失败后，怎么办？ 默认情况下，当一条消息被消费失败 16次后，会被存储到 Topic 为 &quot;%DLQ%&quot; + ConsumerGroup 到死信队列。 为什么 Topic 是 &quot;%DLQ%&quot; + ConsumerGroup 呢？因为，是这个 ConsumerGroup 对消息的消费失败，所以 Topic 里要以 ConsumerGroup 为维度。 后续，我们可以通过订阅 &quot;%DLQ%&quot; + ConsumerGroup ，做相应的告警。 RocketMQ 是否会弄丢数据 注意，RocketMQ 是否会丢数据，主要取决于我们如何使用，这点非常重要 1、🦅 生产者会不会弄丢数据？ Producer 可以设置三次发送消息重试。 2、🦅 Broker 弄丢了数据？ 在上面的问题中，我们已经看到了 Broker 提供了两个特性： 刷盘方式：同步刷盘、异步刷盘。 复制方式：同步复制、异步复制。 如果要保证 Broker 数据最大化的不丢，需要在搭建 Broker 集群时，设置为同步刷盘、同步复制。当然，带来了可靠性，也会一定程度降低性能。 如果想要在可靠性和性能之间做一个平衡，可以选择同步复制，加主从 Broker 都是和异步刷盘。因为，刷盘比较消耗性能。 3、🦅 消费端弄丢了数据？ 对于消费端，如果我们在使用 Push 模式的情况下，只有我们消费返回成功，才会异步定期更新消费进度到 Broker 上。 如果消费端异常崩溃，可能导致消费进度未更新到 Broker 上，那么无非是Consumer 可能重复拉取到已经消费过的消息。关于这个，就需要消费端做好消费的幂等性。 参考 https://www.jianshu.com/p/4a275e779afa https://m.2cto.com/os/201702/592453.html 芋道源码 http://www.iocoder.cn","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"}]},{"title":"RabbitMQ-基础概念","slug":"backend/framework/mq/RabbitMQ-基础概念","date":"2019-04-14T16:02:00.000Z","updated":"2020-04-11T14:24:10.480Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-基础概念/","excerpt":"","text":"前言概念 RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件） 相关概念生产者（Producer） 投递消息的一方 消费者（Consumer） 接受消息的一方 队列（Queue） 用于存储消息，消息只能存储在消息队列中 多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin ，即轮询)，给多个消费者进行处理，而不是每个消费者都收到所有的消息井处理 服务节点（Broker） 消息中间间的服务节点 交换器（Exchange） 类型： fanout fanout是一种发布/订阅模式的交换器，当你发送一条消息的时候，交换器会把消息广播到所有绑定到这个交换器的队列上，可以不用指定routingKey direct direct为默认的交换器类型，也非常的简单，它会把消息路由到哪些RoutingKey和BindingKey完全匹配的队列中 topic topic类型是在direct的基础上扩展的，direct类型是严格完全匹配，topic类型的交换器匹配规则更灵活 下图是RabbitMQ实战指南的截图 headers 其中headers交换器允许你匹配AMQP消息的header而非路由键，除此之外headers交换器和direct交换器完全一致，但性能却很差，几乎用不到 路由键（RoutingKey） 生产者将消息发送到交换器的时候，一般会指定一个RoutingKey，用来指定这个消息的路由规则，而这个RoutingKey需要和绑定键Binding联合才能最终生效 绑定（Binding） 将交换器和队列关联起来，通过这个键RabbitMQ就知道如何正确的的将消息路由到队列 连接（Connection） 无论是生产者还是消费者，都需要和RabbitMQ Broker建立联系，这个连接就是一条TCP连接，也就是Connection 信道（Channel） Connection可以用来创建多个Channel实例，当每个信道的流量不是很大时，复用单一的Connection 可以在产生性能瓶颈的情况下有效地节省 TCP 连接资源 补充参考 RabbitMQ实战指南 https://www.cnblogs.com/vipstone/p/9295625.html https://www.jianshu.com/p/19af0f40bbde","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-下载安装","slug":"backend/framework/mq/RabbitMQ-下载安装","date":"2019-04-14T16:01:00.000Z","updated":"2020-04-04T03:31:04.763Z","comments":true,"path":"2019/04/15/backend/framework/mq/RabbitMQ-下载安装/","link":"","permalink":"http://www.songshuiyang.com/2019/04/15/backend/framework/mq/RabbitMQ-下载安装/","excerpt":"","text":"Centos7中安装RabbitMQ 1).首先需要安装erlang，安装过程中会有提示，一路输入“y”即可。 12#rpm -Uvh http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm#yum install erlang 2).完成后安装RabbitMQ： 先下载rpm： 1#wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.6/rabbitmq-server-3.6.6-1.el7.noarch.rpm 下载完成后安装： 1#yum install rabbitmq-server-3.6.6-1.el7.noarch.rpm 完成后启动服务： 1#service rabbitmq-server start 可以查看服务状态： 1#service rabbitmq-server status RabbitMQ的配置1.修改配置文件 service rabbitmq-server status查看服务状态， 这里可以看到log文件的位置（/var/log/rabbitmq/rabbit@VM_0_8_centos.log），转到文件位置，打开文件： 12345678910111213141516171819202122Redirecting to /bin/systemctl status rabbitmq-server.service鈼[0m rabbitmq-server.service - RabbitMQ broker Loaded: loaded (/usr/lib/systemd/system/rabbitmq-server.service; disabled; vendor preset: disabled) Active: active (running) since Mon 2019-11-04 11:33:30 CST; 4min 31s ago Process: 24631 ExecStop=/usr/sbin/rabbitmqctl stop (code=exited, status=0/SUCCESS) Main PID: 24761 (beam) Status: \"Initialized\" CGroup: /system.slice/rabbitmq-server.service 鈹溾攢24761 /usr/lib64/erlang/erts-5.10.4/bin/beam -W w -A 64 -P 1048576 -t 5000000 -stbt db -zdbbl 32000 -K true -- -root /usr/lib64/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /u... 鈹溾攢25062 inet_gethost 4 鈹斺攢25063 inet_gethost 4Nov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: RabbitMQ 3.6.6. Copyright (C) 2007-2016 Pivotal Software, Inc.Nov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: ## ## Licensed under the MPL. See http://www.rabbitmq.com/Nov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: ## ##Nov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: ########## Logs: /var/log/rabbitmq/rabbit@VM_0_8_centos.logNov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: ###### ## /var/log/rabbitmq/rabbit@VM_0_8_centos-sasl.logNov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: ##########Nov 04 11:33:28 VM_0_8_centos rabbitmq-server[24761]: Starting broker...Nov 04 11:33:30 VM_0_8_centos rabbitmq-server[24761]: systemd unit for activation check: \"rabbitmq-server.service\"Nov 04 11:33:30 VM_0_8_centos systemd[1]: Started RabbitMQ broker.Nov 04 11:33:31 VM_0_8_centos rabbitmq-server[24761]: completed with 6 plugins. 这里显示的是没有找到配置文件，我们可以自己创建这个文件 12#cd /etc/rabbitmq/#vim rabbitmq.config 编辑内容如下，注意后面有个点 1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. 这里的意思是开放使用，rabbitmq默认创建的用户guest，密码也是guest，这个用户默认只能是本机访问，localhost或者127.0.0.1，从外部访问需要添加上面的配置。 保存配置后重启服务： 12#service rabbitmq-server stop#service rabbitmq-server start 2.安装插件1#/sbin/rabbitmq-plugins enable rabbitmq_management #service rabbitmq-server restart重启rabbitmq服务 到此,就可以通过http://ip:15672 使用guest,guest进行登陆web页面了 参考 https://www.cnblogs.com/php-linux/p/10855350.html","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.songshuiyang.com/tags/RabbitMQ/"}]},{"title":"RocketMQ-下载安装","slug":"backend/framework/mq/RocketMQ-下载安装","date":"2019-04-13T16:00:00.000Z","updated":"2020-04-05T03:08:54.762Z","comments":true,"path":"2019/04/14/backend/framework/mq/RocketMQ-下载安装/","link":"","permalink":"http://www.songshuiyang.com/2019/04/14/backend/framework/mq/RocketMQ-下载安装/","excerpt":"","text":"前言RocketMQ 是什么？ RocketMQ 是阿里巴巴在 2012 年开源的分布式消息中间件，目前已经捐赠给 Apache 软件基金会，并于 2017 年 9 月 25 日成为 Apache 的顶级项目。 作为经历过多次阿里巴巴双十一这种“超级工程”的洗礼并有稳定出色表现的国产中间件，以其高性能、低延时和高可靠等特性近年来已经也被越来越多的国内企业使用。 官网：http://rocketmq.apache.org 如下是 RocketMQ 产生的原因： 淘宝内部的交易系统使用了淘宝自主研发的 Notify 消息中间件，使用 MySQL 作为消息存储媒介，可完全水平扩容，为了进一步降低成本，我们认为存储部分可以进一步优化 2011 年初，Linkin开源了 Kafka 这个优秀的消息中间件，淘宝中间件团队在对 Kafka 做过充分 Review 之后， Kafka 无限消息堆积，高效的持久化速度吸引了我们，但是同时发现这个消息系统主要定位于日志传输 对于使用在淘宝交易、订单、充值等场景下还有诸多特性不满足，为此我们重新用 Java 语言编写了 RocketMQ ，定位于非日志的可靠消息传输（日志场景也OK），目前 RocketMQ 在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理， binglog 分发等场景 下载安装Windows环境下1、下载 下载页面地址： http://rocketmq.apache.org/dowloading/releases/ 选择Binary版本进行下载 下载目录: D:\\Downloads\\rocketmq-all-4.5.2-bin-release 2、配置 新增环境变量 键：ROCKETMQ_HOME 值：D:\\Downloads\\rocketmq-all-4.5.2-bin-release 3、启动3.1 启动NAMESERVER 进入下载目录\\bin，执行命令start mqnamesrv.cmd启动NAMESERVER，成功后会弹出提示框，此框勿关闭。 3.2 启动BROKER 打开下载目录\\runbroker.cmd文件，修改下面这行%CLASSPATH%加上英文双引号，不然会报错误: 找不到或无法加载主类 xxxxxx 1set &quot;JAVA_OPT=%JAVA_OPT% -cp %CLASSPATH%&quot; 进入下载目录\\bin，执行命令start mqbroker.cmd -n 127.0.0.1:9876 autoCreateTopicEnable=true启动BROKER，成功后会弹出提示框，此框勿关闭 Linux环境下* 问题记录发送消息报磁盘空间不足的问题 向RocketMQ发消息后，发生如下错误 12345678910com.alibaba.rocketmq.client.exception.MQBrokerException: CODE: 14 DESC: service not available now, maybe disk full, CL: 0.87 CQ: 0.87 INDEX: 0.87, maybe your broker machine memory too small.For more information, please visit the url, https://github.com/alibaba/RocketMQ/issues/64 at com.alibaba.rocketmq.client.impl.MQClientAPIImpl.processSendResponse(MQClientAPIImpl.java:492) at com.alibaba.rocketmq.client.impl.MQClientAPIImpl.sendMessageSync(MQClientAPIImpl.java:398) at com.alibaba.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:379) at com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendKernelImpl(DefaultMQProducerImpl.java:698) at com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendSelectImpl(DefaultMQProducerImpl.java:877) at com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:851) at com.alibaba.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:163) at com.ruishenh.rocketmq.example.Producer.main(Producer.java:78) 解决方法: 修改启动脚本runbroker.sh，添加JAVA_OPT=&quot;${JAVA_OPT} -Drocketmq.broker.diskSpaceWarningLevelRatio=0.98&quot; 这里把磁盘保护的百分比设置成98%，只有磁盘空间使用率达到98%时才拒绝接收producer消息。 参考 https://www.jianshu.com/p/4a275e779afa https://m.2cto.com/os/201702/592453.html 芋道源码 http://www.iocoder.cn","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"}]},{"title":"消息队列-基础概念","slug":"backend/framework/mq/消息队列-基础概念","date":"2019-04-12T16:00:00.000Z","updated":"2020-04-05T03:08:54.836Z","comments":true,"path":"2019/04/13/backend/framework/mq/消息队列-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2019/04/13/backend/framework/mq/消息队列-基础概念/","excerpt":"","text":"前言什么是消息队列？ 消息队列的主要特点是异步处理，主要目的是减少请求响应时间和解耦。所以主要的使用场景就是将比较耗时而且不需要即时（同步）返回结果的操作作为消息放入消息队列。同时由于使用了消息队列，只要保证消息格式不变，消息的发送方和接收方并不需要彼此联系，也不需要受对方的影响 可实现高性能，高可用，可伸缩和最终一致性架构，是大型分布式系统不可缺少的中间件。 现实中的例子 来自知乎链接的帖子，将消息队列解释的通俗易懂 小红是小明的姐姐，小红希望小明多读书，常寻找好书给小明看，之前的方式是这样：小红问小明什么时候有空，把书给小明送去，并亲眼监督小明读完书才走。久而久之，两人都觉得麻烦。 后来的方式改成了：小红对小明说「我放到书架上的书你都要看」，然后小红每次发现不错的书都放到书架上，小明则看到书架上有书就拿下来看。 书架就是一个消息队列，小红是生产者，小明是消费者。 这带来的好处有： 1.小红想给小明书的时候，不必问小明什么时候有空，亲手把书交给他了，小红只把书放到书架上就行了。这样小红小明的时间都更自由。 2.小红相信小明的读书自觉和读书能力，不必亲眼观察小明的读书过程，小红只要做一个放书的动作，很节省时间。 3.当明天有另一个爱读书的小伙伴小强加入，小红仍旧只需要把书放到书架上，小明和小强从书架上取书即可（唔，姑且设定成多个人取一本书可以每人取走一本吧，可能是拷贝电子书或复印，暂不考虑版权问题）。 4.书架上的书放在那里，小明阅读速度快就早点看完，阅读速度慢就晚点看完，没关系，比起小红把书递给小明并监督小明读完的方式，小明的压力会小一些。 这就是消息队列的四大好处： 1.解耦 每个成员不必受其他成员影响，可以更独立自主，只通过一个简单的容器来联系。 小红甚至可以不知道从书架上取书的是谁，小明也可以不知道往书架上放书的人是谁，在他们眼里，都只有书架，没有对方。 毫无疑问，与一个简单的容器打交道，比与复杂的人打交道容易一万倍，小红小明可以自由自在地追求各自的人生。 2.提速 小红选择相信「把书放到书架上，别的我不问」，为自己节省了大量时间。 小红很忙，只能抽出五分钟时间，但这时间足够把书放到书架上了。 3.广播 小红只需要劳动一次，就可以让多个小伙伴有书可读，这大大地节省了她的时间，也让新的小伙伴的加入成本很低。 4.削峰 假设小明读书很慢，如果采用小红每给一本书都监督小明读完的方式，小明有压力，小红也不耐烦。 反正小红给书的频率也不稳定，如果今明两天连给了五本，之后隔三个月才又给一本，那小明只要在三个月内从书架上陆续取走五本书读完就行了，压力就不那么大了。 当然，使用消息队列也有其成本： 1.引入复杂度 毫无疑问，「书架」这东西是多出来的，需要地方放它，还需要防盗。 2.暂时的不一致性 假如妈妈问小红「小明最近读了什么书」，在以前的方式里，小红因为亲眼监督小明读完书了，可以底气十足地告诉妈妈，但新的方式里，小红回答妈妈之后会心想「小明应该会很快看完吧……」 这中间存在着一段「妈妈认为小明看了某书，而小明其实还没看」的时期，当然，小明最终的阅读状态与妈妈的认知会是一致的，这就是所谓的「最终一致性」。 那么，该使用消息队列的情况需要满足什么条件呢？ 1.生产者不需要从消费者处获得反馈 引入消息队列之前的直接调用，其接口的返回值应该为空，这才让明明下层的动作还没做，上层却当成动作做完了继续往后走——即所谓异步——成为了可能。 小红放完书之后小明到底看了没有，小红根本不问，她默认他是看了，否则就只能用原来的方法监督到看完了。 2.容许短暂的不一致性 妈妈可能会发现「有时候据说小明看了某书，但事实上他还没看」，只要妈妈满意于「反正他最后看了就行」，异步处理就没问题。 如果妈妈对这情况不能容忍，对小红大发雷霆，小红也就不敢用书架方式了。 3.确实是用了有效果 即解耦、提速、广播、削峰这些方面的收益，超过放置书架、监控书架这些成本。 否则如果是盲目照搬，「听说老赵家买了书架，咱们家也买一个」，买回来却没什么用，只是让步骤变多了，还不如直接把书递给对方呢，那就不对了。 解析 目前主流的消息队列有 Kafka RabbitMQ RocketMQ，老版本是 MetaQ ActiveMQ，目前用的人越来越少了 四种消息队列的差异 角色组成 生产者（Producer） 发送消息的客户端角色，发送消息的时候需要指定Topic。 消费者（Consumer）： 消费消息的客户端角色，通常是后台处理异步消费的系统 RocketMQ中Consumer有两种实现：PushConsumer和PullConsumer。 消息代理（Message Broker）：负责存储消息和转发消息两件事情。其中，转发消息分为推送和拉取两种方式 拉取（Pull），是指 Consumer 主动从 Message Broker 获取消息 推送（Push），是指 Message Broker 主动将 Consumer 感兴趣的消息推送给 Consumer 概念术语 消息队列存储方式 当前业界几款主流的MQ消息队列采用的存储方式主要有以下三种方式。 🦅 1. 分布式KV存储 这类 MQ 一般会采用诸如 LevelDB 、RocksDB 和 Redis 来作为消息持久化的方式。由于分布式缓存的读写能力要优于 DB ，所以在对消息的读写能力要求都不是比较高的情况下，采用这种方式倒也不失为一种可以替代的设计方案。 消息存储于分布式 KV 需要解决的问题在于如何保证 MQ 整体的可靠性。 🦅 2. 文件系统 目前业界较为常用的几款产品（RocketMQ / Kafka / RabbitMQ）均采用的是消息刷盘至所部署虚拟机/物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）。 🦅 3. 关系型数据库 DB Apache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用 JDBC 的方式来做消息持久化，通过简单的 XML 配置信息即可实现JDBC消息存储。 由于，普通关系型数据库（如 MySQL ）在单表数据量达到千万级别的情况下，其 IO 读写性能往往会出现瓶颈。因此，如果要选型或者自研一款性能强劲、吞吐量大、消息堆积能力突出的 MQ 消息队列，那么并不推荐采用关系型数据库作为消息持久化的方案。在可靠性方面，该种方案非常依赖DB，如果一旦 DB 出现故障，则 MQ 的消息就无法落盘存储会导致线上故障。 存储效率来说：文件系统 &gt; 分布式 KV 存储 &gt; 关系型数据库 DB 总结参考 芋道源码 http://www.iocoder.cn https://www.zhihu.com/question/34243607/answer/58314162 http://jaskey.github.io/blog/2016/12/15/rocketmq-concept/?FbmNv=5dba84fc235eeb1f","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.songshuiyang.com/tags/消息队列/"}]},{"title":"并发多线程(五)ThreadPoolExecutor参数设置","slug":"backend/java/concurrent/并发多线程(五)ThreadPoolExecutor参数设置","date":"2019-04-05T14:00:03.000Z","updated":"2020-03-29T01:30:23.759Z","comments":true,"path":"2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor参数设置/","link":"","permalink":"http://www.songshuiyang.com/2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor参数设置/","excerpt":"","text":"概述1.线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 2.线程池容量的参数配置 Java 线程池大小为何会大多被设置成 CPU 核心数 +1 ？一般说来，大家认为线程池的大小经验值应该这样设置：（其中 N 为CPU的个数） 如果是 CPU 密集型应用，则线程池大小设置为 N+1，因为 CPU 密集型任务使得 CPU 使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。 如果是 IO 密集型应用，则线程池大小设置为 2N+1，IO密 集型任务 CPU 使用率并不高，因此可以让 CPU 在等待 IO 的时候去处理别的任务，充分利用 CPU 时间。 如果是混合型应用，那么分别创建线程池，可以将任务分成 IO 密集型和 CPU 密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。因为如果划分之后两个任务执行时间相差甚远，那么先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失。 maximumPoolSize和workQueue的设置需要根据服务器配置，业务的情况来决定： 如果缓存队列及线程池最大线程数设置太小的话会导致线程池过早的拒绝处理任务 如果设置过大的话会导致在未达到最大线程数的情况机器cpu load已经满了 参考转载 https://www.cnblogs.com/dolphin0520/p/3932921.html https://blog.csdn.net/tanghui270270/article/details/80595961 https://www.cnblogs.com/superfj/p/7544971.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(五)ThreadPoolExecutor4种拒绝策略","slug":"backend/java/concurrent/并发多线程(五)ThreadPoolExecutor4种拒绝策略","date":"2019-04-05T14:00:02.000Z","updated":"2020-03-16T11:43:55.431Z","comments":true,"path":"2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor4种拒绝策略/","link":"","permalink":"http://www.songshuiyang.com/2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor4种拒绝策略/","excerpt":"","text":"概述 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： 1234ThreadPoolExecutor.AbortPolicy:这个是默认使用的拒绝策略，丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常也不做任何处理ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy： 直接用自己的主线程来运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，不会放到线程池中，线程池处理不了的自己来处理 例子 CallerRunsPolicy策略示例代码： 1234567891011121314151617181920212223242526272829303132333435363738public class CallerRunsPolicyTest1 &#123; public static void main(String[] args) throws Exception &#123; ThreadPoolExecutor pool = new ThreadPoolExecutor(2, 5, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10)); // 设置线程池的4种拒绝策略 // pool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardPolicy()); // pool.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardOldestPolicy()); pool.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // pool.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy()); // 新建线程任务，并将它们添加到线程池中。 for (int i = 1; i &lt;= 30; i++) &#123; Runnable myrun = new CallerRunsPolicyRunnable(\"task-\"+i); pool.execute(myrun); &#125; // 关闭线程池 pool.shutdown(); &#125;&#125;class CallerRunsPolicyRunnable implements Runnable &#123; private String name; public CallerRunsPolicyRunnable(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + \"：\" + this.name); Thread.sleep(5000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果： 123456789101112131415161718192021222324252627282930pool-1-thread-1：task-1main：task-16pool-1-thread-2：task-2pool-1-thread-3：task-13pool-1-thread-4：task-14pool-1-thread-5：task-15pool-1-thread-4：task-3pool-1-thread-5：task-5pool-1-thread-3：task-4main：task-22pool-1-thread-1：task-7pool-1-thread-2：task-6pool-1-thread-3：task-8pool-1-thread-1：task-12main：task-27pool-1-thread-5：task-10pool-1-thread-4：task-9pool-1-thread-2：task-11pool-1-thread-3：task-17pool-1-thread-2：task-19pool-1-thread-5：task-18pool-1-thread-4：task-21pool-1-thread-1：task-20pool-1-thread-5：task-23pool-1-thread-3：task-26pool-1-thread-2：task-28pool-1-thread-4：task-24pool-1-thread-1：task-25pool-1-thread-5：task-29pool-1-thread-1：task-30 可以发现所有的任务都被执行,而且还有两个是在主线程执行的，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务 总结 ThreadPoolExecutor的4种拒绝策略前3种都是会直接丢弃任务，但我们最常使用的是CallerRunsPolicy策略，这个不会直接丢弃任务，但使用的时候要注意的下面几点： CallerRunsPolicy策略是直接用自己的主线程来运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，线程池处理不了的自己来处理 这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。 参考转载","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(五)ThreadPoolExecutor线程池原理分析","slug":"backend/java/concurrent/并发多线程(五)ThreadPoolExecutor线程池原理分析","date":"2019-04-05T14:00:02.000Z","updated":"2020-03-16T11:43:55.459Z","comments":true,"path":"2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor线程池原理分析/","link":"","permalink":"http://www.songshuiyang.com/2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor线程池原理分析/","excerpt":"","text":"概述 在前面的文章中，我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题：如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的ThreadPoolExecutor类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。 Java中的ThreadPoolExecutor类 java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 123456789101112131415public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 下面解释下一下构造器中各个参数的含义： corePoolSize：核心池的大小 核心池的大小定义了最小可以同时运行的线程数量。 这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。 默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位， 有7种取值，在TimeUnit类中有7种静态属性：1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务 这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。123ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue; threadFactory：线程工厂，主要用来创建线程； * handler：表示当拒绝处理任务时的策略 有以下四种取值：1234ThreadPoolExecutor.AbortPolicy:这个是默认使用的拒绝策略，丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常也不做任何处理ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy： 直接用自己的主线程来运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，不会放到线程池中，线程池处理不了的自己来处理 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService，我们来看一下AbstractExecutorService的实现： 12345678910111213141516171819202122232425public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; &#125;; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; &#125;; public Future&lt;?&gt; submit(Runnable task) &#123;&#125;; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; &#125;; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; &#125;; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;;&#125; AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。我们接着看ExecutorService接口的实现： 12345678910111213141516171819202122public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 而ExecutorService又是继承了Executor接口，我们看一下Executor接口的实现： Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 123public interface Executor &#123; void execute(Runnable command);&#125; 在ThreadPoolExecutor类中有几个非常重要的方法： 1234execute()submit()shutdown()shutdownNow() 方法讲解 execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果。 shutdown()和shutdownNow()是用来关闭线程池的。 还有很多其他的方法，比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。 深入剖析线程池实现原理 在上一节我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解： 123456789101112131.线程池状态2.任务的执行3.线程池中的线程初始化4.任务缓存队列及排队策略5.任务拒绝策略6.线程池的关闭7.线程池容量的动态调整 1.线程池状态 在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态： 123456789101112volatile int runState;static final int RUNNING = 0;static final int SHUTDOWN = 1;static final int STOP = 2;static final int TERMINATED = 3;runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性；下面的几个static final变量表示runState可能的几个取值。当创建线程池后，初始时，线程池处于RUNNING状态；如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕；如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务；当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2.任务的执行 在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量： 1234567891011121314151617181920212223private final BlockingQueue&lt;Runnable&gt; workQueue; // 任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); // 线程池的主要状态锁，对线程池状态（比如线程池大小runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 用来存放工作集 private volatile long keepAliveTime; // 线程存活时间 private volatile boolean allowCoreThreadTimeOut; // 是否允许为核心线程设置存活时间private volatile int corePoolSize; // 核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; // 线程池最大的线程数 private volatile int poolSize; // 线程池中当前的线程数 private volatile RejectedExecutionHandler handler; // 任务拒绝策略 private volatile ThreadFactory threadFactory; // 线程工厂，用来创建线程 private int largestPoolSize; // 用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; // 用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize这个就是线程池的大小。举个简单的例子： - 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current &#123;@code RejectedExecutionHandler&#125;. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * &#123;@code RejectedExecutionHandler&#125;, if the task * cannot be accepted for execution * @throws NullPointerException if &#123;@code command&#125; is null */public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); /** * 1.如果当前线程数量小于corePoolSize，则创建并启动线程。 * 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中； * 然后，启动该线程从而执行任务。 */ if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2.步骤1失败，则尝试进入阻塞队列， if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 入队列成功，检查线程池状态，如果状态部署RUNNING而且remove成功，则拒绝任务 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果当前worker数量为0，通过addWorker(null, false)创建一个线程，其任务为null else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 3. 步骤1和2失败，也就是队列满了，尝试将线程池的数量有corePoolSize扩充至maxPoolSize，新建线程来处理，如果失败，则拒绝任务 else if (!addWorker(command, false)) reject(command);&#125; 任务提交给线程池之后的处理策略 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，让线程先等等 若添加成功，则该任务会等待空闲线程将其取出去执行； 如果这时候队列满了，则添加失败，那么会执行下面的逻辑 如果正在运行的线程数量小于 maximumPoolSize，则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 这样的过程说明，并不是先加入任务就一定会先执行。 假设队列大小为 10，corePoolSize 为 3，maximumPoolSize 为 6，那么当加入 20 个任务时，执行的顺序就是这样的：首先执行任务 1、2、3，然后任务 4~13 被放入队列。这时候队列满了，任务 14、15、16 会被马上执行，而任务 17~20 则会抛出异常。最终顺序是：1、2、3、14、15、16、4、5、6、7、8、9、10、11、12、13 3.线程池中的线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 4.任务缓存队列及排队策略 在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5.任务拒绝策略 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： 1234ThreadPoolExecutor.AbortPolicy:这个是默认使用的拒绝策略，丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常也不做任何处理ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy： 直接用自己的主线程来运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，不会放到线程池中，线程池处理不了的自己来处理 6.线程池的关闭 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7.线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 总结 为什么要用线程池，因为每次new Thread新建对象性能差，使用线程池可以重用存在的线程，减少对象创建、消亡的开销，性能佳。 相比普通线程的执行，使用线程池可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞，同时还提供了定时执行、定期执行、单线程、并发数控制等功能。 其他 Java 线程池大小为何会大多被设置成 CPU 核心数 +1 ？一般说来，大家认为线程池的大小经验值应该这样设置：（其中 N 为CPU的个数） 如果是 CPU 密集型应用，则线程池大小设置为 N+1，因为 CPU 密集型任务使得 CPU 使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。 如果是 IO 密集型应用，则线程池大小设置为 2N+1，IO密 集型任务 CPU 使用率并不高，因此可以让 CPU 在等待 IO 的时候去处理别的任务，充分利用 CPU 时间。 如果是混合型应用，那么分别创建线程池，可以将任务分成 IO 密集型和 CPU 密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。因为如果划分之后两个任务执行时间相差甚远，那么先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失。 参考转载 https://www.cnblogs.com/dolphin0520/p/3932921.html https://blog.csdn.net/tanghui270270/article/details/80595961 https://www.cnblogs.com/superfj/p/7544971.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(五)ThreadPoolExecutor线程池使用","slug":"backend/java/concurrent/并发多线程(五)ThreadPoolExecutor线程池使用","date":"2019-04-05T14:00:01.000Z","updated":"2020-04-18T05:15:04.317Z","comments":true,"path":"2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor线程池使用/","link":"","permalink":"http://www.songshuiyang.com/2019/04/05/backend/java/concurrent/并发多线程(五)ThreadPoolExecutor线程池使用/","excerpt":"","text":"概述使用示例ThreadPoolExecutor 使用示例1234567891011121314151617181920212223242526272829303132333435public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); for (int i = 0; i &lt; 15; i++) &#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println( \"线程池中线程数目：\" + executor.getPoolSize() + \"，队列中等待执行的任务数目：\" + executor.getQueue().size() + \"，已执行玩别的任务数目：\" + executor.getCompletedTaskCount()); &#125; executor.shutdown(); &#125;&#125;class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println(\"正在执行task \" + taskNum); try &#123; Thread.currentThread().sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"task \" + taskNum + \"执行完毕\"); &#125;&#125; 输出结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647线程池中线程数目：1，队列中等待执行的任务数目：0，已执行玩别的任务数目：0正在执行task 0线程池中线程数目：2，队列中等待执行的任务数目：0，已执行玩别的任务数目：0线程池中线程数目：3，队列中等待执行的任务数目：0，已执行玩别的任务数目：0线程池中线程数目：4，队列中等待执行的任务数目：0，已执行玩别的任务数目：0正在执行task 2正在执行task 1线程池中线程数目：5，队列中等待执行的任务数目：0，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：1，已执行玩别的任务数目：0正在执行task 3线程池中线程数目：5，队列中等待执行的任务数目：2，已执行玩别的任务数目：0正在执行task 4线程池中线程数目：5，队列中等待执行的任务数目：3，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：4，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：5，已执行玩别的任务数目：0线程池中线程数目：6，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 10线程池中线程数目：7，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 11线程池中线程数目：8，队列中等待执行的任务数目：5，已执行玩别的任务数目：0线程池中线程数目：9，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 12正在执行task 13线程池中线程数目：10，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 14task 1执行完毕task 0执行完毕task 4执行完毕task 2执行完毕正在执行task 7task 3执行完毕正在执行task 6正在执行task 5正在执行task 8正在执行task 9task 12执行完毕task 14执行完毕task 10执行完毕task 11执行完毕task 13执行完毕task 7执行完毕task 5执行完毕task 8执行完毕task 6执行完毕task 9执行完毕Process finished with exit code 0 从执行结果可以看出，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。 Executors提供四种线程池的创建实现 将线程放入线程池的两种方法 1、ExecutorService 类中的 submit(Runnable task) submit(Callable task) 2、Executor 接口中的execute(Runnable command) newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。线程池的规模不存在限制。 缓存线程池，缓存的线程默认存活60秒。线程的核心池corePoolSize大小为0，核心池最大为Integer.MAX_VALUE,阻塞队列使用的是SynchronousQueue。是一个直接提交的阻塞队列， 他总会迫使线程池增加新的线程去执行新的任务。在没有任务执行时，当线程的空闲时间超过keepAliveTime（60秒），则工作线程将会终止被回收，当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销。如果同时又大量任务被提交，而且任务执行的时间不是特别快，那么线程池便会新增出等量的线程池处理任务，这很可能会很快耗尽系统的资源。 构造ThreadPoolExecutor 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 示例代码 1234567891011121314151617181920212223242526272829303132public class NewCachedThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 1- 在未来某个时间执行给定的命令。 // 该命令可能在新的线程、已入池的线程或者正调用的线程中执行，这由 Executor 实现决定。 cachedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(index); &#125; &#125;); // 2- 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future。 // 该 Future 的 get 方法在成功完成时将会返回给定的结果 cachedThreadPool.submit(new Runnable() &#123; @Override public void run() &#123; System.out.println(index); &#125; &#125;); &#125; cachedThreadPool.shutdown(); &#125;&#125; newFixedThreadPool 创建一个固定长度线程池，可控制线程最大并发数，超出的线程会在队列中等待。 构造ThreadPoolExecutor12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; newScheduledThreadPool 创建一个固定长度线程池，支持定时及周期性任务执行，这个在实际项目中基本不会被用到 构造ThreadPoolExecutor12345678910public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;...public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 构造ThreadPoolExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 正确使用例子：1234567891011121314151617181920212223242526272829303132333435Positive example 1： //org.apache.commons.lang3.concurrent.BasicThreadFactory ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(\"example-schedule-pool-%d\").daemon(true).build()); Positive example 2： ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"demo-pool-%d\").build(); //Common Thread Pool ExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); pool.execute(()-&gt; System.out.println(Thread.currentThread().getName())); pool.shutdown();//gracefully shutdown Positive example 3： &lt;bean id=\"userThreadPool\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"&gt; &lt;property name=\"corePoolSize\" value=\"10\" /&gt; &lt;property name=\"maxPoolSize\" value=\"100\" /&gt; &lt;property name=\"queueCapacity\" value=\"2000\" /&gt; &lt;property name=\"threadFactory\" value= threadFactory /&gt; &lt;property name=\"rejectedExecutionHandler\"&gt; &lt;ref local=\"rejectedExecutionHandler\" /&gt; &lt;/property&gt; &lt;/bean&gt; //in code userThreadPool.execute(thread); 总结 从Executors提供四种线程池具体实现来看，它们实际上也是调用了ThreadPoolExecutor，只不过参数都已配置好了。 虽然jdk提供了以上线程池的创建实现，但在实际项目中不推荐使用，在阿里巴巴编码规范插件中是这么提示的：线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors各个方法的弊端： 1）newCachedThreadPool和newScheduledThreadPool: 主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。 2）newFixedThreadPool和newSingleThreadExecutor: 主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。 线程池正确的使用方式应该是需要指定下面这几个参数，而不是让其裸奔（没有限制maxPoolSize及队列长度） corePoolSize maxPoolSize queueCapacity rejectedExecutionHandler 参考转载 https://www.cnblogs.com/dolphin0520/p/3932921.html https://blog.csdn.net/tanghui270270/article/details/80595961 https://www.cnblogs.com/superfj/p/7544971.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(四)Lock同步锁","slug":"backend/java/concurrent/并发多线程(四)Lock同步锁","date":"2019-04-04T14:59:44.000Z","updated":"2019-12-03T12:17:09.431Z","comments":true,"path":"2019/04/04/backend/java/concurrent/并发多线程(四)Lock同步锁/","link":"","permalink":"http://www.songshuiyang.com/2019/04/04/backend/java/concurrent/并发多线程(四)Lock同步锁/","excerpt":"","text":"概述 在上上篇文章中我们讲到了如何使用关键字synchronized来实现同步访问。本文我们继续来探讨这个问题，从Java 5之后，在java.util.concurrent.locks包下提供了另外一种方式来实现同步访问，那就是Lock。 也许有朋友会问，既然都可以通过synchronized来实现同步访问了，那么为什么还需要提供Lock？这个问题将在下面进行阐述。本文先从synchronized的缺陷讲起，然后再讲述java.util.concurrent.locks包下常用的有哪些类和接口，最后讨论以下一些关于锁的概念方面的东西 一：synchronized的缺陷 synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？在上面一篇文章中，我们了解到如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况： 1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有； 2）线程执行发生异常，此时JVM会让线程自动释放锁。 那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一下，这多么影响程序执行效率。因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过Lock就可以办到。 再举个例子：当有多个线程读写文件时，读操作和写操作会发生冲突现象，写操作和写操作会发生冲突现象，但是读操作和读操作不会发生冲突现象。但是采用synchronized关键字来实现同步的话，就会导致一个问题：如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。因此就需要一种机制来使得多个线程都只是进行读操作时，线程之间不会发生冲突，通过Lock就可以办到。另外，通过Lock可以知道线程有没有成功获取到锁。这个是synchronized无法办到的。 二.java.util.concurrent.locks包下常用的类 下面我们就来探讨一下java.util.concurrent.locks包中常用的类和接口。 1.Lock 首先要说明的就是Lock，通过查看Lock的源码可知，Lock是一个接口： 12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 下面来逐个讲述Lock接口中每个方法的使用，lock()、tryLock()、tryLock(long time, TimeUnit unit)和lockInterruptibly()是用来获取锁的。unLock()方法是用来释放锁的。newCondition()这个方法暂且不在此讲述，会在后面的线程协作一文中讲述。 在Lock中声明了四个方法来获取锁，那么这四个方法有何区别呢？ lock() 首先lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。由于在前面讲到如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。通常使用Lock来进行同步的话，是以下面这种形式去使用的： 123456789Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125; tryLock() tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 所以，一般情况下通过tryLock来获取锁时是这样使用的： 123456789101112Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则直接做其他事情&#125; lockInterruptibly() lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 由于lockInterruptibly()的声明中抛出了异常，所以lock.lockInterruptibly()必须放在try块中或者在调用lockInterruptibly()的方法外声明抛出InterruptedException。 因此lockInterruptibly()一般的使用形式如下： 123456789public void method() throws InterruptedException &#123; lock.lockInterruptibly(); try &#123; //..... &#125; finally &#123; lock.unlock(); &#125; &#125; 注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。 而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。 2.ReentrantLock ReentrantLock，意思是“可重入锁”，关于可重入锁的概念在下一节讲述。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。下面通过一些实例看具体看一下如何使用ReentrantLock。 lock()的错误使用方法 代码 12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; Lock lock = new ReentrantLock(); //注意这个地方 lock.lock(); try &#123; System.out.println(thread.getName()+\"得到了锁\"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+\"释放了锁\"); lock.unlock(); &#125; &#125;&#125; 各位朋友先想一下这段代码的输出结果是什么？ 1234Thread-0得到了锁Thread-1得到了锁Thread-0释放了锁Thread-1释放了锁 也许有朋友会问，怎么会输出这个结果？第二个线程怎么会在第一个线程释放锁之前得到了锁？原因在于，在insert方法中的lock变量是局部变量，每个线程执行该方法时都会保存一个副本，那么理所当然每个线程执行到lock.lock()处获取的是不同的锁，所以就不会发生冲突。 知道了原因改起来就比较容易了，只需要将lock声明为类的属性即可。 12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; lock.lock(); try &#123; System.out.println(thread.getName()+\"得到了锁\"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+\"释放了锁\"); lock.unlock(); &#125; &#125;&#125; 这样就是正确地使用Lock的方法了。 tryLock()的使用方法 代码 12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; if(lock.tryLock()) &#123; try &#123; System.out.println(thread.getName()+\"得到了锁\"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+\"释放了锁\"); lock.unlock(); &#125; &#125; else &#123; System.out.println(thread.getName()+\"获取锁失败\"); &#125; &#125;&#125; 输出结果： 123Thread-0得到了锁Thread-1获取锁失败Thread-0释放了锁 lockInterruptibly()响应中断的使用方法： 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Test &#123; private Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; Test test = new Test(); MyThread thread1 = new MyThread(test); MyThread thread2 = new MyThread(test); thread1.start(); thread2.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread2.interrupt(); &#125; public void insert(Thread thread) throws InterruptedException&#123; lock.lockInterruptibly(); //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出 try &#123; System.out.println(thread.getName()+\"得到了锁\"); long startTime = System.currentTimeMillis(); for( ; ;) &#123; if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE) break; //插入数据 &#125; &#125; finally &#123; System.out.println(Thread.currentThread().getName()+\"执行finally\"); lock.unlock(); System.out.println(thread.getName()+\"释放了锁\"); &#125; &#125;&#125; class MyThread extends Thread &#123; private Test test = null; public MyThread(Test test) &#123; this.test = test; &#125; @Override public void run() &#123; try &#123; test.insert(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+\"被中断\"); &#125; &#125;&#125; 运行之后，发现thread2能够被正确中断 12Thread-0得到了锁Thread-1被中断 3.ReadWriteLock ReadWriteLock也是一个接口，在它里面只定义了两个方法： 123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading. */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing. */ Lock writeLock();&#125; 一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。 4.ReentrantReadWriteLock ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。 下面通过几个例子来看一下ReentrantReadWriteLock具体用法。 假如有多个线程要同时进行读操作的话，先看一下synchronized达到的效果： 12345678910111213141516171819202122232425262728public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public synchronized void get(Thread thread) &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+\"正在进行读操作\"); &#125; System.out.println(thread.getName()+\"读操作完毕\"); &#125;&#125; 这段程序的输出结果会是，直到thread1执行完读操作之后，才会打印thread2执行读操作的信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0读操作完毕Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1读操作完毕 而改成用读写锁的话： 12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void get(Thread thread) &#123; rwl.readLock().lock(); try &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+\"正在进行读操作\"); &#125; System.out.println(thread.getName()+\"读操作完毕\"); &#125; finally &#123; rwl.readLock().unlock(); &#125; &#125;&#125; 此时打印的结果为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0读操作完毕Thread-1读操作完毕 说明thread1和thread2在同时进行读操作。这样就大大提升了读操作的效率。不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。 三.锁的相关概念介绍1.可重入锁 如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。 看下面这段代码就明白了： 123456789class MyClass &#123; public synchronized void method1() &#123; method2(); &#125; public synchronized void method2() &#123; &#125;&#125; 上述代码中的两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。 而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。 2.可中断锁 可中断锁：顾名思义，就是可以相应中断的锁。 在Java中，synchronized就不是可中断锁，而Lock是可中断锁。 如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。 在前面演示lockInterruptibly()的用法时已经体现了Lock的可中断性。 3.公平锁 公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。 而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。 4.读写锁 读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。 ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。可以通过readLock()获取读锁，通过writeLock()获取写锁。 四.总结 1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问； 2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； 3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 5）Lock可以提高多个线程进行读操作的效率。 6）在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。 参考转载 https://www.cnblogs.com/dolphin0520/p/3932921.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(三)volatile关键字","slug":"backend/java/concurrent/并发多线程(三)volatile关键字","date":"2019-04-01T14:59:44.000Z","updated":"2019-11-28T13:40:49.425Z","comments":true,"path":"2019/04/01/backend/java/concurrent/并发多线程(三)volatile关键字/","link":"","permalink":"http://www.songshuiyang.com/2019/04/01/backend/java/concurrent/并发多线程(三)volatile关键字/","excerpt":"","text":"剖析volatile关键字1. volatile关键字的两层语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行： 1234567891011// 线程1boolean stop = false; // 类成员变量...while(!stop)&#123; doSomething();&#125; // 线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程，上图是JMM的结构图，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 2. volatile保证原子性吗? 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 i++ 的操作实际上分为三个步骤 1、读 int temp = i; 2、改 i = i + 1 3、写 i = temp 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized： 1234567891011121314151617181920212223public class Test &#123; public int inc = 0; public synchronized void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用Lock 1234567891011121314151617181920212223242526272829public class Test &#123; public int inc = 0; Lock lock = new ReentrantLock(); public void increase() &#123; lock.lock(); try &#123; inc++; &#125; finally&#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 3.volatile能保证有序性吗？ 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子 12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.volatile的原理和实现机制 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： * 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； * 2）它会强制将对缓存的修改操作立即写入主存； * 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 为什么代码会重排序？ 在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件： 在单线程环境下不能改变程序运行的结果。 存在数据依赖关系的不允许重排序 5.volatile 使用场景 只有在一些特殊的场景下，才能适用volatile。总的来说，必须同时满足下面两个条件才能保证在并发环境的线程安全： （1）对变量的写操作不依赖于当前值。 （2）该变量没有包含在具有其他变量的不变式中。 状态标志 实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 123456789101112volatile boolean shutdownRequested; ... // 其他线程调用，通知需要结束，并改变状态public void shutdown() &#123; shutdownRequested = true; &#125; public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 很可能会从循环外部调用 shutdown() 方法 —— 即在另一个线程中 —— 因此，需要执行某种同步来确保正确实现 shutdownRequested 变量的可见性。（可能会从 JMX 侦听程序、GUI 事件线程中的操作侦听程序、通过 RMI 、通过一个 Web 服务等调用）。然而，使用 synchronized 块编写循环要比使用清单 2 所示的 volatile 状态标志编写麻烦很多。由于 volatile 简化了编码，并且状态标志并不依赖于程序内任何其他状态，因此此处非常适合使用 volatile。 这种类型的状态标记的一个公共特性是：通常只有一种状态转换；shutdownRequested 标志从 false 转换为 true，然后程序停止。这种模式可以扩展到来回转换的状态标志，但是只有在转换周期不被察觉的情况下才能扩展（从 false 到 true，再转换到 false）。此外，还需要某些原子状态转换机制，例如原子变量。 总结其他 Java 中可以创建 volatile 类型数组，不过只是一个指向数组的引用，而不是整个数组。如果改变引用指向的数组，将会受到 volatile 的保护，但是如果多个线程同时改变数组的元素，volatile 标示符就不能起到之前的保护作用了。 volatile 和 synchronized 的区别： volatile 本质是在告诉 JVM 当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取。synchronized 则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile 仅能使用在变量级别。synchronized 则可以使用在变量、方法、和类级别的。 volatile 仅能实现变量的修改可见性，不能保证原子性。而synchronized 则可以保证变量的修改可见性和原子性。 volatile 不会造成线程的阻塞。synchronized 可能会造成线程的阻塞。 volatile 标记的变量不会被编译器优化。synchronized标记的变量可以被编译器优化。 参考转载 https://www.cnblogs.com/dolphin0520/p/3920373.html https://blog.csdn.net/y874961524/article/details/82934831","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(二)synchronized关键字","slug":"backend/java/concurrent/并发多线程(二)synchronized关键字","date":"2019-04-01T13:59:44.000Z","updated":"2020-03-21T13:41:29.996Z","comments":true,"path":"2019/04/01/backend/java/concurrent/并发多线程(二)synchronized关键字/","link":"","permalink":"http://www.songshuiyang.com/2019/04/01/backend/java/concurrent/并发多线程(二)synchronized关键字/","excerpt":"","text":"synchronized 关键字简介 synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized效率低的原因。庆幸的是在 Java 6 之后Java官方对从JVM层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 synchronized关键字最主要的三种使用方式 修饰实例方法，作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 。也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份，所以对该类的所有对象都加了锁）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 和 synchronized 方法一样，synchronized(this)代码块也是锁定当前对象的。synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。这里再提一下：synchronized关键字加到非 static 静态方法上是给对象实例上锁。另外需要注意的是：尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓冲功能！ 下面以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。 双重校验锁实现对象单例（线程安全） 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; // 先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; // 类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 另外，需要注意uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance 采用 volatile关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程T1 执行了1和3，此时T2 调用 getUniqueInstance() 后发现uniqueInstance不为空，因此返回uniqueInstance，但此时uniqueInstance 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 synchronized 关键字底层原理synchronized 关键字底层原理属于 JVM 层面。 ① synchronized 同步语句块的情况 1234567public class SynchronizedDemo &#123; public void method() &#123; synchronized (this) &#123; System.out.println(\"synchronized 代码块\"); &#125; &#125;&#125; 通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -c -s -v -l SynchronizedDemo.class。 synchronized 关键字原理 从上面我们可以看出： synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 对象被创建在堆中。并且对象在内存中的存储布局方式可以分为3块区域：对象头、实例数据、对齐填充。对于对象头来说，主要是包括俩部分信息: 1、自身运行时的数据，比如：如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。（此部分内容被称之为Mark Word） 2、另一部分是类型指针：JVM通过这个指针来确定这个对象是哪个类的实例。 ② synchronized 修饰方法的的情况 12345public class SynchronizedDemo2 &#123; public synchronized void method() &#123; System.out.println(\"synchronized 方法\"); &#125;&#125; synchronized 关键字原理 synchronized 修饰的方法并没有 monitorenter 指令和monitorexit指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM通过该 ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 在 Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock来实现的，Java的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的synchronized锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 JDK 1.6锁优化1、自旋锁 由来 线程的阻塞和唤醒，需要 CPU 从用户态转为核心态。频繁的阻塞和唤醒对 CPU 来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时，我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间。为了这一段很短的时间，频繁地阻塞和唤醒线程是非常不值得的。所以引入自旋锁。 定义 所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。 怎么等待呢？执行一段无意义的循环即可（自旋）。，比如排队排困了，那不能睡呀，睡着了再醒来那又落后几十名了，那么就自己找乐子吧 自旋等待不能替代阻塞，先不说对处理器数量的要求（多核，貌似现在没有单核的处理器了），虽然它可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何有意义的工作，典型的占着茅坑不拉屎，这样反而会带来性能上的浪费。 所以说，自旋等待的时间（自旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。 自旋锁在 JDK 1.4.2 中引入，默认关闭，但是可以使用-XX:+UseSpinning 开开启。 在 JDK1.6 中默认开启。同时自旋的默认次数为 10 次，可以通过参数 -XX:PreBlockSpin 来调整。 如果通过参数 -XX:PreBlockSpin 来调整自旋锁的自旋次数，会带来诸多不便。假如我将参数调整为 10 ，但是系统很多线程都是等你刚刚退出的时候，就释放了锁（假如你多自旋一两次就可以获取锁），你是不是很尴尬。于是 JDK 1.6 引入自适应的自旋锁，让虚拟机会变得越来越聪明。 适应自旋锁 JDK 1.6 引入了更加聪明的自旋锁，即自适应自旋锁。 线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。 反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。 有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准确，虚拟机会变得越来越聪明。 2、锁消除 由来 为了保证数据的完整性，我们在进行操作时需要对这部分操作进行同步控制。但是，在有些情况下，JVM检测到不可能存在共享数据竞争，这是JVM会对这些同步锁进行锁消除。如果不存在竞争，为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。 定义 锁消除的依据是逃逸分析的数据支持。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是对于我们程序员来说这还不清楚么？我们会在明明知道不存在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？我们虽然没有显示使用锁，但是我们在使用一些 JDK 的内置 API 时，如 StringBuffer、Vector、HashTable 等，这个时候会存在隐性的加锁操作。比如 StringBuffer 的 #append(..)方法，Vector 的 add(…) 方法： 1234567public void vectorTest()&#123; Vector&lt;String&gt; vector = new Vector&lt;String&gt;(); for (int i = 0 ; i &lt; 10 ; i++)&#123; vector.add(i + \"\"); &#125; System.out.println(vector);&#125; 在运行这段代码时，JVM 可以明显检测到变量 vector 没有逃逸出方法 #vectorTest() 之外，所以 JVM 可以大胆地将 vector 内部的加锁操作消除。 3、锁粗化 由来 我们知道在使用同步锁的时候，需要让同步块的作用范围尽可能小：仅在共享数据的实际作用域中才进行同步。这样做的目的，是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。 在大多数的情况下，上述观点是正确的，LZ 也一直坚持着这个观点。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗话的概念。 定义 锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。 如上面实例：vector 每次 add 的时候都需要加锁操作，JVM 检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到 for 循环之外。 4、锁升级 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。它们会随着竞争的激烈而逐渐升级。注意，锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 4.1 偏向锁 偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。 它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。 4.1 轻量级锁 引入轻量级锁的主要目的，是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 等待轻量锁的线程不会阻塞，它会一直自旋等待锁，这就是自旋锁，尝试获取锁的线程，在没有获得锁的时候，不被挂起，而转而去执行一个空循环，即自旋。在若干个自旋后，如果还没有获得锁，则才被挂起，获得锁，则执行代码。 当关闭偏向锁功能或者多个线程竞争偏向锁，导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁其步骤如下： 获取锁 判断当前对象是否处于无锁状态？若是，则 JVM 首先将在当前线程的栈帧中，建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的 Mark Word的 拷贝（官方把这份拷贝加了一个 Displaced 前缀，即 Displaced Mark Word）；否则，执行步骤（3）； JVM 利用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 的指正。如果成功，表示竞争到锁，则将锁标志位变成 00（表示此对象处于轻量级锁状态），执行同步操作；如果失败，则执行步骤（3）； 判断当前对象的 Mark Word 是否指向当前线程的栈帧？如果是，则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则，只能说明该锁对象已经被其他线程抢占了，当前线程便尝试使用自旋来获取锁。若自旋后没有获得锁，此时轻量级锁会升级为重量级锁，锁标志位变成 10，当前线程会被阻塞。 释放锁 轻量级锁的释放也是通过 CAS 操作来进行的，主要步骤如下： 取出在获取轻量级锁保存在 Displaced Mark Word 中 数据。 使用 CAS 操作将取出的数据替换当前对象的 Mark Word 中。如果成功，则说明释放锁成功；否则，执行（3）。 无论（2）是否释放成功，都会唤醒被挂起的线程，重新争夺锁，访问同步代码块。 下图是争夺锁导致的锁膨胀的流程图：其中，绿框的 0 指的是无偏向锁，01 指的是无锁状态。 注意事项: 对于轻量级锁，其性能提升的依据是：“对于绝大部分的锁，在整个生命周期内都是不会存在竞争的”。如果打破这个依据则除了互斥的开销外，还有额外的 CAS 操作，因此在有多线程竞争的情况下，轻量级锁比重量级锁更慢。 4.1 重量级锁 重量级锁通过对象内部的监视器（Monitor）实现。 其中，Monitor 的本质是，依赖于底层操作系统的 Mutex Lock 实现。操作系统实现线程之间的切换，需要从用户态到内核态的切换，切换成本非常高。 4.1总结 Synchronized 关键字使用、底层原理、JDK1.6 之后的底层优化以及 和ReenTrantLock 的对比 参考转载 https://github.com/Snailclimb/JavaGuide/edit/master/docs/java/synchronized.md http://www.iocoder.cn/JUC/sike/synchronized/ https://www.cnblogs.com/linghu-java/p/8944784.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"并发多线程(一)Thread的创建及使用","slug":"backend/java/concurrent/并发多线程(一)Thread的创建及使用","date":"2019-04-01T12:59:44.000Z","updated":"2019-11-28T13:06:55.355Z","comments":true,"path":"2019/04/01/backend/java/concurrent/并发多线程(一)Thread的创建及使用/","link":"","permalink":"http://www.songshuiyang.com/2019/04/01/backend/java/concurrent/并发多线程(一)Thread的创建及使用/","excerpt":"","text":"1. 线程创建及使用1.1 继承Thread类创建线程类 实现最简单，如果要访问当前线程，则无需使用 Thread.currentThread()直接使用this即可得到当前线程 不能再继承其他父类，因为线程类已经继承了Thread类 Thread类继承Runnable类12345678910111213141516public class ThreadTest &#123; public static void main(String[] args) &#123; CustomThread customThread = new CustomThread(); customThread.start(); &#125;&#125;class CustomThread extends Thread &#123; @Override public void run() &#123; System.out.println(\"CustomThread doing\"); &#125;&#125; 1.2 实现Runnable类创建线程类 线程类只是实现了Runnable类，还可以继承其他类 访问线程需要使用 Thread.currentThread()访问当前线程1234567891011121314151617public class RunnableTest &#123; public static void main(String[] args) &#123; // CustomRunnable对象作为Thread构造参数 Thread thread = new Thread(new CustomRunnable()); thread.start(); &#125;&#125;class CustomRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(\"CustomRunnable doing\"); &#125;&#125; 1.3 使用Callable和Future创建线程 线程类只是实现了Callable类，还可以继承其他类 访问线程需要使用 Thread.currentThread()访问当前线程 可以得到线程方法体的结果，得到call()方法返回值 可以得到执行异常1234567891011121314151617181920212223242526272829303132public class CallableTest &#123; public static void main(String[] args) &#123; CustomCallable customCallable = new CustomCallable(); // 使用Callable方式创建线程，需要FutureTask类的支持，用于接收运算结果，可以使用泛型指定返回值的类型 FutureTask&lt;Integer&gt; futureTask = new FutureTask(customCallable); new Thread(futureTask).start(); int sum = 0; // 接收运算结果，只有当该线程执行完毕后才会获取到运算结果，等同于闭锁的效果 try &#123; sum = futureTask.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println(\"sum is \" + sum); &#125;&#125;class CustomCallable implements Callable &#123; @Override public Object call() throws Exception &#123; // 计算1-100的和 int sum = 0; for (int i = 1; i &lt;= 100; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 2. 线程的生命周期 线程从创建到最终的消亡，要经历若干个状态。一般来说，线程包括以下这几个状态：创建(new)、就绪(runnable)、运行(running)、阻塞(blocked)、消亡（dead）。 当需要新起一个线程来执行某个子任务时，就创建了一个线程。但是线程创建之后，不会立即进入就绪状态，因为线程的运行需要一些条件（比如内存资源，在前面的JVM内存区域划分一篇博文中知道程序计数器、Java栈、本地方法栈都是线程私有的，所以需要为线程分配一定的内存空间），只有线程运行需要的所有条件满足了，才进入就绪状态。 线程上下文切换，线程的上下文切换实际上就是 存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行，上下文切换过程中会记录程序计数器、CPU寄存器状态等数据。 虽然多线程可以使得任务执行的效率得到提升，但是由于在线程切换时同样会带来一定的开销代价，并且多个线程会导致系统资源占用的增加，所以在进行多线程编程时要注意这些因素。 3. 控制线程3.1 join线程 让一个线程等待另一个线程完成的方法，当在某个程序执行流中调用其他线程的join()方法时，调用线程将被阻塞，直到加入的join()线程执行完为止 3.2 sleep睡眠线程 sleep相当于让线程睡眠，交出CPU，让CPU去执行其他的任务。 3.3 yield线程让步 调用yield方法并不会让线程进入阻塞状态，而是让线程重回就绪状态，它只需要等待重新获取CPU执行时间，这一点是和sleep方法不一样的。 3.4 setPriority() 改变线程优先级 优先级高的线程获得较多的执行机会 补充 Java 线程是重量级的，每个线程默认使用 1024KB 的内存，所以一个 Java 进程是无法开启大量线程的 为什么 wait, notify 和 notifyAll 这三方法不在 Thread类里面？ 一个很明显的原因是 Java 提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。 由于 wait，notify 和notifyAll 方法都是锁级别的操作，所以把它们定义在 Object 类中，因为锁属于对象。 总结 线程可以比作上班工作流程： 招来一个新员工就是new 了一个Thread 当然刚进来肯定要先熟悉一下才能真正进入工作状态，那就是线程就绪(runnable)状态 熟悉的差不多了那就可以真正的工作运行了(running)，哈哈开始干活了 在工作过程中经常遇到需要其他部门的人支持，这时候就需要等待他们一起配合，那么工作进度就会进入到阻塞(blocked)状态或者join()状态 当然不可能24小时工作喽，人还是需要休息的sleep，休息完之后又要9点打卡上班了 那么才算一个工作项目结束呢，1、项目按照预期圆满结束 2、哇老板突然说不做了stop 3、哇，项目发生重大事故error了 线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。 从另一角度来说，进程属于操作系统的范畴，主要是同一段时间内，可以同时执行一个以上的程序，而线程则是在同一程序内几乎同时执行一个以上的程序段。 参考转载 https://www.cnblogs.com/dolphin0520/p/3920357.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"http://www.songshuiyang.com/tags/Java并发/"}]},{"title":"JVM堆转储文件分析EclipseMemoryAnalyzer","slug":"backend/java/jvm/JVM堆转储文件分析EclipseMemoryAnalyzer","date":"2019-03-26T14:59:44.000Z","updated":"2019-09-19T12:25:24.478Z","comments":true,"path":"2019/03/26/backend/java/jvm/JVM堆转储文件分析EclipseMemoryAnalyzer/","link":"","permalink":"http://www.songshuiyang.com/2019/03/26/backend/java/jvm/JVM堆转储文件分析EclipseMemoryAnalyzer/","excerpt":"","text":"简介 Eclipse Memory Analyzer 它是一个功能丰富的 JAVA 堆转储文件分析工具，可以帮助你发现内存漏洞和减少内存消耗 简称MAT 下载安装 下载链接: https://www.eclipse.org/mat/downloads.php 解压后直接打开MemoryAnalyzer.exe 使用EclipseMemoryAnalyzer1、获取Heap Dump 堆转储文件什么是Heap Dump文件 Heap Dump 是一个 Java 进程在某个时间点上的内存快照。 Heap Dump 是有着多种格式的。 不过总体上Heap Dump 在触发快照的时候都保存了 java 对象和类的信息。通常在写 Heap Dump 文件前会触发一次 FullGC，所以 Heap Dump 文件中保存的是 FullGC 后留下的对象信息。 Memory Analyzer 可以用来处理 HPROF 二进制 Heap Dump 文件、 IBM 系统 dump 文件（经过处理后）、以及来自各个平台上的 IBM portable Heap Dumps (PHD)文件。 一般在 Heap Dump 文件中可以获取到（ 这仍然取决于 Heap Dump 文件的类型） 如下信息： 对象信息：类、成员变量、直接量以及引用值； 类信息： 类加载器、 名称、 超类、 静态成员； Garbage Collections Roots： JVM 可达的对象； 线程栈以及本地变量： 获取快照时的线程栈信息， 以及局部变量的详细信息。 MAT根据这个文件可以分析出内存泄露和高内存消耗地点。 获取Heap Dump文件 这可是一个相当便捷的参数了，因为当你需要分析Java内存使用情况时，往往是在OOM(OutOfMemoryError)发生时。那么通过在你的启动脚本中，为Java命令添加以下参数，就可以得到一份内存信息了 Java –Xmx1024m …. -XX:+HeapDumpOnOutOfMemoryError …… 使用JDK工具获取，jmap –dump:format=b,file=heap.bin PID 使用基本的GUI工具，如jconsol, Eclipse memory analyzer等 2、使用EclipseMemoryAnalyzer 得到Heap Dump 堆转储文件之后，就可以使用这个工具直接打开了 2.1 Overview 在右侧窗口上方的位置可以看到 heapDump 的 size，以及类、对象和类加载器的数量。 右侧窗口中最醒目的饼图直观地显示了 dump 中最大的几个对象。鼠标光标划过饼图中代表某个对象的区块时可以在左侧 Inspector 窗口中看到对象的细节，在区块上点击鼠标左键可以通过菜单项钻取到关于其对应的对象更多的细节。 我们可以看到占用很大一部分内存的有几个深色的饼区，这些就可以当做我们稍后着重看的地方 2.2 Histogram 列出内存中的对象，对象的个数以及大小。 Shallow Heap 对象自身占用的内存大小，不包括它引用的对象 Retained Heap 是该对象自己的shallow size，加上从该对象能直接或间接访问到对象的shallow size之和 换句话说，Retained size是该对象被GC之后所能回收到内存的总和。 并且排除被GC Roots直接或者间接引用的对象 Shallow Heap 与 Retained Heap A对象的 Retained Heap = A对象的 Shallow Heap + C对象的 Shallow Heap 这里不包含 D 对象的 Shallow Heap因为 D对象被Root根对象所引用。 B对象的 Retained Heap = B对象的 Shallow Heap。 鼠标右键 List Object Incomming Reference（呼入 被谁依赖） 指的是引用当前对象的外部对象， Outgoing Reference（外向的 依赖谁） 指的是当前对象引用的外部对象 Paths to GC Roots 从当前对象到GC roots的路径，这个路径解释了为什么当前对象还能存活，对分析内存泄露很有帮助，这个查询只能针对单个对象使用 Merge Shortest Paths to GC roots 从GC roots到一个或一组对象的公共路径 Merge shortest Paths to GC roots 和Path to GC roots 这两个查询都有很多选项 意思是在查询到GC root的路径时，是包含所有引用，还是排除一些类型的引用（如软引用、弱引用、虚引用） 从GC角度说，一个对象无法被GC，一定是因为有强引用存在，其它引用类型在GC需要的情况下都是可以被GC掉的，所以可以使用 exclude all phantom/weak/soft etc. references 只查看GC路径上的强引用 需要注意的是，Paths to GC roots是针对单个对象的，故在Histogram视图无法使用，因为Histogram视图是针对类的，只能使用Merge shortest Paths to GC roots查询2.3 Dominator Tree 可以列出那个线程，以及线程下面的那些对象占用的空间。 Dominator Tree 展示了 Heap Dump 中最大的几个对象。 如果 dominator tree 中对象的父节点被移除的话那么， 那么相应对象及其后代节点也面临被回收的状态。 2.4 Top consumers 通过图形列出最大的object。 2.5 Leak Suspects Leak Suspects 是MAT帮我们分析的可能有内存泄露嫌疑的地方，可以体现出哪些对象被保持在内存中，以及为什么它们没有被垃圾回收 2.6 Thread Overview 在分析内存Dump的MAT中还可以看到线程栈信息，这本身就是一个强大的功能，类似于jstack命令的效果 Thread视图的入口，在工具栏上： 在Thread Overview视图可以看到：线程对象/线程栈信息、线程名、Shallow Heap、Retained Heap、类加载器、是否Daemon线程等信息 在分析内存Dump的MAT中还可以看到线程栈信息，这本身就是一个强大的功能，类似于jstack命令的效果 而且还能结合内存Dump分析，看到线程栈帧中的本地变量，在左下方的对象属性区域还能看到本地变量的属性，真的很方便 123456789public class TestThreadOverview &#123; private String str1 = \"str1\"; private String str2 = \"str2\"; public static void main(String[] args) &#123; TestThreadOverview test = new TestThreadOverview(); String local_str = \"local_str\"; LockSupport.park(); &#125;&#125; 在上面代码的Heap Dump分析中，可以看到线程调用栈的信息，以及main线程的 本地变量TestThreadOverview 和 字符串local_str 的信息 上图中第一个框起来的部分是 new TestThreadOverview()对象（代码第6行），TestThreadOverview对象有两个属性str1、str2 第二个框起来的部分是main方法中的字符串变量local_str（代码第8行） 结合左侧的对象属性区域，可以更方便的看清线程中对象的具体情况 其他 分析较大的dump文件（根据经验2G以上的dump文件就需要使用以下介绍的方法，不然mat会出现oom）需要调整虚拟机参数找个64位的系统在MemoryAnalyzer.ini设置-Xmx2g MAT提供了一个很贴心的功能，将报告的内容压缩打包到一个zip文件，并放在原始堆转储文件的目录下，一般命名为“xxx_Leak_Suspects.zip”，xxx是dump文件的名字，如果需要和同事一起分析这个内存问题的话，只需要把这个小小的zip包发给他就可以了，不需要把整个堆文件发给他。并且整个报告是一个HTML格式的文件，用浏览器就可以轻松打开 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/cc907566076/article/details/79108782 https://www.cnblogs.com/ldq2016/p/6632174.html https://www.cnblogs.com/trust-freedom/p/6744948.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM虚拟机性能监控与故障处理工具","slug":"backend/java/jvm/JVM虚拟机性能监控与故障处理工具","date":"2019-03-26T13:59:44.000Z","updated":"2019-09-19T12:25:24.536Z","comments":true,"path":"2019/03/26/backend/java/jvm/JVM虚拟机性能监控与故障处理工具/","link":"","permalink":"http://www.songshuiyang.com/2019/03/26/backend/java/jvm/JVM虚拟机性能监控与故障处理工具/","excerpt":"","text":"JDK的命令行工具jcmd 综合工具 jcmd -l 列出当前运行的所有虚拟机 1235362 sun.tools.jcmd.JCmd -l1236 /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --httpPort=9080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=207167 org.apache.catalina.startup.Bootstrap start jcmd [pid] VM.uptime 查看虚拟机启动时间VM.uptime jcmd [pid] Thread.print 打印线程栈信息Thread.print jcmd [pid] GC.class_histogram 查看系统中类统计信息GC.class_histogram jcmd [pid] GC.heap_dump [filepath&amp;name] 导出堆信息GC.heap_dump 这个命令功能和 jmap -dump 功能一样 jcmd [pid] VM.system_properties 获取系统Properties内容VM.system_properties jcmd [pid] VM.flags 获取启动参数VM.flags jcmd [pid] PerfCounter.print 获取所有性能相关数据PerfCounter.printjps 虚拟机进程状况工具 jps（JVM Process Status Tool）可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class,main()函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier,LVMID）。虽然功能比较单一，但它是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到的LVMID来确定要监控的是哪一个虚拟机进程。对于本地虚拟机进程来说，LVMID与操作系统的进程ID（Process Identifier,PID）是一致的，使用Windows的任务管理器或者UNIX的ps命令也可以查询到虚拟机进程的LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名称定位时，那就只能依赖jps命令显示主类的功能才能区分了。 命令格式，其中[option]、[hostid]参数也可以不写。 1234567jps [options] [hostid]option参数 •-l : 输出主类全名或jar路径 •-q : 只输出LVMID •-m : 输出JVM启动时传递给main()的参数 •-v : 输出JVM启动时显示指定的JVM参数 示例 123456789$ jps -l15232 org.gradle.launcher.daemon.bootstrap.GradleDaemon3104 sun.tools.jps.Jps6784 org.jetbrains.idea.maven.server.RemoteMavenServer8916 org.jetbrains.jps.cmdline.Launcher159768936 org.jetbrains.jps.cmdline.Launcher11580 com.songsy.iframe.Application jinfo 配置信息工具 jinfo(JVM Configuration info)这个命令作用是实时查看和调整虚拟机运行参数。 之前的jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令 命令格式 123456jinfo [option] [args] LVMIDoption参数 •-flag : 输出指定args参数的值 •-flags : 不需要args参数，输出所有JVM参数的值 •-sysprops : 输出系统属性，等同于System.getProperties() 示例 12345678$ jinfo -flags 11580Attaching to process ID 11580, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.121-b13Non-default VM flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:CICompilerCount=3 -XX:InitialHeapSize=134217728 -XX:+ManagementServer -XX:MaxHeapSize=2118123520 -XX:MaxNewSize=705691648 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=44564480 -XX:OldSize=89653248 -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGCCommand line: -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:58771,suspend=y,server=n -XX:TieredStopAtLevel=1 -Xverify:none -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=58770 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\\Users\\asua\\.IntelliJIdea2017.2\\system\\groovyHotSwap\\gragent.jar -Dfile.encoding=UTF-8 jstat：虚拟机统计信息监视工具 jstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 命令格式 12345678910111213jstat [option] LVMID [interval] [count]参数 •[option] : 操作参数 •LVMID : 本地虚拟机进程ID •[interval] : 连续输出的时间间隔 •[count] : 连续输出的次数 对于命令格式中的VMID与LVMID需要特别说明一下：如果是本地虚拟机进程，VMID与LVMID是一致的;如果是远程虚拟机进程，那VMID的格式应当是：protocol://lvmid@hostname:port/servername参数interval和count代表查询间隔(单位毫秒)和次数，如果省略这两个参数，说明只查询一次。假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：jstat -gc 2764 250 20 选项option代表着用户希望查询的虚拟机信息，主要分为3类：类装载、垃圾收集、运行期编译状况，具体选项及作用请参考表4-3中的描述。 option参数详解 jstat -class监视类装载、卸载数量、总空间以及耗费的时间 12345678910$ jstat -class 11580Loaded Bytes Unloaded Bytes Time 7107 13135.3 0 0.0 6.84•Loaded : 加载class的数量•Bytes : class字节大小•Unloaded : 未加载class的数量•Bytes : 未加载class的字节大小•Time : 加载时间 jstat -compiler输出JIT编译过的方法数量耗时等12345678910$ jstat -compiler 11580Compiled Failed Invalid Time FailedType FailedMethod 4079 3 0 1.62 1 org/springframework/beans/CachedIntrospectionResults &lt;init&gt;•Compiled : 编译数量•Failed : 编译失败数量•Invalid : 无效数量•Time : 编译耗时•FailedType : 失败类型•FailedMethod : 失败方法的全限定名 jstat -gc 垃圾回收堆的行为统计12345678910111213141516171819$ jstat -gc 11580 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT39424.0 29696.0 0.0 0.0 414208.0 353447.8 118272.0 46473.8 35072.0 34285.7 4608.0 4457.1 9 0.233 2 0.149 0.382•S0C : survivor0区的总容量•S1C : survivor1区的总容量•S0U : survivor0区已使用的容量•S1C : survivor1区已使用的容量•EC : Eden区的总容量•EU : Eden区已使用的容量•OC : Old区的总容量•OU : Old区已使用的容量•PC 当前perm的容量 (KB)•PU perm的使用 (KB)•YGC : 新生代垃圾回收次数•YGCT : 新生代垃圾回收时间•FGC : 老年代垃圾回收次数•FGCT : 老年代垃圾回收时间•GCT : 垃圾回收总消耗时间 jstat -gccapacity同-gc，不过还会输出Java堆各区域使用到的最大、最小空间123456789101112$ jstat -gccapacity 11580 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 43520.0 689152.0 689152.0 39424.0 29696.0 414208.0 87552.0 1379328.0 118272.0 118272.0 0.0 1079296.0 35072.0 0.0 1048576.0 4608.0 9 2 •NGCMN : 新生代占用的最小空间•NGCMX : 新生代占用的最大空间•OGCMN : 老年代占用的最小空间•OGCMX : 老年代占用的最大空间•OGC：当前年老代的容量 (KB)•OC：当前年老代的空间 (KB)•PGCMN : perm占用的最小空间•PGCMX : perm占用的最大空间 jstat -gcutil 同-gc，不过输出的是已使用空间占总空间的百分比12S0 S1 E O M CCS YGC YGCT FGC FGCT GCT0.00 0.00 85.33 39.29 97.76 96.73 9 0.233 2 0.149 0.382 jstat -gccause 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因123456$ jstat -gccause 11580 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT LGCC GCC 0.00 0.00 85.33 39.29 97.76 96.73 9 0.233 2 0.149 0.382 Allocation Failure No GC•LGCC：最近垃圾回收的原因•GCC：当前垃圾回收的原因 jstat -gcnew 统计新生代的行为123$ jstat -gcnew 11580 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT39424.0 29696.0 0.0 0.0 2 15 39424.0 414208.0 353447.8 9 0.233 jstat -gcnewcapacity 新生代与其相应的内存空间的统计123456789$ jstat -gcnewcapacity 11580 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 43520.0 689152.0 689152.0 229376.0 39424.0 229376.0 29696.0 688128.0 414208.0 9 2•NGC:当前年轻代的容量 (KB)•S0CMX:最大的S0空间 (KB)•S0C:当前S0空间 (KB)•ECMX:最大eden空间 (KB)•EC:当前eden空间 (KB) jmap：Java内存映像工具 jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。 如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较“暴力”的手段：譬如加-XX：+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出现之后自动生成dump文件，通过-XX：+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成dump文件，又或者在Linux系统下通过Kill-3命令发送进程退出信号“吓唬”一下虚拟机，也能拿到dump文件。 jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的-dump选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。 命令格式 123456789jmap [option] LVMIDoption参数 •dump : 生成堆转储快照，格式为:-dump:[live, ] format=b,file=&lt;filename&gt;,其中live子参数说明是否只dump出存活的对象。 •finalizerinfo : 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象 •heap : 显示Java堆详细信息 •histo : 显示堆中对象的统计信息，GC使用的算法，heap的配置及wise heap的使用情况,可以用此来判断内存目前的使用情况以及垃圾回收情况 •permstat : to print permanent generation statistics •F : 当-dump没有响应时，强制生成dump快照 示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748$ jmap -heap 28920Attaching to process ID 28920, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.71-b01 using thread-local object allocation. Parallel GC with 4 thread(s) //GC 方式 Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB) //对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB //对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB) //对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB) //对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB) Heap Usage: //堆内存使用情况 PS Young Generation Eden Space: //Eden区内存分布 capacity = 33030144 (31.5MB) //Eden区总容量 used = 1524040 (1.4534378051757812MB)//Eden区已使用 free = 31506104 (30.04656219482422MB)//Eden区剩余容量 4.614088270399305% used //Eden区使用比率 From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used To Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% used PS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% used PS Perm Generation //当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used interned Strings occupying 43720 bytes. jmap -histo:live 28920 | more 打印堆的对象统计，包括对象数、内存大小等等 （因为在dump:live前会进行full gc，如果带上live则只统计活对象，因此不加live的堆大小要大于加live堆的大小 ）1234567891011121314151617181920212223num #instances #bytes class name---------------------------------------------- 1: 83613 12012248 &lt;constMethodKlass&gt; 2: 23868 11450280 [B 3: 83613 10716064 &lt;methodKlass&gt; 4: 76287 10412128 [C 5: 8227 9021176 &lt;constantPoolKlass&gt; 6: 8227 5830256 &lt;instanceKlassKlass&gt; 7: 7031 5156480 &lt;constantPoolCacheKlass&gt; 8: 73627 1767048 java.lang.String 9: 2260 1348848 &lt;methodDataKlass&gt; 10: 8856 849296 java.lang.Class class name是对象类型，说明如下：B byteC charD doubleF floatI intJ longZ boolean[ 数组，如[I表示int[][L+类名 其他对象 jhat：虚拟机堆转储快照分析工具 jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。 不过实事求是地说，在实际工作中，除非手上真的没有别的工具可用，否则一般都不会去直接使用jhat命令来分析dump文件，主要原因有二：一是一般不会在部署应用程序的服务器上直接分析dump文件，即使可以这样做，也会尽量将dump文件复制到其他机器。二是用于分析的机器一般也是服务器，由于加载dump快照文件需要比生成dump更大的内存，所以一般在64位JDK、大内存的服务器上进行分析，因为分析工作是一个耗时而且消耗硬件资源的过程，既然都要在其他机器进行，就没有必要受到命令行工具的限制了；另一个原因是jhat的分析功能相对来说比较简陋，VisualVM，以及专业用于分析dump文件的Eclipse Memory Analyzer、IBM HeapAnalyzer等工具，都能实现比jhat更强大更专业的分析功能。 命令格式 12345678910 jhat [option] [dumpfile]参数 •-stack false|true 关闭对象分配调用栈跟踪(tracking object allocation call stack)。 如果分配位置信息在堆转储中不可用. 则必须将此标志设置为 false. 默认值为 true.&gt; •-refs false|true 关闭对象引用跟踪(tracking of references to objects)。 默认值为 true. 默认情况下, 返回的指针是指向其他特定对象的对象,如反向链接或输入引用(referrers or incoming references), 会统计/计算堆中的所有对象。&gt; •-port port-number 设置 jhat HTTP server 的端口号. 默认值 7000.&gt; •-exclude exclude-file 指定对象查询时需要排除的数据成员列表文件(a file that lists data members that should be excluded from the reachable objects query)。 例如, 如果文件列列出了 java.lang.String.value , 那么当从某个特定对象 Object o 计算可达的对象列表时, 引用路径涉及 java.lang.String.value 的都会被排除。&gt; •-baseline exclude-file 指定一个基准堆转储(baseline heap dump)。 在两个 heap dumps 中有相同 object ID 的对象会被标记为不是新的(marked as not being new). 其他对象被标记为新的(new). 在比较两个不同的堆转储时很有用.&gt; •-debug int 设置 debug 级别. 0 表示不输出调试信息。 值越大则表示输出更详细的 debug 信息.&gt; •-version 启动后只显示版本信息就退出&gt; •-J&lt; flag &gt; 因为 jhat 命令实际上会启动一个JVM来执行, 通过 -J 可以在启动JVM时传入一些启动参数. 例如, -J-Xmx512m 则指定运行 jhat 的Java虚拟机使用的最大堆内存为 512 MB. 如果需要使用多个JVM启动参数,则传入多个 -Jxxxxxx. 示例 12345678910111213 ~ jhat eclipse.bin Reading from eclipse.bin...Dump file created Mon Oct 31 19:32:57 CST 2016Snapshot read, resolving...Resolving 185857 objects...Chasing references, expect 37 dots.....................................Eliminating duplicate references.....................................Snapshot resolved.Started HTTP server on port 7000Server is ready.屏幕显示“Server is ready.”的提示后，用户在浏览器中键入http://localhost:7000/就可以看到分析结果.分析结果默认是以包为单位进行分组显示，分析内存泄漏问题主要会使用到其中的“Heap Histogram”（与jmap -histo功能一样）与OQL页签的功能，前者可以找到内存中总容量最大的对象，后者是标准的对象查询语言，使用类似SQL的语法对内存中的对象进行查询统计. jstack：Java堆栈跟踪工具 jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。 命令格式123456jstack [option] LVMIDoption参数 •-F : 当正常输出请求不被响应时，强制输出线程堆栈 •-l : 除堆栈外，显示关于锁的附加信息 •-m : 如果调用到本地方法的话，可以显示C/C++的堆栈 JDK的可视化工具参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/wade-luffy/p/6017137.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM内存模型与线程(一)Java内存模型","slug":"backend/java/jvm/JVM内存模型与线程(一)Java内存模型","date":"2019-03-21T13:59:44.000Z","updated":"2019-09-19T12:25:24.422Z","comments":true,"path":"2019/03/21/backend/java/jvm/JVM内存模型与线程(一)Java内存模型/","link":"","permalink":"http://www.songshuiyang.com/2019/03/21/backend/java/jvm/JVM内存模型与线程(一)Java内存模型/","excerpt":"","text":"解析 在说Java内存模型之前，我们先说一下Java的内存结构，也就是运行时的数据区域，这一块前面的章节已经介绍过了，很多人容易把内存结构跟内存模型搞混，内存结构就是下图中内存空间这些东西，而Java内存模型，完全是另外的一个东西。 Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽掉各种硬件和操作系统的访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模型，因此，会由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错，因此在某些场景下就不许针对不同的平台来编写程序。 1. 主内存与工作内存 Java内存模型的主要目的是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。注意一下，此处的变量并不包括局部变量与方法参数，因为它们是线程私有的，不会被共享，自然也不会存在竞争，此处的变量应该是实例字段、静态字段和构成数组对象的元素。 Java内存模型规定了所有的变量都存储在主内存（Main Memory）中，每条线程还有自己的工作内存（Working Memory），线程的工作内存中保存了被该线程使用到的变量和主内存副本拷贝（注意这里绝不会是整个对象的拷贝，试想一个10M的对象，在每个用到这个对象的工作内存中有一个10M的拷贝，内存还受得了？也就是一些在线程中用到的对象中的字段罢了），线程对变量所有的操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成 2. 内存间交互操作 关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面体积的每一种操作都是原子的、不可再分的 1、lock（锁定）：作用于主内存中的变量，它把一个变量标识为一条线程独占的状态 2、unlock（解锁）：作用于主内存中的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 3、read（读取）：作用于主内存中的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用 4、load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中 5、use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，没当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作 6、assign（赋值）：作用于工作内存中的变量，它把一个从执行引擎接收到的值赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作 7、store（存储）：作用于工作内存中的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用 8、write（写入）：作用于主内存中的变量，它把store操作从工作内存中得到的变量值放入主内存的变量中 Java内存模型还规定了在执行上述8种基本操作时必须满足以下规则： 1、不允许read和load、store和write操作之一单独出现 2、不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了滞后必须把该变化同步回主内存 3、不允许一个线程无原因地把数据从线程的工作内存同步回主内存中 4、一个新的变量只能从主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量 5、一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁 6、如果对同一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值 7、如果一个变量事先没有被lock操作锁定，那就不允许对它进行unlock操作，也不允许去unlock一个被其他线程锁定的变量 8、对一个变量执行unlock操作之前，必须先把此变量同步回主内存中 3. 对于volatile型变量的特殊规则 关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制。 一个变量被定义为volatile后，它将具备两种特性： 1、保证此变量对所有线程的”可见性”，所谓”可见性”是指当一条线程修改了这个变量的值，新值对于其它线程来说都是可以立即得知的，而普通变量不能做到这一点，普通变量的值在在线程间传递均需要通过主内存来完成，关于volatile关键字的操作请参见volatile关键字使用举例，再强调一遍，volatile只保证了可见性，并不保证基于volatile变量的运算在并罚下是安全的 2、使用volatile变量的第二个语义是禁止指令重排序优化，普通变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。 总结一下Java内存模型对volatile变量定义的特殊规则： 1、在工作内存中，每次使用某个变量的时候都必须线从主内存刷新最新的值，用于保证能看见其他线程对该变量所做的修改之后的值 2、在工作内存中，每次修改完某个变量后都必须立刻同步回主内存中，用于保证其他线程能够看见自己对该变量所做的修改 3、volatile修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序顺序相同 4. 原子性、可见性与有序性 1、原子性（Atomicity） 由Java内存模型来直接保证原子性变量操作包括read、load、assign、use、store、write，大致可以认为基本数据类型的访问读写是具备原子性的。如果应用场景需要一个更大的原子性保证，Java内存模型还提供了lock和unlock，尽管虚拟机没有把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块—-synchronized关键字 2、可见性（Visibility） 可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。volatile其实已经详细写了这一点，其实synchronized关键字也是可以实现可见性的，synchronized的可见性是由”对一个变量执行unlock操作之前，必须先把此变量同步回主内存中”这条规则获得的。另外，final关键字也可以实现可见性，因为被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把this传递出去，那在其他线程中就能看见final字段的值。 3、有序性（Ordering） Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另外一个线程，所有的操作都是无须的。前半句是指”线程内表现为穿行的语义”，后半句是指”指令重排序”和”工作内存与主内存同步延迟”现象。Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由”一个变量在同一时刻只允许一条线程对其进行lock操作”这条规则获得的，这条规则规定了持有同一个锁的两个同步块只能串行地进入 5. 先行发生原则 如果Java内存模型中所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操作将变得很繁琐，但是我们在编写Java代码时并未感觉到这一点，这是因为Java语言中有一个”先行发生（happens-before）”原则。这个原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则就判断出并发环境下两个操作之间是否可能存在冲突的问题。 所谓先行发生原则是指Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，那么操作A产生的影响能够被操作b观察到，”影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。Java内存模型下有一些天然的，不需要任何同步协助器就已经存在的先行发生关系： 1、程序次序规则：在一个线程内，按照控制流顺序，控制流前面的操作先行发生于控制流后面的操作，说”控制流”是因为还要考虑到分支、循环结构 2、管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作 3、volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作 4、线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作 5、线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测 6、线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 7、对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始 8、传递新：如果操作A先行发生于操作B，操作B先行发生于操作C，那么操作A必然先行发生于操作C 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/nexiyi/p/java_memory_model_and_thread.html https://baijiahao.baidu.com/s?id=1595082600371869908&amp;wfr=spider&amp;for=pc http://www.importnew.com/28456.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"字节码执行(二)基于栈的字节码解释器执行过程","slug":"backend/java/jvm/JVM字节码执行(二)基于栈的字节码解释器执行过程","date":"2019-03-19T14:59:44.000Z","updated":"2019-09-19T12:25:24.493Z","comments":true,"path":"2019/03/19/backend/java/jvm/JVM字节码执行(二)基于栈的字节码解释器执行过程/","link":"","permalink":"http://www.songshuiyang.com/2019/03/19/backend/java/jvm/JVM字节码执行(二)基于栈的字节码解释器执行过程/","excerpt":"","text":"解析 根据一个代码实例来介绍虚拟机中解释器的执行过程 123456public int calculate()&#123; int a = 100; int b = 200; int c = 300; return (a + b) * c; &#125; 由上面的代码可以看出，该方法的逻辑很简单，就是进行简单的四则运算加减乘除，我们编译代码后使用javap -verbose命令查看字节码指令，具体字节码代码如下所示: 12345678910111213141516171819202122public int calculate(); Code: Stack=2, Locals=4, Args_size=1 0: bipush 100 2: istore_1 3: sipush 200 6: istore_2 7: sipush 300 10: istore_3 11: iload_1 12: iload_2 13: iadd 14: iload_3 15: imul 16: ireturn LineNumberTable: line 3: 0 line 4: 3 line 5: 7 line 6: 11 &#125; 根据字节码可以看出，这段代码需要深度为2的操作数栈（Stack=2）和4个Slot的局部变量空间（Locals=4）。下面，使用7张图片来描述上面的字节码代码执行过程中的代码、操作数栈和局部变量表的变化情况。 上图展示了执行偏移地址为0的指令的情况，bipush指令的作用是将单字节的整型常量值（-128~127）推入操作数栈顶，后跟一个参数，指明推送的常量值，这里是100。 上图则是执行偏移地址为2的指令，istore_1指令的作用是将操作数栈顶的整型值出栈并存放到第1个局部变量Slot中。后面四条指令（3、6、7、10）都是做同样的事情，也就是在对应代码中把变量a、b、c赋值为100、200、300。后面四条指令的图就不重复画了。 上面展示了执行偏移地址为11的指令，iload_1指令的作用是将局部变量第1个Slot中的整型值复制到操作数栈顶。 上图为执行偏移地址12的指令，iload_2指令的执行过程与iload_1类似，把第2个Slot的整型值入栈。 上图展示了执行偏移地址为13的指令情况，iadd指令的作用是将操作数栈中前两个栈顶元素出栈，做整型加法，然后把结果重新入栈。在iadd指令执行完毕后，栈中原有的100和200出栈，它们相加后的和300重新入栈。 上图为执行偏移地址为14的指令的情况，iload_3指令把存放在第3个局部变量Slot中的300入栈到操作数栈中。这时操作数栈为两个整数300,。 下一条偏移地址为15的指令imul是将操作数栈中前两个栈顶元素出栈，做整型乘法，然后把结果重新入栈，这里和iadd指令执行过程完全类似，所以就不重复画图了。 上图是最后一条指令也就是偏移地址为16的指令的执行过程，ireturn指令是方法返回指令之一，它将结束方法执行并将操作数栈顶的整型值返回给此方法的调用者。到此为止，该方法执行结束。 注：上面的执行过程只是一种概念模型，虚拟机最终会对执行过程做出一些优化来提高性能，实际的运作过程不一定完全符合概念模型的描述。不过从这段程序的执行过程也可以看出栈结构指令集的一般运行过程，整个运算过程的中间变量都是以操作数栈的出栈和入栈为信息交换途径。 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/azhegps/article/details/54092466","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"字节码执行(一)运行时栈帧结构","slug":"backend/java/jvm/JVM字节码执行(一)运行时栈帧结构","date":"2019-03-19T13:59:44.000Z","updated":"2019-12-05T12:19:35.274Z","comments":true,"path":"2019/03/19/backend/java/jvm/JVM字节码执行(一)运行时栈帧结构/","link":"","permalink":"http://www.songshuiyang.com/2019/03/19/backend/java/jvm/JVM字节码执行(一)运行时栈帧结构/","excerpt":"","text":"概述 前几章介绍了Class类的文件结构及类的加载，有了原材料及已经运送过来了，那么就要生产产品了，那么字节码的执行就在生产产品 栈帧(Stack Frame)是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区的虚拟机栈(Virtual Machine Stack)的栈元素。栈帧存储了方法的局部变量表，操作数栈，动态连接和方法返回地址等信息。第一个方法从调用开始到执行完成，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 每一个栈帧都包括了局部变量表，操作数栈，动态连接，方法返回地址和一些额外的附加信息。在编译代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到了方法表的Code属性中，因此一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体虚拟机的实现。 一个线程中的方法调用链可能会很长，很多方法都同时处理执行状态。对于执行引擎来讲，活动线程中，只有虚拟机栈顶的栈帧才是有效的，称为当前栈帧(Current Stack Frame)，这个栈帧所关联的方法称为当前方法(Current Method)。执行引用所运行的所有字节码指令都只针对当前栈帧进行操作。栈帧的概念结构如下图所示： 运行时栈帧结构1. 局部变量表 局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在Java程序编译为Class文件时，就在方法表的Code属性的max_locals数据项中确定了该方法需要分配的最大局部变量表的容量。 在方法执行时，虚拟机是使用局部变量表完成参数变量列表的传递过程，如果是实例方法，那么局部变量表中的每0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问这个隐含的参数，其余参数则按照参数列表的顺序来排列，占用从1开始的局部变量Slot，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域来分配其余的Slot。局部变量表中的Slot是可重用的，方法体中定义的变量，其作用域并不一定会覆盖整个方法，如果当前字节码PC计算器的值已经超出了某个变量的作用域，那么这个变量对应的Slot就可以交给其它变量使用。 局部变量不像前面介绍的类变量那样存在“准备阶段”。类变量有两次赋初始值的过程，一次在准备阶段，赋予系统初始值；另外一次在初始化阶段，赋予程序员定义的值。因此即使在初始化阶段程序员没有为类变量赋值也没有关系，类变量仍然具有一个确定的初始值。但局部变量就不一样了，如果一个局部变量定义了但没有赋初始值是不能使用的。 2. 操作数栈 操作数栈也常被称为操作栈，它是一个后入先出栈。同局部变量表一样，操作数栈的最大深度也是编译的时候被写入到方法表的Code属性的max_stacks数据项中。操作数栈的每一个元素可以是任意Java数据类型，包括long和double。32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。栈容量的单位为“字宽”，对于32位虚拟机来说，一个”字宽“占4个字节，对于64位虚拟机来说，一个”字宽“占8个字节。 当一个方法刚刚执行的时候，这个方法的操作数栈是空的，在方法执行的过程中，会有各种字节码指向操作数栈中写入和提取值，也就是入栈与出栈操作。例如，在做算术运算的时候就是通过操作数栈来进行的，又或者调用其它方法的时候是通过操作数栈来行参数传递的。 另外，在概念模型中，两个栈帧作为虚拟机栈的元素，相互之间是完全独立的，但是大多数虚拟机的实现里都会作一些优化处理，令两个栈帧出现一部分重叠。让下栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样在进行方法调用返回时就可以共用一部分数据，而无须进行额外的参数复制传递了，重叠过程如下图： 3. 动态连接 每个栈帧都包含一个指向运行时常量池中该栈帧所属性方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。在Class文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用，这种转化称为静态解析。另外一部分将在每一次的运行期期间转化为直接引用，这部分称为动态连接。 4. 方法返回地址 当一个方法被执行后，有两种方式退出这个方法。第一种方式是执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者(调用当前方法的的方法称为调用者)，是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法方式称为正常完成出口(Normal Method Invocation Completion)。 另外一种退出方式是，在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方式称为异常完成出口(Abrupt Method Invocation Completion)。一个方法使用异常完成出口的方式退出，是不会给它的调用都产生任何返回值的。 无论采用何种方式退出，在方法退出之前，都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者PC计数器的值就可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常处理器来确定的，栈帧中一般不会保存这部分信息。 方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值(如果有的话)压入调用都栈帧的操作数栈中，调用PC计数器的值以指向方法调用指令后面的一条指令等。 5. 附加信息 虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中，例如与高度相关的信息，这部分信息完全取决于具体的虚拟机实现。在实际开发中，一般会把动态连接，方法返回地址与其它附加信息全部归为一类，称为栈帧信息。 方法调用 虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中，例如与高度相关的信息，这部分信息完全取决于具体的虚拟机实现。在实际开发中，一般会把动态连接，方法返回地址与其它附加信息全部归为一类，称为栈帧信息。 解析 如前所述，所有的方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载阶段，会将其中的一部分符号引用转化为直接引用，这种解析能成立的前提是：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期间是不可变的。也就是说，调用目标在程序代码写好、编译器进行编译时就必须确定下来，这类方法的调用成为解析。 JAVA中符号“编译器可知、运行期不可变”的方法包括：静态方法、私有方法两大类。前者与类型直接关联，后者在外部不可被访问，这就决定了他们都不可能通过继承或别的方式重写其版本。因此都适合在类的加载阶段进行解析。 JAVA虚拟机里面提供了5条方法调用字节码指令。分别如下： 123456789invokestatic:调用静态方法invokespecial:调用实例构造器&lt;init&gt;方法、私有方法和父类方法（super(),super.method()）。invokevirtual:调用所有的虚方法(静态方法、私有方法、实例构造器、父类方法、final方法都是非虚方法)。invokeinterface:调用接口方法，会在运行时期再确定一个实现此接口的对象。invokedynamic:现在运行时期动态解析出调用点限定符所引用的方法，然后再执行该方法，在此之前的4条指令，分派逻辑都是固化在虚拟机里面的，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。 只要能被invokestatic和invokespecial指令调用的方法都可以在解析阶段中确定唯一的调用版本，符合这个条件的有静态方法、私有方法、实例构造器、父类方法4类，它们在类加载阶段就会把符号引用解析为该方法的直接引用。这些方法称为非虚方法（还包括使用final修饰的方法，虽然final方法使用invokevirtual指令调用，因为final方法注定不会被重写，也就是无法被覆盖，也就无需对其进行多态选择）。 解析调用一定是一个静态的过程，在编译期间就可以完全确定，在类装载的解析阶段就会把涉及的符号引用全部转化为可确定的直接引用，不会延迟到运行期去完成。而分派调用可能是静态的也可能是动态的，根据分派一句的宗量数可分为单分派和多分派。因此分派可分为：静态单分派、静态多分派、动态单分派、动态多分派。 问题记录参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/xtayfjpk/article/details/41924283 https://www.cnblogs.com/chenyangyao/p/5305352.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"类加载机制(二)类加载器","slug":"backend/java/jvm/JVM类加载机制(二)类加载器","date":"2019-03-18T13:59:44.000Z","updated":"2019-12-05T12:19:35.285Z","comments":true,"path":"2019/03/18/backend/java/jvm/JVM类加载机制(二)类加载器/","link":"","permalink":"http://www.songshuiyang.com/2019/03/18/backend/java/jvm/JVM类加载机制(二)类加载器/","excerpt":"","text":"解析1. 类加载器 虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类， 3种类加载器： 启动类加载器(Bootstrap ClassLoader)：负责加载JRE的核心类库（JAVA_HOME\\lib）目录中的类包，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。启动类加载器是无法被Java程序直接引用的。 扩展类加载器(Extension ClassLoader)：负责加载JRE扩展目录 （JAVA_HOME\\lib\\ext） 目录中的类包，或通过java.ext.dirs系统变量指定路径中的类库。开发者可以直接使用扩展类加载器。 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 例子： 寻找类加载器 123456789package com.neo.classloader;public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println(loader); System.out.println(loader.getParent()); System.out.println(loader.getParent().getParent()); &#125;&#125; 结果 123sun.misc.Launcher$AppClassLoader@64fef26asun.misc.Launcher$ExtClassLoader@1ddd40f3null 从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是Bootstrap Loader（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。 注意：这里父类加载器并不是通过继承关系来实现的，而是采用组合实现的。 站在Java虚拟机的角度来讲，只存在两种不同的类加载器：启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分；所有其他的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 在执行非置信代码之前，自动验证数字签名。 动态地创建符合用户特定需要的定制化构建类。 从特定的场所取得java class，例如数据库中和网络中。 2. 自定义类加载器 通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java 类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自 ClassLoader 类，从上面对 loadClass 方法来分析来看，我们只需要重写 findClass 方法即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.neo.classloader;import java.io.*;public class MyClassLoader extends ClassLoader &#123; private String root; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = loadClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] loadClassData(String className) &#123; String fileName = root + File.separatorChar + className.replace('.', File.separatorChar) + \".class\"; try &#123; InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, length); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public String getRoot() &#123; return root; &#125; public void setRoot(String root) &#123; this.root = root; &#125; public static void main(String[] args) &#123; MyClassLoader classLoader = new MyClassLoader(); classLoader.setRoot(\"E:\\\\temp\"); Class&lt;?&gt; testClass = null; try &#123; testClass = classLoader.loadClass(\"com.neo.classloader.Test2\"); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3. 类的加载 类加载有三种方式 命令行启动应用时候由JVM初始化加载 通过Class.forName()方法动态加载 通过ClassLoader.loadClass()方法动态加载 Class.forName()和ClassLoader.loadClass()区别 Class.forName()：将类的.class文件加载到jvm中，还会对类进行解释，执行类中的static块； ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。 注：Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。 双亲委派模型 双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 双亲委派机制: 1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 3、如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 双亲委派模型意义： 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行，如果一个人编写了一个恶意的基础类(java.lang.String)并装载到JVM中，将会引起多么可怕的后果，有了这个机制(java.lang.String)永远是由启动类加载器来加载 参考转载 周志明版 《深入理解Java虚拟机》 http://www.importnew.com/25295.html https://www.cnblogs.com/ityouknow/p/5603287.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"类加载机制(一)类加载时机及过程","slug":"backend/java/jvm/JVM类加载机制(一)类加载时机及过程","date":"2019-03-16T03:59:44.000Z","updated":"2019-12-05T12:19:35.279Z","comments":true,"path":"2019/03/16/backend/java/jvm/JVM类加载机制(一)类加载时机及过程/","link":"","permalink":"http://www.songshuiyang.com/2019/03/16/backend/java/jvm/JVM类加载机制(一)类加载时机及过程/","excerpt":"","text":"什么是类的加载 虚拟机的加载机制：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型 类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口 类的生命周期 如下图所示，JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化，在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。下面我们就分别来看一下这五个过程。 1. 加载 加载的过程： 1、通过一个类的全限定名来获取其定义的二进制字节流。 2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 3、在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 加载.class文件的方式: 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件，比如java.lang.reflect.Proxy 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，然后在内存中实例化一个java.lang.Class类的对象（并没有明确规定是Java堆中，在hotspot中它是存放在方法区中），这样便可以通过该对象访问方法区中的这些数据。 2. 验证 验证是为了确保被加载的类的正确性 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 3. 准备 准备是为类的静态变量分配内存，并将其初始化为默认值 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中 这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。 假设一个类变量的定义为：public static int value = 3；那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的putstatic指令是在程序编译后，存放于类构造器（）方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行 4. 解析 解析是把类中的符号引用转换为直接引用 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 5. 初始化 初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。 在Java中对类变量进行初始值设定有两种方式： 声明类变量是指定初始值 使用静态代码块为类变量指定初始值 JVM初始化步骤 1、假如这个类还没有被加载和连接，则程序先加载并连接该类 2、假如该类的直接父类还没有被初始化，则先初始化其直接父类 3、假如类中有初始化语句，则系统依次执行这些初始化语句 类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下五种(有且只有)： 1、Java虚拟机启动时被标明为启动类的类（Java Test），直接使用java.exe命令来运行某个主类 2、创建类的实例，也就是new的方式或者访问某个类或接口的静态变量，或者对该静态变量赋值，以及调用一个类的静态方法 3、使用java.lang.reflect包的方法对类进行反射调用的时候（如Class.forName(“com.shengsiyuan.Test”)） 4、初始化某个类的子类，如果父类没有初始化则其父类也会被初始化 5、当使用JDK 1.7 的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。 被动引用 通过子类引用父类的静态字段，不会导致子类初始化 通过数组定义来引用类，不会触发此类的初始化 常量在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发 6.结束 在如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Ja 总结 研究类加载全过程有助于连接JVM运行过程 深入了解java动态性（热部署，动态加载），提高程序的灵活性 参考转载 周志明版 《深入理解Java虚拟机》 http://www.importnew.com/25295.html https://www.cnblogs.com/ityouknow/p/5603287.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM类文件结构(三)字节码指令","slug":"backend/java/jvm/JVM类文件结构(三)字节码指令","date":"2019-03-16T02:59:44.000Z","updated":"2019-09-19T12:25:24.522Z","comments":true,"path":"2019/03/16/backend/java/jvm/JVM类文件结构(三)字节码指令/","link":"","permalink":"http://www.songshuiyang.com/2019/03/16/backend/java/jvm/JVM类文件结构(三)字节码指令/","excerpt":"","text":"解析 Java虚拟机的指令由一个字节长度、代表着某种特定操作含义的数字（操作码）以及跟随其后代表此操作所需参数（操作数）而构成。由于JAVA虚拟机采用的是面向操作数栈而不是寄存器的架构，所以大多数指令都不包含操作数，只有一个操作码 伪代码执行模型 加载、存储指令12341）iload、iload&lt;n&gt;、lload、lload&lt;n&gt;、fload、fload&lt;n&gt;、dload、dload&lt;n&gt;、aload、aload&lt;n&gt;：将一个局部变量加载到操作数栈。2）istore、istore&lt;n&gt;、lstore、lstore&lt;n&gt;、fstore、fstore&lt;n&gt;、dstore、dstore&lt;n&gt;、astore、astore&lt;n&gt;：将一个数值从操作数栈存储到局部变量表。3）bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconstm1、iconst&lt;i&gt;、lconst&lt;l&gt;、fconst&lt;f&gt;、dconst_&lt;d&gt;：将一个常量加载到操作数栈。4）wide：扩充局部变量表的访问索引的指令。 示例： 代码 12345678910public static int methodE()&#123; int e = 100; int c = 300; int d = 300000; e++; ++e; --e; e--; return c + d + e;&#125; 对应的字节码 123456789101112131415161718192021222324252627282930public static int methodE(); Signature: ()I flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=0 0: bipush 100 2: istore_0 3: sipush 300 6: istore_1 7: ldc #5 // int 300000 9: istore_2 10: iinc 0, 1 13: iinc 0, 1 16: iinc 0, -1 19: iinc 0, -1 22: iload_1 23: iload_2 24: iadd 25: iload_0 26: iadd 27: ireturn LineNumberTable: line 40: 0 line 41: 3 line 42: 7 line 43: 10 line 44: 13 line 45: 16 line 46: 19 line 47: 22 运算指令1234567891011121）iadd、ladd、fadd、dadd：加法指令。2）isub、lsub、fsub、dsub：减法指令。3）imul、lmul、fmul、dmul：乘法指令。4）idiv、ldiv、fdiv、ddiv：除法指令。5）irem、lrem、frem、drem：求余指令。6）ineg、lneg、fneg、dneg：取反指令。7）ishl、ishr、iushr、lshl、lshr、lushr：位移指令。8）ior、lor：按位或指令。9）iand、land：按位与指令。10）ixor、lxor：按位异或指令。11）iinc：局部变量自增指令。12）dcmpg、dcmpl、fcmpg、fcmpl、lcmp：比较指令。 示例参照上例 类型转换指令121）int类型到long、float或者double类型，long类型到float、double类型，float类型到double类型：宽化类型转换（虚拟机直接支持）。2）i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l、d2f：窄化类型转换（显式指令）。 示例： 代码 12345678910public static void methodK()&#123; int i = 97; short i2s = (short) i; char i2c = (char) i; long i2l = i; float i2f = i; double i2d = i; float l2f = i2l; double l2d = i2l;&#125; 对应的字节码 123456789101112131415161718192021222324252627282930313233343536373839public static void methodK();Signature: ()Vflags: ACC_PUBLIC, ACC_STATICCode: stack=2, locals=11, args_size=0 0: bipush 97 2: istore_0 3: iload_0 4: i2s 5: istore_1 6: iload_0 7: i2c 8: istore_2 9: iload_0 10: i2l 11: lstore_3 12: iload_0 13: i2f 14: fstore 5 16: iload_0 17: i2d 18: dstore 6 20: lload_3 21: l2f 22: fstore 8 24: lload_3 25: l2d 26: dstore 9 28: return LineNumberTable: line 100: 0 line 101: 3 line 102: 6 line 103: 9 line 104: 12 line 105: 16 line 106: 20 line 107: 24 line 108: 28 对象创建与访问指令12345671）new ：创建类实例的指令。2）newarray、anewarray、multianewarray：创建数组的指令。3）getstatic、putstatic、getfield、putfield：访问类字段（类变量）和实例字段（实例变量）的指令。4）baload、caload、saload、iaload、laload、faload、daload、aaload：把一个数组元素加载到操作数栈的指令。5）bastore、castore、sastore、iastore、lastore、fastore、dastore、aastore：把一个操作数栈的值存储到数组元素中的指令。6）arraylength：取数组长度的指令。7）instanceof、checkcast：检查类实例类型的指令。 示例： 代码 12345public static void methodJ()&#123; new SimpleMethodExecuteProcess(); System.out.println(SimpleMethodExecuteProcess.i);&#125; 对应的字节码 1234567891011121314151617public static void methodJ();Signature: ()Vflags: ACC_PUBLIC, ACC_STATICCode: stack=2, locals=0, args_size=0 0: new #9 // class edu/atlas/demo/java/jvm/SimpleMethodExecuteProcess 3: dup 4: invokespecial #10 // Method \"&lt;init&gt;\":()V 7: pop 8: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 11: getstatic #11 // Field i:I 14: invokevirtual #12 // Method java/io/PrintStream.println:(I)V 17: return LineNumberTable: line 91: 0 line 93: 8 line 94: 17 操作数栈管理指令1231）pop、pop2：将操作数栈的栈顶一个或两个元素出栈。2）dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2：复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶。3）swap：将栈最顶端两个数值互换 示例： 代码 123public static void main(String[] args) &#123; heavyMethod();&#125; 对应的字节码 1234567891011public static void main(java.lang.String[]); Signature: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=1, args_size=1 0: invokestatic #23 // Method heavyMethod:()I 3: pop 4: return LineNumberTable: line 115: 0 line 116: 4 控制转移指令1231）ifeq、iflt、ifle、ifne、ifgt、ifge、ifnull、ifnonnull、if_icmpeq、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_icmpge、if_acmpeq、if_acmpne：条件分支。2）tableswitch、lookupswitch：复合条件分支。3）goto、goto_w、jsr、jsr_w、ret：无条件分支。 示例： 代码 12345678910public static void methodG()&#123; if(i == 0)&#123; System.out.println(System.currentTimeMillis()); &#125; while(i &lt; 1)&#123; System.out.println(System.currentTimeMillis()); i++; &#125;&#125; 对应的字节码 1234567891011121314151617181920212223242526272829303132public static void methodG(); Signature: ()V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=0, args_size=0 0: getstatic #6 // Field i:I 3: ifne 15 6: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 9: invokestatic #7 // Method java/lang/System.currentTimeMillis:()J 12: invokevirtual #8 // Method java/io/PrintStream.println:(J)V 15: getstatic #6 // Field i:I 18: iconst_1 19: if_icmpge 42 22: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 25: invokestatic #7 // Method java/lang/System.currentTimeMillis:()J 28: invokevirtual #8 // Method java/io/PrintStream.println:(J)V 31: getstatic #6 // Field i:I 34: iconst_1 35: iadd 36: putstatic #6 // Field i:I 39: goto 15 42: return LineNumberTable: line 62: 0 line 63: 6 line 66: 15 line 67: 22 line 68: 31 line 70: 42 StackMapTable: number_of_entries = 2 frame_type = 15 /* same */ frame_type = 26 /* same */ 异常处理指令1athrow ：显式抛出异常指令。 示例： 代码 12345678public static void methodH()&#123; try &#123; throw new NullPointerException(\"nothing ...\"); // do nothing ... &#125; catch (Throwable t)&#123; // do nothing ... &#125;&#125; 对应的字节码 12345678910111213141516171819202122public static void methodH();Signature: ()Vflags: ACC_PUBLIC, ACC_STATICCode: stack=3, locals=1, args_size=0 0: new #9 // class java/lang/NullPointerException 3: dup 4: ldc #10 // String nothing ... 6: invokespecial #11 // Method java/lang/NullPointerException.\"&lt;init&gt;\":(Ljava/lang/String;)V 9: athrow 10: astore_0 11: return Exception table: from to target type 0 10 10 Class java/lang/Throwable LineNumberTable: line 77: 0 line 79: 10 line 82: 11 StackMapTable: number_of_entries = 1 frame_type = 74 /* same_locals_1_stack_item */ stack = [ class java/lang/Throwable ] 同步指令 1monitorenter、monitorexit：支持synchronized语句块语义的指令。 示例： 代码 12345public void methodI()&#123; synchronized (Integer.class)&#123; // do nothing ... &#125;&#125; 对应的字节码 123456789101112131415161718192021222324252627282930313233public void methodI();Signature: ()Vflags: ACC_PUBLICCode: stack=2, locals=3, args_size=1 0: ldc_w #13 // class java/lang/Integer 3: dup 4: astore_1 5: monitorenter 6: aload_1 7: monitorexit 8: goto 16 11: astore_2 12: aload_1 13: monitorexit 14: aload_2 15: athrow 16: return Exception table: from to target type 6 8 11 any 11 14 11 any LineNumberTable: line 88: 0 line 90: 6 line 91: 16 StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 11 locals = [ class edu/atlas/demo/java/jvm/SimpleMethodExecuteProcess, class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 synchronized 修饰方法的语义解析：可以直接从方法常量池的方法表结构中ACC_SYNCHRONIZED访问标志得知一个方法是否声明为同步方法，不需要解析出monitorenter、monitorexit同步指令。 123456789101112131415public static synchronized void methodL()&#123; int i = 97;&#125; public static synchronized void methodL(); Signature: ()V flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED Code: stack=1, locals=1, args_size=0 0: bipush 97 2: istore_0 3: return LineNumberTable: line 120: 0 line 121: 3 方法调用和返回指令 1234561）invokestatic：调用静态方法。2）invokespecial：调用实例构造器&lt;init&gt;方法、私有方法和父类方法。3）invokevirtual：调用所有的虚方法。非虚方法以外的都是虚方法，非虚方法包括使用invokestatic、invokespecial调用的方法和被final修饰的方法。4）invokeinterface：调用接口方法，运行时再确定一个实现此接口的对象。5）invokedynamic：用于在运行时动态解析出调用点限定符所引用的方法，并执行该方法。ireturn（返回值是boolean、byte、char、short、int）、lreturn、freturn、dreturn、areturn：方法返回指令。 示例： 代码 123456789101112131415public static int heavyMethod()&#123; int a = 200; int b = 100; int c = methodC(methodA(methodA(a, b), b), methodB(a, b)); methodD(); methodE(); methodF(); methodG(); methodH(); new SimpleMethodExecuteProcess().methodI(); methodJ(); methodK(); methodL(); return c;&#125; 对应的字节码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static int heavyMethod();Signature: ()Iflags: ACC_PUBLIC, ACC_STATICCode: stack=3, locals=3, args_size=0 0: sipush 200 3: istore_0 4: bipush 100 6: istore_1 7: iload_0 8: iload_1 9: invokestatic #17 // Method methodA:(II)I 12: iload_1 13: invokestatic #17 // Method methodA:(II)I 16: iload_0 17: iload_1 18: invokestatic #18 // Method methodB:(II)I 21: invokestatic #19 // Method methodC:(II)I 24: istore_2 25: invokestatic #20 // Method methodD:()V 28: invokestatic #21 // Method methodE:()I 31: pop 32: invokestatic #22 // Method methodF:()D 35: pop2 36: invokestatic #23 // Method methodG:()V 39: invokestatic #24 // Method methodH:()V 42: new #14 // class edu/atlas/demo/java/jvm/SimpleMethodExecuteProcess 45: dup 46: invokespecial #15 // Method \"&lt;init&gt;\":()V 49: invokevirtual #25 // Method methodI:()V 52: invokestatic #26 // Method methodJ:()V 55: invokestatic #27 // Method methodK:()V 58: invokestatic #28 // Method methodL:()V 61: iload_2 62: ireturn LineNumberTable: line 128: 0 line 129: 4 line 130: 7 line 131: 25 line 132: 28 line 133: 32 line 134: 36 line 135: 39 line 136: 42 line 137: 52 line 138: 55 line 139: 58 line 140: 61 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.51cto.com/damon188/2131035","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM类文件结构(二)Code属性","slug":"backend/java/jvm/JVM类文件结构(二)Code属性","date":"2019-03-16T01:59:44.000Z","updated":"2019-09-19T12:25:24.528Z","comments":true,"path":"2019/03/16/backend/java/jvm/JVM类文件结构(二)Code属性/","link":"","permalink":"http://www.songshuiyang.com/2019/03/16/backend/java/jvm/JVM类文件结构(二)Code属性/","excerpt":"","text":"解析 Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码（Code，方法体内的Java代码）和元数据（Metadata，包括类、字段、方法定义及其他信息）两部分，那么在整个Class文件中，Code属性用于描述代码，所有的其他数据项目都用于描述元数据 Java虚拟机执行字节码是基于栈的体系结构 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/yxwkf/p/5222589.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM类文件结构(一)Class类文件结构","slug":"backend/java/jvm/JVM类文件结构(一)Class类文件结构","date":"2019-03-16T00:59:44.000Z","updated":"2019-12-05T12:19:35.291Z","comments":true,"path":"2019/03/16/backend/java/jvm/JVM类文件结构(一)Class类文件结构/","link":"","permalink":"http://www.songshuiyang.com/2019/03/16/backend/java/jvm/JVM类文件结构(一)Class类文件结构/","excerpt":"","text":"解析 不论什么一个Class文件都相应唯一一个类或接口的定义信息，可是不是全部的类或接口都得定义在文件里（它们也能够通过类载入器直接生成)。 Class文件是一组以8位字节为基础单位的二进制流。各个数据项严格按顺序排列，没有不论什么分隔符。 Class文件格式採用一种类似于C语言结构体的伪结构来存储数据。这样的伪结构仅仅有两种数据类型：无符号数和表。 无符号数属于基本的数据类型，以 u1、u2、u4、u8 来分别代表 1 个字节、2 个字节、4 个字节和 8 个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照 UTF-8 编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性地以 “_info” 结尾。表用于描述有层次关系的复合结构的数据，整个 Class 文件本质上就是一张表，它由表 6-1 所示的数据项构成。 image 使用以下的类进行说明： 123456789package com.test;public class Test &#123; private int m; public int getM()&#123; return m + 1; &#125;&#125; javap -verbose 执行后的可视byteCode（只存在两种数据类型：无符号数字与表）: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Classfile /D:/workspace-github/jvm/target/production/jvm/com/songsy/Test.class Last modified 2019-3-16; size 361 bytes MD5 checksum bb8e54060828e4bf1f709c2f4434dca8 Compiled from \"Test.java\"public class com.songsy.Test minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#18 // java/lang/Object.\"&lt;init&gt;\":()V #2 = Fieldref #3.#19 // com/songsy/Test.m:I #3 = Class #20 // com/songsy/Test #4 = Class #21 // java/lang/Object #5 = Utf8 m #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/songsy/Test; #14 = Utf8 getM #15 = Utf8 ()I #16 = Utf8 SourceFile #17 = Utf8 Test.java #18 = NameAndType #7:#8 // \"&lt;init&gt;\":()V #19 = NameAndType #5:#6 // m:I #20 = Utf8 com/songsy/Test #21 = Utf8 java/lang/Object&#123; public com.songsy.Test(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 7: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/songsy/Test; public int getM(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field m:I 4: iconst_1 5: iadd 6: ireturn LineNumberTable: line 11: 0 LocalVariableTable: Start Length Slot Name Signature 0 7 0 this Lcom/songsy/Test;&#125;SourceFile: \"Test.java\" 编译后的class文件例如以下： 1. 魔数与Class版本 每一个class文件的头4个字节称为魔数，它唯一的作用是确定这个文件是否为一个能被虚拟机接受的Class文件。非常多文件存储标准中都使用魔数来进行身份识别。譬如图片格式gif、jpeg等。使用魔数而不是拓展名来进行识别主要是基于安全方面的考虑，由于文件拓展格式能够任意修改。Class文件的魔数为：0xCAFEBABE（咖啡宝贝？）。这个魔数似乎也预示着日后JAVA这个商标名称的出现。 第五六个字节是次版本（Minor Version）。第7和第8个字节是主版本（Major Version）。 高版本号的JDK能够向下兼容曾经版本号的Class文件，可是无法执行以后版本号的Class文件，即使文件格式并未发生变化，虚拟机也必须拒绝执行超过其版本号号的Class文件。 2. 常量池 紧接着版本之后就是常量池，常量池能够理解为Class文件之中的资源仓库，是Class文件结构中与其它项目关联最多的数据类型，也是占用Class文件空间最大的数据项目之中的一个。同一时候也是在Class文件里第一个出现的表类型数据项目 常量池中主要存放两大类常量 字面量和符号引用。字面量如文本字符串、声明为final的常量值等 符号引用包含三类常量：类和接口的全限定名、字段的名称和描写叙述符、方法的名称和描写叙述符。 3. 访问标志 在常量池结束之后，紧接着的两个字节代表訪问标志。用于识别一些类或者接口层次的訪问信息。包括：这个类是Class类还是接口；是否定义为public类型，是否被声明为final，具体的标志位及其含义例如以下表所看到的。 依据上面的表格，測试类的訪问标志0x0021= 0x0001 | 0x0020 =ACC_PUBLIC | ACC_SUPER 4. 类索引、父类索引和接口索引集合 Class文件里由这3项数据来确定这个类的继承关系 this_class：类索引，用于确定这个类的全限定名，占2字节 super_class：父类索引。用于确定这个类父类的全限定名（Java语言不同意多重继承，故父类索引仅仅有一个。除了java.lang.Object类之外全部类都有父类，故除了java.lang.Object类之外，全部类该字段值都不为0），占2字节 interfaces_count：接口索引计数器。占2字节。接口索引计数器。占2字节。 interfaces：接口索引集合，一组u2类型数据的集合。用来描写叙述这个类实现了哪些接口。这些被实现的接口将按implements语句（假设该类本身为接口，则为extends语句）后的接口顺序从左至右排列在接口的索引集合中 this_class、super_class与interfaces中保存的索引值均指向常量池中一个CONSTANT_Class_info类型的常量。通过这个常量中保存的索引值能够找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串this_class的值为0x0001，即常量池中第一个常量，super_class的值为0x0003，即常量池中的第三个常量，interfaces_counts的值为0x0000，故接口索引集合大小为0 5. 字段表集合 字段表用于描写叙述接口或者类中声明的变量，包含类级变量和实例级变量(是否是static)。但不包含在方法内部声明的局部变量。 fields_count：字段表计数器。即字段表集合中的字段表数据个数。占2字节，其值为0x0001，即仅仅有一个字段表数据。也就是測试类中仅仅包括一个变量（不算方法内部变量） 字段表集合，一组字段表类型数据的集合。字段表用于描写叙述接口或类中声明的变量。包含类级别（static）和实例级别变量，不包含在方法内部声明的变量 6. 方法表集合 methods_count：方法表计数器，即方法表集合中的方法表数据个数。占2字节，其值为0x0002，即測试类中有2个方法(还自己主动添加了一个构造函数） methods：方法表集合，一组方法表类型数据的集合。方法表结构和字段表结构一样： 7. 属性表集合 在Class文件、属性表、方法表中都能够包括自己的属性表集合。用于描写叙述某些场景的专有信息 与Class文件里其他数据项对长度、顺序、格式的严格要求不同，属性表集合不要求当中包括的属性表具有严格的顺序，而且仅仅要属性的名称不与已有的属性名称反复。不论什么人实现的编译器可以向属性表中写入自定义的属性信息。虚拟机在执行时会忽略不能识别的属性，为了能正确解析Class文件 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/yxwkf/p/5222589.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM垃圾回收(六)常用GC调优策略","slug":"backend/java/jvm/JVM垃圾回收(六)常用GC调优策略","date":"2019-03-11T15:01:00.000Z","updated":"2020-03-16T11:43:55.487Z","comments":true,"path":"2019/03/11/backend/java/jvm/JVM垃圾回收(六)常用GC调优策略/","link":"","permalink":"http://www.songshuiyang.com/2019/03/11/backend/java/jvm/JVM垃圾回收(六)常用GC调优策略/","excerpt":"","text":"前言GC 调优原则 在调优之前，我们需要记住下面的原则： 多数的 Java 应用不需要在服务器上进行 GC 优化； 多数导致 GC 问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC 优化是到最后不得已才采用的手段； 在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多 GC 调优目的 将转移到老年代的对象数量降低到最小； 减少 GC 的执行时间。 GC 调优策略 策略 1：将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。 策略 2：大对象进入老年代，虽然大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配的老年代，破坏新生代的对象结构，可能会出现频繁的 full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说简直就是噩梦）。-XX:PretenureSizeThreshold 可以设置直接进入老年代的对象大小。 策略 3：合理设置进入老年代对象的年龄，-XX:MaxTenuringThreshold 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 full gc 发生的频率。 策略 4：设置稳定的堆大小，堆大小设置有两个参数：-Xms 初始化堆大小，-Xmx 最大堆大小。 策略5：注意： 如果满足下面的指标，则一般不需要进行 GC 优化： MinorGC 执行时间不到50ms； Minor GC 执行不频繁，约10秒一次； Full GC 执行时间不到1s； Full GC 执行频率不算频繁，不低于10分钟1次； 参考转载 周志明版 《深入理解Java虚拟机》 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/GC调优参数","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM垃圾回收(五)GC日志分析","slug":"backend/java/jvm/JVM垃圾回收(五)GC日志分析","date":"2019-03-11T15:00:00.000Z","updated":"2020-03-16T11:43:55.485Z","comments":true,"path":"2019/03/11/backend/java/jvm/JVM垃圾回收(五)GC日志分析/","link":"","permalink":"http://www.songshuiyang.com/2019/03/11/backend/java/jvm/JVM垃圾回收(五)GC日志分析/","excerpt":"","text":"GC日志查看 可以通过在java命令种加入参数来指定对应的gc类型，打印gc日志信息并输出至文件等策略。GC的日志是以替换的方式(&gt;)写入的，而不是追加(&gt;&gt;)，如果下次写入到同一个文件中的话，以前的GC内容会被清空。 对应的参数列表 123456-XX:+PrintGC 输出GC日志-XX:+PrintGCDetails 输出GC的详细日志-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息-Xloggc:../logs/gc.log 日志文件的输出路径 示例 -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:./gclogs 新生代回收日志123452014-07-18T16:02:17.606+0800: 611.633: [GC 611.633: [DefNew: 843458K-&gt;2K(948864K), 0.0059180 secs] 2186589K-&gt;1343132K(3057292K), 0.0059490 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]``` ```sql2014-07-18T16:02:17.606+0800（当前时间戳）: 611.633（时间戳）: [GC（表示Young GC） 611.633: [DefNew（单线程Serial年轻代GC）: 843458K（年轻代垃圾回收前的大小）-&gt;2K（年轻代回收后的大小）(948864K（年轻代总大小）), 0.0059180 secs（本次回收的时间）] 2186589K（整个堆回收前的大小）-&gt;1343132K（整个堆回收后的大小）(3057292K（堆总大小）), 0.0059490 secs（回收时间）] [Times: user=0.00（用户耗时） sys=0.00（系统耗时）, real=0.00 secs（实际耗时）] 老年代回收的日志如下：12014-07-18T16:19:16.794+0800: 1630.821: [GC 1630.821: [DefNew: 1005567K-&gt;111679K(1005568K), 0.9152360 secs]1631.736: [Tenured:2573912K-&gt;1340650K(2574068K), 1.8511050 secs] 3122548K-&gt;1340650K(3579636K), [Perm : 17882K-&gt;17882K(21248K)], 2.7854350 secs] [Times: user=2.57 sys=0.22, real=2.79 secs] 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/qlqwjy/p/7929414.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM垃圾回收(四)常用参数","slug":"backend/java/jvm/JVM垃圾回收(四)常用参数","date":"2019-03-11T13:59:44.000Z","updated":"2019-09-19T12:25:24.470Z","comments":true,"path":"2019/03/11/backend/java/jvm/JVM垃圾回收(四)常用参数/","link":"","permalink":"http://www.songshuiyang.com/2019/03/11/backend/java/jvm/JVM垃圾回收(四)常用参数/","excerpt":"","text":"JVM参数的含义 参数名称 含义 默认值 备注 -Xms 初始堆大小starting 物理内存的1/64(&lt;1GB) 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. -Xmx 最大堆大小max 物理内存的1/4(&lt;1GB) 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 -Xmn 年轻代大小(1.4or lator)new 注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 -XX:NewSize 设置年轻代大小(for 1.3/1.4) -XX:MaxNewSize 年轻代最大值(for 1.3/1.4) -XX:PermSize 设置持久代(perm gen)初始值 物理内存的1/64 -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 -Xss 每个线程的堆栈大小 JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:””-Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了。 -XX:ThreadStackSize Thread Stack Size -XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5 Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置 -XX:SurvivorRatio Eden区与Survivor区的大小比值 设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10 -XX:LargePageSizeInBytes 内存页的大小不可设置过大， 会影响Perm的大小 =128m -XX:+UseFastAccessorMethods 原始类型的快速优化 -XX:+DisableExplicitGC 关闭System.gc() 这个参数需要严格的测试 -XX:MaxTenuringThreshold 垃圾最大年龄 如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率该参数只有在串行GC时才有效 -XX:+AggressiveOpts 加快编译 -XX:+UseBiasedLocking 锁机制的性能改善 -Xnoclassgc 禁用垃圾回收 -XX:SoftRefLRUPolicyMSPerMB 每兆堆空闲空间中SoftReference的存活时间 1s -XX:PretenureSizeThreshold 对象超过多大是直接在旧生代分配 0 单位字节 新生代采用Parallel Scavenge GC时无效另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. -XX:TLABWasteTargetPercent TLAB占eden区的百分比 1% -XX:+CollectGen0First FullGC时是否先YGC false 并行收集器相关参数 参数名称 含义 默认值 备注 -XX:+UseParallelGC Full GC采用parallel MSC(此项待验证) 选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集.(此项待验证) -XX:+UseParNewGC 设置年轻代为并行收集 可与CMS收集同时使用JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值 -XX:ParallelGCThreads 并行收集器的线程数 此值最好配置与处理器数目相等 同样适用于CMS -XX:+UseParallelOldGC 年老代垃圾收集方式为并行收集(Parallel Compacting) 这个是JAVA 6出现的参数选项 -XX:MaxGCPauseMillis 每次年轻代垃圾回收的最长时间(最大暂停时间) 如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值. -XX:+UseAdaptiveSizePolicy 自动选择年轻代区大小和相应的Survivor区比例 设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开. -XX:GCTimeRatio 设置垃圾回收时间占程序运行时间的百分比 公式为1/(1+n) -XX:+ScavengeBeforeFullGC Full GC前调用YGC true Do young generation GC prior to a full GC. (Introduced in 1.4.1.) CMS相关参数 参数名称 含义 默认值 备注 -XX:+UseConcMarkSweepGC 使用CMS内存收集 -XX:+AggressiveHeap 试图是使用大量的物理内存长时间大内存使用的优化，能检查计算资源（内存， 处理器数量）至少需要256MB内存大量的CPU／内存， （在1.4.1在4CPU的机器上已经显示有提升） -XX:CMSFullGCsBeforeCompaction 多少次后进行内存压缩 由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生”碎片”,使得运行效率降低.此值设置运行多少次GC以后对内存空间进行压缩,整理. -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX+UseCMSCompactAtFullCollection 在FULL GC的时候， 对年老代的压缩 CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用。 增加这个参数是个好习惯。可能会影响性能,但是可以消除碎片 -XX:+UseCMSInitiatingOccupancyOnly 使用手动定义初始化定义开始CMS收集 禁止hostspot自行触发CMS GC -XX:CMSInitiatingOccupancyFraction=70 使用cms作为垃圾回收使用70％后开始CMS收集 92 为了保证不出现promotion failed(见下面介绍)错误,该值的设置需要满足以下公式CMSInitiatingOccupancyFraction计算公式 -XX:CMSInitiatingPermOccupancyFraction 设置Perm Gen使用到达多少比率时触发 92 -XX:+CMSIncrementalMode 设置为增量模式 用于单CPU情况 -XX:+CMSClassUnloadingEnabled 辅助参数 参数名称 含义 默认值 备注 -XX:+PrintGC 输出形式:[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] -XX:+PrintGCDetails 输出形式:[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime 打印垃圾回收期间程序暂停的时间.可与上面混合使用 可与-XX:+PrintGC -XX:+PrintGCDetails混合使用输出形式:11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationConcurrentTime 打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用 输出形式:Total time for which application threads were stopped: 0.0468229 seconds -XX:+PrintHeapAtGC 打印GC前后的详细堆栈信息 -Xloggc:filename 把相关日志信息记录到文件以便分析，与上面几个配合使用 -XX:+PrintClassHistogram garbage collects before printing the histogram. -XX:+PrintTLAB 查看TLAB空间的使用情况 XX:+PrintTenuringDistribution 查看每次minor GC后新的存活周期的阈值 Desired survivor size 1048576 bytes, new threshold 7 (max 15)new threshold 7即标识新的存活周期的阈值为7。 备注 -X 开头参数的是非标准，不是所有虚拟机都支持，-XX更流氓，不保证其稳定性 参考转载 周志明版 《深入理解Java虚拟机》 http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM垃圾回收(三)内存分配及回收策略","slug":"backend/java/jvm/JVM垃圾回收(三)内存分配及回收策略","date":"2019-03-10T14:59:44.000Z","updated":"2020-03-16T11:43:55.480Z","comments":true,"path":"2019/03/10/backend/java/jvm/JVM垃圾回收(三)内存分配及回收策略/","link":"","permalink":"http://www.songshuiyang.com/2019/03/10/backend/java/jvm/JVM垃圾回收(三)内存分配及回收策略/","excerpt":"","text":"概述 Java技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。关于回收内存这一点，我们已经使用了大量篇幅去介绍虚拟机中的垃圾收集器体系以及运作原理，现在我们再一起来探讨一下给对象分配内存的那点事儿。 对象的内存分配，往大方向讲，就是在堆上分配（但也可能经过JIT编译后被拆散为标量类型并间接地栈上分配），对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 TLAB: 首先讲讲什么是TLAB。内存分配的动作，可以按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer，TLAB）。哪个线程需要分配内存，就在哪个线程的TLAB上分配。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。这么做的目的之一，也是为了并发创建一个对象时，保证创建对象的线程安全性。TLAB比较小，直接在TLAB上分配内存的方式称为快速分配方式，而TLAB大小不够，导致内存被分配在Eden区的内存分配方式称为慢速分配方式。 接下来我们将会讲解几条最普遍的内存分配规则，并通过代码去验证这些规则。由于条件因素，只能在Client模式下测试，因此CMS和G1并未提及。 解析1. 对象优先在Eden分配 所有通过new创建的对象的内存都在堆中分配，堆被划分为新生代和老年代，新生代又被进一步划分为Eden和Survivor区，而Survivor由FromSpace和ToSpace组成。 新生代：新创建的对象都是用新生代分配内存，Eden空间不足时，触发Minor GC，这时会把存活的对象转移进Survivor区。 老年代：老年代用于存放经过多次Minor GC之后依然存活的对象。 大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。这时会把存活的对象转移进Survivor区。 Minor GC 新生代GC，指发生在新生代的垃圾收集动作，所有的Minor GC都会触发全世界的暂停（stop-the-world），停止应用程序的线程，不过这个过程非常短暂。 Major GC 老年代GC，指发生在老年代的GC。 Full GC 包括前两个 举例说明 下面的代码来看一下jvm具体是怎样分配的，下面的代码注释有详细解释 123456789101112131415161718192021222324252627282930313233/** * VM参数： * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC * 参数解析： * * 初始堆大小为20兆，不可扩展，年轻代大小为10兆剩下的10兆分配给老年代，PrintGCDetails打印内存回收日志，SurvivorRatio标识 eden与Survivor比例为8:1 * * \"eden space 8192K from space 1024K to space 1024K\" 新生代总可用空间为9216KB (一个Eden区 + 一个Survivor区) * @author songsy * @date 2019/3/11 18:37 */public class Jvm1 &#123; private static final int _1KB = 1024; private static final int _1MB = 1024 * _1KB; public static void testAllocation() &#123; byte [] allocation1,allocation2, allocation3,allocation4,allocation5; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; /** * 执行到下一步出现一次Minor GC，因为发现Eden已经被占用了6Mb，剩余空间装不下4Mb， * 执行gc的时候发现已有3*2Mb的对象无法放入Survivor（只有1mb）空间，所以只好通过 * 分配担保机制提前转移到老年代去 */ allocation4 = new byte[4 * _1MB]; /** * Gc结束，4Mb的allocation4对象将分配在Eden区，老年代占用6Mb */ &#125; public static void main(String[] args) &#123; testAllocation(); &#125;&#125; 输出日志 1234567891011[GC[DefNew: 7485K-&gt;526K(9216K), 0.0076710 secs] 7485K-&gt;6671K(19456K), 0.0077381 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] Heap def new generation total 9216K, used 4952K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 54% used [0x00000000f9a00000, 0x00000000f9e526c8, 0x00000000fa200000) from space 1024K, 51% used [0x00000000fa300000, 0x00000000fa383bd8, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2950K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 13% used [0x00000000fae00000, 0x00000000fb0e1918, 0x00000000fb0e1a00, 0x00000000fc2c0000)No shared spaces configured. 2. 大对象直接进入老年代 所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组（例子中的byte[]数组就是典型的大对象）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。 虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。只对Serial和ParNew两款收集器有效，Parallel Scavenge收集器不认识这个参数，Parallel Scavenge收集器一般并不需要设置。 举例说明 代码 123456789101112131415161718192021222324/** * 测试大对象直接进入老年代 * * VM参数： * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC * -XX:PretenureSizeThreshold=3145728 可选 * * @author songsy * @date 2019/3/11 18:37 */public class Jvm2 &#123; private static final int _1KB = 1024; private static final int _1MB = 1024 * _1KB; public static void testAllocation() &#123; byte [] allocation1; // 直接分配在老年代 allocation1 = new byte[4 * _1MB]; &#125; public static void main(String[] args) &#123; testAllocation(); &#125;&#125; 没设置PretenureSizeThreshold，可以看到新生代def new generation total 9216K, used 5773K，老年代tenured generation total 10240K, used 0K 12345678910Heap def new generation total 9216K, used 5773K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 70% used [0x00000000f9a00000, 0x00000000f9fa3668, 0x00000000fa200000) from space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) to space 1024K, 0% used [0x00000000fa300000, 0x00000000fa300000, 0x00000000fa400000) tenured generation total 10240K, used 0K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 0% used [0x00000000fa400000, 0x00000000fa400000, 0x00000000fa400200, 0x00000000fae00000) compacting perm gen total 21248K, used 3237K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 15% used [0x00000000fae00000, 0x00000000fb129600, 0x00000000fb129600, 0x00000000fc2c0000)No shared spaces configured. 设置了PretenureSizeThreshold结果，可以看到新生代def new generation total 9216K, used 1671K ,老年代tenured generation total 10240K, used 4096K 12345678910Heap def new generation total 9216K, used 1671K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 20% used [0x00000000f9a00000, 0x00000000f9ba1c08, 0x00000000fa200000) from space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) to space 1024K, 0% used [0x00000000fa300000, 0x00000000fa300000, 0x00000000fa400000) tenured generation total 10240K, used 4096K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 40% used [0x00000000fa400000, 0x00000000fa800010, 0x00000000fa800200, 0x00000000fae00000) compacting perm gen total 21248K, used 2938K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 13% used [0x00000000fae00000, 0x00000000fb0de9e0, 0x00000000fb0dea00, 0x00000000fc2c0000)No shared spaces configured. 3. 长期存活的对象将进入老年代 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别那些对象放在新生代，那些对象放在老年代中 为了能做到这一点，虚拟机给每个对象定义了一个对象年龄计数器，如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX：MaxTenuringThreshold设置。 举例说明 1234567891011121314151617181920212223242526272829/** * 测试长期存活的对象进入老年代 * * VM参数： * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC * -XX:MaxTenuringThreshold=1 可选 * * @author songsy * @date 2019/3/11 18:37 */public class Jvm3 &#123; private static final int _1KB = 1024; private static final int _1MB = 1024 * _1KB; public static void testAllocation() &#123; byte [] allocation1,allocation2, allocation3; allocation1 = new byte[_1MB / 4]; allocation2 = new byte[4 * _1MB]; allocation3 = new byte[4 * _1MB]; // 虽然此处赋值为null，但未进行Gc空间仍被占用，下一行代码会执行minor GC allocation3 = null; // 将MaxTenuringThreshold设为1，可以看出第二次Minor GC时，年轻代已经被清空，allocation1对象因为年龄符合MaxTenuringThreshold设置的值，因此进入老年代。 allocation3 = new byte[4 * _1MB]; &#125; public static void main(String[] args) &#123; testAllocation(); &#125;&#125; 4. 动态对象年龄判定 为了能更好的适应不同程序的内存状态，虚拟机并不是永远的要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代的 如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 5. 空间分配担保 内存分配是在JVM在内存分配的时候，新生代内存不足时，把新生代的存活的对象搬到老生代，然后新生代腾出来的空间用于为分配给最新的对象。这里老生代是担保人。在不同的GC机制下，也就是不同垃圾回收器组合下，担保机制也略有不同。 Parallel Scavenge收集器与其他收集器在空间分配担保上有一点差别, 正常是在Minor GC前进行检查, 而Parallel Scavenge收集器在Minor GC后也会进行检查。 另外当出现大量对象在Minor GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/v123411739/article/details/78941793","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM垃圾回收(二)垃圾回收器","slug":"backend/java/jvm/JVM垃圾回收(二)垃圾回收器","date":"2019-03-10T13:59:50.000Z","updated":"2020-03-16T11:43:55.484Z","comments":true,"path":"2019/03/10/backend/java/jvm/JVM垃圾回收(二)垃圾回收器/","link":"","permalink":"http://www.songshuiyang.com/2019/03/10/backend/java/jvm/JVM垃圾回收(二)垃圾回收器/","excerpt":"","text":"概述 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 Java虚拟机规范对垃圾回收器应该如何实现并没有任何规定，因此不同的厂商、不同的版本的回收器可能会有很大差异，一般是提供参数供用户根据自己的应用特点和要求组合各个年代所使用的回收器 虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。 试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的 HotSpot 虚拟机就不会实现那么多不同的垃圾收集器了。 这里讨论的收集器基于JDK1.7Update 14之后的HotSpot虚拟机，这个虚拟机包含的所有收集器如下图3-5所示，上半部分是新生代的回收器，下半部分是老年代的回收器 1. Serial 收集器 Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。 大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 新生代采用复制算法，老年代采用标记-整理算法。 虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。 但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial收集器对于运行在Client模式下的虚拟机来说是个不错的选择。 2. Serial Old 收集器 Serial收集器的老年代版本，它同样是一个单线程收集器。 它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。 3. ParNew 收集器 ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。 新生代采用复制算法，老年代采用标记-整理算法。 它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。 4. Parallel Old收集器 Parallel Scavenge收集器的老年代版本。 使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。 5. Parallel Scavenge收集器 Parallel Scavenge 收集器类似于ParNew 收集器。 那么它有什么特别之处呢？ Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 1234567-XX:+UseParallelGC 使用Parallel收集器+ 老年代串行-XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行 Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 新生代采用复制算法，老年代采用标记-整理算法。 6. CMS收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与root相连的对象，速度很快 并发标记： 同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时GC线程开始对为标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对CPU资源敏感 无法处理浮动垃圾 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生 7. G1收集器 G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征. 被视为JDK1.7中HotSpot虚拟机的一个重要进化特征。它具备一下特点 G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。 与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内。 G1收集器的运作大致分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/chengxuyuanzhilu/p/7088316.html https://blog.csdn.net/qq_34337272/article/details/82177383","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM垃圾回收(一)垃圾回收算法","slug":"backend/java/jvm/JVM垃圾回收(一)垃圾回收算法","date":"2019-03-10T13:59:44.000Z","updated":"2019-09-19T12:25:24.439Z","comments":true,"path":"2019/03/10/backend/java/jvm/JVM垃圾回收(一)垃圾回收算法/","link":"","permalink":"http://www.songshuiyang.com/2019/03/10/backend/java/jvm/JVM垃圾回收(一)垃圾回收算法/","excerpt":"","text":"概述 猿们都知道JVM的内存结构包括五大区域：程序计数器、虚拟机栈、本地方法栈、堆区、方法区。其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生、随线程而灭，因此这几个区域的内存分配和回收都具备确定性，就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。 而Java堆区和方法区则不一样、不一样!(怎么不一样说的朗朗上口)，这部分内存的分配和回收是动态的，正是垃圾收集器所需关注的部分。 判断对象是否存活的算法 垃圾收集器在对堆区和方法区进行回收前，首先要确定这些区域的对象哪些可以被回收，哪些暂时还不能回收，这就要用到判断对象是否存活的算法！（面试官肯定没少问你吧） 1. 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。 一个对象如果没有任何引用指向它，就可认为该对象已经”消亡“，这种方法有个缺点就是无法检测到引用环的存在。 2. 可达性分析算法 通过一系列叫做”GCRoots“的对象作为起点向下搜索，走过的路径称为引用链,当一个对象到GCRoots没有任何引用链时，表明该对象已经”消亡“。 image 上图中每个对象都存在引用链与GCRoots相连，表明对象还在，不能回收。有图中三个对象虽然互相引用，但是没有链接与GCRoots相连，则可判断它们是可回收的对象。 什么对象可以为GCRoots， 虚拟机栈中本地变量表引用的对象，局部变量 方法区中的类静态变量引用的对象及常量引用的对象 本地方法栈中JNI引用的对象 彻底死亡条件： 条件1：通过GC Roots作为起点的向下搜索形成引用链，没有搜到该对象，这是第一次标记。 条件2：在finalize方法中没有逃脱回收（将自身被其他对象引用），这是第一次标记的清理。 引用 强引用Object o = new Object() 软引用SoftReference 定义了软引用对象之后，GC可达的算法就切断与此对象的连接，那么下次垃圾回收的时候就会优化回收此对象 弱引用 虚引用 垃圾回收算法1. 标记-清除算法 该算法是最基础的收集算法，算法分为标记和清除两个阶段，首先标记所有需要回收的对象，在标记完成之后统一回收所有被标记的对象 之所以说它是最基础的算法是因为后续的算法都是基于这种思路并对其不足进行改进而得到的 缺点 效率不足 会产生大量不连续的内存碎片，碎片过多的话再分配一个较大对象时就无容身之地从而不得不提前触发另一次垃圾收集 2. 复制算法 为了解决效率问题，此算法把内存划分为相等大小的两个区域，每一只使用其中一个，回收过程中将存活的对象全部复制到另一个区域中，清空原区域。在年轻代中eden区和两个survivor区就是使用了此种算法。这种算法只复制存活的对象，成本较低，而且不会出现内存碎片问题 现在的商业虚拟机都采用这种算法来回收新生代 缺点 费内存，需要2倍的内存空间 3. 标记-整理算法 该算法标记阶段和标记-清除算法一样，但是在完成标记之后，它不是直接清理可回收对象，而是将存活对象都向一端移动，然后清理掉端边界以外的内存。所以，特别适用于存活对象多，回收对象少的情况下。效率比“标记-清理”算法低，但不会产生内存碎片。 4. 分代收集算法 分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）。老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/aspirant/p/8662690.html http://baijiahao.baidu.com/s?id=1565631804713416&amp;wfr=spider&amp;for=pc","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(七)HotSpot虚拟机对象探秘","slug":"backend/java/jvm/JVM运行时数据区域(七)HotSpot虚拟机对象探秘","date":"2019-03-04T06:59:44.000Z","updated":"2020-03-16T11:43:55.492Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(七)HotSpot虚拟机对象探秘/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(七)HotSpot虚拟机对象探秘/","excerpt":"","text":"概述 通过上面的介绍我们大概知道了虚拟机的内存情况，下面我们来详细的了解一下 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。 ## 参考转载 周志明版 《深入理解Java虚拟机》 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java内存区域","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM内存溢出异常(一)OutOfMemoryError","slug":"backend/java/jvm/JVM内存溢出异常(一)OutOfMemoryError","date":"2019-03-04T05:59:44.000Z","updated":"2019-12-03T13:10:39.014Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM内存溢出异常(一)OutOfMemoryError/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM内存溢出异常(一)OutOfMemoryError/","excerpt":"","text":"在Java虚拟机规范的描述中，除了程序计数器外，虚拟机内存的其他几个运行时区域都有可能发生OutOfMemoryError（OOM）异常的可能，下面将介绍这些运行时区域出现OOM的场景及解决方法 Java堆溢出 Java堆用于存储对象实例，只要不断的创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量到达最大堆的容量限制之后就会产生内存溢出异常 测试代码 12345678910111213141516171819/** * Java堆内存异常测试 * * VM参数： * -Xms20M -Xmx20M -XX:+HeapDumpOnOutOfMemoryError * 堆的最小值-Xms参数与最大值-Xmx参数设置为一样即可避免堆自动扩展 * @author songsy * @date 2019/3/22 18:37 */public class Jvm4 &#123; public static void main(String[] args) &#123; List&lt;Jvm4&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new Jvm4()); &#125; &#125;&#125; 输出结果 1234567891011java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid17684.hprof ...Heap dump file created [29356301 bytes in 0.114 secs]Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:2245) at java.util.Arrays.copyOf(Arrays.java:2219) at java.util.ArrayList.grow(ArrayList.java:242) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:216) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:208) at java.util.ArrayList.add(ArrayList.java:440) at com.songsy.Jvm4.main(Jvm4.java:24) 我们可以在vm参数中配置-XX:+HeapDumpOnOutOfMemoryError参数，配置完成之后如果程序发生了OutOfMemoryError后会生成堆转储快照文件java_pid17684.hprof 通过JProfiler打开此文件，发现都是com.songsy.Jvm4.main对象，原因是因为虚拟机限制了堆的最大空间(-Xmx20M)。当准备创建的对象需要的内存已经超过虚拟机堆所剩的空间。虚拟机会尝试通过full GC来回收内存，如果不行的话，就会抛出OutOfMemoryError 虚拟机栈和本地方法栈溢出 由于在HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，因此，对于HotSpot来说，虽然-Xoss参数（设置本地方法栈大小）存在，但实际上是无效的，栈容量只由-Xss参数设定。 关于虚拟机栈和本地方法栈，在Java虚拟机规范中描述了两种异常： 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。 如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 这里把异常分成两种情况，看似更加严谨，但却存在着一些互相重叠的地方：当栈空间无法继续分配时，到底是内存太小，还是已使用的栈空间太大，其本质上只是对同一件事情的两种描述而已。 测试代码： 1234567891011121314151617181920212223242526/** * 测试 StackOverflowError异常 * VM Args：-Xss128k * @author songsy * @date 2019/3/22 16:31 */public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) throws Throwable &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; // 抛出StackOverflowError异常，异常出现时输出的堆栈深度相应缩小。 System.out.println(\"stack length:\" + oom.stackLength); throw e; &#125; &#125;&#125; 输出结果 12345stack length:11424Exception in thread \"main\" java.lang.StackOverflowError at com.songsy.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:13) at com.songsy.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:14) at com.songsy.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:14) 测试代码2： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285/** * 测试 StackOverflowError异常 * VM Args：-Xss128k * @author songsy * @date 2019/3/22 17:15 */public class JavaVMStackSOF1 &#123; private int stackLength = 1; public void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF1 oom = new JavaVMStackSOF1(); long e0 = 1; long e1 = 1; long e2 = 1; long e3 = 1; long e4 = 1; long e5 = 1; long e6 = 1; long e7 = 1; long e8 = 1; long e9 = 1; long q0 = 1; long q1 = 1; long q2 = 1; long q3 = 1; long q4 = 1; long q5 = 1; long q6 = 1; long q7 = 1; long q8 = 1; long q9 = 1; long r0 = 1; long r1 = 1; long r2 = 1; long r3 = 1; long r4 = 1; long r5 = 1; long r6 = 1; long r7 = 1; long r8 = 1; long r9 = 1; long t0 = 1; long t1 = 1; long t2 = 1; long t3 = 1; long t4 = 1; long t5 = 1; long t6 = 1; long t7 = 1; long t8 = 1; long t9 = 1; long y0 = 1; long y1 = 1; long y2 = 1; long y3 = 1; long y4 = 1; long y5 = 1; long y6 = 1; long y7 = 1; long y8 = 1; long y9 = 1; long u0 = 1; long u1 = 1; long u2 = 1; long u3 = 1; long u4 = 1; long u5 = 1; long u6 = 1; long u7 = 1; long u8 = 1; long u9 = 1; long i0 = 1; long i1 = 1; long i2 = 1; long i3 = 1; long i4 = 1; long i5 = 1; long i6 = 1; long i7 = 1; long i8 = 1; long i9 = 1; long o0 = 1; long o1 = 1; long o2 = 1; long o3 = 1; long o4 = 1; long o5 = 1; long o6 = 1; long o7 = 1; long o8 = 1; long o9 = 1; long p0 = 1; long p1 = 1; long p2 = 1; long p3 = 1; long p4 = 1; long p5 = 1; long p6 = 1; long p7 = 1; long p8 = 1; long p9 = 1; long a0 = 1; long a1 = 1; long a2 = 1; long a3 = 1; long a4 = 1; long a5 = 1; long a6 = 1; long a7 = 1; long a8 = 1; long a9 = 1; long s0 = 1; long s1 = 1; long s2 = 1; long s3 = 1; long s4 = 1; long s5 = 1; long s6 = 1; long s7 = 1; long s8 = 1; long s9 = 1; long d0 = 1; long d1 = 1; long d2 = 1; long d3 = 1; long d4 = 1; long d5 = 1; long d6 = 1; long d7 = 1; long d8 = 1; long d9 = 1; long f0 = 1; long f1 = 1; long f2 = 1; long f3 = 1; long f4 = 1; long f5 = 1; long f6 = 1; long f7 = 1; long f8 = 1; long f9 = 1; long g0 = 1; long g1 = 1; long g2 = 1; long g3 = 1; long g4 = 1; long g5 = 1; long g6 = 1; long g7 = 1; long g8 = 1; long g9 = 1; long h0 = 1; long h1 = 1; long h2 = 1; long h3 = 1; long h4 = 1; long h5 = 1; long h6 = 1; long h7 = 1; long h8 = 1; long h9 = 1; long j0 = 1; long j1 = 1; long j2 = 1; long j3 = 1; long j4 = 1; long j5 = 1; long j6 = 1; long j7 = 1; long j8 = 1; long j9 = 1; long k0 = 1; long k1 = 1; long k2 = 1; long k3 = 1; long k4 = 1; long k5 = 1; long k6 = 1; long k7 = 1; long k8 = 1; long k9 = 1; long l0 = 1; long l1 = 1; long l2 = 1; long l3 = 1; long l4 = 1; long l5 = 1; long l6 = 1; long l7 = 1; long l8 = 1; long l9 = 1; long z0 = 1; long z1 = 1; long z2 = 1; long z3 = 1; long z4 = 1; long z5 = 1; long z6 = 1; long z7 = 1; long z8 = 1; long z9 = 1; long c0 = 1; long c1 = 1; long c2 = 1; long c3 = 1; long c4 = 1; long c5 = 1; long c6 = 1; long c7 = 1; long c8 = 1; long c9 = 1; long v0 = 1; long v1 = 1; long v2 = 1; long v3 = 1; long v4 = 1; long v5 = 1; long v6 = 1; long v7 = 1; long v8 = 1; long v9 = 1; long b0 = 1; long b1 = 1; long b2 = 1; long b3 = 1; long b4 = 1; long b5 = 1; long b6 = 1; long b7 = 1; long b8 = 1; long b9 = 1; long n0 = 1; long n1 = 1; long n2 = 1; long n3 = 1; long n4 = 1; long n5 = 1; long n6 = 1; long n7 = 1; long n8 = 1; long n9 = 1; long m0 = 1; long m1 = 1; long m2 = 1; long m3 = 1; long m4 = 1; long m5 = 1; long m6 = 1; long m7 = 1; long m8 = 1; long m9 = 1; long qq0 = 1; long qq1 = 1; long qq2 = 1; long qq3 = 1; long qq4 = 1; long qq5 = 1; long qq6 = 1; long qq7 = 1; long qq8 = 1; long qq9 = 1; long ww0 = 1; long ww1 = 1; long ww2 = 1; long ww3 = 1; long ww4 = 1; long ww5 = 1; long ww6 = 1; long ww7 = 1; long ww8 = 1; long ww9 = 1; try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println(\"stack length:\" + oom.stackLength); throw e; &#125; &#125;&#125; 实验结果表明：在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是StackOverflowError异常。 如果测试时不限于单线程，通过不断地建立线程的方式倒是可以产生内存溢出异常，如代码清单2-5所示。但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系，或者准确地说，在这种情况下，为每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。 其实原因不难理解，操作系统分配给每个进程的内存是有限制的，譬如32位的Windows限制为2GB。虚拟机提供了参数来控制Java堆和方法区的这两部分内存的最大值。剩余的内存为2GB（操作系统限制）减去Xmx（最大堆容量），再减去MaxPermSize（最大方法区容量），程序计数器消耗内存很小，可以忽略掉。如果虚拟机进程本身耗费的内存不计算在内，剩下的内存就由虚拟机栈和本地方法栈“瓜分”了。每个线程分配到的栈容量越大，可以建立的线程数量自然就越少，建立线程时就越容易把剩下的内存耗尽。 java.lang.OutOfMemoryError： unable to create new native thread 线上出现了这个问题导致服务直接挂，查看jstack.log发现大部分是名为pool-253-thread-1的线程，怀疑是线程池使用不当的问题 先使用ps -ef | grep java 查看java进程的pid，得到pid之后cat /proc/27653/status查看java进程状态，Threads: 917线程数有917条 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[ops@sh-123 ~]$ cat /proc/27653/statusName: javaUmask: 0022State: S (sleeping)Tgid: 27653Ngid: 0Pid: 27653PPid: 27652TracerPid: 0Uid: 1001 1001 1001 1001Gid: 1001 1001 1001 1001FDSize: 128Groups: 1001 VmPeak: 6888664 kBVmSize: 6888660 kBVmLck: 0 kBVmPin: 0 kBVmHWM: 1858868 kBVmRSS: 1818044 kBRssAnon: 1803264 kBRssFile: 14780 kBRssShmem: 0 kBVmData: 6717104 kBVmStk: 132 kBVmExe: 4 kBVmLib: 18780 kBVmPTE: 5744 kBVmSwap: 0 kBThreads: 917SigQ: 0/31215SigPnd: 0000000000000000ShdPnd: 0000000000000000SigBlk: 0000000000000000SigIgn: 0000000000000002SigCgt: 2000000181005ccdCapInh: 0000000000000000CapPrm: 0000000000000000CapEff: 0000000000000000CapBnd: 0000001fffffffffCapAmb: 0000000000000000Seccomp: 0Cpus_allowed: fCpus_allowed_list: 0-3Mems_allowed: 00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001Mems_allowed_list: 0voluntary_ctxt_switches: 5nonvoluntary_ctxt_switches: 1 再查看系统用户的最大进程数，发现java的进程数已超过系统的最大进程数 ulimit值参数值大小的设置很重要，root的ulimit默认值是65536，普通用户的ulimit值默认是1024，当进程数过多的时候甚至连ssh都成问题。max user processes，用户最大进程数。 用ulimit -a命令查看root用户值的大小1234567891011121314151617[ops@sh-123 ~]$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 31215max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 102400pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 4096virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 最后排查项目代码发现是Executors.newFixedThreadPool()出现的问题 方法区和运行时常量池溢出 由于运行时常量池是方法区的一部分，因此这两个区域的溢出测试就放在一起进行。前面提到JDK 1.7开始逐步“去永久代”的事情，在此就以测试代码观察一下这件事对程序的实际影响。 String.intern()是一个Native方法，它的作用是：如果字符串常量池中已经包含一个等于此String对象的字符串，则返回代表池中这个字符串的String对象；否则，将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。在JDK 1.6及之前的版本中，由于常量池分配在永久代内，我们可以通过-XX:PermSize和-XX:MaxPermSize限制方法区大小，从而间接限制其中常量池的容量，如代码清单2-6所示。 测试代码 123456789101112131415161718/** * VM Args：-XX:PermSize=10M -XX:MaxPermSize=10M * @author songsy * @date 2019/3/22 17:31 */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; // 使用List保持着常量池引用，避免Full GC回收常量池行为 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 10MB的PermSize在integer范围内足够产生OOM了 int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); System.out.println(String.valueOf(i++).intern()); &#125; &#125;&#125; 输出结果 123Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space at java.lang.String.intern(Native Method) at org.fenixsoft.oom.RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java:18) 从运行结果中可以看到，运行时常量池溢出，在OutOfMemoryError后面跟随的提示信息是“PermGen space”，说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部分。 方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。对于这些区域的测试，基本的思路是运行时产生大量的类去填满方法区，直到溢出。虽然直接使用Java SE API也可以动态产生类（如反射时的GeneratedConstructorAccessor和动态代理等），但在本次实验中操作起来比较麻烦。在代码清单2-8中，笔者借助CGLib直接操作字节码运行时生成了大量的动态类。 值得特别注意的是，我们在这个例子中模拟的场景并非纯粹是一个实验，这样的应用经常会出现在实际应用中：当前的很多主流框架，如Spring、Hibernate，在对类进行增强时，都会使用到CGLib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以加载入内存。另外，JVM上的动态语言（例如Groovy等）通常都会持续创建类来实现语言的动态性，随着这类语言的流行，也越来越容易遇到与代码清单2-8相似的溢出场景。 代码清单2-8 借助CGLib使方法区出现内存溢出异常 1234567891011121314151617181920212223242526/** * VM Args： -XX:PermSize=10M -XX:MaxPermSize=10M * @author songsy * @date 2019/3/22 17:45 */public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; static class OOMObject &#123; &#125;&#125; 输出结果 12345Caused by: java.lang.OutOfMemoryError: PermGen space at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClassCond(ClassLoader.java:632) at java.lang.ClassLoader.defineClass(ClassLoader.java:616) ... 8 more 方法区溢出也是一种常见的内存溢出异常，一个类要被垃圾收集器回收掉，判定条件是比较苛刻的。在经常动态生成大量Class的应用中，需要特别注意类的回收状况。这类场景除了上面提到的程序使用了CGLib字节码增强和动态语言之外，常见的还有：大量JSP或动态产生JSP文件的应用（JSP第一次运行时需要编译为Java类）、基于OSGi的应用（即使是同一个类文件，被不同的加载器加载也会视为不同的类）等。 本机直接内存溢出 直接内存并不是虚拟机运行时数据区的一部分，也不是Java 虚拟机规范中定义的内存区域。在JDK1.4 中新加入了NIO(New Input/Output)类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 native 函数库直接分配堆外内存，然后通过一个存储在Java堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 特点 本机直接内存的分配不会受到Java 堆大小的限制，受到本机总内存大小限制 直接内存也可以由 -XX:MaxDirectMemorySize 指定 直接内存申请空间耗费更高的性能 直接内存IO读写的性能要优于普通的堆内存 当我们的需要频繁访问大的内存而不是申请和释放空间时，通过使用直接内存可以提高性能。 直接内存溢出测试，测试代码如下，运行时添加参数-Xmx20M -XX:MaxDirectMemorySize=10M 设置降低直接内存的空间来加快异常的抛出 测试代码： 12345678910111213141516171819/** * 本机直接内存溢出 * VM args:-Xmx20M -XX:MaxDirectMemorySize=10M * @author songsy * @date 2019/3/22 18:08 */public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125; 输出结果 123Exception in thread \"main\" java.lang.OutOfMemoryError at sun.misc.Unsafe.allocateMemory(Native Method) at com.songsy.DirectMemoryOOM.main(DirectMemoryOOM.java:22) 由DirectMemory导致的内存溢出，一个明显的特征就是再Heap Dump文件中不会看见明显的异常，如果读者发现OOM之后Dump文件很小，而程序中又直接或间接的使用了NIO，那就可以考虑检查一下是不是这方面的原因。 内存溢出及内存泄漏1、内存溢出 out of memory 是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出 1.1 方法区溢出 out of memory: PermGen space1.2 本机直接内存溢出2、内存泄露 memory leak 是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光 memory leak会最终会导致out of memory！ 内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。 内存泄漏是指你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。一个盘子用尽各种方法只能装4个果子，你装了5个，结果掉倒地上不能吃了。这就是溢出！比方说栈，栈满时再做进栈必定产生空间溢出，叫上溢，栈空时再做退栈也产生空间溢出，称为下溢。就是分配的内存不足以放下数据项序列,称为内存溢出. 从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终消耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到 3、引起内存溢出的原因 内存中加载的数据量过于庞大，如一次从数据库取出过多数据； 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收； 代码中存在死循环或循环产生过多重复的对象实体； 使用的第三方软件中的BUG； 启动参数内存值设定的过小； 4、内存溢出的解决方案 修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。) 检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。 对代码进行走查和分析，找出可能发生内存溢出的位置。 其他 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -Xmx3550m：设置JVM最大可用内存为3550M。 -Xms3550m：设置JVM初始内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xmn2g：设置年轻代大小为2G。整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -Xss128k： 设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内 存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/Sharley/p/5285045.html https://blog.csdn.net/u012552052/article/details/44204735 https://blog.csdn.net/sells2012/article/details/18656263","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(六)方法区","slug":"backend/java/jvm/JVM运行时数据区域(六)方法区","date":"2019-03-04T05:59:44.000Z","updated":"2020-03-16T11:43:55.505Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(六)方法区/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(六)方法区/","excerpt":"","text":"概述 方法区（Method Area）与Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java 堆区分开来。 对于习惯在HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot 虚拟机的设计团队选择把GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。对于其他虚拟机（如BEA JRockit、IBM J9 等）来说是不存在永久代的概念的。即使是HotSpot 虚拟机本身，根据官方发布的路线图信息，现在也有放弃永久代并“搬家”至Native Memory 来实现方法区的规划了。 Java 虚拟机规范对这个区域的限制非常宽松，除了和Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。在Sun 公司的BUG 列表中，曾出现过的若干个严重的BUG 就是由于低版本的HotSpot 虚拟机对此区域未完全回收而导致内存泄漏。根据Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError 异常。 运行时常量池 Class 文件中除了有类的版本、字段、方法、接口等描述等信息外，还有一项信息是常量池（Constant PoolTable），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 JDK1.7之前运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分；JDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 Java 虚拟机对Class 文件的每一部分（自然也包括常量池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会被虚拟机认可、装载和执行。但对于运行时常量池，Java 虚拟机规范没有做任何细节的要求，不同的提供商实现的虚拟机可以按照自己的需要来实现这个内存区域。不过，一般来说，除了保存Class 文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。 运行时常量池相对于Class 文件常量池的另外一个重要特征是具备动态性，Java 语言并不要求常量一定只能在编译期产生，也就是并非预置入Class 文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String 类的intern() 方法。 既然运行时常量池是方法区的一部分，自然会受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError 异常 1. String 类和常量池 直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用。 尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。 12345678910111213141516171819202122232425262728// 第一种方式是在常量池中拿对象String str1 = \"abcd\";// 第二种方式是直接在堆内存空间创建一个新的对象。 String str2 = new String(\"abcd\");System.out.println(str1==str2);//false``` * 记住一点：只要使用 new 方法，便需要创建新的对象。* 再给大家一个图应该更容易理解，图片来源：https://www.journaldev.com/797/what-is-java-string-pool：![](/images/server/java/JVM/heap/2019-3String-Pool-Java1-450x249.png)#### 2. 8种基本类型的包装类和常量池* Java 基本类型的包装类的大部分都实现了常量池技术，即Byte,Short,Integer,Long,Character,Boolean；这5种包装类默认创建了数值[-128，127]的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。* 两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。```javaInteger i1 = 33;Integer i2 = 33;System.out.println(i1 == i2);// 输出trueInteger i11 = 333;Integer i22 = 333;System.out.println(i11 == i22);// 输出falseDouble i3 = 1.2;Double i4 = 1.2;System.out.println(i3 == i4);// 输出false 备注 《Java虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 方法区和永久代的关系很像Java中接口和类的关系，类实现了接口，而永久代就是HotSpot虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是HotSpot的概念，方法区是Java虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久带这一说法。 JDK 1.8 的时候，方法区（HotSpot的永久代）被彻底移除了（JDK1.7就已经开始了），取而代之是元空间，元空间使用的是直接内存。 整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。 当你元空间溢出时会得到如下错误： java.lang.OutOfMemoryError: MetaSpace JDK1.7 就开始“去永久代”的工作了。 1.7把字符串常量池从永久代中剥离出来，存放在堆空间中。 参考转载 周志明版 《深入理解Java虚拟机》","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(五)堆","slug":"backend/java/jvm/JVM运行时数据区域(五)堆","date":"2019-03-04T04:59:44.000Z","updated":"2020-03-16T11:43:55.502Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(五)堆/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(五)堆/","excerpt":"","text":"概述 对于大多数应用来说，Java 堆（Java Heap）是Java 虚拟机所管理的内存中最大的一块，Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。这一点在Java 虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配①，但是随着JIT 编译器的发展与逃逸分析技术的逐渐成熟，栈上分配、标量替换②优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。 Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”（GarbageCollected Heap，幸好国内没翻译成“垃圾堆”）。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代；再细致一点的有Eden 空间、From Survivor 空间、To Survivor 空间等。如果从内存分配的角度看，线程共享的Java 堆中可能划分出多个线程私有的分配缓冲区（Thread LocalAllocation Buffer，TLAB）。不过，无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好地回收内存，或者更快地分配内存。 根据Java 虚拟机规范的规定，Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms 控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。 解析 所有通过new创建的对象的内存都在堆中分配，堆被划分为新生代和老年代和永久代，但不同的JDK版本又是不一样的 在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 永生代(Permanent Generation) JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 1. 新生代 新创建的对象都是用新生代分配内存 新生代又被进一步划分为Eden和Survivor区，Eden空间不足时，触发Minor GC，这时会把存活的对象转移进Survivor区，而Survivor由FromSpace和ToSpace组成。 Eden区：Java新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老年代）。当Eden区内存不够的时候就会触发MinorGC，对新生代区进行一次垃圾回收。 ServivorFrom：上一次GC的幸存者，作为这一次GC的被扫描者。 ServivorTo：保留了一次MinorGC过程中的幸存者。 MinorGC采用复制算法，MinorGC的过程： 首先，把Eden和ServivorFrom区域中存活的对象复制到ServicorTo区域（如果有对象的年龄以及达到了老年的标准,默认为 15 岁，则赋值到老年代区），同时把这些对象的年龄+1（如果ServicorTo不够位置了就放到老年区）； 然后，清空Eden和ServicorFrom中的对象； 最后，ServicorTo和ServicorFrom互换，原ServicorTo成为下一次GC时的ServicorFrom区。 新生代分为Eden、FromSpace、ToSpace是为了尽量让对象在新生代MinorGC，如果到了老年代之后MajorGC执行时间长 2. 老年代 老年代用于存放经过多次Minor GC之后依然存活的对象。 老年代的对象比较稳定，所以MajorGC不会频繁执行。在进行MajorGC前一般都先进行了一次MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。 MajorGC采用标记—清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。MajorGC的耗时比较长，因为要扫描再回收。MajorGC会产生内存碎片，为了减少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。 当老年代也满了装不下的时候，就会抛出OOM（Out of Memory）异常。 3. 永久代 指内存的永久保存区域，主要存放Class和Meta（元数据）的信息,Class在被加载的时候被放入永久区域. 它和和存放实例的区域不同,GC不会在主程序运行期对永久区域进行清理。所以这也导致了永久代的区域会随着加载的Class的增多而胀满，最终抛出OOM异常。 在Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 native memory, 字符串池和类的静态变量放入java堆中. 这样可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制. 采用元空间而不用永久代的几点原因： 1、为了解决永久代的OOM问题，元数据和class对象存在永久代中，容易出现性能问题和内存溢出。 2、类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出（因为堆空间有限，此消彼长）。 3、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。 4、Oracle 可能会将HotSpot 与 JRockit 合二为一。 -Xmx20M -XX:MaxHeapSize简写，表示设置堆容量的最大值为20M，必须以M为单位。将-Xmx和-Xms设置为一样可以避免堆自动扩展，减少程序运行时的垃圾回收次数，从而提供性能。大的项目-Xmx和-Xms一般都要设置到10G、20G甚至还要高 总结 Minor GC 和 Full GC 有什么不同 新生代 GC（Minor GC）:指发生新生代的的垃圾收集动作，Minor GC 非常频繁，回收速度一般也比较快。 老年代 GC（Major GC/Full GC）:指发生在老年代的 GC，出现了 Major GC 经常会伴随至少一次的 Minor GC（并非绝对），Major GC 的速度一般会比 Minor GC 的慢 10 倍以上。 #### 参考转载 周志明版 《深入理解Java虚拟机》 https://www.cnblogs.com/Sharley/p/5285045.html https://www.cnblogs.com/ygj0930/p/6522828.html https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java内存区域","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(四)本地方法栈","slug":"backend/java/jvm/JVM运行时数据区域(四)本地方法栈","date":"2019-03-04T03:59:44.000Z","updated":"2020-03-16T11:43:55.507Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(四)本地方法栈/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(四)本地方法栈/","excerpt":"","text":"概述 本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 解析Native Method 简单地讲，一个Native Method就是一个java调用非java代码的接口。一个Native Method是这样一个java的方法：该方法的实现由非java语言实现，比如C。这个特征并非java所特有，很多其它的编程语言都有这一机制，比如在C＋＋中，你可以用extern “C”告知C＋＋编译器去调用一个C的函数 例如 Object.java 类下就有很多Native Method 1public final native Class&lt;?&gt; getClass(); 本地方法非常有用，因为它有效地扩充了jvm.事实上，我们所写的java代码已经用到了本地方法，在sun的java的并发（多线程）的机制实现中，许多与操作系统的接触点都用到了本地方法，这使得java程序能够超越java运行时的界限。有了本地方法，java程序可以做任何应用层次的任务。 为什么要使用Native Method 与java环境外交互：有时java应用需要与java外面的环境交互。这是本地方法存在的主要原因，你可以想想java需要与一些底层系统如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解java应用之外的繁琐的细节。 与操作系统交互：JVM支持着java语言本身和运行时库，它是java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎 样，它毕竟不是一个完整的系统，它经常依赖于一些底层（underneath在下面的）系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用C写的，还有，如果我们要使用一些java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。 Sun’s Java： Sun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用java实现的，它也通过一些本地方法与外界交互。例如：类java.lang.Thread 的 setPriority()方法是用java实现的，但是它实现调用的是该类里的本地方法setPriority0()。这个本地方法是用C实现的，并被植入JVM内部，在Windows 95的平台上，这个本地方法最终将调用Win32 SetPriority() API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被JVM调用。 栈溢出(StackOverflowError) 栈是线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口灯信息。局部变量表又包含基本数据类型，对象引用类型（局部变量表编译器完成，运行期间不会变化） 所以我们可以理解为栈溢出就是方法执行时创建的栈帧超过了栈的深度。那么最有可能的就是方法递归调用产生这种结果。 我们需要使用参数 -Xss 去调整JVM栈的大小 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/qq_28885149/article/details/52672475 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java内存区域","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(三)Java虚拟机栈","slug":"backend/java/jvm/JVM运行时数据区域(三)Java虚拟机栈","date":"2019-03-04T02:59:44.000Z","updated":"2020-03-16T11:43:55.495Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(三)Java虚拟机栈/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(三)Java虚拟机栈/","excerpt":"","text":"何为虚拟机栈 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存放局部变量表、操作数栈、动态链接、方法出口等信息，每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 与程序计数器一样，Java虚拟机栈也是线程私有的，他的生命周期与线程相同。 解析 执行引擎运行的所有字节码指令只针对当前栈帧进行操作，在概念模型上，典型的栈帧结构如图所示： 栈帧数据结构 每一个栈帧包含的内容有局部变量表、操作数栈、动态链接、方法返回地址和一些额外的附加信息。在编译代码时，栈帧需要多大的局部变量表，多深的操作数栈都可以完全确定的，并写入到方法表的code属性中 我们先来理解一下虚拟机是如何执行一个方法的，这样我们才能理解为什么栈帧需要这些部分，这些部分分别提供了什么功能。首先我们的方法被编译成了字节码，并生成了可执行的命令。通过程序计数器，虚拟机会一行一行的执行命令，直到进入一个新的方法入口，对应虚拟机栈也就是新的栈帧入栈，当前栈帧改变，又或者遇到返回指令或出现异常结束了方法，对应虚拟机也就是出栈。 1、局部变量表 是一片逻辑连续的内存空间，最小单位是Slot，用来存放方法参数和方法内部定义的局部变量 局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。 2、操作数栈 每个栈帧都包含一个被叫做操作数栈的后进先出的栈。叫操作栈，或者操作数栈。 栈桢刚创建时，里面的操作数栈是空的。 Java虚拟机提供指令来让操作数栈对一些数据进行入栈操作，比如可以把局部变量表里的数据、实例的字段等数据入栈。 同时也有指令来支持出栈操作。 向其他方法传参的参数，也存在操作数栈中。 其他方法返回的结果，返回时存在操作数栈中。 3、动态链接 一个方法调用另一个方法，或者一个类使用另一个类的成员变量时，总得知道被调用者的名字吧？(你可以不认识它本身，但调用它就需要知道他的名字)。符号引用就相当于名字，这些被调用者的名字就存放在Java字节码文件里。名字是知道了，但是Java真正运行起来的时候，真的能靠这个名字（符号引用）就能找到相应的类和方法吗？需要解析成相应的直接引用，利用直接引用来准确地找到。 举个例子，就相当于我在0X0300H这个地址存入了一个数526，为了方便编程，我把这个给这个地址起了个别名叫A, 以后我编程的时候(运行之前)可以用别名A来暗示访问这个空间的数据，但其实程序运行起来后，实质上还是去寻找0X0300H这片空间来获取526这个数据的。 这样的符号引用和直接引用在运行时进行解析和链接的过程，叫动态链接。 4、方法返回地址 返回一个值给调用它的方法，方法正常完成发生在一个方法执行过程 中遇到了方法返回的字节码指令（§2.11.8）的时候，使用哪种返回指令取决于方法返回值的数 据类型（如果有返回值的话）。 5、附加信息其他 Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。 总结 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。 Java 方法有两种返回方式： return 语句。 抛出异常。 不管哪种返回方式都会导致栈帧被弹出。 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/ychenfeng/article/details/77247807 https://blog.csdn.net/u014296316/article/details/82668670 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java内存区域","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(二)程序计数器","slug":"backend/java/jvm/JVM运行时数据区域(二)程序计数器","date":"2019-03-04T01:59:44.000Z","updated":"2020-03-16T11:43:55.498Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(二)程序计数器/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(二)程序计数器/","excerpt":"","text":"概述程序计数器是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器，在虚拟机的概念模型里（仅仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时，就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳准、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 特点 线程私有的 是java虚拟机规范里面， 唯一 一个 没有规定任何 OutOfMemoryError 情况的区域 生命周期随着线程，线程启动而产生，线程结束而消亡 作用 程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 解析 程序计数器，可以看做是当前线程执行的字节码的 行号指示器 ，这句话；要理解这句话，需要先知道字节码文件长什么样子，看下面的代码 12345678// java 文件被翻译为字节码的时候，字节码大概类似于下面的样子public void haha()&#123;// 原来的 haha 方法内部的 java 代码，被翻译为下面的类似于汇编语言的指令 0 xxxx .... 2 xxxx .... 4 xx ... 5 xxx ...&#125; 上面左边的 0、2、4、5 ，就是类似于字节码的行号（实际是指令的偏移地址），程序计数器中保存中的值，就是它们；字节码解释器，就是根据它们，来执行程序的 理解了程序计数器，就好理解它的这些特点了；我们都知道，Java是支持多线程的，当CPU执行权从 A 线程，转移到 B 线程的时候，JVM就要暂时挂起线程 A ，去执行线程 B ；当线程 A 再次得到CPU执行权的时候，又会挂起B线程，继续执行 A 线程 ； 我们想象下，CPU是怎么知道记住之前A线程，执行到哪一处的？ 答案是，CPU根本就不会记住之前执行到哪里了，它只是埋头苦干；那是什么保证了切换线程的程序可以正常执行的；答案是 ： 程序计数器 ；程序计数器里面保存的是 当前线程执行的字节码的行号（看着像行号，其实是指令地址）； 那么，我们需要几个程序计数器呢？如果，我们只有一个的话，切换B线程以后，程序计数器里面保存的就是B线程所执行的字节码的行号了，再切换回A线程，就蒙圈了，不知道执行到哪里了，因为，程序计数器里面保存的是B线程当前执行的字节码地址 ；因此，我们可以想象出，要为每个线程都分配一个程序计数器，因此，程序计数器的内存空间是线程私有的 ；这样即使线程 A 被挂起，但是线程 A 里面的程序计数器，记住了A线程当前执行到的字节码的指令地址了 ，等再次切回到A线程的时候，看一下程序计数器，就知道之前执行到哪里了！ 那么程序计数器，什么时候分配内存呢？我们试想下，一个线程在执行的任何期间，都会失去CPU执行权，因此，我们要从一个线程被创建开始执行，就要无时无刻的记录着该线程当前执行到哪里了！因此，线程计数器，必须是线程被创建开始执行的时候，就要一同被创建； 程序计数器，保存的是当前执行的字节码的偏移地址（也就是之前说的行号，其实那不是行号，是指令的偏移地址，只是为了好理解，才说是行号的，），当执行到下一条指令的时候，改变的只是程序计数器中保存的地址，并不需要申请新的内存来保存新的指令地址；因此，永远都不可能内存溢出的；因此，jvm虚拟机规范，也就没有规定，也是唯一一个没有规定 OutOfMemoryError 异常 的区域； 当线程执行的是本地方法的时候，程序计数器中保存的值是空（undefined）；原因很简单：本地方法是C++/C 写的，由系统调用，根本不会产生字节码文件，因此，程序计数器也就不会做任何记录 ； 参考转载 周志明版 《深入理解Java虚拟机》 https://blog.csdn.net/youngyouth/article/details/79868299 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java内存区域","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"JVM运行时数据区域(一)介绍","slug":"backend/java/jvm/JVM运行时数据区域(一)介绍","date":"2019-03-04T00:59:44.000Z","updated":"2020-03-16T11:43:55.490Z","comments":true,"path":"2019/03/04/backend/java/jvm/JVM运行时数据区域(一)介绍/","link":"","permalink":"http://www.songshuiyang.com/2019/03/04/backend/java/jvm/JVM运行时数据区域(一)介绍/","excerpt":"","text":"前言 对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像 C/C++程序开发程序员这样为每一个 new 操作去写对应的 delete/free 操作，对象的销毁都是由JVM来完成的，这样的话对于开发者而言可以减少开发，但是作为开发者还是要对这一块有一定的了解，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。 Java虚拟机在执行Java程序的过程中会将其管理的内存划分为若干个不同的数据区域，这些区域有各自的用途、创建和销毁的时间，有些区域随虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束来建立和销毁。Java虚拟机所管理的内存包括以下几个运行时数据区域，如图 1.7版本 Java 虚拟机的内存结构分为两部分 线程共享的（数据） 方法区 Java 堆 直接内存(非运行时数据区的一部分) 线程私有的（指令） 虚拟机栈 本地方法栈 程序计数器 1.8版本 1.8同1.7比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。 运行时数据区域 程序计数器：指向当前线程正在执行的字节码指令。线程私有的。 虚拟机栈：虚拟机栈是Java执行方法的内存模型。每个方法被执行的时候，都会创建一个栈帧，把栈帧压人栈，当方法正常返回或者抛出未捕获的异常时，栈帧就会出栈 本地方法栈：调用本地native的内存模型 方法区：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据 堆（Heap）：Java对象存储的地方 参考转载 周志明版 《深入理解Java虚拟机》 https://segmentfault.com/a/1190000014395186 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java内存区域","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.songshuiyang.com/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://www.songshuiyang.com/tags/Jvm/"}]},{"title":"Mybatis源码(二十二)使用拦截器Interceptor完成分页","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十二)使用拦截器Interceptor完成分页","date":"2018-12-22T12:56:00.000Z","updated":"2019-12-05T12:19:35.204Z","comments":true,"path":"2018/12/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十二)使用拦截器Interceptor完成分页/","link":"","permalink":"http://www.songshuiyang.com/2018/12/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十二)使用拦截器Interceptor完成分页/","excerpt":"","text":"前言只要有列表就会有分页功能，利用Mybatis拦截器Interceptor可以十分方便的完成分页功能 思路在执行查询sql之前的时候只要添加limit关键字，即可完成分页，除了分页之外需要count(*)获取数据总数，然后通过页码得到页数 实现 Page.java 分页对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class Page&lt;T&gt; &#123; private int end; // 当前页尾条记录位置 private int limit; // 每页记录数 private int page; // 当前页 private long total; // 总记录数 private String sortName; // 排序列 private String sortOrder; // 排序方式 private Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); // 请求参数 private List&lt;String&gt; columns = Lists.newArrayList(); // 查询出来的参数 private List&lt;T&gt; rows = new ArrayList&lt;&gt;(); // 记录 /** * 限制分页长度 * limit：0 不限制大小 * @param limit */ public Page(int limit) &#123; this.limit = limit; &#125; public Page(HttpServletRequest request) &#123; String param = null; String value = null; param = \"pageIndex\"; value = request.getParameter(param); if (value != null &amp;&amp; value.length() &gt; 0) &#123; this.page = Integer.parseInt(value); &#125; else &#123; this.page = 1; &#125; param = \"limit\"; value = request.getParameter(param); if (value != null &amp;&amp; value.length() &gt; 0) &#123; this.limit = Integer.parseInt(value); if (this.limit &gt; 15) &#123; this.limit = 15; &#125; &#125; else &#123; this.limit = 15; &#125; param = \"sortName\"; value = request.getParameter(param); if (value != null &amp;&amp; value.length() &gt; 0) &#123; this.sortName = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, value); &#125; param = \"sortOrder\"; value = request.getParameter(param); if (value != null &amp;&amp; value.length() &gt; 0) &#123; this.sortOrder = value; &#125; else &#123; this.sortOrder = \"asc\"; &#125; Map&lt;String, String[]&gt; paramMap = request.getParameterMap(); for (String key : paramMap.keySet()) &#123; if (key.startsWith(\"s_\")) &#123; String vkey = key.substring(2); String[] _params = paramMap.get(key); if (_params.length &gt; 0 &amp;&amp; StringUtils.isNotEmpty(_params[0])) &#123; getParams().put(vkey, StringUtils.join(_params, \"&gt;\").trim()); &#125; &#125; &#125; &#125; /** * 当前页首条记录位置 * * @return */ public int getStart() &#123; if (page == 0) &#123; return 0; &#125; return (page - 1) * limit; &#125; /** * 总页数 * * @return */ public int getTotalPage() &#123; if (limit == 0) &#123; return 0; &#125; return (int) Math.ceil(total / Double.valueOf(limit)); &#125; /** * 必须和数据库字段一致 * * @param sortName */ public void setSortName(String sortName) &#123; this.sortName = sortName; &#125; /** * 设置默认排序方式 * * @param sortName 需要排序的表字段，数据库字段 * @param sortOrder */ public void sortDefault(String sortName, String sortOrder) &#123; if (org.apache.commons.lang3.StringUtils.isEmpty(getSortName()) || org.apache.commons.lang3.StringUtils.isEmpty(getSortOrder())) &#123; setSortName(sortName); setSortOrder(sortOrder); &#125; &#125; public String getSortName() &#123; return sortName; &#125; public String getSortOrder() &#123; return sortOrder; &#125; public void setSortOrder(String sortOrder) &#123; this.sortOrder = sortOrder; &#125; public Map&lt;String, Object&gt; getParams() &#123; return params; &#125; public void setParams(Map&lt;String, Object&gt; params) &#123; this.params = params; &#125; public void setParams(String key, Object value) &#123; Assert.notNull(key, \"key must be not null\"); Assert.notNull(value, \"value must be not null \"); this.params.put(key, value); &#125; public List&lt;T&gt; getRows() &#123; return rows; &#125; public void setRows(List&lt;T&gt; rows) &#123; this.rows = rows; &#125; public List&lt;String&gt; getColumns() &#123; return columns; &#125; public void setColumns(List&lt;String&gt; columns) &#123; this.columns = columns; &#125; public int getEnd() &#123; return end; &#125; public void setEnd(int end) &#123; this.end = end; &#125; public int getLimit() &#123; return limit; &#125; public void setLimit(int limit) &#123; this.limit = limit; &#125; public int getPage() &#123; return page; &#125; public void setPage(int page) &#123; this.page = page; &#125; public long getTotal() &#123; return total; &#125; public void setTotal(long total) &#123; this.total = total; &#125;&#125; PageInterceptor.java 拦截器，此类intercept 方法是完成分页实现方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233/** * mybatis拦截器，实现接口分页，拦截Executor接口的query方法 */@Component@Intercepts(&#123; @Signature(type = Executor.class, method = \"query\", args = &#123; MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class &#125;) &#125;)public class PageInterceptor implements Interceptor &#123; private static Logger logger = LoggerFactory.getLogger(PageInterceptor.class); static int MAPPED_STATEMENT_INDEX = 0; static int PARAMETER_INDEX = 1; static int ROWBOUNDS_INDEX = 2; static int RESULT_HANDLER_INDEX = 3; // 需要拦截的ID(正则匹配) private static final String DEFAULT_PAGE_SQL_ID = \".*Page$\"; /** * setProperties方法是用于在Mybatis配置文件中指定一些属性的。 * @param properties */ @Override public void setProperties(Properties properties) &#123; &#125; /** * 拦截器用于封装目标对象 * 在plugin方法中我们可以决定是否要进行拦截进而决定要返回一个什么样的目标对象 * @param o * @return */ @Override public Object plugin(Object o) &#123; if (Executor.class.isAssignableFrom(o.getClass())) &#123; // 在这里返回新的 PageExecutor，用于装饰原Executor return Plugin.wrap(new PageExecutor((Executor) o), this); &#125; return Plugin.wrap(o, this); &#125; /** * 在这里完成分页及排序操作得到 新的BoundSql 然后执行查询 * @param invocation * @return * @throws Throwable */ @Override public Object intercept(Invocation invocation) throws Throwable &#123; final Object[] queryArgs = invocation.getArgs(); // MappedStatement对象对应Mapper配置文件中的一个select/update/insert/delete节点，主要描述的是一条SQL语句 final MappedStatement mappedStatement = (MappedStatement) queryArgs[MAPPED_STATEMENT_INDEX]; // 获取查询参数 final Object parameterObject = queryArgs[PARAMETER_INDEX]; BoundSql boundSql = mappedStatement.getBoundSql(parameterObject); // 拦截以Page结尾的查询方法 if (mappedStatement.getId().matches(DEFAULT_PAGE_SQL_ID)) &#123; if (parameterObject == null) &#123; throw new NullPointerException(\"parameterObject is null!\"); &#125; else &#123; // 如果查询参数是Page对象 if (parameterObject instanceof Page&lt;?&gt;) &#123; Page&lt;?&gt; page = (Page&lt;?&gt;) parameterObject; // 执行总记录数查询 setTotalRecord(page, mappedStatement, boundSql); // 拼接排序sql String orderSql = getOrderSql(boundSql.getSql(), page); // 拼接分页sql String pageSql = getPageSql(orderSql, page); logger.debug(\"page sql : &#123;&#125; \", pageSql); BoundSql newBoundSql = copyFromBoundSql(mappedStatement, boundSql, pageSql); MappedStatement newMappedStatement = copyFromMappedStatement(mappedStatement, new BoundSqlSqlSource(newBoundSql)); queryArgs[ROWBOUNDS_INDEX] = new RowBounds(RowBounds.NO_ROW_OFFSET, RowBounds.NO_ROW_LIMIT); queryArgs[MAPPED_STATEMENT_INDEX] = newMappedStatement; &#125; &#125; &#125; return invocation.proceed(); &#125; /** * 得到新的 BoundSql * @param ms * @param boundSql * @param sql * @return */ public static BoundSql copyFromBoundSql(MappedStatement ms, BoundSql boundSql, String sql) &#123; BoundSql newBoundSql = new BoundSql(ms.getConfiguration(), sql, boundSql.getParameterMappings(), boundSql.getParameterObject()); for (ParameterMapping mapping : boundSql.getParameterMappings()) &#123; String prop = mapping.getProperty(); if (boundSql.hasAdditionalParameter(prop)) &#123; newBoundSql.setAdditionalParameter(prop, boundSql.getAdditionalParameter(prop)); &#125; &#125; return newBoundSql; &#125; /** * 得到新的 MappedStatement * @param ms * @param newSqlSource * @return */ private static MappedStatement copyFromMappedStatement(MappedStatement ms, SqlSource newSqlSource) &#123; MappedStatement.Builder builder = new MappedStatement.Builder(ms.getConfiguration(), ms.getId(), newSqlSource, ms.getSqlCommandType()); builder.resource(ms.getResource()); builder.fetchSize(ms.getFetchSize()); builder.statementType(ms.getStatementType()); builder.keyGenerator(ms.getKeyGenerator()); String[] keyProperties = ms.getKeyProperties(); builder.keyProperty(keyProperties == null ? null : keyProperties[0]); builder.timeout(ms.getTimeout()); builder.parameterMap(ms.getParameterMap()); builder.resultMaps(ms.getResultMaps()); builder.resultSetType(ms.getResultSetType()); builder.cache(ms.getCache()); builder.flushCacheRequired(ms.isFlushCacheRequired()); builder.useCache(ms.isUseCache()); return builder.build(); &#125; public static class BoundSqlSqlSource implements SqlSource &#123; BoundSql boundSql; public BoundSqlSqlSource(BoundSql boundSql) &#123; this.boundSql = boundSql; &#125; public BoundSql getBoundSql(Object parameterObject) &#123; return boundSql; &#125; &#125; /** * 查询数据总数 * @param page * @param mappedStatement * @param boundSql */ private void setTotalRecord(Page&lt;?&gt; page, MappedStatement mappedStatement, BoundSql boundSql) throws Throwable &#123; String sql = getCountSql(boundSql.getSql()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); BoundSql countBoundSql = new BoundSql(mappedStatement.getConfiguration(), sql, parameterMappings, page); ParameterHandler parameterHandler = new DefaultParameterHandler(mappedStatement, page, countBoundSql); Connection con = mappedStatement.getConfiguration().getEnvironment().getDataSource().getConnection(); PreparedStatement stmt = null; ResultSet rs = null; try &#123; int total = 0; stmt = con.prepareStatement(sql); parameterHandler.setParameters(stmt); rs = stmt.executeQuery(); if (rs.next()) &#123; total = rs.getInt(1); &#125; page.setTotal(total); logger.debug(\"page count sql : &#123;&#125;\", sql); logger.debug(\"page count total : &#123;&#125;\", total); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; JdbcUtils.close(rs, stmt); JdbcUtils.close(con); &#125; &#125; /** * 得到统计总数sql * @param sql * @return */ private String getCountSql(String sql) &#123; int index = sql.indexOf(\"from\") == -1 ? sql.indexOf(\"FROM\") : sql.indexOf(\"from\"); return \"select count(*) \" + sql.substring(index); &#125; /** * 得到分页sql * @param sql * @param page * @return */ private String getPageSql(String sql, Page&lt;?&gt; page) &#123; if (page != null &amp;&amp; page.getLimit() &gt; 0) &#123; StringBuilder pageSql = getMySQLPageSql(sql, page); return pageSql.toString(); &#125; else &#123; return sql; &#125; &#125; /** * 得到排序sql * @param sql * @param page * @return */ private String getOrderSql(String sql, Page&lt;?&gt; page) &#123; if (org.apache.commons.lang3.StringUtils.isNotEmpty(page.getSortName())) &#123; StringBuilder pageSql = new StringBuilder(100); pageSql.append(sql); if ((page.getSortName().indexOf(\"_\") == -1)) &#123; page.setSortName(CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, page.getSortName())); &#125; if ((\"asc\".equalsIgnoreCase(page.getSortOrder()) || \"desc\".equalsIgnoreCase(page.getSortOrder()))) &#123; pageSql.append(\" order by \" + page.getSortName() + \" \" + page.getSortOrder()); &#125; return pageSql.toString(); &#125; else &#123; return sql; &#125; &#125; /** * 得到mysql 分页语句 * @param sql * @param page * @return */ public StringBuilder getMySQLPageSql(String sql, Page page) &#123; StringBuilder pageSql = new StringBuilder(100); pageSql.append(sql); pageSql.append(\" limit \" + page.getStart() + \",\" + page.getLimit()); return pageSql; &#125;&#125; PageExecutor.java 用于装饰之前的Executor用于将结果赋值到Page对象的rows属性中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112public class PageExecutor implements Executor &#123; private static Logger logger = LoggerFactory.getLogger(PageExecutor.class); private final Executor executor; public PageExecutor(Executor executor) &#123; this.executor = executor; &#125; @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey cacheKey, BoundSql boundSql) throws SQLException &#123; final List&lt;E&gt; rows = executor.query(ms, parameter, rowBounds, resultHandler); if (parameter != null &amp;&amp; parameter instanceof Page&lt;?&gt;) &#123; Page&lt;E&gt; page = (Page&lt;E&gt;) parameter; doCache(ms, page, parameter, rowBounds); // 将结果赋值到Page对象的rows属性 page.setRows(rows); &#125; return rows; &#125; @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; final List&lt;E&gt; rows = executor.query(ms, parameter, rowBounds, resultHandler); if (parameter != null &amp;&amp; parameter instanceof Page&lt;?&gt;) &#123; Page&lt;E&gt; page = (Page&lt;E&gt;) parameter; doCache(ms, page, parameter, rowBounds); // 将结果赋值到Page对象的rows属性 page.setRows(rows); &#125; return rows; &#125; private &lt;E&gt; void doCache(MappedStatement ms, Page&lt;E&gt; result, Object parameter, RowBounds rowBounds) &#123; final Cache cache = ms.getCache(); if (executor.getClass().isAssignableFrom(CachingExecutor.class) &amp;&amp; cache != null) &#123; BoundSql boundSql = ms.getBoundSql(parameter); final CacheKey cacheKey = createCacheKey(ms, parameter, rowBounds, boundSql); if (logger.isDebugEnabled()) &#123; logger.debug(\"cache executor the cache's kye is \" + cacheKey); &#125; cache.putObject(cacheKey, result); &#125; &#125; @Override public void setExecutorWrapper(Executor executor) &#123; executor.setExecutorWrapper(executor); &#125; @Override public int update(MappedStatement ms, Object parameter) throws SQLException &#123; return executor.update(ms, parameter); &#125; @Override public List&lt;BatchResult&gt; flushStatements() throws SQLException &#123; return executor.flushStatements(); &#125; @Override public void commit(boolean required) throws SQLException &#123; executor.commit(required); &#125; @Override public void rollback(boolean required) throws SQLException &#123; executor.rollback(required); &#125; @Override public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; return executor.createCacheKey(ms, parameterObject, rowBounds, boundSql); &#125; @Override public boolean isCached(MappedStatement ms, CacheKey key) &#123; return executor.isCached(ms, key); &#125; @Override public void clearLocalCache() &#123; executor.clearLocalCache(); &#125; @Override public void deferLoad(MappedStatement mappedStatement, MetaObject metaObject, String s, CacheKey cacheKey, Class&lt;?&gt; aClass) &#123; executor.deferLoad(mappedStatement, metaObject, s, cacheKey, aClass); &#125; @Override public Transaction getTransaction() &#123; return executor.getTransaction(); &#125; @Override public void close(boolean forceRollback) &#123; executor.close(forceRollback); &#125; @Override public boolean isClosed() &#123; return executor.isClosed(); &#125; @Override public &lt;E&gt; Cursor&lt;E&gt; queryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125;&#125;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis通用增删改查实现","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十四)通用增删改查实现","date":"2018-12-22T10:13:00.000Z","updated":"2019-09-16T13:11:04.581Z","comments":true,"path":"2018/12/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十四)通用增删改查实现/","link":"","permalink":"http://www.songshuiyang.com/2018/12/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十四)通用增删改查实现/","excerpt":"","text":"iframe 一个基于Mybtais的通用增删改查功能的工具包，mapper接口只要继承相应的接口，实体类添加几个注解即可面向对象操作数据 iframe 基于Spring boot, Gradle, mybatis3实现，代码已通过测试 代码： https://github.com/songshuiyang/iframe 为什么有这个开发需求： 1、在实际整合了Mybatis的项目开发过程中经常会遇到变更数据库字段的情况，如果表结构发生了变化就需要重新修改mapper对应的xml文件，每次修改都要同步更新xml文件。 2、在普通的mapper接口中发现普通的增删改查这些方法每一个mapper接口都有，通过对比可以发现方法除了实体类属性不一样之外，其他的都一样(如下所示)，而且mapper文件也有大量增删改查的sql1234567891011int deleteByPrimaryKey(E id);int insert(T record);int insertSelective(T record);T selectByPrimaryKey(E id);int updateByPrimaryKeySelective(T record);int updateByPrimaryKey(T id); Mybatis 和 Hibernate 优缺点对比 现在开源项目中持久层框架用到最多的基本就是 MyBatis 和 Hibernate Mybatis优点 Mybatis入门简单，即学即用，提供了数据库查询的自动对象绑定功能，而且延续了很好的SQL使用经验 可以进行更为细致的SQL优化，可以减少查询字段缺点 虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。 Hibernate优点 不需要编写的SQL语句(不需要编辑JDBC)，只需要操作相应的对象就可以了，就可以能够存储、更新、删除、加载对象，可以提高生产效率 使用Hibernate，移植性好缺点 由于对持久层封装过于完整，导致开发人员无法对SQL进行优化，无法灵活使用JDBC的原生SQL，Hibernate封装了JDBC，所以没有JDBC直接访问数据库效率高。要使用数据库的特定优化机制的时候，不适合用Hibernate 开发目的对比Mybatis 和 Hibernate 优缺点，可以发现他们之间的优缺点可以互补，为何不取其精华, 去其糟粕, 双剑合并呢, 所以初步想法是在Mybatis的基础框架上, 扩展一下其面向对象操作的功能。 使用方法准备 在自己的项目中导入 com.songsy.iframe.core.persistence.provider 包下的所有文件。 默认数据库各张表都有如下字段, 如果不符合项目需要即可修改对应的源码 1234567`created_date` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',`created_by` varchar(32) DEFAULT NULL COMMENT '创建人',`last_modified_date` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',`last_modified_by` varchar(32) DEFAULT NULL COMMENT '最后修改人',`version` bigint(20) DEFAULT NULL COMMENT '版本',`remarks` varchar(255) DEFAULT NULL COMMENT '备注',`enable` bit(1) DEFAULT b'1' COMMENT '是否启用', mybatis版本在3.0以上，需要使用其新特性 使用 实体类继承BaseEntity.class类获得公共属性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * 实体类基类 * @author songshuiyang * @date 2018/10/28 10:13 */@Getter@Setterpublic class BaseEntity&lt;ID&gt; implements Serializable &#123; private static final long serialVersionUID = -3873745966284869947L; /** * 主键 */ @Id(type = Integer.class) @GeneratedValue(strategy = GenerationType.CUSTOM) private ID id; /** * 创建人 */ private String createdBy; /** * 创建时间 */ private Date createdDate; /** * 最后修改人 */ private String lastModifiedBy; /** * 最后修改时间 */ private Date lastModifiedDate; /** * 备注 */ private String remarks; /** * 乐观锁字段 */ @Version private Long version; /** * 逻辑删除标识 */ @Deleted private boolean enable = true; @Override public int hashCode() &#123; return this.id != null ? this.id.hashCode() : null; &#125; @Override public boolean equals(Object obj) &#123; if (!(obj instanceof BaseEntity)) &#123; return false; &#125; BaseEntity i = (BaseEntity) obj; if (i.getId() == null || this.getId() == null) &#123; return false; &#125; if (this.getId().equals(i.getId())) &#123; return true; &#125; return false; &#125;&#125; 实体类加上对应的注解 1234567891011121314151617181920212223242526272829303132/** * 用户 * @author songshuiyang * @date 2017/11/28 21:36 */@Data@Entity@Table(name = \"sys_user\")@EqualsAndHashCode(callSuper = false)public class User extends BaseEntity&lt;Integer&gt; &#123; private String username; private String password; private String nickname; private Integer sex; private Integer age; private String phone; private String email; private String address; private String salt; @Column(name = \"head_portrait\") private String headPortrait;&#125; 注解是参照Jpa的注解来定制的，详情可见com.songsy.iframe.core.persistence.provider.annotation 注解 作用 @Entity 修饰实体类，指明该类将映射到指定的数据表 @Table 当实体类与映射的数据库表名不同名时需要使用 @Table 注解，该注解与 @Entity 注解并列使用，使用其 name 属性指明数据库的表名, 不填写name属性则默认是类名的转化成_格式的表名 @Column 当实体类属性名与数据库字段名不一致时, 可用该注解标识实体类对应在数据库的字段名 @Id 标识该属性为主键 @GeneratedValue 标注主键的生成策略，通过其 strategy 属性标识生成策略 @Transient 标注此注解后在操作数据表的时候将会忽略该属性 @Version 标识乐观锁字段 @Deleted 逻辑删除标识 mapper接口继承BaseCurdMapper.java ，Mapper层增加其通用增删改查方法, &lt;User,Integer&gt;：第一个是实体类类型，第二个标识主键类型12345678/** * 用户 * @author songshuiyang * @date 2017/11/28 20:12 */public interface UserMapper extends BaseCurdMapper&lt;User,Integer&gt; &#123;&#125; 增加的方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 查询所有数据 * @return */List&lt;T&gt; findAll();/** * 根据id查询记录 * @return */T findById(Object id);/** * 插入记录 * @param entity * @return */int insert(T entity);/** * 更新记录 * @param entity * @return */int update(T entity);/** * 更新记录(null值记录也更新) * @param entity * @return */int updateNull(T entity);/** * 根据id物理删除记录 * @param id * @return */int deleteOne (Object id);/** * 根据id逻辑删除记录 * @param id * @return */int logicDeleteOne (Object id); service接口继承BaseService.java ，Service层增加其通用增删改查方法1234567/** * @author songshuiyang * @date 2018/10/28 10:13 */public interface UserService extends BaseService&lt;User, Integer&gt; &#123;&#125; 增加的方法：1234567891011121314151617181920/** * @author songsy * @Date 2018/10/31 18:06 */public interface BaseService &lt;T extends BaseEntity, ID extends Serializable&gt;&#123; List&lt;T&gt; findAll(); T findById(ID id); T saveSelective(T entity); T saveSelective(T entity, Boolean hasId); int updateNull(T entity); int deleteOne (ID id); int logicDeleteOne (ID id);&#125; service实现类继承AbstractBaseService.java ，重写getRepository()方法12345678910111213141516/** * @author songshuiyang * @date 2018/10/28 10:13 */@Servicepublic class UserServiceImpl extends AbstractBaseService&lt;User, Integer&gt; implements UserService &#123; @Autowired private UserMapper userMapper; @Override public BaseCurdMapper&lt;User, Integer&gt; getRepository() &#123; return userMapper; &#125;&#125; AbstractBaseService.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * 抽象service基类 * * @author songsy * @Date 2018/131 17:17 */@Slf4jpublic abstract class AbstractBaseService&lt;T extends BaseEntity, ID extends Serializable&gt; &#123; public abstract BaseCurdMapper&lt;T, ID&gt; getRepository(); public List&lt;T&gt; findAll() &#123; return getRepository().findAll(); &#125; public T findById(ID id) &#123; return getRepository().findById(id); &#125; public int updateNull(T entity) &#123; return getRepository().updateNull(entity); &#125; public int deleteOne(ID id) &#123; return getRepository().deleteOne(id); &#125; public int logicDeleteOne(ID id) &#123; return getRepository().logicDeleteOne(id); &#125; /** * 通用插入更新方法 * * @param entity * @return */ @Transactional public T saveSelective(T entity) &#123; return saveSelective(entity, false); &#125; @Transactional public T saveSelective(T entity, Boolean hasId) &#123; if (hasId) &#123; // 之前已经生成了id insertSelective(entity); &#125; else if (!StringUtils.isEmpty(entity.getId())) &#123; updateSelective(entity); // 插入数据库之后 实体类乐观锁字段自增 entity.setVersion(entity.getVersion() + 1); &#125; else &#123; Class idClass = ReflectionUtils.getPrimarykeyClassType(entity.getClass()); // 如果主键是字符类型，则采用32位随机字符作为主键 if (idClass.equals(String.class)) &#123; entity.setId(IDGeneratorUtils.generateID()); &#125; else &#123; // 默认主键由数据库自动生成（主要是自动增长型） &#125; insertSelective(entity); &#125; return entity; &#125; private void insertSelective(T entity) &#123; entity.setCreatedDate(new Date()); entity.setLastModifiedDate(new Date()); entity.setVersion(new Long(1)); // 设置当前登录人// if (null == entity.getCreatedBy()) &#123;// entity.setCreatedBy(\"\");// &#125;// if (null == entity.getLastModifiedBy()) &#123;// entity.setLastModifiedBy(\"\");// &#125; getRepository().insert(entity); &#125; private void updateSelective(T entity) &#123; if (entity.getVersion() == null) &#123; throw new VersionException(); &#125; entity.setLastModifiedDate(new Date()); // 设置当前登录人// if (null == entity.getLastModifiedBy()) &#123;// entity.setLastModifiedBy(\"\");// &#125; Integer flag = getRepository().update(entity); if (flag == 0) &#123; throw new UpdateException(); &#125; &#125;&#125; 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * @author songsy * @Date 2018/10/31 18:00 */public class UserServiceTest extends BaseTest &#123; @Autowired UserService userService; @Test public void findAll () &#123; userService.findAll(); &#125; @Test public void insertUser () &#123; User user = new User(); user.setUsername(\"songsy\"); user.setAddress(\"广东深圳\"); user.setAge(88); user.setEmail(\"1459074711@qq.com\"); user.setHeadPortrait(\"头像\"); user.setNickname(\"宋某\"); user.setPassword(\"root\"); user.setSex(1); userService.saveSelective(user); &#125; @Test public void updateUser1 () &#123; User user = new User(); user.setId(48); user.setUsername(\"songsy\"); user.setAddress(\"广东深圳\"); user.setAge(88); user.setEmail(\"1459074711@qq.com\"); user.setHeadPortrait(\"头像\"); user.setNickname(\"宋某某\"); user.setPassword(\"root\"); user.setSex(1); user.setVersion(1l); userService.saveSelective(user); &#125; @Test public void updateUser2 () &#123; User user = userService.findAll().get(0); User userDb = new User(); userDb.setId(user.getId()); userDb.setVersion(user.getVersion()); userDb.setUsername(\"测试乐观锁111\"); userService.saveSelective(userDb); &#125; @Test public void updateNull () &#123; User user = userService.findById(50); User userDb = new User(); userDb.setId(user.getId()); userDb.setVersion(user.getVersion()); userDb.setUsername(\"测试updateNull\"); userService.updateNull(userDb); &#125; @Test public void deleteOne () &#123; userService.deleteOne(48); &#125; @Test public void logicDeleteOne () &#123; userService.logicDeleteOne(49); &#125;&#125; 使用总结 如果增加或者修改了数据库字段，只要修改对应的实体类文件即可，配合注解的使用可以十分方便完成修改，对于增删改查的操作代码再也不用一个个去修改xml文件了 不用在每一个mapper接口, Mybatis xml文件添加一些重复的代码 在service层即可完成通用增删改查方法，使用Mybatis也可以像Hibernate 那样用对象来更新数据库了 实现解析 详细实现可见com.songsy.iframe.core.persistence.provider 按步骤解析： 使用Spring Aop收集实体类信息及缓存起来，每次调用继承了BaseCurdMapper.java的Mapper接口就会触发 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package com.songsy.iframe.core.persistence.provider.aspect;import com.google.common.collect.Maps;import com.songsy.iframe.core.persistence.provider.exception.ParameterizedTypeException;import com.songsy.iframe.core.persistence.provider.mapper.BaseCurdMapper;import com.songsy.iframe.core.persistence.provider.threadlocal.EntityProperty;import com.songsy.iframe.core.persistence.provider.threadlocal.EntityThreadLocal;import com.songsy.iframe.core.persistence.provider.utils.ReflectionUtils;import org.apache.ibatis.binding.MapperProxy;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Proxy;import java.lang.reflect.Type;import java.util.Map;/** * BaseCurdMapper接口AOP，用于获取实体类属性 * * @author songshuiyang * @date 2018/10/30 21:44 */@Aspect@Componentpublic class BaseCurdMapperAspect &#123; private final static Logger logger = LoggerFactory.getLogger(BaseCurdMapperAspect.class); /** * 缓存实体类属性 * key: 实体类类型 * value: 实体类属性对象 */ private static Map&lt;String, EntityProperty&gt; entityPropertyMap = Maps.newHashMap(); /** * 定义切点 * Spring Aop是基于代理的，生成的bean也是一个代理对象，this就是这个代理对象， * 当这个对象可以转换为指定的类型时，对应的切入点就是它了，Spring Aop将生效。 */ @Pointcut(\"this(com.songsy.iframe.core.persistence.provider.mapper.BaseCurdMapper)\") public void pointcut() &#123; &#125; /** * 前置增强：获取BaseCurdMapper接口 泛型属性，并设置到ThreadLocal中 * @param point */ @Before(\"pointcut()\") public void before(JoinPoint point) &#123; Class entityClass = null; Class entityIdClass = null; Object target= point.getTarget(); // 是否继承 BaseCurdMapper 接口 if (BaseCurdMapper.class.isAssignableFrom(target.getClass())) &#123; // 获取Mybatis代理类对象 MapperProxy mapperProxy = (MapperProxy) Proxy.getInvocationHandler(target); Class mapperInterface = (Class) ReflectionUtils.getFieldValue(mapperProxy, \"mapperInterface\"); // 获取接口泛型对象 ParameterizedType parameterizedType = (ParameterizedType) mapperInterface.getGenericInterfaces()[0]; Type[] types = parameterizedType.getActualTypeArguments(); if (types.length != 2) &#123; logger.error(\"parameterizedType type length error\"); throw new ParameterizedTypeException(parameterizedType.getTypeName()); &#125; try &#123; entityClass = Class.forName(types[0].getTypeName()); entityIdClass = Class.forName(types[1].getTypeName()); // 如果不存在则加入到entityPropertyMap缓存中 if (!entityPropertyMap.containsKey(entityClass.getName())) &#123; EntityProperty entityProperty = new EntityProperty(entityClass, entityIdClass); entityPropertyMap.put(entityClass.getTypeName(),entityProperty); &#125; &#125; catch (ClassNotFoundException e) &#123; logger.error(e.getMessage()); &#125; &#125; // 设置ThreadLocal if (null != entityClass) &#123; EntityThreadLocal.set(entityPropertyMap.get(entityClass.getName())); &#125; &#125; /** * 后置增强：清除 threadLocal 防止内存泄漏 * @param point */ @After(\"pointcut()\") public void after(JoinPoint point) &#123; EntityThreadLocal.remove(); &#125;&#125; 使用ThreadLocal 获取当前访问线程实体类信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 * 每次调用mapper接口方法的时候，先把实体类的信息存放在ThreadLocal中 * @author songshuiyang * @date 2018/10/30 21:27 */public class EntityThreadLocal &#123; private static ThreadLocal&lt;EntityProperty&gt; threadLocal = new ThreadLocal&lt;&gt;(); /** * 获取当前线程的实体类属性 * @return */ public static EntityProperty get () &#123; if (null == threadLocal) &#123; initialValue(); &#125; return threadLocal.get(); &#125; /** * 设置当前线程的实体类属性 * @param entityProperty */ public static void set(EntityProperty entityProperty) &#123; if (entityProperty != null) &#123; threadLocal.set(entityProperty); &#125; &#125; /** * 清除 threadLocal */ public static void remove() &#123; threadLocal.remove(); &#125; /** * 默认初始化Object.class */ private static void initialValue() &#123; EntityProperty entityProperty = new EntityProperty(); entityProperty.setEntityClass(Object.class); entityProperty.setIdClass(null); threadLocal.set(entityProperty); &#125;&#125; 使用Mybatis3的@SelectProvider、@InsertProvider, @UpdateProvider,@DeleteProvider，使用注解来配置Mapper 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 通用增删改查Mapper * @author songshuiyang * @date 2018/10/28 11:22 */public interface CurdMapper&lt;T extends BaseEntity, ID extends Serializable&gt; &#123; /** * 查询所有数据 * @return */ @SelectProvider(type=MybatisProvider.class,method = MybatisProvider.FIND_ALL) List&lt;T&gt; findAll(); /** * 根据id查询记录 * @return */ @SelectProvider(type=MybatisProvider.class, method = MybatisProvider.FIND_BY_ID) T findById(Object id); /** * 插入记录 * @param entity * @return */ @InsertProvider(type=MybatisProvider.class, method = MybatisProvider.INSERT) int insert(T entity); /** * 更新记录 * @param entity * @return */ @UpdateProvider(type=MybatisProvider.class, method = MybatisProvider.UPDATE) int update(T entity); /** * 更新记录(null值记录也更新) * @param entity * @return */ @UpdateProvider(type=MybatisProvider.class, method = MybatisProvider.UPDATE_NULL) int updateNull(T entity); /** * 根据id物理删除记录 * @param id * @return */ @DeleteProvider(type=MybatisProvider.class, method = MybatisProvider.DELETE_ONE) int deleteOne (Object id); /** * 根据id逻辑删除记录 * @param id * @return */ @DeleteProvider(type=MybatisProvider.class, method = MybatisProvider.LOGIC_DELETE_ONE) int logicDeleteOne (Object id); /** * 分页查询 * @param page * @return */ @SelectProvider(type=MybatisProvider.class,method = MybatisProvider.FIND_AUTO_BY_PAGE) List&lt;T&gt; findAutoByPage(Page&lt;T&gt; page);&#125; 通用增删改查实现类，在这里实现sql的拼接 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197package com.songsy.iframe.core.persistence.provider;import com.google.common.collect.Lists;import com.google.common.collect.Maps;import com.songsy.iframe.core.persistence.provider.annotation.Version;import com.songsy.iframe.core.persistence.provider.entity.ColumnEntity;import com.songsy.iframe.core.persistence.provider.entity.TableEntity;import com.songsy.iframe.core.persistence.provider.utils.MybatisTableUtils;import com.songsy.iframe.core.persistence.provider.utils.PageUtils;import com.songsy.iframe.core.persistence.provider.utils.ReflectionUtils;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.lang.reflect.Field;import java.text.ParseException;import java.util.List;import java.util.Map;import java.util.Set;/** * 通用增删改查实现方法 * @author songshuiyang * @date 2018/10/28 11:34 */public class CrudProvider &#123; private static Logger logger = LoggerFactory.getLogger(CrudProvider.class); public static final String FIND_ALL = \"findAll\"; public static final String FIND_BY_ID = \"findById\"; public static final String INSERT = \"insert\"; public static final String UPDATE = \"update\"; public static final String UPDATE_NULL = \"updateNull\"; public static final String DELETE_ONE = \"deleteOne\"; public static final String LOGIC_DELETE_ONE =\"logicDeleteOne\"; public static final String FIND_AUTO_BY_PAGE = \"findAutoByPage\"; /** * 查询所有数据 * @return */ public String findAll() &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); String sql = \"SELECT * FROM \" + tableEntity.getTableName(); return sql; &#125; /** * 根据id查询记录 * @param id * @return */ public String findById (Object id) &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); StringBuilder sb = new StringBuilder(\"SELECT \"); sb.append(\" * \"); sb.append(\"FROM\"); sb.append(\" \").append(tableEntity.getTableName()).append(\" \"); sb.append(\" WHERE \").append(tableEntity.getIdColumnEntity().getColumnName()).append(\"=\").append(id); return sb.toString(); &#125; /** * 插入记录 * @param entity */ public String insert (Object entity) &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); List&lt;ColumnEntity&gt; columnEntities = tableEntity.getColumnEntities(); List&lt;String&gt; fieldNames = Lists.newArrayList(); List&lt;String&gt; columnNames = Lists.newArrayList(); for (ColumnEntity columnEntity : columnEntities) &#123; Object value = ReflectionUtils.getFieldValue(entity, columnEntity.getFieldName()); // 字段为null不插入 if (value != null) &#123; columnNames.add(columnEntity.getColumnName()); fieldNames.add(\"#&#123;\" + columnEntity.getFieldName() + \"&#125;\"); &#125; &#125; StringBuilder sb = new StringBuilder(\"INSERT INTO \"); sb.append(tableEntity.getTableName()); sb.append(\" (\"); sb.append(StringUtils.join(columnNames, \",\")); sb.append(\") \"); sb.append(\" VALUES(\"); sb.append(StringUtils.join(fieldNames, \",\")); sb.append(\")\"); String sql = sb.toString(); return sql; &#125; /** * 更新记录 * 字段属性为null不更新 * @param entity */ public String update (Object entity) &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); List&lt;ColumnEntity&gt; columnEntities = tableEntity.getColumnEntities(); ColumnEntity versionColumnEntity = null; List&lt;String&gt; updateColumns = Lists.newArrayList(); for (ColumnEntity columnEntity : columnEntities) &#123; // 乐观锁处理 更新后version字段加一 Field field = columnEntity.getField(); Version version = field.getAnnotation(Version.class); &#123; if (version != null) &#123; versionColumnEntity = columnEntity; updateColumns.add(columnEntity.getColumnName() + \" = \" + columnEntity.getFieldName() + \" + 1\"); continue; &#125; &#125; Object value = ReflectionUtils.getFieldValue(entity, columnEntity.getFieldName()); if (value != null) &#123; updateColumns.add(columnEntity.getColumnName() + \" = \" + \"#&#123;\" + columnEntity.getFieldName() + \"&#125;\"); &#125; &#125; StringBuilder sb = new StringBuilder(\"UPDATE \"); sb.append(tableEntity.getTableName()); sb.append(\" SET \"); sb.append(StringUtils.join(updateColumns, \",\")); sb.append(\" WHERE \"); sb.append(tableEntity.getIdColumnEntity().getColumnName()); sb.append(\" = \"); sb.append(\"#&#123;\" + tableEntity.getIdColumnEntity().getFieldName() + \"&#125;\"); sb.append(\" and \"); sb.append(versionColumnEntity.getColumnName()); sb.append(\" = \"); sb.append(\"#&#123;\" + versionColumnEntity.getFieldName() + \"&#125;\"); String sql = sb.toString(); return sql; &#125; /** * 更新记录 * 字段属性为null 也会更新为null * @param entity */ public String updateNull (Object entity) &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); List&lt;ColumnEntity&gt; columnEntities = tableEntity.getColumnEntities(); ColumnEntity versionColumnEntity = null; List&lt;String&gt; updateColumns = Lists.newArrayList(); for (ColumnEntity columnEntity : columnEntities) &#123; // 乐观锁处理 更新后version字段加一 Field field = columnEntity.getField(); Version version = field.getAnnotation(Version.class); &#123; if (version != null) &#123; versionColumnEntity = columnEntity; updateColumns.add(columnEntity.getColumnName() + \" = \" + columnEntity.getFieldName() + \" + 1\"); continue; &#125; &#125; updateColumns.add(columnEntity.getColumnName() + \" = \" + \"#&#123;\" + columnEntity.getFieldName() + \"&#125;\"); &#125; StringBuilder sb = new StringBuilder(\"UPDATE \"); sb.append(tableEntity.getTableName()); sb.append(\" SET \"); sb.append(StringUtils.join(updateColumns, \",\")); sb.append(\" WHERE \"); sb.append(tableEntity.getIdColumnEntity().getColumnName()); sb.append(\" = \"); sb.append(\"#&#123;\" + tableEntity.getIdColumnEntity().getFieldName() + \"&#125;\"); sb.append(\" and \"); sb.append(versionColumnEntity.getColumnName()); sb.append(\" = \"); sb.append(\"#&#123;\" + versionColumnEntity.getFieldName() + \"&#125;\"); String sql = sb.toString(); return sql; &#125; /** * 根据id物理删除记录 * @param id * @return */ public String deleteOne(Object id) &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); String sql = \"DELETE FROM \" + tableEntity.getTableName() + \" WHERE \" + tableEntity.getIdColumnEntity().getColumnName() + \" = #&#123;id&#125;\"; return sql; &#125; /** * 根据id逻辑删除记录 * @param id * @return */ public String logicDeleteOne(Object id) &#123; TableEntity tableEntity = MybatisTableUtils.getCurrentTableEntity(); String sql = \"UPDATE \" + tableEntity.getTableName() + \" SET \" + tableEntity.getDeleteColunmEntity().getColumnName() + \" = 0 \" + \"WHERE \" + tableEntity.getIdColumnEntity().getColumnName() + \" = #&#123;id&#125;\"; return sql; &#125;&#125;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(二十三)Mybatis占位符","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十三)Mybatis占位符","date":"2018-12-22T10:12:00.000Z","updated":"2019-12-05T12:19:35.200Z","comments":true,"path":"2018/12/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十三)Mybatis占位符/","link":"","permalink":"http://www.songshuiyang.com/2018/12/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十三)Mybatis占位符/","excerpt":"","text":"前言Mybatis的Sql语句传参有两种方式：#{}和${} #{}是预编译处理 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； 使用#{}可以有效的防止SQL注入，提高系统安全。 如：order by #{sortName}#，如果传入的值是111,那么解析成sql时的值为order by &quot;111&quot;, ${}是字符串替换 Mybatis在处理${}时，就是把${}替换成变量的值。 如果是在SQL语句中插入一个不改变的字符串。比如，像ORDER BY，你可以这样来使用：ORDER BY ${columnName} 举个栗子 现在通过一个例子来分析其两者的区别 测试类1234567891011121314151617181920/** * 测试 $ 和 # * @throws Exception */@Testpublic void selectByUsernameAndPasswordTest() throws Exception &#123; // 读取配置文件 File file = new File(\"src/test/java/resources/mybatis-config.xml\"); InputStream inputStream = new FileInputStream(file); // 构建SqlSessionFactory SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); // 得到SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); // 得到Mapper UserMapper mapper = sqlSession.getMapper(UserMapper.class); User user = new User(); user.setUsername(\"songsy\"); user.setPassword(\"root\"); System.out.println(mapper.selectByUsernameAndPassword(user));&#125; Mapper.xml 配置文件1234567SELECT *FROM sys_userWHERE username = $&#123;username&#125;AND password = #&#123;password&#125; 执行mapper方法，打好断点，进入到Executor的query方法，关注BoundSql boundSql = ms.getBoundSql(parameterObject); 这行，BoundSql对象存放了处理完成之后的sql 1234567 @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameterObject);//query时传入一个cachekey参数 CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; 如下图所示，${username} 已经替换成了 songsy ， #{password} 替换成了 ? image 栗子剖析 Mybatis是怎样完成上面的替换解析过程呢，进入BoundSql boundSql = ms.getBoundSql(parameterObject); 方法，可以看到其实就是调用sqlSource.getBoundSql 12345678910111213141516171819 public BoundSql getBoundSql(Object parameterObject) &#123;// 其实就是调用sqlSource.getBoundSql BoundSql boundSql = sqlSource.getBoundSql(parameterObject); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings == null || parameterMappings.isEmpty()) &#123; boundSql = new BoundSql(configuration, boundSql.getSql(), parameterMap.getParameterMappings(), parameterObject); &#125; // check for nested result maps in parameter mappings (issue #30) for (ParameterMapping pm : boundSql.getParameterMappings()) &#123; String rmId = pm.getResultMapId(); if (rmId != null) &#123; ResultMap rm = configuration.getResultMap(rmId); if (rm != null) &#123; hasNestedResultMaps |= rm.hasNestedResultMaps(); &#125; &#125; &#125; return boundSql; &#125; 进入sqlSource.getBoundSql(parameterObject); ，因为sql不是静态sql所以进入DynamicSqlSource 类的getBoundSql方法，这里传入了我们的user查询对象 12345678910111213141516171819202122232425262728293031323334/** * 动态SQL源码 * @author Clinton Begin */public class DynamicSqlSource implements SqlSource &#123; private Configuration configuration; private SqlNode rootSqlNode; public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123; this.configuration = configuration; this.rootSqlNode = rootSqlNode; &#125; // 得到绑定的SQL @Override public BoundSql getBoundSql(Object parameterObject) &#123; // 生成一个动态上下文 DynamicContext context = new DynamicContext(configuration, parameterObject); // 这里SqlNode.apply只是将$&#123;&#125;这种参数替换掉，并没有替换#&#123;&#125;这种参数 rootSqlNode.apply(context); // 调用SqlSourceBuilder SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); // SqlSourceBuilder.parse,注意这里返回的是StaticSqlSource,解析完了就把那些参数都替换成?了，也就是最基本的JDBC的SQL写法 SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 看似是又去递归调用SqlSource.getBoundSql，其实因为是StaticSqlSource，所以没问题，不是递归调用 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql; &#125;&#125; 下面的语句是动态sql的处理，循环执行SqlNode.apply方法，进入 rootSqlNode.apply(context);方法 123DynamicContext context = new DynamicContext(configuration, parameterObject);// 这里SqlNode.apply只是将$&#123;&#125;这种参数替换掉，并没有替换#&#123;&#125;这种参数rootSqlNode.apply(context); 进入rootSqlNode.apply(context); 之后来到了MixedSqlNode类，这里依次调用list里每个元素的apply，如下图所示 image 执行sqlNode.apply(context);方法这里进入到TextSqlNode的apply方法，这里又调用了GenericTokenParser类的parser.parse(text)方法 1234567891011121314151617181920212223242526272829public class TextSqlNode implements SqlNode &#123; private String text; private Pattern injectionFilter; public TextSqlNode(String text) &#123; this(text, null); &#125; public TextSqlNode(String text, Pattern injectionFilter) &#123; this.text = text; this.injectionFilter = injectionFilter; &#125; //判断是否是动态sql public boolean isDynamic() &#123; DynamicCheckerTokenParser checker = new DynamicCheckerTokenParser(); GenericTokenParser parser = createParser(checker); parser.parse(text); return checker.isDynamic(); &#125; @Override public boolean apply(DynamicContext context) &#123; GenericTokenParser parser = createParser(new BindingTokenParser(context, injectionFilter)); context.appendSql(parser.parse(text)); return true; &#125; ... 进入 GenericTokenParser类的parser.parse(text)方法，可以看到这个类是处理#{}和${}参数的主要方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 普通记号解析器，处理#&#123;&#125;和$&#123;&#125;参数 * @author Clinton Begin */public class GenericTokenParser &#123; // 有一个开始和结束记号 private final String openToken; private final String closeToken; // 记号处理器 private final TokenHandler handler; public GenericTokenParser(String openToken, String closeToken, TokenHandler handler) &#123; this.openToken = openToken; this.closeToken = closeToken; this.handler = handler; &#125; public String parse(String text) &#123; StringBuilder builder = new StringBuilder(); if (text != null &amp;&amp; text.length() &gt; 0) &#123; char[] src = text.toCharArray(); int offset = 0; int start = text.indexOf(openToken, offset); // #&#123;favouriteSection,jdbcType=VARCHAR&#125; // 这里是循环解析参数，参考GenericTokenParserTest,比如可以解析$&#123;first_name&#125; $&#123;initial&#125; $&#123;last_name&#125; reporting.这样的字符串,里面有3个 $&#123;&#125; while (start &gt; -1) &#123; // 判断一下 $&#123; 前面是否是反斜杠，这个逻辑在老版的mybatis中（如3.1.0）是没有的 if (start &gt; 0 &amp;&amp; src[start - 1] == '\\\\') &#123; // the variable is escaped. remove the backslash. // 新版已经没有调用substring了，改为调用如下的offset方式，提高了效率 // issue #760 builder.append(src, offset, start - offset - 1).append(openToken); offset = start + openToken.length(); &#125; else &#123; int end = text.indexOf(closeToken, start); if (end == -1) &#123; builder.append(src, offset, src.length - offset); offset = src.length; &#125; else &#123; builder.append(src, offset, start - offset); offset = start + openToken.length(); String content = new String(src, offset, end - offset); // 得到一对大括号里的字符串后，调用handler.handleToken,比如替换变量 $&#123;username&#125;这种功能 builder.append(handler.handleToken(content)); offset = end + closeToken.length(); &#125; &#125; start = text.indexOf(openToken, offset); &#125; if (offset &lt; src.length) &#123; builder.append(src, offset, src.length - offset); &#125; &#125; return builder.toString(); &#125;&#125; 执行完builder.append(handler.handleToken(content)); 这行代码之后就可以看到${username} 已经替换成songsy了 image 到现在已经完成了${username} 的处理，回到 DynamicSqlSource 类中，现在是处理#{password} 这些参数了 123456789101112131415161718192021222324252627282930public class DynamicSqlSource implements SqlSource &#123; private Configuration configuration; private SqlNode rootSqlNode; public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123; this.configuration = configuration; this.rootSqlNode = rootSqlNode; &#125; // 得到绑定的SQL @Override public BoundSql getBoundSql(Object parameterObject) &#123; // 生成一个动态上下文 DynamicContext context = new DynamicContext(configuration, parameterObject); // 这里SqlNode.apply只是将$&#123;&#125;这种参数替换掉，并没有替换#&#123;&#125;这种参数 rootSqlNode.apply(context); // 调用SqlSourceBuilder SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); // SqlSourceBuilder.parse,注意这里返回的是StaticSqlSource,解析完了就把那些参数#&#123;password&#125;都替换成?了，也就是最基本的JDBC的SQL写法 SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 看似是又去递归调用SqlSource.getBoundSql，其实因为是StaticSqlSource，所以没问题，不是递归调用 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql; &#125;&#125; 下图是处理完动态sql节点及${username}之后的结果 处理完${username} 节点之后现在就是处理#{password} 节点了，解析完了就把那些参数#{password}都替换成?了，也就是最基本的JDBC的SQL写法 12345// 调用SqlSourceBuilder SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass();// SqlSourceBuilder.parse,注意这里返回的是StaticSqlSource,解析完了就把那些参数#&#123;password&#125;都替换成?了，也就是最基本的JDBC的SQL写法 SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); 进入sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings());方法，之后又是进入 GenericTokenParser类的parser.parse(text)方法，只不过handleToken方法执行的是下面的代码 1234567@Override public String handleToken(String content) &#123; // 先构建参数映射 parameterMappings.add(buildParameterMapping(content)); // 如何替换很简单，永远是一个问号，但是参数的信息要记录在parameterMappings里面供后续使用 return \"?\"; &#125; 最后拼接成的结果如下 1234567SELECT *FROM sys_userWHERE username = songsyAND password = ? 总结 #{}在一定程度上可以防止SQL的注入 ${}一般用在动态表名，动态字段，设置排序字段上 参考https://www.jianshu.com/p/a9cb929b533e","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(二十一)拦截器Interceptor原理探究","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十一)拦截器Interceptor原理探究","date":"2018-12-21T12:56:00.000Z","updated":"2019-12-05T12:19:35.195Z","comments":true,"path":"2018/12/21/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十一)拦截器Interceptor原理探究/","link":"","permalink":"http://www.songshuiyang.com/2018/12/21/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十一)拦截器Interceptor原理探究/","excerpt":"","text":"前言 MyBatis 允许你在已映射语句执行过程中的某一点进行拦截调用，拦截后用户可以完成一些额外的定制操作，比如实现分页，这一章节来介绍拦截器的一些基本知识及实现原理，下一章节将介绍如何用拦截器实现查询分页功能 默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： 12345678// 拦截执行器的方法Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed)// 拦截参数的处理ParameterHandler (getParameterObject, setParameters)// 拦截结果集的处理ResultSetHandler (handleResultSets, handleOutputParameters)// 拦截Sql语法构建的处理StatementHandler (prepare, parameterize, batch, update, query) 拦截器的使用 通过 MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截的方法签名即可。 123456789101112131415// ExamplePlugin.java@Intercepts(&#123;@Signature( type= Executor.class, method = \"update\", args = &#123;MappedStatement.class,Object.class&#125;)&#125;)public class ExamplePlugin implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; return invocation.proceed(); &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; public void setProperties(Properties properties) &#123; &#125;&#125; xml 配置 123456&lt;!-- mybatis-config.xml --&gt;&lt;plugins&gt; &lt;plugin interceptor=\"org.mybatis.example.ExamplePlugin\"&gt; &lt;property name=\"someProperty\" value=\"100\"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 上面的插件将会拦截在 Executor 实例中所有的名为update 且参数为(MappedStatement.class,Object.class)的方法调用， 这里的 Executor 是负责执行低层映射语句的内部对象。 拦截器原理探究 拦截器定义 首先我们看下MyBatis拦截器的接口定义 Interceptor.java 12345678910111213141516/** * 拦截器 * @author Clinton Begin */public interface Interceptor &#123; // 在这里完成拦截操作 Object intercept(Invocation invocation) throws Throwable; // 用于封装目标对象，我们可以决定是否要进行拦截进而决定要返回一个什么样的目标对象 Object plugin(Object target); // 用于在Mybatis配置文件中指定一些属性的。 void setProperties(Properties properties);&#125; Signature注解用于定义拦截方法，规则为：type这个类下方法名为method且参数为args的方法 1234567891011121314/** * 就是定义哪些类，方法，参数需要被拦截 * @author Clinton Begin */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface Signature &#123; Class&lt;?&gt; type(); String method(); Class&lt;?&gt;[] args();&#125; 当定义拦截器类之后就是要让Mybatis知道有哪些拦截器了，那Mybatis是怎么知道有哪些拦截器呢，通过以上章节可以知道Spring集成Mybatis有两种方法，一种是通过xml配置的方式，另一种是通过注解的方式，下面来介绍这两种方式是怎样获取定义好的拦截器的 通过xml配置的方式 先是在 mybatis-config.xml 定义好哪些拦截器 123456&lt;!-- mybatis-config.xml --&gt;&lt;plugins&gt; &lt;plugin interceptor=\"org.mybatis.example.ExamplePlugin\"&gt; &lt;property name=\"someProperty\" value=\"100\"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 定义好之后那么Mybatis就会解析pluginElement 然后将会添加到Configuration 对象的InterceptorChain对象中，这样拦截器就解析完成了 123456789101112private void pluginElement(XNode parent) throws Exception &#123; if (parent != null) &#123; for (XNode child : parent.getChildren()) &#123; String interceptor = child.getStringAttribute(\"interceptor\"); Properties properties = child.getChildrenAsProperties(); Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).newInstance(); interceptorInstance.setProperties(properties); //调用InterceptorChain.addInterceptor configuration.addInterceptor(interceptorInstance); &#125; &#125;&#125; 看看InterceptorChain类，内部就是一个拦截器的List，可以定义多个拦截器 123456789101112131415161718192021222324252627 /** * 拦截器链 * @author Clinton Begin */public class InterceptorChain &#123; // 内部就是一个拦截器的List，可以定义多个拦截器 private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;Interceptor&gt;(); public Object pluginAll(Object target) &#123; // 循环调用每个Interceptor.plugin方法 for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125; public void addInterceptor(Interceptor interceptor) &#123; interceptors.add(interceptor); &#125; public List&lt;Interceptor&gt; getInterceptors() &#123; return Collections.unmodifiableList(interceptors); &#125;&#125; 通过注解的方式 通过注解的方式获取拦截器需要准备环境，查看第十九章 在拦截器那个类添加@Component 让拦截器类注册成Spring bean，这样此拦截器将会自动装配到Mybatis中 123456789101112131415@Component@Intercepts(&#123;@Signature( type= Executor.class, method = \"update\", args = &#123;MappedStatement.class,Object.class&#125;)&#125;)public class ExamplePlugin implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; return invocation.proceed(); &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; public void setProperties(Properties properties) &#123; &#125;&#125; 那么是怎么实现拦截器的自动装配到Mybatis中，可以查看org.mybatis.spring.boot.autoconfigure 包下的MybatisAutoConfiguration 类，查看其构造方法，关注this.interceptors = interceptorsProvider.getIfAvailable(); 方法，这里实现了查找实现了Interceptor接口的的类，这个方法是Spring的方法，所以之前需要将拦截器类注册成Bean，这样Spring才能找到对应的拦截器 1234567891011public MybatisAutoConfiguration(MybatisProperties properties, ObjectProvider&lt;Interceptor[]&gt; interceptorsProvider, ResourceLoader resourceLoader, ObjectProvider&lt;DatabaseIdProvider&gt; databaseIdProvider, ObjectProvider&lt;List&lt;ConfigurationCustomizer&gt;&gt; configurationCustomizersProvider) &#123; this.properties = properties; this.interceptors = interceptorsProvider.getIfAvailable(); this.resourceLoader = resourceLoader; this.databaseIdProvider = databaseIdProvider.getIfAvailable(); this.configurationCustomizers = configurationCustomizersProvider.getIfAvailable();&#125; 现在来看SqlSessionFactory注册为Bean的过程，得到interceptors之后就需要将其添加到万能类Configuration中， 查看SqlSessionFactoryBean的buildSqlSessionFactory 方法，下面的代码就是此操作的实现 12345678if (!isEmpty(this.plugins)) &#123; for (Interceptor plugin : this.plugins) &#123; configuration.addInterceptor(plugin); if (LOGGER.isDebugEnabled()) &#123; LOGGER.debug(\"Registered plugin: '\" + plugin + \"'\"); &#125; &#125; &#125; 拦截器是如何拦截的 以下4个方法都是Configuration的方法。这些方法在MyBatis的新增，删除，修改，查询这些操作中都会被执行到，执行的先后顺序是Executor，ParameterHandler，ResultSetHandler，StatementHandler(其中ParameterHandler和ResultSetHandler的创建是在创建StatementHandler（3个可用的实现类CallableStatementHandler,PreparedStatementHandler,SimpleStatementHandler）的时候，其构造函数调用的（这3个实现类的构造函数其实都调用了父类BaseStatementHandler的构造函数）。 123456789101112131415161718192021222324252627282930313233343536public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler;&#125;public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler;&#125;public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125;public Executor newExecutor(Transaction transaction, ExecutorType executorType, boolean autoCommit) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor, autoCommit); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 这4个方法实例化了对应的对象之后，都会调用interceptorChain的pluginAll方法，InterceptorChain的pluginAll刚才已经介绍过了，就是遍历所有的拦截器，然后调用各个拦截器的plugin方法。注意：拦截器的plugin方法的返回值会直接被赋值给原先的对象 1234567public Object pluginAll(Object target) &#123; // 循环调用每个Interceptor.plugin方法 for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125; 在哪里插入的 12345678910111213141516171819202122232425@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); //新建一个StatementHandler //这里看到ResultHandler传入了 拦截器在这里完成工作 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //准备语句 stmt = prepareStatement(handler, ms.getStatementLog()); //StatementHandler.query return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125;// org.apache.ibatis.session.Configuration#newStatementHandlerpublic StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; // 创建路由选择语句处理器 StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); // 拦截器在这里执行 statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125; 由上图可以看到org.apache.ibatis.executor.SimpleExecutor#doQuery方法可以知道拦截器的具体执行点是各个 Handler被构建的时候执行的，Handler都会调用interceptorChain的pluginAll方法 回到之前的拦截器类，这里查看plugin方法Plugin.wrap(target, this);，这里执行了Plugin类的wrap(target, this) 方法，返回了一个新的对象。注意：拦截器的plugin方法的返回值会直接被赋值给原先的对象 1234567891011121314@Intercepts(&#123;@Signature( type= Executor.class, method = \"update\", args = &#123;MappedStatement.class,Object.class&#125;)&#125;)public class ExamplePlugin implements Interceptor &#123; public Object intercept(Invocation invocation) throws Throwable &#123; return invocation.proceed(); &#125; public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; public void setProperties(Properties properties) &#123; &#125;&#125; 进入Plugin类，可以看到这里用了动态代理模式来实现拦截器的拦截操作Plugin.wrap(target, this);返回的是一个动态代理对象，当其动态代理对象执行方法的时候就会执行本Plugin类的invoke方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * 插件,用的代理模式 * @author Clinton Begin */public class Plugin implements InvocationHandler &#123; private Object target; private Interceptor interceptor; private Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap; private Plugin(Object target, Interceptor interceptor, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; &#125; public static Object wrap(Object target, Interceptor interceptor) &#123; // 取得签名Map Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); // 取得要改变行为的类(ParameterHandler|ResultSetHandler|StatementHandler|Executor) Class&lt;?&gt; type = target.getClass(); // 取得接口 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); // 产生代理 if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // 看看如何拦截 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); // 看哪些方法需要拦截 if (methods != null &amp;&amp; methods.contains(method)) &#123; // 调用Interceptor.intercept，也即插入了我们自己的逻辑 return interceptor.intercept(new Invocation(target, method, args)); &#125; // 最后还是执行原来逻辑 return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; // 取得签名Map private static Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; getSignatureMap(Interceptor interceptor) &#123; // 取Intercepts注解，例子可参见ExamplePlugin.java Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class); // issue #251 // 必须得有Intercepts注解，没有报错 if (interceptsAnnotation == null) &#123; throw new PluginException(\"No @Intercepts annotation was found in interceptor \" + interceptor.getClass().getName()); &#125; // value是数组型，Signature的数组 Signature[] sigs = interceptsAnnotation.value(); // 每个class里有多个Method需要被拦截,所以这么定义 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = new HashMap&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt;(); for (Signature sig : sigs) &#123; Set&lt;Method&gt; methods = signatureMap.get(sig.type()); if (methods == null) &#123; methods = new HashSet&lt;Method&gt;(); signatureMap.put(sig.type(), methods); &#125; try &#123; Method method = sig.type().getMethod(sig.method(), sig.args()); methods.add(method); &#125; catch (NoSuchMethodException e) &#123; throw new PluginException(\"Could not find method on \" + sig.type() + \" named \" + sig.method() + \". Cause: \" + e, e); &#125; &#125; return signatureMap; &#125; // 取得接口 private static Class&lt;?&gt;[] getAllInterfaces(Class&lt;?&gt; type, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; Set&lt;Class&lt;?&gt;&gt; interfaces = new HashSet&lt;Class&lt;?&gt;&gt;(); while (type != null) &#123; for (Class&lt;?&gt; c : type.getInterfaces()) &#123; //貌似只能拦截ParameterHandler|ResultSetHandler|StatementHandler|Executor //拦截其他的无效 //当然我们可以覆盖Plugin.wrap方法，达到拦截其他类的功能 if (signatureMap.containsKey(c)) &#123; interfaces.add(c); &#125; &#125; type = type.getSuperclass(); &#125; return interfaces.toArray(new Class&lt;?&gt;[interfaces.size()]); &#125;&#125; 查看invoke方法,从而调用了我们之前定义的interceptor.intercept();的方法，这里是实现拦截的核心，interceptor.intercept(new Invocation(target, method, args)); 这里插入了我们自己的逻辑 12345678910111213141516@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // 看看如何拦截 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); // 看哪些方法需要拦截 if (methods != null &amp;&amp; methods.contains(method)) &#123; // 调用Interceptor.intercept，也即插入了我们自己的逻辑 return interceptor.intercept(new Invocation(target, method, args)); &#125; // 最后还是执行原来逻辑 return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125;&#125; 回到之前的节点，在构建Executor的时候，executor = (Executor) interceptorChain.pluginAll(executor);这里返回的是 Plugin.wrap(target, this);一个动态代理对象 1234567891011121314151617public Executor newExecutor(Transaction transaction, ExecutorType executorType, boolean autoCommit) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor, autoCommit); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 所以当SqlSession执行Executor的方法时候，这里Executor是个动态代理之后的Executor，当执行Executor的方法的时候就会执行动态代理的invoke方法，在invoke方法执行我们额外的代码 在此拦截器的任务才真正完成 参考官网：http://www.mybatis.org/mybatis-3/zh/configuration.html#plugins https://www.cnblogs.com/fangjian0423/p/mybatis-interceptor.html","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(二十)Spring Mybatis集成之事务管理","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十)Spring Mybatis集成之事务管理","date":"2018-12-18T15:56:00.000Z","updated":"2019-12-05T12:19:35.191Z","comments":true,"path":"2018/12/18/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十)Spring Mybatis集成之事务管理/","link":"","permalink":"http://www.songshuiyang.com/2018/12/18/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二十)Spring Mybatis集成之事务管理/","excerpt":"","text":"前言使用 MyBatis-Spring 的主要原因是它允许 MyBatis 参与到 Spring 的事务管理中。而 不是给 MyBatis 创建一个新的特定的事务管理器,MyBatis-Spring 利用了存在于 Spring 中的 DataSourceTransactionManager。 如何集成 Spring的事务管理 配置 DataSourceTransactionManager Bean 1234&lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt; 要注意, 为事务管理器指定的 DataSource 必须和用来创建 SqlSessionFactoryBean 的 是同一个数据源,否则事务管理器就无法工作了。 一旦 Spring 的 DataSourceTransactionManager 配置好了,你可以在 Spring 中你可以使用@Transactional 注解来完成事物操作。在事务处理期间,一个单独的 SqlSession 对象（线程级别）将会被创建 和使用。当事务完成时,这个 SqlSession 会以合适的方式提交或回滚。相反如果没有开启事物那么SqlSession 对象就是方法级别的了，每次调用Mapper里的方法都会返回一个新的SqlSession 来处理，下面来看其内部是怎么实现的 事务实现解析 与Spring集成以后，Spring提供了一个全局唯一的SqlSessionTemplate 来完成DefailtSqlSession的功能 进入SqlSessionTemplate 可以看到里面有个SqlSession 属性，看属性名可以看出这里又用了动态代理，为什么又要代理呢？下面来看看 12// SqlSession代理private final SqlSession sqlSessionProxy; 观察其构造方法，这里形成SqlSession代理类，再来看动态代理类SqlSessionInterceptor做了什么 123456789101112131415public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sqlSessionFactory, \"Property 'sqlSessionFactory' is required\"); notNull(executorType, \"Property 'executorType' is required\"); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; // 形成SqlSession代理类 this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor()); &#125; 进入SqlSessionInterceptor类，这个SqlSession代理类的出现是为了让Spring 来管理SqlSession 的，从而实现事物管理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * SqlSession 代理类，MyBatis路由方法调用得到有Spring Transaction的SqlSession * Proxy needed to route MyBatis method calls to the proper SqlSession got * from Spring's Transaction Manager * It also unwraps exceptions thrown by &#123;@code Method#invoke(Object, Object...)&#125; to * pass a &#123;@code PersistenceException&#125; to the &#123;@code PersistenceExceptionTranslator&#125;. */private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 获取SqlSession(这个SqlSession才是真正使用的，它不是线程安全的) SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; // 调用真实SqlSession的方法 Object result = method.invoke(sqlSession, args); // 判断一下当前的sqlSession是否被Spring托管 if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() // 没有使用事务 sqlSession.commit(true); &#125; return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator.translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; // 关闭SqlSession,如果sqlSession被Spring管理 则调用holder.released(); 使计数器-1 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; &#125;&#125; 进入getSqlSession()方法，这里是获取SqlSession 的方法 1234567891011121314151617181920public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); notNull(executorType, NO_EXECUTOR_TYPE_SPECIFIED); // 根据sqlSessionFactory从当前线程对应的资源map中获取SqlSessionHolder SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); SqlSession session = sessionHolder(executorType, holder); if (session != null) &#123; return session; &#125; // 如果找不到，则根据执行类型构造一个新的sqlSession LOGGER.debug(() -&gt; \"Creating a new SqlSession\"); session = sessionFactory.openSession(executorType); registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session;&#125; 关注TransactionSynchronizationManager 内部成员，这里使用TreadLocal记录事务的一些属性，用于应用扩展同步器的使用，在事务的开启，挂起，提交等各个点上回调应用的逻辑 1234567891011121314151617181920212223 // 应用代码随事务的声明周期绑定的对象private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;&gt;(\"Transactional resources\"); // synchronizations-使用的同步器，用于应用扩展private static final ThreadLocal&lt;Set&lt;TransactionSynchronization&gt;&gt; synchronizations = new NamedThreadLocal&lt;&gt;(\"Transaction synchronizations\"); // 事务的名称private static final ThreadLocal&lt;String&gt; currentTransactionName = new NamedThreadLocal&lt;&gt;(\"Current transaction name\"); // 事务是否是只读private static final ThreadLocal&lt;Boolean&gt; currentTransactionReadOnly = new NamedThreadLocal&lt;&gt;(\"Current transaction read-only status\"); // 事务的隔离界别private static final ThreadLocal&lt;Integer&gt; currentTransactionIsolationLevel = new NamedThreadLocal&lt;&gt;(\"Current transaction isolation level\"); // 事务是否开启private static final ThreadLocal&lt;Boolean&gt; actualTransactionActive = new NamedThreadLocal&lt;&gt;(\"Actual transaction active\"); 回到SqlSessionInterceptor 类invoke方法，这里有个if判断if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) { 来判断是否开启了Spring事务，如果该Session未被Spring托管则自动commit 12345678public static boolean isSqlSessionTransactional(SqlSession session, SqlSessionFactory sessionFactory) &#123; notNull(session, NO_SQL_SESSION_SPECIFIED); notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); return (holder != null) &amp;&amp; (holder.getSqlSession() == session);&#125; 关注invoke方法的finally块的 closeSqlSession()方法，如果是开启了事务则没有执行session.close(); 123456finally &#123; if (sqlSession != null) &#123; // 关闭SqlSession,如果sqlSession被Spring管理 则调用holder.released(); 使计数器-1 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; 1234567891011121314public static void closeSqlSession(SqlSession session, SqlSessionFactory sessionFactory) &#123; notNull(session, NO_SQL_SESSION_SPECIFIED); notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); if ((holder != null) &amp;&amp; (holder.getSqlSession() == session)) &#123; LOGGER.debug(() -&gt; \"Releasing transactional SqlSession [\" + session + \"]\"); // 如果是开启了事务 SqlSession是没有被close的，所以方法体内使用的是一个SqlSession，当然一级缓存是生效的 holder.released(); &#125; else &#123; LOGGER.debug(() -&gt; \"Closing non transactional SqlSession [\" + session + \"]\"); session.close(); &#125;&#125; 总结 通过上述代码可以得出如果开启了事务，同一事务中同一个sqlSessionFactory创建的唯一sqlSession，一个事务中使用的是同一个sqlSession，为什么要用同一个sqlSession呢，是为了使用同一个connection (JDBC) 如果没有开启事务，调用一次mapper里的方法将会新建一个sqlSession来执行方法 参考http://www.mybatis.org/spring/zh/factorybean.html https://www.cnblogs.com/daxin/p/3544188.html","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十九)Spring Mybatis集成之基于注解的配置原理解析","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十九)Spring Mybatis集成之基于注解的配置原理解析","date":"2018-12-18T13:56:00.000Z","updated":"2019-12-05T12:19:35.232Z","comments":true,"path":"2018/12/18/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十九)Spring Mybatis集成之基于注解的配置原理解析/","link":"","permalink":"http://www.songshuiyang.com/2018/12/18/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十九)Spring Mybatis集成之基于注解的配置原理解析/","excerpt":"","text":"前言Mybatis与Spring的集成实现有两种方式，一种是通过XML配置，另一种是通过注解的信息进行配置，上一章节介绍了通过XML的方式来集成，这一章节来介绍如何通过注解的形式来在Spring Boot环境中集成Mybatis 环境准备 基于MyBatis-Spring-Boot-Starter 快速在Spring Boot环境中集成Mybatis，使用注解解决一切问题 基于Spring Boot环境中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 配置类中添加注解 1@MapperScan(\"com.songsy.iframe.mapper\") 添加配置（选填） 1234567mybatis: type-aliases-package: com.songsy.iframe.model type-handlers-package: com.songsy.iframe.typehandler configuration: map-underscore-to-camel-case: true default-fetch-size: 100 default-statement-timeout: 30 以上完成之后就可以使用Mybatis了 原理解析 打开mybatis-spring-boot-starter 源码可以看到是个空壳子 image 打开里面的pom.xml文件，可以看到其依赖，里面已经帮我们导入了mybatis及mybatis-spring的包 123456789101112131415161718192021222324252627282930&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;parent&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/parent&gt;&lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;&lt;name&gt;mybatis-spring-boot-starter&lt;/name&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 关注mybatis-spring-boot-autoconfigure 包，这里完成了其自动配置的功能，可以看到里面就只有几个类 image MybatisProperties.java是属性配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@ConfigurationProperties(prefix = MybatisProperties.MYBATIS_PREFIX)public class MybatisProperties &#123; public static final String MYBATIS_PREFIX = \"mybatis\"; /** * Location of MyBatis xml config file. */ private String configLocation; /** * Locations of MyBatis mapper files. */ private String[] mapperLocations; /** * Packages to search type aliases. (Package delimiters are \",; \\t\\n\") */ private String typeAliasesPackage; /** * Packages to search for type handlers. (Package delimiters are \",; \\t\\n\") */ private String typeHandlersPackage; /** * Indicates whether perform presence check of the MyBatis xml config file. */ private boolean checkConfigLocation = false; /** * Execution mode for &#123;@link org.mybatis.spring.SqlSessionTemplate&#125;. */ private ExecutorType executorType; /** * Externalized properties for MyBatis configuration. */ private Properties configurationProperties; /** * A Configuration object for customize default settings. If &#123;@link #configLocation&#125; * is specified, this property is not used. */ @NestedConfigurationProperty private Configuration configuration; ... MybatisAutoConfiguration 是完成自动配置的主要实现类，可以看到这里定义了SqlSessionFactory及SqlSessionTemplate Bean，这里完成了之前使用xml配置bean的功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178/** * &#123;@link EnableAutoConfiguration Auto-Configuration&#125; for Mybatis. Contributes a * &#123;@link SqlSessionFactory&#125; and a &#123;@link SqlSessionTemplate&#125;. * * If &#123;@link org.mybatis.spring.annotation.MapperScan&#125; is used, or a * configuration file is specified as a property, those will be considered, * otherwise this auto-configuration will attempt to register mappers based on * the interface definitions in or under the root auto-configuration package. * * @author Eddú Meléndez * @author Josh Long * @author Kazuki Shimizu * @author Eduardo Macarrón */@org.springframework.context.annotation.Configuration@ConditionalOnClass(&#123; SqlSessionFactory.class, SqlSessionFactoryBean.class &#125;)@ConditionalOnBean(DataSource.class)@EnableConfigurationProperties(MybatisProperties.class)@AutoConfigureAfter(DataSourceAutoConfiguration.class)public class MybatisAutoConfiguration &#123; private static final Logger logger = LoggerFactory.getLogger(MybatisAutoConfiguration.class); private final MybatisProperties properties; private final Interceptor[] interceptors; private final ResourceLoader resourceLoader; private final DatabaseIdProvider databaseIdProvider; private final List&lt;ConfigurationCustomizer&gt; configurationCustomizers; public MybatisAutoConfiguration(MybatisProperties properties, ObjectProvider&lt;Interceptor[]&gt; interceptorsProvider, ResourceLoader resourceLoader, ObjectProvider&lt;DatabaseIdProvider&gt; databaseIdProvider, ObjectProvider&lt;List&lt;ConfigurationCustomizer&gt;&gt; configurationCustomizersProvider) &#123; this.properties = properties; this.interceptors = interceptorsProvider.getIfAvailable(); this.resourceLoader = resourceLoader; this.databaseIdProvider = databaseIdProvider.getIfAvailable(); this.configurationCustomizers = configurationCustomizersProvider.getIfAvailable(); &#125; @PostConstruct public void checkConfigFileExists() &#123; if (this.properties.isCheckConfigLocation() &amp;&amp; StringUtils.hasText(this.properties.getConfigLocation())) &#123; Resource resource = this.resourceLoader.getResource(this.properties.getConfigLocation()); Assert.state(resource.exists(), \"Cannot find config location: \" + resource + \" (please add config file or check your Mybatis configuration)\"); &#125; &#125; @Bean @ConditionalOnMissingBean public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setDataSource(dataSource); factory.setVfs(SpringBootVFS.class); if (StringUtils.hasText(this.properties.getConfigLocation())) &#123; factory.setConfigLocation(this.resourceLoader.getResource(this.properties.getConfigLocation())); &#125; Configuration configuration = this.properties.getConfiguration(); if (configuration == null &amp;&amp; !StringUtils.hasText(this.properties.getConfigLocation())) &#123; configuration = new Configuration(); &#125; if (configuration != null &amp;&amp; !CollectionUtils.isEmpty(this.configurationCustomizers)) &#123; for (ConfigurationCustomizer customizer : this.configurationCustomizers) &#123; customizer.customize(configuration); &#125; &#125; factory.setConfiguration(configuration); if (this.properties.getConfigurationProperties() != null) &#123; factory.setConfigurationProperties(this.properties.getConfigurationProperties()); &#125; if (!ObjectUtils.isEmpty(this.interceptors)) &#123; factory.setPlugins(this.interceptors); &#125; if (this.databaseIdProvider != null) &#123; factory.setDatabaseIdProvider(this.databaseIdProvider); &#125; if (StringUtils.hasLength(this.properties.getTypeAliasesPackage())) &#123; factory.setTypeAliasesPackage(this.properties.getTypeAliasesPackage()); &#125; if (StringUtils.hasLength(this.properties.getTypeHandlersPackage())) &#123; factory.setTypeHandlersPackage(this.properties.getTypeHandlersPackage()); &#125; if (!ObjectUtils.isEmpty(this.properties.resolveMapperLocations())) &#123; factory.setMapperLocations(this.properties.resolveMapperLocations()); &#125; return factory.getObject(); &#125; @Bean @ConditionalOnMissingBean public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) &#123; ExecutorType executorType = this.properties.getExecutorType(); if (executorType != null) &#123; return new SqlSessionTemplate(sqlSessionFactory, executorType); &#125; else &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; &#125; /** * This will just scan the same base package as Spring Boot does. If you want * more power, you can explicitly use * &#123;@link org.mybatis.spring.annotation.MapperScan&#125; but this will get typed * mappers working correctly, out-of-the-box, similar to using Spring Data JPA * repositories. */ public static class AutoConfiguredMapperScannerRegistrar implements BeanFactoryAware, ImportBeanDefinitionRegistrar, ResourceLoaderAware &#123; private BeanFactory beanFactory; private ResourceLoader resourceLoader; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; logger.debug(\"Searching for mappers annotated with @Mapper\"); ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); try &#123; if (this.resourceLoader != null) &#123; scanner.setResourceLoader(this.resourceLoader); &#125; List&lt;String&gt; packages = AutoConfigurationPackages.get(this.beanFactory); if (logger.isDebugEnabled()) &#123; for (String pkg : packages) &#123; logger.debug(\"Using auto-configuration base package '&#123;&#125;'\", pkg); &#125; &#125; scanner.setAnnotationClass(Mapper.class); scanner.registerFilters(); scanner.doScan(StringUtils.toStringArray(packages)); &#125; catch (IllegalStateException ex) &#123; logger.debug(\"Could not determine auto-configuration package, automatic mapper scanning disabled.\", ex); &#125; &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125; @Override public void setResourceLoader(ResourceLoader resourceLoader) &#123; this.resourceLoader = resourceLoader; &#125; &#125; /** * &#123;@link org.mybatis.spring.annotation.MapperScan&#125; ultimately ends up * creating instances of &#123;@link MapperFactoryBean&#125;. If * &#123;@link org.mybatis.spring.annotation.MapperScan&#125; is used then this * auto-configuration is not needed. If it is _not_ used, however, then this * will bring in a bean registrar and automatically register components based * on the same component-scanning path as Spring Boot itself. */ @org.springframework.context.annotation.Configuration @Import(&#123; AutoConfiguredMapperScannerRegistrar.class &#125;) @ConditionalOnMissingBean(MapperFactoryBean.class) public static class MapperScannerRegistrarNotFoundConfiguration &#123; @PostConstruct public void afterPropertiesSet() &#123; logger.debug(\"No &#123;&#125; found.\", MapperFactoryBean.class.getName()); &#125; &#125;&#125; 通过注解配置来集成Spring、Mybatis 的方式可以看到是通过这个注解@MapperScan来实现的，查看注解可以看到通过@Import(MapperScannerRegistrar.class)把实例加入springIOC容器中 123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class) // 通过导入的方式实现把实例加入springIOC容器中@Repeatable(MapperScans.class)// 被此注解修饰的注解是可以重复的。注解的参数是可重复注解的存储容器注解类型。@Repeatable括号内的就相当于用来保存该注解内容的容器。public @interface MapperScan &#123; 查看MapperScannerRegistrar类，可以看到实现了 ImportBeanDefinitionRegistrar接口，重写了registerBeanDefinitions方法， 由于实现了该接口让该类成为了拥有注册bean的能力 image 进入registerBeanDefinitions方法 123456789@Overridepublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 拿到注解信息，内部实现是 LinkedHashMap AnnotationAttributes mapperScanAttrs = AnnotationAttributes .fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); if (mapperScanAttrs != null) &#123; registerBeanDefinitions(mapperScanAttrs, registry); &#125;&#125; 进入第二个registerBeanDefinitions方法，可以看到又出现了ClassPathMapperScanner这个类，果不其然，还是调用了scanner.doScan(StringUtils.toStringArray(basePackages)); 这个方法完成了Mapper的注册 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void registerBeanDefinitions(AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry) &#123; // 获得spring的注册器registry ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // this check is needed in Spring 3.1 if (resourceLoader != null) &#123; scanner.setResourceLoader(resourceLoader); &#125; Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass(\"annotationClass\"); if (!Annotation.class.equals(annotationClass)) &#123; scanner.setAnnotationClass(annotationClass); &#125; Class&lt;?&gt; markerInterface = annoAttrs.getClass(\"markerInterface\"); if (!Class.class.equals(markerInterface)) &#123; scanner.setMarkerInterface(markerInterface); &#125; Class&lt;? extends BeanNameGenerator&gt; generatorClass = annoAttrs.getClass(\"nameGenerator\"); if (!BeanNameGenerator.class.equals(generatorClass)) &#123; scanner.setBeanNameGenerator(BeanUtils.instantiateClass(generatorClass)); &#125; Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass(\"factoryBean\"); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) &#123; scanner.setMapperFactoryBean(BeanUtils.instantiateClass(mapperFactoryBeanClass)); &#125; scanner.setSqlSessionTemplateBeanName(annoAttrs.getString(\"sqlSessionTemplateRef\")); scanner.setSqlSessionFactoryBeanName(annoAttrs.getString(\"sqlSessionFactoryRef\")); List&lt;String&gt; basePackages = new ArrayList&lt;&gt;(); // 如果配置了包路径则将入进去 basePackages.addAll( Arrays.stream(annoAttrs.getStringArray(\"value\")) .filter(StringUtils::hasText) .collect(Collectors.toList())); // 与上面功能一致 basePackages.addAll( Arrays.stream(annoAttrs.getStringArray(\"basePackages\")) .filter(StringUtils::hasText) .collect(Collectors.toList())); basePackages.addAll( Arrays.stream(annoAttrs.getClassArray(\"basePackageClasses\")) .map(ClassUtils::getPackageName) .collect(Collectors.toList())); scanner.registerFilters(); // 开始扫描包 scanner.doScan(StringUtils.toStringArray(basePackages));&#125; 总结 使用注解的方式集成Mybatis比xml配置的方式更为简洁，在Spring Boot项目中就是以这种方式来配置的 mybatis-spring-boot-autoconfigure 帮助我们完成了以下功能1234自动检测现有的DataSource。将创建并注册的一个实例的SqlSessionFactory传递一个数据源作为使用输入SqlSessionFactoryBean的。将创建并注册SqlSessionTemplate的实例从SqlSessionFactory中获取。自动扫描映射器，将它们链接到SqlSessionTemplate并将它们注册到Spring上下文，以便将它们注入到bean中。 参考http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十八)Spring Mybatis集成之基于XML的配置原理解析","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十八)Spring Mybatis集成之基于XML的配置原理解析","date":"2018-12-18T12:56:00.000Z","updated":"2019-12-05T12:19:35.242Z","comments":true,"path":"2018/12/18/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十八)Spring Mybatis集成之基于XML的配置原理解析/","link":"","permalink":"http://www.songshuiyang.com/2018/12/18/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十八)Spring Mybatis集成之基于XML的配置原理解析/","excerpt":"","text":"前言在实际项目开发中，Mybatis一般都是与Spring集成配合使用的，Mybatis与Spring集成需要另一个项目https://github.com/mybatis/spring，该项目提供了Mybatis与Spring的集成实现，Mybatis与Spring的集成实现有两种方式，一种是通过XML配置，另一种是通过注解的信息进行配置，这一章节来介绍如何通过XML的方式来在Spring中集成Mybatis及实现原理 开始集成 在Spring环境中集成MyBatis 添加依赖 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;31-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 添加xml配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!-- 数据库连接池 --&gt;&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;driver.encryption&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;url.encryption&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;user.encryption&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;password.encryption&#125;\"/&gt; &lt;property name=\"initialSize\" value=\"1\"/&gt; &lt;property name=\"minIdle\" value=\"1\"/&gt; &lt;property name=\"maxActive\" value=\"20\"/&gt; &lt;property name=\"maxWait\" value=\"60000\"/&gt; &lt;property name=\"timeBetweenEvictionRunsMillis\" value=\"60000\"/&gt; &lt;property name=\"minEvictableIdleTimeMillis\" value=\"300000\"/&gt; &lt;property name=\"validationQuery\" value=\"SELECT 1 FROM DUAL\"/&gt; &lt;property name=\"testWhileIdle\" value=\"true\"/&gt; &lt;property name=\"testOnBorrow\" value=\"false\"/&gt; &lt;property name=\"testOnReturn\" value=\"false\"/&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;property name=\"maxPoolPreparedStatementPerConnectionSize\" value=\"20\"/&gt; &lt;property name=\"filters\" value=\"stat,wall,log4j\"/&gt; &lt;property name=\"connectionProperties\"&gt; &lt;value&gt;clientEncoding=UTF-8&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置SqlSessionFactory对象 --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.songsy.admin.entity\"/&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\"/&gt;&lt;/bean&gt;&lt;!-- 配置扫描Dao接口包，动态实现Dao接口，注入到spring容器中 --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"com.songsy.admin.dao\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt; 实现解析dataSource 配置数据源 在Spring框架中有如下3种获得DataSource对象的方法: 1、从JNDI获得DataSource 2、从第三方的连接池获得DataSource 3、使用DriverManagerDataSource获得DataSource 用户可以根据需要选择不同的数据源配置 使用 SqlSessionFactoryBean 来创建SqlSession工厂 在基本的 MyBatis 中,session 工厂可以使用 SqlSessionFactoryBuilder 来创建。而在 MyBatis-Spring 中,则使用 SqlSessionFactoryBean 来替代。 SqlSessionFactoryBean.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SqlSessionFactoryBean.class); private Resource configLocation; private Configuration configuration; private Resource[] mapperLocations; private DataSource dataSource; private TransactionFactory transactionFactory; private Properties configurationProperties; private SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); private SqlSessionFactory sqlSessionFactory; //EnvironmentAware requires spring 3.1 private String environment = SqlSessionFactoryBean.class.getSimpleName(); private boolean failFast; private Interceptor[] plugins; private TypeHandler&lt;?&gt;[] typeHandlers; private String typeHandlersPackage; private Class&lt;?&gt;[] typeAliases; private String typeAliasesPackage; private Class&lt;?&gt; typeAliasesSuperType; //issue #19. No default provider. private DatabaseIdProvider databaseIdProvider; private Class&lt;? extends VFS&gt; vfs; private Cache cache; private ObjectFactory objectFactory; private ObjectWrapperFactory objectWrapperFactory; @Override public void afterPropertiesSet() throws Exception &#123; notNull(dataSource, \"Property 'dataSource' is required\"); notNull(sqlSessionFactoryBuilder, \"Property 'sqlSessionFactoryBuilder' is required\"); state((configuration == null &amp;&amp; configLocation == null) || !(configuration != null &amp;&amp; configLocation != null), \"Property 'configuration' and 'configLocation' can not specified with together\"); this.sqlSessionFactory = buildSqlSessionFactory(); &#125; ... /** * &#123;@inheritDoc&#125; */ @Override public SqlSessionFactory getObject() throws Exception &#123; if (this.sqlSessionFactory == null) &#123; afterPropertiesSet(); &#125; return this.sqlSessionFactory; &#125; 要注意 SqlSessionFactoryBean 实现了 Spring 的 FactoryBean 接口,这就说明了由 Spring 最终创建的 bean 不是 SqlSessionFactoryBean 本身, 。 而是工厂类的 getObject()返回的方法的结果。这种情况下,Spring 将会在应用启动时为你 创建 SqlSessionFactory 对象,然后将它以 SqlSessionFactory 为名来存储。在 Java 中, 相同的代码是: 12SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean();SqlSessionFactory sessionFactory = factoryBean.getObject(); 关注afterPropertiesSet 方法，这个方法将在Spring将所有的属性被初始化后调用，只需要实现InitializingBean接口就行，里面的buildSqlSessionFactory(); 方法，此方法是构建SqlSessionFactory的主体方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128protected SqlSessionFactory buildSqlSessionFactory() throws IOException &#123; Configuration configuration; XMLConfigBuilder xmlConfigBuilder = null; if (this.configuration != null) &#123; configuration = this.configuration; if (configuration.getVariables() == null) &#123; configuration.setVariables(this.configurationProperties); &#125; else if (this.configurationProperties != null) &#123; configuration.getVariables().putAll(this.configurationProperties); &#125; &#125; else if (this.configLocation != null) &#123; // 解析Mybatis配置文件 xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties); configuration = xmlConfigBuilder.getConfiguration(); &#125; else &#123; LOGGER.debug(() -&gt; \"Property 'configuration' or 'configLocation' not specified, using default MyBatis Configuration\"); configuration = new Configuration(); if (this.configurationProperties != null) &#123; configuration.setVariables(this.configurationProperties); &#125; &#125; if (this.objectFactory != null) &#123; configuration.setObjectFactory(this.objectFactory); &#125; if (this.objectWrapperFactory != null) &#123; configuration.setObjectWrapperFactory(this.objectWrapperFactory); &#125; if (this.vfs != null) &#123; configuration.setVfsImpl(this.vfs); &#125; // 基于包名注册别名 if (hasLength(this.typeAliasesPackage)) &#123; String[] typeAliasPackageArray = tokenizeToStringArray(this.typeAliasesPackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); for (String packageToScan : typeAliasPackageArray) &#123; configuration.getTypeAliasRegistry().registerAliases(packageToScan, typeAliasesSuperType == null ? Object.class : typeAliasesSuperType); LOGGER.debug(() -&gt; \"Scanned package: '\" + packageToScan + \"' for aliases\"); &#125; &#125; // 注册别名 if (!isEmpty(this.typeAliases)) &#123; for (Class&lt;?&gt; typeAlias : this.typeAliases) &#123; configuration.getTypeAliasRegistry().registerAlias(typeAlias); LOGGER.debug(() -&gt; \"Registered type alias: '\" + typeAlias + \"'\"); &#125; &#125; // 添加插件 if (!isEmpty(this.plugins)) &#123; for (Interceptor plugin : this.plugins) &#123; configuration.addInterceptor(plugin); LOGGER.debug(() -&gt; \"Registered plugin: '\" + plugin + \"'\"); &#125; &#125; // 基于包名注册类型处理器 if (hasLength(this.typeHandlersPackage)) &#123; String[] typeHandlersPackageArray = tokenizeToStringArray(this.typeHandlersPackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); for (String packageToScan : typeHandlersPackageArray) &#123; configuration.getTypeHandlerRegistry().register(packageToScan); LOGGER.debug(() -&gt; \"Scanned package: '\" + packageToScan + \"' for type handlers\"); &#125; &#125; // 添加类型处理器 if (!isEmpty(this.typeHandlers)) &#123; for (TypeHandler&lt;?&gt; typeHandler : this.typeHandlers) &#123; configuration.getTypeHandlerRegistry().register(typeHandler); LOGGER.debug(() -&gt; \"Registered type handler: '\" + typeHandler + \"'\"); &#125; &#125; if (this.databaseIdProvider != null) &#123;//fix #64 set databaseId before parse mapper xmls try &#123; configuration.setDatabaseId(this.databaseIdProvider.getDatabaseId(this.dataSource)); &#125; catch (SQLException e) &#123; throw new NestedIOException(\"Failed getting a databaseId\", e); &#125; &#125; if (this.cache != null) &#123; configuration.addCache(this.cache); &#125; if (xmlConfigBuilder != null) &#123; try &#123; xmlConfigBuilder.parse(); LOGGER.debug(() -&gt; \"Parsed configuration file: '\" + this.configLocation + \"'\"); &#125; catch (Exception ex) &#123; throw new NestedIOException(\"Failed to parse config resource: \" + this.configLocation, ex); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; if (this.transactionFactory == null) &#123; this.transactionFactory = new SpringManagedTransactionFactory(); &#125; configuration.setEnvironment(new Environment(this.environment, this.transactionFactory, this.dataSource)); // 解析Mapper if (!isEmpty(this.mapperLocations)) &#123; for (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), configuration, mapperLocation.toString(), configuration.getSqlFragments()); xmlMapperBuilder.parse(); &#125; catch (Exception e) &#123; throw new NestedIOException(\"Failed to parse mapping resource: '\" + mapperLocation + \"'\", e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; LOGGER.debug(() -&gt; \"Parsed mapper file: '\" + mapperLocation + \"'\"); &#125; &#125; else &#123; LOGGER.debug(() -&gt; \"Property 'mapperLocations' was not specified or no matching resources found\"); &#125; return this.sqlSessionFactoryBuilder.build(configuration);&#125; 如下配置可以看到设置了数据源dataSource，指定了Mybatis的配置文件mybatis-config.xml，配置了别名包路径typeAliasesPackage，及Mapper文件的路径 1234567&lt;!-- 配置SqlSessionFactory对象 --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.songsy.admin.entity\"/&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\"/&gt;&lt;/bean&gt; basePackage 属性是让你为映射器接口文件设置基本的包路径。 你可以使用分号或逗号 作为分隔符设置多于一个的包路径。每个映射器将会在指定的包路径中递归地被搜索到。 SqlSessionFactory 有一个单独的必须属性,就是 JDBC 的 DataSource。这可以是任意 的 DataSource,其配置应该和其它 Spring 数据库连接是一样的。 要注意这个配置文件不需要是一个完整的 MyBatis 配置。确切地说,任意环境,数据源 和 MyBatis 的事务管理器都会被忽略。SqlSessionFactoryBean 会创建它自己的,使用这些 值定制 MyBatis 的 Environment 时是需要的。 使用 MapperScannerConfigurer 来扫描Mapper 使用MapperScannerConfigurer来注册所有的映射器，它将会查找类路径下的映射器并自动将它们创建成MapperFactoryBean，把SqlSession或者SqlSessionFactory注入进去 image MapperScannerConfigurer实现了 BeanDefinitionRegistryPostProcessor接口，如果实现了该接口，那么说明在Spring Application初始化的时候将会调用下面的方法 1234567891011121314151617181920@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; if (this.processPropertyPlaceHolders) &#123; // 处理PropertyResourceConfigurers 加载属性配置问题 processPropertyPlaceHolders(); &#125; ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.registerFilters(); scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));&#125; 从上面代码可以看到是通过ClassPathMapperScanner 这个类来实现解析的，重点关注scanner.scan() 方法，进入该方法，因为ClassPathMapperScanner继承了ClassPathBeanDefinitionScanner 所以这里调用的是ClassPathBeanDefinitionScanner这个类的scan()方法，可以看到第二行doScan(basePackages); 这个方法是ClassPathMapperScanner 的本地方法，该方法重载了ClassPathBeanDefinitionScanner的doScan方法 123456789101112public int scan(String... basePackages) &#123; int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); doScan(basePackages); // Register annotation config processors, if necessary. if (this.includeAnnotationConfig) &#123; AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125; return (this.registry.getBeanDefinitionCount() - beanCountAtScanStart);&#125; 进入doScan(basePackages); 返回到ClassPathMapperScanner 这个类，这里是实现MapperScan的核心方法，可以看到通过Spring 的ClassPathBeanDefinitionScanner 类来生成BeanDefinitionHolder，这里是一个接口一个BeanDefinitionHolder 12345678910111213@Overridepublic Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; // 通过Spring 的ClassPathBeanDefinitionScanner 类来生成BeanDefinitionHolder Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) &#123; LOGGER.warn(() -&gt; \"No MyBatis mapper was found in '\" + Arrays.toString(basePackages) + \"' package. Please check your configuration.\"); &#125; else &#123; // 在这里完成对Spring Bean的属性配置 processBeanDefinitions(beanDefinitions); &#125; return beanDefinitions;&#125; 进入processBeanDefinitions(beanDefinitions); 方法，关注definition.setBeanClass(this.mapperFactoryBean.getClass());这一行，这里是关键，可以看到这里设置了Mapper类的Bean，实际的源头Bean是MapperFactoryBean 123456789101112131415161718192021222324252627282930313233343536373839404142434445private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -&gt; \"Creating MapperFactoryBean with name '\" + holder.getBeanName() + \"' and '\" + beanClassName + \"' mapperInterface\"); // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // issue #59 // 设置了Mapper类的Bean，实际的源头Bean是MapperFactoryBean，Mapper是由该bean生成 definition.setBeanClass(this.mapperFactoryBean.getClass()); definition.getPropertyValues().add(\"addToConfig\", this.addToConfig); boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) &#123; definition.getPropertyValues().add(\"sqlSessionFactory\", new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionFactory != null) &#123; definition.getPropertyValues().add(\"sqlSessionFactory\", this.sqlSessionFactory); explicitFactoryUsed = true; &#125; if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn(() -&gt; \"Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\"); &#125; definition.getPropertyValues().add(\"sqlSessionTemplate\", new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionTemplate != null) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn(() -&gt; \"Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\"); &#125; definition.getPropertyValues().add(\"sqlSessionTemplate\", this.sqlSessionTemplate); explicitFactoryUsed = true; &#125; if (!explicitFactoryUsed) &#123; LOGGER.debug(() -&gt; \"Enabling autowire by type for MapperFactoryBean with name '\" + holder.getBeanName() + \"'.\"); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); &#125; &#125;&#125; MapperScannerConfigurer不需要指定SqlSessionFactory 或SqlSessionTemplate,MapperScannerConfigurer 将会创建 MapperFactoryBean之后自动装配，如果你使用了一个以上的 DataSource ,那么自动装配可能会失效 。这种情况下你可以使用 SqlSessionFactoryBeanName 或 SqlSessionTemplateBeanName 属性来设置正确的 Bean 名 称来使用 下面来看一下MapperFactoryBean，可以看到getObject()方法调用的是 SqlSessionDaoSupport类中 SqlSessionTemplate 类的getMapper(this.mapperInterface);方法，该Bean将会在这里返回了Mapper接口的动态代理类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; &#123; private Class&lt;T&gt; mapperInterface; private boolean addToConfig = true; public MapperFactoryBean() &#123; //intentionally empty &#125; public MapperFactoryBean(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; /** * &#123;@inheritDoc&#125; */ @Override protected void checkDaoConfig() &#123; super.checkDaoConfig(); notNull(this.mapperInterface, \"Property 'mapperInterface' is required\"); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123; try &#123; configuration.addMapper(this.mapperInterface); &#125; catch (Exception e) &#123; logger.error(\"Error while adding the mapper '\" + this.mapperInterface + \"' to configuration.\", e); throw new IllegalArgumentException(e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; &#125; /** * &#123;@inheritDoc&#125; */ @Override public T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface); &#125; /** * &#123;@inheritDoc&#125; */ @Override public Class&lt;T&gt; getObjectType() &#123; return this.mapperInterface; &#125; /** * &#123;@inheritDoc&#125; */ @Override public boolean isSingleton() &#123; return true; &#125; //------------- mutators -------------- /** * Sets the mapper interface of the MyBatis mapper * * @param mapperInterface class of the interface */ public void setMapperInterface(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; /** * Return the mapper interface of the MyBatis mapper * * @return class of the interface */ public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; /** * If addToConfig is false the mapper will not be added to MyBatis. This means * it must have been included in mybatis-config.xml. * &lt;p&gt; * If it is true, the mapper will be added to MyBatis in the case it is not already * registered. * &lt;p&gt; * By default addToConfig is true. * * @param addToConfig a flag that whether add mapper to MyBatis or not */ public void setAddToConfig(boolean addToConfig) &#123; this.addToConfig = addToConfig; &#125; /** * Return the flag for addition into MyBatis config. * * @return true if the mapper will be added to MyBatis in the case it is not already * registered. */ public boolean isAddToConfig() &#123; return addToConfig; &#125;&#125; MapperFactoryBean 创建的代理类实现了 UserMapper 接口,并且注入到应用程序中。 因为代理创建在运行时环境中(Runtime,译者注),那么指定的映射器必须是一个接口,而不是一个具体的实现类 SqlSessionTemplate 是MyBatis-Spring的核心。这个类负责管理MyBatis的SqlSession,调用MyBatis的SQL方法。SqlSessionTemplate是线程安全的，可以被多个DAO所共享使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112public class SqlSessionTemplate implements SqlSession, DisposableBean &#123; private final SqlSessionFactory sqlSessionFactory; private final ExecutorType executorType; // SqlSession代理 private final SqlSession sqlSessionProxy; private final PersistenceExceptionTranslator exceptionTranslator; /** * Constructs a Spring managed SqlSession with the &#123;@code SqlSessionFactory&#125; * provided as an argument. * * @param sqlSessionFactory a factory of SqlSession */ public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory) &#123; this(sqlSessionFactory, sqlSessionFactory.getConfiguration().getDefaultExecutorType()); &#125; /** * Constructs a Spring managed SqlSession with the &#123;@code SqlSessionFactory&#125; * provided as an argument and the given &#123;@code ExecutorType&#125; * &#123;@code ExecutorType&#125; cannot be changed once the &#123;@code SqlSessionTemplate&#125; * is constructed. * * @param sqlSessionFactory a factory of SqlSession * @param executorType an executor type on session */ public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType) &#123; this(sqlSessionFactory, executorType, new MyBatisExceptionTranslator( sqlSessionFactory.getConfiguration().getEnvironment().getDataSource(), true)); &#125; /** * Constructs a Spring managed &#123;@code SqlSession&#125; with the given * &#123;@code SqlSessionFactory&#125; and &#123;@code ExecutorType&#125;. * A custom &#123;@code SQLExceptionTranslator&#125; can be provided as an * argument so any &#123;@code PersistenceException&#125; thrown by MyBatis * can be custom translated to a &#123;@code RuntimeException&#125; * The &#123;@code SQLExceptionTranslator&#125; can also be null and thus no * exception translation will be done and MyBatis exceptions will be * thrown * * @param sqlSessionFactory a factory of SqlSession * @param executorType an executor type on session * @param exceptionTranslator a translator of exception */ public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sqlSessionFactory, \"Property 'sqlSessionFactory' is required\"); notNull(executorType, \"Property 'executorType' is required\"); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; // 形成SqlSession代理类 this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor()); &#125; /** * SqlSession 代理类，MyBatis路由方法调用得到有Spring Transaction的SqlSession * Proxy needed to route MyBatis method calls to the proper SqlSession got * from Spring's Transaction Manager * It also unwraps exceptions thrown by &#123;@code Method#invoke(Object, Object...)&#125; to * pass a &#123;@code PersistenceException&#125; to the &#123;@code PersistenceExceptionTranslator&#125;. */ private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 每次新生成一个SqlSession，一次调用一个SqlSession SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; Object result = method.invoke(sqlSession, args); // 判断是否事务 if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() // 没有使用事务 sqlSession.commit(true); &#125; return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator.translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; // 关闭SqlSession closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; &#125; &#125; ... SqlSessionTemplate 自动装配实现 TODO 总结 SqlSessionFactory 为什么能被Spring Ioc容器管理的原因是因为FactoryBean这个接口，这是个支持泛型的接口，Spring 将会在应用启动时为你 创建SqlSessionFactory对象,然后将它以 SqlSessionFactory为名来存储。当把这个bean注入到Spring中去了以后，IOC容器中的其他类型就可以拿到SqlSession实例了，就可以进行相关的SQL执行任务了。 当SqlSessionFactory 被Spring管理之后，如果单纯的使用Mybatis的话，是使用session.getMapper(UserMapper.class)来获取mapper的，但是现在在Spring环境中一般都是通过如下形式来调用的 12@Autowireprivate UserMapper userMapper; 所以Spring Mybatis 通过MapperScannerConfigurer 来将各个UserMapper RoleMapper...注册成为Spring bean (MapperFactoryBean)，由MapperFactoryBean来生成Mapper的代理类对象 参考http://www.mybatis.org/spring/zh/factorybean.html","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十七)结果映射DefaultResultSetHandler","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十七)结果映射DefaultResultSetHandler","date":"2018-12-09T02:52:00.000Z","updated":"2019-09-16T13:11:04.748Z","comments":true,"path":"2018/12/09/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十七)结果映射DefaultResultSetHandler/","link":"","permalink":"http://www.songshuiyang.com/2018/12/09/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十七)结果映射DefaultResultSetHandler/","excerpt":"","text":"前言上一章节介绍了Mybatis的参数绑定处理，本章将介绍Mybatis的结果映射过程，有执行就应该有结果，那Mybaits是怎样处理Jdbc返回的结果，并将结果映射成我们需要的对象呢？ 结果映射解析原生Jdbc结果映射 还是老套路，在介绍Mybatis结果映射处理之前先来看一下原生Jdbc结果映射是怎样处理的，可以看到通过迭代resultSet并根据列名来获取的值1234567resultSet=statement.executeQuery(sql);while (resultSet.next())&#123; String loginName=resultSet.getString(\"loginName\"); String userName=resultSet.getString(\"userName\"); String password=resultSet.getString(\"password\"); int sex=resultSet.getInt(\"sex\");&#125; Mybatis结果映射解析下面还是通过一个示例来介绍 测试用例 123456789101112// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper1 = sqlSession.getMapper(UserMapper.class);User user = new User();user.setUsername(\"admin\");System.out.println(userMapper1.selectSelective(user)); xml 配置 1234567891011121314151617&lt;select id=\"selectSelective\" resultType=\"org.apache.songsy.entity.User\" parameterType=\"org.apache.songsy.entity.User\"&gt; SELECT * FROM sys_user &lt;where&gt; &lt;if test=\"id != null\"&gt; AND id = #&#123;id&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username = #&#123;username&#125; &lt;/if&gt; &lt;if test=\"password != null\"&gt; AND password = #&#123;password&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 还是打入断点进入SimpleExecutor 的 doQuery 方法 12345678910111213141516@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 新建一个StatementHandler // 这里看到ResultHandler传入了 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 准备语句 stmt = prepareStatement(handler, ms.getStatementLog()); // StatementHandler.query return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 上一章节已经完成了stmt = prepareStatement(handler, ms.getStatementLog());操作，这一章节来处理return handler.&lt;E&gt;query(stmt, resultHandler); 进入该方法之后转到 RoutingStatementHandler 之后又转入 PreparedStatementHandler 进入query 方法，如下如可以看到又出现了Jdbc代码ps.execute(); 123456@Overridepublic &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.&lt;E&gt; handleResultSets(ps);&#125; execute 完成之后就是处理结果集了resultSetHandler.&lt;E&gt; handleResultSets(ps)， 进入该方法之后进入到DefaultResultSetHandler 类的handleResultSets 方法，以下代码可以知道数据结果都是存放在multipleResults 里面 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 处理ResultSets 并返回结果集 * @param stmt * @return * @throws SQLException */@Overridepublic List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity(\"handling results\").object(mappedStatement.getId()); // 存放所有数据 final List&lt;Object&gt; multipleResults = new ArrayList&lt;Object&gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); // 由MappedStatement 获取ResultMap List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); // 一般resultMaps里只有一个元素 int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; ResultMap resultMap = resultMaps.get(resultSetCount); // 处理结果集 handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; String[] resultSets = mappedStatement.getResulSets(); if (resultSets != null) &#123; while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) &#123; ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) &#123; String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); &#125; rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; &#125; return collapseSingleResultList(multipleResults);&#125; 继续跳入handleResultSet(rsw, resultMap, multipleResults, null); ，可以看到这行代码multipleResults.add(defaultResultHandler.getResultList()); 将结果赋值到了multipleResults，下面的方法对resultHandler 进行了判断，我们现在是没有指定ResultHandler所以这里该值为null，将跳入默认的ResultHandler 处理类 12345678910111213141516171819202122232425// 处理结果集private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List&lt;Object&gt; multipleResults, ResultMapping parentMapping) throws SQLException &#123; try &#123; if (parentMapping != null) &#123; handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping); &#125; else &#123; if (resultHandler == null) &#123; // 如果没有resultHandler // 新建DefaultResultHandler DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory); // 调用自己的handleRowValues handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null); // 得到记录的list multipleResults.add(defaultResultHandler.getResultList()); &#125; else &#123; //如果有resultHandler handleRowValues(rsw, resultMap, resultHandler, rowBounds, null); &#125; &#125; &#125; finally &#123; //最后别忘了关闭结果集，这个居然出bug了 // issue #228 (close resultsets) closeResultSet(rsw.getResultSet()); &#125;&#125; 跳入handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);，这里有个是否有嵌套的结果集判读，当然如果是有的话肯定要特殊处理的 12345678910private void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException &#123; // 是否有嵌套的结果集 if (resultMap.hasNestedResultMaps()) &#123; ensureNoRowBounds(); checkResultHandler(); handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping); &#125; else &#123; handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping); &#125;&#125; 我们现在这没有嵌套，所以else进入handleRowValuesForSimpleResultMap 方法，可以看到这里是一行一行的处理结果，ResultSetWrapper 是对ResultSet的包装 123456789101112131415161718192021/** * 见方法名知 ResultMap根据处理行数据 * @param rsw * @param resultMap * @param resultHandler 结果存放在这，里面是一个List&lt;Object&gt; * @param rowBounds * @param parentMapping * @throws SQLException */private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException &#123; DefaultResultContext resultContext = new DefaultResultContext(); skipRows(rsw.getResultSet(), rowBounds); // 一行一行赋值 rsw.getResultSet().next() Jdbc while (shouldProcessMoreRows(resultContext, rowBounds) &amp;&amp; rsw.getResultSet().next()) &#123; ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rsw.getResultSet(), resultMap, null); // 获取一行数据 Object rowValue = getRowValue(rsw, discriminatedResultMap); storeObject(resultHandler, resultContext, rowValue, parentMapping, rsw.getResultSet()); &#125;&#125; 重点关注Object rowValue = getRowValue(rsw, discriminatedResultMap); 这里的处理，这里是处理一行的数据 12345678910111213141516171819202122// 核心，取得一行的值private Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap) throws SQLException &#123; // 实例化ResultLoaderMap(延迟加载器) final ResultLoaderMap lazyLoader = new ResultLoaderMap(); // 调用自己的createResultObject,内部就是new一个对象(如果是简单类型，new完也把值赋进去) Object resultObject = createResultObject(rsw, resultMap, lazyLoader, null); if (resultObject != null &amp;&amp; !typeHandlerRegistry.hasTypeHandler(resultMap.getType())) &#123; // 一般不是简单类型不会有typehandler,这个if会进来 final MetaObject metaObject = configuration.newMetaObject(resultObject); boolean foundValues = !resultMap.getConstructorResultMappings().isEmpty(); if (shouldApplyAutomaticMappings(resultMap, false)) &#123; // 自动映射咯 // 这里把每个列的值都赋到相应的字段里去了 foundValues = applyAutomaticMappings(rsw, resultMap, metaObject, null) || foundValues; &#125; foundValues = applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, null) || foundValues; foundValues = lazyLoader.size() &gt; 0 || foundValues; resultObject = foundValues ? resultObject : null; return resultObject; &#125; return resultObject;&#125; 跳入applyAutomaticMappings 方法，可以看到这里是结果映射的核心代码，巧妙的用TypeHandler取得结果，根据columnName从ResultSet取值 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 自动映射 * @param rsw 对 ResultSet 的包装 * @param resultMap ResultMap * @param metaObject 返回的对象 * @param columnPrefix * @return * @throws SQLException */private boolean applyAutomaticMappings(ResultSetWrapper rsw, ResultMap resultMap, MetaObject metaObject, String columnPrefix) throws SQLException &#123; // 得到表列名list final List&lt;String&gt; unmappedColumnNames = rsw.getUnmappedColumnNames(resultMap, columnPrefix); boolean foundValues = false; // 一列一列数据循环赋值 for (String columnName : unmappedColumnNames) &#123; String propertyName = columnName; if (columnPrefix != null &amp;&amp; !columnPrefix.isEmpty()) &#123; // When columnPrefix is specified, // ignore columns without the prefix. if (columnName.toUpperCase(Locale.ENGLISH).startsWith(columnPrefix)) &#123; propertyName = columnName.substring(columnPrefix.length()); &#125; else &#123; continue; &#125; &#125; final String property = metaObject.findProperty(propertyName, configuration.isMapUnderscoreToCamelCase()); if (property != null &amp;&amp; metaObject.hasSetter(property)) &#123; final Class&lt;?&gt; propertyType = metaObject.getSetterType(property); if (typeHandlerRegistry.hasTypeHandler(propertyType)) &#123; // 根据实体类字段类型获取对应的TypeHandler final TypeHandler&lt;?&gt; typeHandler = rsw.getTypeHandler(propertyType, columnName); // 巧妙的用TypeHandler取得结果，根据columnName从ResultSet取值 final Object value = typeHandler.getResult(rsw.getResultSet(), columnName); // issue #377, call setter on nulls if (value != null || configuration.isCallSettersOnNulls()) &#123; if (value != null || !propertyType.isPrimitive()) &#123; // 然后巧妙的用反射来设置到对象 metaObject.setValue(property, value); &#125; foundValues = true; &#125; &#125; &#125; &#125; return foundValues;&#125; 又出现了TypeHandler，下面的方法出现了Jdbc代码return rs.getString(columnName); 12345678public class StringTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; return rs.getString(columnName); &#125; 在此Mybatis结果映射处理完成 总结 Mybatis的参数绑定和结果映射最终处理都是通过不同的TypeHandler来处理的，Mybatis也支持自定义TypeHandler 但一般情况Mybatis提供的就可以应付常见需求了","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十六)参数绑定DefaultParameterHandler","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十六)参数绑定DefaultParameterHandler","date":"2018-12-09T01:17:00.000Z","updated":"2019-09-16T13:11:04.802Z","comments":true,"path":"2018/12/09/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十六)参数绑定DefaultParameterHandler/","link":"","permalink":"http://www.songshuiyang.com/2018/12/09/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十六)参数绑定DefaultParameterHandler/","excerpt":"","text":"前言Mybatis 一个重要功能是参数的自动绑定，Mybatis是怎样帮我们做好Jdbc的参数绑定的呢，这一章节来介绍Mybatis的参数绑定 参数绑定解析原生Jdbc参数绑定 在介绍Mybatis参数绑定之前先来看一下原生Jdbc参数绑定是怎样处理的，从下面的Jdbc代码可以看到，是通过下标顺序来设置参数值的，一个问号一个参数 12345String sql = \"insert into user(sno,name,age)values(?,?,?)\";//定义一个要执行的SQL语句PreparedStatement ps = connection.prepareStatement(sql);ps.setString(1,student.getSno());//设置SQL语句的第一个参数ps.setString(2,student.getName());//设置SQL语句的第二个参数ps.setInt(3,student.getAge());//设置SQL语句的第三个参数 Mybatis参数绑定解析下面通过一个示例来介绍 测试用例，下面的代码是通过User对象来查找对应的数据，user设置了两个属性值id 和 admin 12345678910111213// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper1 = sqlSession.getMapper(UserMapper.class);User user = new User();user.setId(1);user.setUsername(\"admin\");System.out.println(userMapper1.selectSelective(user)); xml 配置 1234567891011121314151617&lt;select id=\"selectSelective\" resultType=\"org.apache.songsy.entity.User\" parameterType=\"org.apache.songsy.entity.User\"&gt; SELECT * FROM sys_user &lt;where&gt; &lt;if test=\"id != null\"&gt; AND id = #&#123;id&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username = #&#123;username&#125; &lt;/if&gt; &lt;if test=\"password != null\"&gt; AND password = #&#123;password&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 从第十五章可以知道，由传入的参数对象配合SqlSource 完成了动态Sql的处理， 下面是得到的结果 SELECT * FROM sys_user WHERE id = ? AND username = ?，这里得到了Jdbc的代码，现在要Mybatis要处理的就是这两个问号? image 还是打入断点进入SimpleExecutor 的 doQuery 方法，在这里可以看到这里新建了一个 StatementHandler 这个是SQL语句的执行器，在由来调度sql的参数绑定，sql执行，sql结果映射，现在重点关注stmt = prepareStatement(handler, ms.getStatementLog()); 这一行，看方法名称就大概知道这里是sql之前预备处理 12345678910111213141516@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 新建一个StatementHandler // 这里看到ResultHandler传入了 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 准备语句 stmt = prepareStatement(handler, ms.getStatementLog()); // StatementHandler.query return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 进入stmt = prepareStatement(handler, ms.getStatementLog()); 方法，这里主要是对Connection 和 sql参数 进行了设置，继续跳入handler.parameterize(stmt); 123456789private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection = getConnection(statementLog); // 调用StatementHandler.prepare 设置Connection stmt = handler.prepare(connection); // 调用StatementHandler.parameterize 设置参数 handler.parameterize(stmt); return stmt;&#125; 进入handler.parameterize(stmt);方法之后，转到 RoutingStatementHandler 之后又转入 PreparedStatementHandler，一系列的转发之后进入DefaultParameterHandler 类的setParameters 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class DefaultParameterHandler implements ParameterHandler &#123; private final TypeHandlerRegistry typeHandlerRegistry; private final MappedStatement mappedStatement; // 参数对象 private final Object parameterObject; // BoundSql private BoundSql boundSql; // 万能Configuration private Configuration configuration; public DefaultParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; this.mappedStatement = mappedStatement; this.configuration = mappedStatement.getConfiguration(); this.typeHandlerRegistry = mappedStatement.getConfiguration().getTypeHandlerRegistry(); this.parameterObject = parameterObject; this.boundSql = boundSql; &#125; @Override public Object getParameterObject() &#123; return parameterObject; &#125; // 设置参数 @Override public void setParameters(PreparedStatement ps) throws SQLException &#123; ErrorContext.instance().activity(\"setting parameters\").object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) &#123; // 循环设参数 for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; // 如果不是OUT，才设进去 Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; // issue #448 ask first for additional params // 若有额外的参数, 设为额外的参数 value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; // 若参数为null，直接设null value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; // 若参数有相应的TypeHandler，直接设object value = parameterObject; &#125; else &#123; // 除此以外，MetaObject.getValue反射取得值设进去 MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; // 类型处理器 TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) &#123; // 不同类型的set方法不同，所以委派给子类的setParameter方法 jdbcType = configuration.getJdbcTypeForNull(); &#125; // 用在类型处理器进行赋值 typeHandler.setParameter(ps, i + 1, value, jdbcType); &#125; &#125; &#125; &#125;&#125; 进入setParameters 方法之后，可以看到通过我们之前的BoundSql 得到 ParamterMappings对象，如下图可以知道是两个属性，然后下面的操作就是依次赋值了，不过这里有个特殊的地方，也是Mybatis参数绑定高明之处，就是赋值的操作是通过TypeHandler 来赋值的 image 继续跳入typeHandler.setParameter(ps, i + 1, value, jdbcType); 来到 IntegerTypeHandler的 setNonNullParameter方法，有没有看到曙光ps.setInt(i, parameter); ,在这里做了Jdbc的参数绑定操作 1234567891011121314151617public class IntegerTypeHandler extends BaseTypeHandler&lt;Integer&gt; &#123; @Override public void setNonNullParameter(PreparedStatement ps, int i, Integer parameter, JdbcType jdbcType) throws SQLException &#123; ps.setInt(i, parameter); &#125;``` * 同理第二个参数是字符类型，所以跳到`StringTypeHandler````javapublic class StringTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException &#123; ps.setString(i, parameter); &#125; 在此完成Mybatis参数绑定 总结 Mybatis的参数绑定是通过循环 ParamterMappings对象来依次对对象赋值的，具体赋值工作是对应的TypeHandler 来处理的，当然不同类型有不同的处理类","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十五)基于Mapper的二级缓存","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十五)基于Mapper的二级缓存","date":"2018-12-07T16:01:00.000Z","updated":"2019-12-05T12:19:35.237Z","comments":true,"path":"2018/12/08/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十五)基于Mapper的二级缓存/","link":"","permalink":"http://www.songshuiyang.com/2018/12/08/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十五)基于Mapper的二级缓存/","excerpt":"","text":"前言 mybatis的二级缓存主要是在Executor对象上来做文章，当mybatis发现你在mybatis.xml配置文件中设置了cacheEnabled=true时，mybatis在创建sqlsession时创建Executor对象，同时会对Executor加上装饰者【CacheExecutor】。CacheExecutor对于查询请求，会判断application级别的二级缓存是否有缓存结果，如果有查询结果则直接返回，如果没有再交给查询器Executor实现类，也就是【SimpleExecutor】来执行查询。再就是缓存结果，返回给用户。 二级缓存的使用 配置 mybatis-config.xml1234&lt;settings&gt; &lt;!--开启二级缓存--&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt;&lt;/settings&gt; 配置Mapper xml文件，加上&lt;cache/&gt; 1&lt;cache/&gt; 测试代码 12345678910111213// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession1 = sqlSessionFactory.openSession();SqlSession sqlSession2 = sqlSessionFactory.openSession();UserMapper userMapper1 = sqlSession1.getMapper(UserMapper.class);UserMapper userMapper2 = sqlSession2.getMapper(UserMapper.class);// 测试二级缓存System.out.println(userMapper1.selectByPrimaryKey(1));System.out.println(userMapper2.selectByPrimaryKey(1)); 打好断点进入，这里是二级缓存的处理，从下面可以看到缓存是存放在MappedStatement 对象中的，所以说二级缓存是基于Mapper的，这是与多个SqlSession能够共享缓存的关键 1234567891011121314151617181920public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); // 默认情况下是没有开启缓存的(二级缓存).要开启二级缓存,你需要在你的 SQL 映射文件中添加一行: &lt;cache/&gt; // 简单的说，就是先查CacheKey，查不到再委托给实际的执行器去查 if (cache != null) &#123; flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, parameterObject, boundSql); @SuppressWarnings(\"unchecked\") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125; 可以看到缓存放在tcm 变量上，打开 TransactionalCacheManager 类 123456789101112131415161718192021222324252627282930313233343536373839404142public class TransactionalCacheManager &#123; //管理了许多TransactionalCache private Map&lt;Cache, TransactionalCache&gt; transactionalCaches = new HashMap&lt;Cache, TransactionalCache&gt;(); public void clear(Cache cache) &#123; getTransactionalCache(cache).clear(); &#125; //得到某个TransactionalCache的值 public Object getObject(Cache cache, CacheKey key) &#123; return getTransactionalCache(cache).getObject(key); &#125; public void putObject(Cache cache, CacheKey key, Object value) &#123; getTransactionalCache(cache).putObject(key, value); &#125; //提交时全部提交 public void commit() &#123; for (TransactionalCache txCache : transactionalCaches.values()) &#123; txCache.commit(); &#125; &#125; //回滚时全部回滚 public void rollback() &#123; for (TransactionalCache txCache : transactionalCaches.values()) &#123; txCache.rollback(); &#125; &#125; private TransactionalCache getTransactionalCache(Cache cache) &#123; TransactionalCache txCache = transactionalCaches.get(cache); if (txCache == null) &#123; txCache = new TransactionalCache(cache); transactionalCaches.put(cache, txCache); &#125; return txCache; &#125;&#125; 二级缓存过期策略 映射语句文件中的所有 select 语句将会被缓存。 映射语句文件中的所有 insert,update 和 delete 语句会刷新缓存。 缓存会使用 Least Recently Used(LRU,最近最少使用的)算法来收回。 根据时间表(比如 no Flush Interval,没有刷新间隔), 缓存不会以任何时间顺序 来刷新。 缓存会存储列表集合或对象(无论查询方法返回什么)的 1024 个引用。 缓存会被视为是 read/write(可读/可写)的缓存,意味着对象检索不是共享的,而 且可以安全地被调用者修改,而不干扰其他调用者或线程所做的潜在修改。 二级缓存配置所有的这些属性都可以通过缓存元素的属性来修改。比如:123456789101112131415&lt;cache eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\"/&gt;``` * 这个更高级的配置创建了一个 FIFO 缓存,并每隔 60 秒刷新,存数结果对象或列表的 512 个引用,而且返回的对象被认为是只读的,因此在不同线程中的调用者之间修改它们会 导致冲突。可用的收回策略有: 默认的是 LRU。```xmlLRU – 最近最少使用的:移除最长时间不被使用的对象。FIFO – 先进先出:按对象进入缓存的顺序来移除它们。SOFT – 软引用:移除基于垃圾回收器状态和软引用规则的对象。WEAK – 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。 flushInterval(刷新间隔)可以被设置为任意的正整数,而且它们代表一个合理的毫秒 形式的时间段。默认情况是不设置,也就是没有刷新间隔,缓存仅仅调用语句时刷新。 size(引用数目)可以被设置为任意正整数,要记住你缓存的对象数目和你运行环境的 可用内存资源数目。默认值是 1024。 readOnly(只读)属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓 存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。可读写的缓存 会返回缓存对象的拷贝(通过序列化) 。这会慢一些,但是安全,因此默认是 false。 二级缓存设计 image 总结 mybatis的二级缓存主要是在Executor对象上来做文章，当mybatis发现你在mybatis.xml配置文件中设置了cacheEnabled=true时，mybatis在创建sqlsession时创建Executor对象，同时会对Executor加上装饰者【CacheExecutor】。CacheExecutor对于查询请求，会判断application级别的二级缓存是否有缓存结果，如果有查询结果则直接返回，如果没有再交给查询器Executor实现类，也就是【SimpleExecutor】来执行查询。再就是缓存结果，返回给用户。 避免使用二级缓存，如果出现联合查询语句，如果其中一张表发生了变化，就会出现脏数据的问题，因为缓存节点是根据namespace 参考： http://www.mybatis.org/mybatis-3/zh","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十四)基于SqlSession的一级缓存","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十四)基于SqlSession的一级缓存","date":"2018-12-07T16:00:00.000Z","updated":"2019-12-05T12:19:35.245Z","comments":true,"path":"2018/12/08/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十四)基于SqlSession的一级缓存/","link":"","permalink":"http://www.songshuiyang.com/2018/12/08/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十四)基于SqlSession的一级缓存/","excerpt":"","text":"前言MyBatis提供了一级缓存、二级缓存 这两种缓存机制，能够很好地处理和维护缓存，以提高系统的性能。本章的内容是介绍MyBatis的一级缓存，深入源码，解析MyBatis一级缓存的实现原理，二级缓存将在下一章介绍 一级缓存的使用 下面来通过代码来实践一级缓存，看看第二次查询是否使用了缓存 1234567891011// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper = sqlSession.getMapper(UserMapper.class);System.out.println(\"第一次查询: \"+userMapper.selectByPrimaryKey(1));System.out.println(\"第二次查询: \"+userMapper.selectByPrimaryKey(1)); 上面的代码是用SqlSession获取了UserMapper，然后用UserMapper 进行了两次查询，打好断点进入MapperProxy 的invoke 方法 12345678910111213141516@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 代理以后，所有Mapper的方法调用时，都会调用这个invoke方法 // 并不是任何一个方法都需要执行调用代理对象进行执行，如果这个方法是Object中通用的方法（toString、hashCode等）无需执行 if (Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, args); &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125; // 这里优化了，去缓存中找MapperMethod final MapperMethod mapperMethod = cachedMapperMethod(method); //执行 return mapperMethod.execute(sqlSession, args);&#125; 进入mapperMethod.execute(sqlSession, args) 之后跳呀跳进入BaseExecutor 的 query 方法，这个看到会创建一个CacheKey 123456789 @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; // 得到绑定sql BoundSql boundSql = ms.getBoundSql(parameter); // 创建缓存Key CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); // 查询 return query(ms, parameter, rowBounds, resultHandler, key, boundSql);&#125; 下面来看一下这个key是怎么生成的 12345678910111213141516171819202122232425262728293031323334353637383940//创建缓存Key@Overridepublic CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; CacheKey cacheKey = new CacheKey(); // MyBatis 对于其 Key 的生成采取规则为：[mappedStementId + offset + limit + SQL + queryParams + environment]生成一个哈希码 cacheKey.update(ms.getId()); cacheKey.update(Integer.valueOf(rowBounds.getOffset())); cacheKey.update(Integer.valueOf(rowBounds.getLimit())); cacheKey.update(boundSql.getSql()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry(); // mimic DefaultParameterHandler logic // 模仿DefaultParameterHandler的逻辑,不再重复，请参考DefaultParameterHandler for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; cacheKey.update(value); &#125; &#125; if (configuration.getEnvironment() != null) &#123; // issue #176 cacheKey.update(configuration.getEnvironment().getId()); &#125; return cacheKey;&#125; 得到CacheKey 之后 跳入return query(ms, parameter, rowBounds, resultHandler, key, boundSql); 在这里对一级缓存进行了处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445@SuppressWarnings(\"unchecked\")@Overridepublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); //如果已经关闭，报错 if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; //先清局部缓存，再查询.但仅查询堆栈为0，才清。为了处理递归调用 if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; //加一,这样递归调用到上面的时候就不会再清局部缓存了 queryStack++; //先根据cachekey从localCache去查 list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; //若查到localCache缓存，处理localOutputParameterCache handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; //从数据库查 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; //清空堆栈 queryStack--; &#125; if (queryStack == 0) &#123; //延迟加载队列中所有元素 for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 //清空延迟加载队列 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 //如果是STATEMENT，清本地缓存 clearLocalCache(); &#125; &#125; return list;&#125; 重点是下面几行代码，可以看到先根据cachekey从localCache去查，如果有就返回缓存里的数据，没有就从数据库里查 123456789// 先根据cachekey从localCache去查list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null;if (list != null) &#123; // 若查到localCache缓存，处理localOutputParameterCache handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);&#125; else &#123; // 从数据库查 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);&#125; 下面来看localCache 的本体PerpetualCache, 从下面的代码就可以看见其内部实现就是Map&lt;Object, Object&gt; cache 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * 永久缓存 * 一旦存入就一直保持 * @author Clinton Begin */public class PerpetualCache implements Cache &#123; // 每个永久缓存有一个ID来识别 private String id; // 内部就是一个HashMap,所有方法基本就是直接调用HashMap的方法 private Map&lt;Object, Object&gt; cache = new HashMap&lt;Object, Object&gt;(); public PerpetualCache(String id) &#123; this.id = id; &#125; @Override public String getId() &#123; return id; &#125; @Override public int getSize() &#123; return cache.size(); &#125; @Override public void putObject(Object key, Object value) &#123; cache.put(key, value); &#125; @Override public Object getObject(Object key) &#123; return cache.get(key); &#125; @Override public Object removeObject(Object key) &#123; return cache.remove(key); &#125; @Override public void clear() &#123; cache.clear(); &#125; @Override public ReadWriteLock getReadWriteLock() &#123; return null; &#125; @Override public boolean equals(Object o) &#123; //只要id相等就认为两个cache相同 if (getId() == null) &#123; throw new CacheException(\"Cache instances require an ID.\"); &#125; if (this == o) &#123; return true; &#125; if (!(o instanceof Cache)) &#123; return false; &#125; Cache otherCache = (Cache) o; return getId().equals(otherCache.getId()); &#125; @Override public int hashCode() &#123; if (getId() == null) &#123; throw new CacheException(\"Cache instances require an ID.\"); &#125; return getId().hashCode(); &#125;&#125; 现在回到主线，因为第一次查询一级缓存是没有数据的，所以继续执行queryFromDatabase，从下面的方法可以看到在这里实现了缓存的加入操作localCache.putObject(key, list); 12345678910111213141516171819// 从数据库查private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; // 先向缓存中放入占位符 localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; // 最后删除占位符 localCache.removeObject(key); &#125; // 加入缓存 localCache.putObject(key, list); // 如果是存储过程，OUT参数也加入缓存 if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; 一级缓存的生命周期有多长 MyBatis在开启一个数据库会话时，会 创建一个新的SqlSession对象，SqlSession对象中会有一个新的Executor对象，Executor对象中持有一个新的PerpetualCache对象；当会话结束时，SqlSession对象及其内部的Executor对象还有PerpetualCache对象也一并释放掉。 iamge 如果SqlSession调用了close()方法，会释放掉一级缓存PerpetualCache对象，一级缓存将不可用； 123456789101112131415161718192021@Overridepublic void close(boolean forceRollback) &#123; try &#123; try &#123; rollback(forceRollback); &#125; finally &#123; if (transaction != null) &#123; transaction.close(); &#125; &#125; &#125; catch (SQLException e) &#123; // Ignore. There's nothing that can be done at this point. log.warn(\"Unexpected exception on closing transaction. Cause: \" + e); &#125; finally &#123; transaction = null; deferredLoads = null; localCache = null; localOutputParameterCache = null; closed = true; &#125;&#125; 如果SqlSession调用了clearCache()，会清空PerpetualCache对象中的数据，但是该对象仍可使用； 1234567@Overridepublic void clearLocalCache() &#123; if (!closed) &#123; localCache.clear(); localOutputParameterCache.clear(); &#125;&#125; SqlSession中执行了任何一个update操作(update()、delete()、insert()) ，都会清空PerpetualCache对象的数据，但是该对象可以继续使用； 1234567891011// SqlSession.update/insert/delete会调用此方法@Overridepublic int update(MappedStatement ms, Object parameter) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing an update\").object(ms.getId()); if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; //先清局部缓存，再更新，如何更新交由子类，模板方法模式 clearLocalCache(); return doUpdate(ms, parameter);&#125; 缓存分析为什么要使用一级缓存使用缓存是为了提高查询效率，减少资源消费，如果我们在极短的时间内做了完全相同的查询，那么它们的结果极有可能完全相同 所以为了解决这一问题，减少资源的浪费，MyBatis会在表示会话的SqlSession对象中建立一个简单的缓存，将每次查询到的结果结果缓存起来，当下次查询的时候，如果判断先前有个完全一样的查询，会直接从缓存中直接将结果取出，返回给用户，不需要再进行一次数据库查询了 如下图所示，MyBatis会在一次会话的表示—-一个SqlSession对象中创建一个本地缓存(local cache)，对于每一次查询，都会尝试根据查询的条件去本地缓存中查找是否在缓存中，如果在缓存中，就直接从缓存中取出，然后返回给用户；否则，从数据库读取数据，将查询结果存入缓存并返回给用户。 image 一级缓存查询时序图 image CacheKey的定义 Cache最核心的实现其实就是一个Map，将本次查询使用的特征值作为key，将查询结果作为value存储到Map中。 现在最核心的问题出现了：怎样来确定一次查询的特征值？ MyBatis认为，对于两次查询，如果以下条件都完全一样，那么就认为它们是完全相同的两次查询 123451. 传入的statementId，对于MyBatis而言，你要使用它，必须需要一个statementId，它代表着你将执行什么样的Sql；2. MyBatis自身提供的分页功能是通过RowBounds来实现的，它通过rowBounds.offset和rowBounds.limit来过滤查询出来的结果集，这种分页功能是基于查询结果的再过滤，而不是进行数据库的物理分页；3. 由于MyBatis底层还是依赖于JDBC实现的，那么，对于两次完全一模一样的查询，MyBatis要保证对于底层JDBC而言，也是完全一致的查询才行。而对于JDBC而言，两次查询，只要传入给JDBC的SQL语句完全一致，传入的参数也完全一致，就认为是两次查询是完全一致的。 下面是创建CacheKey的代码 12345678910111213141516171819202122232425262728293031323334353637383940//创建缓存Key@Overridepublic CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; CacheKey cacheKey = new CacheKey(); // MyBatis 对于其 Key 的生成采取规则为：[mappedStementId + offset + limit + SQL + queryParams + environment]生成一个哈希码 cacheKey.update(ms.getId()); cacheKey.update(Integer.valueOf(rowBounds.getOffset())); cacheKey.update(Integer.valueOf(rowBounds.getLimit())); cacheKey.update(boundSql.getSql()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry(); // mimic DefaultParameterHandler logic // 模仿DefaultParameterHandler的逻辑,不再重复，请参考DefaultParameterHandler for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; cacheKey.update(value); &#125; &#125; if (configuration.getEnvironment() != null) &#123; // issue #176 cacheKey.update(configuration.getEnvironment().getId()); &#125; return cacheKey;&#125; 总结 一级缓存的作用级别是Session级别的，因为一个Session中存放一个Executor。而一级缓存放在Executor，如果缓存中有数据就不用从数据库中获取，大大提高系统性能。 注意事项： 一级缓存是默认开启的 如果是第一次查询完成之后，然后手动去改数据库，第二次再次读的时候这个时候的数据就不是新数据了 参考：https://blog.csdn.net/chenyao1994/article/details/79233725","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十三)动态Sql实现之BoundSql","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十三)动态Sql实现之BoundSql","date":"2018-12-06T10:43:00.000Z","updated":"2019-12-05T12:19:35.228Z","comments":true,"path":"2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十三)动态Sql实现之BoundSql/","link":"","permalink":"http://www.songshuiyang.com/2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十三)动态Sql实现之BoundSql/","excerpt":"","text":"前言上一章节介绍了SqlSource ，这一章节来介绍 BoundSql，BoundSql 由 SqlSource 生产，BoundSql 存放了动态sql处理后的private String sql;,动态内容处理完成得到的SQL语句字符串，其中包括?,还有绑定的参数 BoundSql 介绍 下面是 BoundSql 的源码，里面又对其变量的介绍 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 绑定的SQL,是从SqlSource而来，将动态内容都处理完成得到的SQL语句字符串，其中包括?,还有绑定的参数 * * An actual SQL String got form an &#123;@link SqlSource&#125; after having processed any dynamic content. * The SQL may have SQL placeholders \"?\" and an list (ordered) of an parameter mappings * with the additional information for each parameter (at least the property name of the input object to read * the value from). * &lt;/br&gt; * Can also have additional parameters that are created by the dynamic language (for loops, bind...). * @author Clinton Begin */public class BoundSql &#123; // 处理完成得到的SQL语句字符串，其中包括?,还有绑定的参数 private String sql; // 参数映射对象 private List&lt;ParameterMapping&gt; parameterMappings; // 外面传入的sql参数 private Object parameterObject; // 额外参数？ private Map&lt;String, Object&gt; additionalParameters; // 参数元数据 private MetaObject metaParameters; public BoundSql(Configuration configuration, String sql, List&lt;ParameterMapping&gt; parameterMappings, Object parameterObject) &#123; this.sql = sql; this.parameterMappings = parameterMappings; this.parameterObject = parameterObject; this.additionalParameters = new HashMap&lt;String, Object&gt;(); this.metaParameters = configuration.newMetaObject(additionalParameters); &#125; public String getSql() &#123; return sql; &#125; public List&lt;ParameterMapping&gt; getParameterMappings() &#123; return parameterMappings; &#125; public Object getParameterObject() &#123; return parameterObject; &#125; public boolean hasAdditionalParameter(String name) &#123; return metaParameters.hasGetter(name); &#125; public void setAdditionalParameter(String name, Object value) &#123; metaParameters.setValue(name, value); &#125; public Object getAdditionalParameter(String name) &#123; return metaParameters.getValue(name); &#125;&#125; BoundSql 构造 BoundSql 由 SqlSource 生产，SqlSource 有四个实现类，但最常用的是 DynamicSqlSource，下面是其源码，可以看到只有一个方法public BoundSql getBoundSql(Object parameterObject) 12345678910111213141516171819202122232425262728293031323334/** * 动态SQL源码 * @author Clinton Begin */public class DynamicSqlSource implements SqlSource &#123; private Configuration configuration; private SqlNode rootSqlNode; public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123; this.configuration = configuration; this.rootSqlNode = rootSqlNode; &#125; // 得到绑定的SQL @Override public BoundSql getBoundSql(Object parameterObject) &#123; // 生成一个动态上下文 DynamicContext context = new DynamicContext(configuration, parameterObject); // 这里SqlNode.apply只是将$&#123;&#125;这种参数替换掉，并没有替换#&#123;&#125;这种参数 rootSqlNode.apply(context); // 调用SqlSourceBuilder SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); // SqlSourceBuilder.parse,注意这里返回的是StaticSqlSource,解析完了就把那些参数都替换成?了，也就是最基本的JDBC的SQL写法 SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 看似是又去递归调用SqlSource.getBoundSql，其实因为是StaticSqlSource，所以没问题，不是递归调用 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql; &#125;&#125; 下面通过一个例子来解析 BoundSql 的构造 xml 配置文件1234567891011121314151617&lt;select id=\"selectSelective\" resultType=\"org.apache.songsy.entity.User\" parameterType=\"org.apache.songsy.entity.User\"&gt; SELECT * FROM sys_user &lt;where&gt; &lt;if test=\"id != null\"&gt; AND id = #&#123;id&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username = #&#123;username&#125; &lt;/if&gt; &lt;if test=\"password != null\"&gt; AND password = #&#123;password&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 测试用例，user对象给id和username赋值了对象 12345678910111213// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper1 = sqlSession.getMapper(UserMapper.class);User user = new User();user.setId(1);user.setUsername(\"admin\");System.out.println(userMapper1.selectSelective(user)); 打好断点进入到 CachingExecutor 的query方法，第一行可以看到 BoundSql 是由MappedStatement 的方法得到的，getBoundSql 方法只传入了参数对象，在这里是User对象 1234567 @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameterObject);//query时传入一个cachekey参数 CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; 进入ms.getBoundSql(parameterObject); 方法，重点关注 BoundSql boundSql = sqlSource.getBoundSql(parameterObject);，没错在这里出现了我们的SqlSource对象 1234567891011121314151617181920 public BoundSql getBoundSql(Object parameterObject) &#123;//其实就是调用sqlSource.getBoundSql BoundSql boundSql = sqlSource.getBoundSql(parameterObject); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings == null || parameterMappings.isEmpty()) &#123; boundSql = new BoundSql(configuration, boundSql.getSql(), parameterMap.getParameterMappings(), parameterObject); &#125; // check for nested result maps in parameter mappings (issue #30) for (ParameterMapping pm : boundSql.getParameterMappings()) &#123; String rmId = pm.getResultMapId(); if (rmId != null) &#123; ResultMap rm = configuration.getResultMap(rmId); if (rm != null) &#123; hasNestedResultMaps |= rm.hasNestedResultMaps(); &#125; &#125; &#125; return boundSql; &#125; 进入sqlSource.getBoundSql(parameterObject) 方法，这个方法是DynamicSqlSource 的唯一方法，当然SqlSource作用就是得到绑定后的BoundSql对象 12345678910111213141516171819202122232425262728293031323334/** * 动态SQL源码 * @author Clinton Begin */public class DynamicSqlSource implements SqlSource &#123; private Configuration configuration; private SqlNode rootSqlNode; public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123; this.configuration = configuration; this.rootSqlNode = rootSqlNode; &#125; // 得到绑定的SQL @Override public BoundSql getBoundSql(Object parameterObject) &#123; // 生成一个动态上下文 DynamicContext context = new DynamicContext(configuration, parameterObject); // 这里SqlNode.apply只是将$&#123;&#125;这种参数替换掉，并没有替换#&#123;&#125;这种参数 rootSqlNode.apply(context); // 调用SqlSourceBuilder SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); // SqlSourceBuilder.parse,注意这里返回的是StaticSqlSource,解析完了就把那些参数都替换成?了，也就是最基本的JDBC的SQL写法 SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 看似是又去递归调用SqlSource.getBoundSql，其实因为是StaticSqlSource，所以没问题，不是递归调用 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql; &#125;&#125; 先看rootSqlNode.apply(context); 这行代码，打开断点进入会发现这里依次调用list里每个元素的apply方法，这里是实现动态SQL的关键，如果有嵌套的话也会嵌套执行里面的apply方法 image 静态sqlNode 的apply方法就是直接 appendSql 123456789101112131415public class StaticTextSqlNode implements SqlNode &#123; private String text; public StaticTextSqlNode(String text) &#123; this.text = text; &#125; @Override public boolean apply(DynamicContext context) &#123; //将文本加入context context.appendSql(text); return true; &#125;&#125; if SQL节点的apply方法 会做一个判断，如果 test=&quot;id != null&quot; 这个表达式为true就会 contents.apply(context); 添加到DynamicContext中，DynamicContext 内部成员 StringBuilder sqlBuilder 来存放解析后的sql 1234567891011121314151617181920212223242526/** * if SQL节点 * */public class IfSqlNode implements SqlNode &#123; private ExpressionEvaluator evaluator; private String test; private SqlNode contents; public IfSqlNode(SqlNode contents, String test) &#123; this.test = test; this.contents = contents; this.evaluator = new ExpressionEvaluator(); &#125; @Override public boolean apply(DynamicContext context) &#123; // 如果满足条件，则apply，并返回true if (evaluator.evaluateBoolean(test, context.getBindings())) &#123; contents.apply(context); return true; &#125; return false; &#125;&#125; rootSqlNode.apply(context); 处理完成之后就会得到拼接后的sql如下图所示，可以看到这里SqlNode.apply只是将${}这种参数替换掉，并没有替换#{}这种参数 image SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); 这个方法是解析完了就把那些参数都替换成?，也就是最基本的JDBC的SQL写法，这个方法在以后章节将介绍 最终的到的结果(BoundSql)如下图所示 image 总结 BoundSql 由 SqlSource 构造而成，最终得到的是JDBC的SQL，而实现动态Sql的关键是 各个SqlNode的 apply方法 通过源码可以看到Mybatis动态sql设计巧妙，分工明确","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十二)动态Sql实现之SqlSource","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十二)动态Sql实现之SqlSource","date":"2018-12-06T10:41:00.000Z","updated":"2019-12-05T12:19:35.235Z","comments":true,"path":"2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十二)动态Sql实现之SqlSource/","link":"","permalink":"http://www.songshuiyang.com/2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十二)动态Sql实现之SqlSource/","excerpt":"","text":"前言从本章开始将介绍Mybatis是怎样实现动态sql的，介绍动态sql实现之前先介绍几个重要对象SqlSource，SqlNode ，BoundSql ,本章开始介绍SqlSource对象， 前面第九章及第十章介绍了SqlSource的构造过程，在xml配置的select update节点的sql将会构造成 SqlSource，其 SqlSource 由一组SqlNode组成，现在来看一下SqlSource能做什么 SqlSource 分析 查看SqlSource 是个接口，但他只有一个方法就是BoundSql getBoundSql(Object parameterObject); ，方法参数是sql的参数，然后根据参数来构造成BoundSql，所以他的作用是根据参数对象生产BoundSql，那么BoundSql有什么用呢，下一章节将介绍其作用 12345public interface SqlSource &#123; BoundSql getBoundSql(Object parameterObject);&#125; 下图可以看到SqlSource 其实现类，主要有4种类型 image DynamicSqlSource:处理动态sql语句。 RawSqlSource：处理静态sql语句，其内部装饰StaticSqlSource。 StaticSqlSource：处理静态sql，无论是静态sql，还是动态sql，最终的处理结果，都是静态sql。 ProviderSqlSource:处理注解Annotation形式的sql。 VelocitySqlSource:只是Mybatis的一个测试类 举个栗子，下面是一个动态sql的xml 1234567891011121314151617&lt;select id=\"selectSelective\" resultType=\"org.apache.songsy.entity.User\" parameterType=\"org.apache.songsy.entity.User\"&gt; SELECT * FROM sys_user &lt;where&gt; &lt;if test=\"id != null\"&gt; AND id = #&#123;id&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username = #&#123;username&#125; &lt;/if&gt; &lt;if test=\"password != null\"&gt; AND password = #&#123;password&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 那么解析成SqlSource将会是下面的样子，SqlSource 是存放在MappedStatement对象的，可以看到SqlSource是一堆嵌套的SqlNode组成 image 从DynamicSqlSource可以看到主要方法就是通过参数对象parameterObject来获取BoundSql对象，BoundSql 存放了动态sql处理后的语句 12345678910111213141516171819202122232425262728293031323334/** * 动态SQL源码 * @author Clinton Begin */public class DynamicSqlSource implements SqlSource &#123; private Configuration configuration; private SqlNode rootSqlNode; public DynamicSqlSource(Configuration configuration, SqlNode rootSqlNode) &#123; this.configuration = configuration; this.rootSqlNode = rootSqlNode; &#125; // 得到绑定的SQL @Override public BoundSql getBoundSql(Object parameterObject) &#123; // 生成一个动态上下文 DynamicContext context = new DynamicContext(configuration, parameterObject); // 这里SqlNode.apply只是将$&#123;&#125;这种参数替换掉，并没有替换#&#123;&#125;这种参数 rootSqlNode.apply(context); // 调用SqlSourceBuilder SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); // SqlSourceBuilder.parse,注意这里返回的是StaticSqlSource,解析完了就把那些#&#123;password&#125;参数都替换成?了，也就是最基本的JDBC的SQL写法 SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 看似是又去递归调用SqlSource.getBoundSql，其实因为是StaticSqlSource，所以没问题，不是递归调用 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql; &#125;&#125; 总结 有图有栗子来理解SqlSource 就很形象了，有了SqlSource就相当于生产商品有基本原材料了，当然原材料(SqlNode)种类有很多，Mybatis会根据用户的需求(**Mapper.xml) 来采购不同的原材料 SqlSource","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十一)MapperXML映射文件OGNL表达式","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十一)MapperXML映射文件OGNL表达式","date":"2018-12-06T10:40:00.000Z","updated":"2019-12-05T12:19:35.226Z","comments":true,"path":"2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十一)MapperXML映射文件OGNL表达式/","link":"","permalink":"http://www.songshuiyang.com/2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十一)MapperXML映射文件OGNL表达式/","excerpt":"","text":"基本介绍 OGNL是Object-Graph Navigation Language的缩写，它是一种功能强大的表达式语言，通过它简单一致的表达式语法，可以存取对象的任意属性，调用对象的方法，遍历整个对象的结构图，实现字段类型转化等功能。它使用相同的表达式去存取对象的属性。 Struts2框架使用OGNL作为默认的表达式语言 OGNL是一种比EL强大很多倍的语言，支持对象方法调用，支持静态方法和字段访问，支持赋值操作等等。 xwork提供了OGNL表达式。 其jar包为ognl-x.x.x.jar。 MyBatis常用OGNL表达式123456789101112131415•e1 or e2•e1 and e2•e1 == e2,e1 eq e2•e1 != e2,e1 neq e2•e1 lt e2：小于•e1 lte e2：小于等于，其他gt（大于）,gte（大于等于）•e1 in e2•e1 not in e2•e1 + e2,e1 * e2,e1/e2,e1 - e2,e1%e2•!e,not e：非，求反•e.method(args)调用对象方法•e.property对象属性值•e1[ e2 ]按索引取值，List,数组和Map•@class@method(args)调用类的静态方法•@class@field调用类的静态字段值 MyBatis中可以使用OGNL的地方有两处 动态SQL表达式中 ${param}参数中 上面这两处地方在MyBatis中处理的时候都是使用OGNL处理的。 下面通过举例来说明这两种情况的用法。 动态SQL表达式中 下面代码中test的值会使用OGNL计算结果。 12345678&lt;select id=\"xxx\" ...&gt; select id,name,... from country &lt;where&gt; &lt;if test=\"name != null and name != ''\"&gt; name like concat('%', #&#123;name&#125;, '%') &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 通用 like 查询及的value值会使用OGNL计算 123456789&lt;select id=\"xxx\" ...&gt; select id,name,... from country &lt;bind name=\"nameLike\" value=\"'%' + name + '%'\"/&gt; &lt;where&gt; &lt;if test=\"name != null and name != ''\"&gt; name like #&#123;nameLike&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 通用Mapper中支持一种UUID的主键 1&lt;bind name=\"username_bind\" value='@java.util.UUID@randomUUID().toString().replace(\"-\", \"\")' /&gt; ${param}参数中1234567891011121314&lt;select id=\"xxx\" ...&gt; select id,name,... from country &lt;where&gt; &lt;if test=\"name != null and name != ''\"&gt; name like '$&#123;'%' + name + '%'&#125;' &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 这里注意写的是$&#123;'%' + name + '%'&#125; ，而不是%$&#123;name&#125;% ，这两种方式的结果一样，但是处理过程不一样。 在MyBatis中处理$&#123;&#125;的时候，只是使用OGNL计算这个结果值，然后替换SQL中对应的$&#123;xxx&#125; ，OGNL处理的只是$&#123;这里的表达式&#125;。 这里表达式可以是OGNL支持的所有表达式，可以写的很复杂，可以调用静态方法返回值，也可以调用静态的属性值。 参考：https://www.jb51.net/article/116160.htm","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(十)MapperXML映射文件构建SqlNode","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十)MapperXML映射文件构建SqlNode","date":"2018-12-06T02:40:00.000Z","updated":"2019-12-05T12:19:35.222Z","comments":true,"path":"2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十)MapperXML映射文件构建SqlNode/","link":"","permalink":"http://www.songshuiyang.com/2018/12/06/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(十)MapperXML映射文件构建SqlNode/","excerpt":"","text":"前言 上一章节介绍了SqlSource的构造过程，SqlSource 由一堆SqlNode构成，本章来介绍SqlNode的构造，如下图可以看到SqlNode的主要成员 image 源码解析SqlNode 还是回到 parseScriptNode 方法，关注List&lt;SqlNode&gt; contents = parseDynamicTags(context); 这个方法会把 select|insert|update|delete 这些标签的sql解析成一堆SqlNode, 包括静态SqlNode 和动态SqlNode(可见上图) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public SqlSource parseScriptNode() &#123; // 获取SqlNode List List&lt;SqlNode&gt; contents = parseDynamicTags(context); MixedSqlNode rootSqlNode = new MixedSqlNode(contents); SqlSource sqlSource = null; if (isDynamic) &#123; sqlSource = new DynamicSqlSource(configuration, rootSqlNode); &#125; else &#123; sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); &#125; return sqlSource;&#125;List&lt;SqlNode&gt; parseDynamicTags(XNode node) &#123; // 一行一个SqlNode List&lt;SqlNode&gt; contents = new ArrayList&lt;SqlNode&gt;(); NodeList children = node.getNode().getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) &#123; XNode child = node.newXNode(children.item(i)); // 如果节点类型CDATA或者是文本，构造一个TextSqlNode或StaticTextSqlNode if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE || child.getNode().getNodeType() == Node.TEXT_NODE) &#123; String data = child.getStringBody(\"\"); TextSqlNode textSqlNode = new TextSqlNode(data); if (textSqlNode.isDynamic()) &#123; contents.add(textSqlNode); isDynamic = true; &#125; else &#123; contents.add(new StaticTextSqlNode(data)); &#125; &#125; else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) &#123; // 如果是xml标签 trim|where|set... String nodeName = child.getNode().getNodeName(); // 得到动态sql标签处理类 trim|where|set... NodeHandler handler = nodeHandlers(nodeName); if (handler == null) &#123; throw new BuilderException(\"Unknown element &lt;\" + nodeName + \"&gt; in SQL statement.\"); &#125; // 解析动态结点 handler.handleNode(child, contents); isDynamic = true; &#125; &#125; return contents;&#125;NodeHandler nodeHandlers(String nodeName) &#123; Map&lt;String, NodeHandler&gt; map = new HashMap&lt;String, NodeHandler&gt;(); map.put(\"trim\", new TrimHandler()); map.put(\"where\", new WhereHandler()); map.put(\"set\", new SetHandler()); map.put(\"foreach\", new ForEachHandler()); map.put(\"if\", new IfHandler()); map.put(\"choose\", new ChooseHandler()); map.put(\"when\", new IfHandler()); map.put(\"otherwise\", new OtherwiseHandler()); map.put(\"bind\", new BindHandler()); return map.get(nodeName);&#125; SqlNode 是 Mybatis 实现动态sql的核心，下面来看看一些常用节点的的处理，IfSqlNode 节点 12345678910111213141516171819202122232425/** * if SQL节点 * @author Clinton Begin */public class IfSqlNode implements SqlNode &#123; private ExpressionEvaluator evaluator; private String test; private SqlNode contents; public IfSqlNode(SqlNode contents, String test) &#123; this.test = test; this.contents = contents; this.evaluator = new ExpressionEvaluator(); &#125; @Override public boolean apply(DynamicContext context) &#123; // 如果满足条件，则apply，并返回true if (evaluator.evaluateBoolean(test, context.getBindings())) &#123; contents.apply(context); return true; &#125; return false; &#125;&#125; ForEachSqlNode 节点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * foreach SQL节点 * @author Clinton Begin */public class ForEachSqlNode implements SqlNode &#123; public static final String ITEM_PREFIX = \"__frch_\"; private ExpressionEvaluator evaluator; private String collectionExpression; private SqlNode contents; private String open; private String close; private String separator; private String item; private String index; private Configuration configuration; public ForEachSqlNode(Configuration configuration, SqlNode contents, String collectionExpression, String index, String item, String open, String close, String separator) &#123; this.evaluator = new ExpressionEvaluator(); this.collectionExpression = collectionExpression; this.contents = contents; this.open = open; this.close = close; this.separator = separator; this.index = index; this.item = item; this.configuration = configuration; &#125; @Override public boolean apply(DynamicContext context) &#123; Map&lt;String, Object&gt; bindings = context.getBindings(); //解析collectionExpression-&gt;iterable,核心用的ognl final Iterable&lt;?&gt; iterable = evaluator.evaluateIterable(collectionExpression, bindings); if (!iterable.iterator().hasNext()) &#123; return true; &#125; boolean first = true; //加上( applyOpen(context); int i = 0; for (Object o : iterable) &#123; DynamicContext oldContext = context; if (first) &#123; context = new PrefixedContext(context, \"\"); &#125; else if (separator != null) &#123; context = new PrefixedContext(context, separator); &#125; else &#123; context = new PrefixedContext(context, \"\"); &#125; int uniqueNumber = context.getUniqueNumber(); // Issue #709 if (o instanceof Map.Entry) &#123; @SuppressWarnings(\"unchecked\") Map.Entry&lt;Object, Object&gt; mapEntry = (Map.Entry&lt;Object, Object&gt;) o; applyIndex(context, mapEntry.getKey(), uniqueNumber); applyItem(context, mapEntry.getValue(), uniqueNumber); &#125; else &#123; //索引 applyIndex(context, i, uniqueNumber); //加上一个元素 applyItem(context, o, uniqueNumber); &#125; contents.apply(new FilteredDynamicContext(configuration, context, index, item, uniqueNumber)); if (first) &#123; first = !((PrefixedContext) context).isPrefixApplied(); &#125; context = oldContext; i++; &#125; //加上) applyClose(context); return true; &#125; ... MixedSqlNode 这个Node比较特殊，获得的SqlNode会以list放在 MixedSqlNode中 123456789101112131415161718192021/** * 混合SQL节点 * @author Clinton Begin */public class MixedSqlNode implements SqlNode &#123; // 组合模式，拥有一个SqlNode的List private List&lt;SqlNode&gt; contents; public MixedSqlNode(List&lt;SqlNode&gt; contents) &#123; this.contents = contents; &#125; @Override public boolean apply(DynamicContext context) &#123; // 依次调用list里每个元素的apply for (SqlNode sqlNode : contents) &#123; sqlNode.apply(context); &#125; return true; &#125;&#125; selectByPrimaryKey 解析成果，见下图 123456&lt;select id=\"selectByPrimaryKey\" resultMap=\"BaseResultMap\" parameterType=\"java.lang.Integer\" &gt; select &lt;include refid=\"Base_Column_List\" /&gt; from sys_role where id = #&#123;id,jdbcType=INTEGER&#125;&lt;/select&gt; image updateByPrimaryKeySelective 解析成果，见下图 123456789101112131415161718192021222324252627282930313233343536&lt;update id=\"updateByPrimaryKeySelective\" parameterType=\"org.apache.songsy.entity.Role\" &gt; update sys_role &lt;set &gt; &lt;if test=\"roleName != null\" &gt; role_name = #&#123;roleName,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"roleCode != null\" &gt; role_code = #&#123;roleCode,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"roleDescribe != null\" &gt; role_describe = #&#123;roleDescribe,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"createdDate != null\" &gt; created_date = #&#123;createdDate,jdbcType=TIMESTAMP&#125;, &lt;/if&gt; &lt;if test=\"createdBy != null\" &gt; created_by = #&#123;createdBy,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"lastModifiedDate != null\" &gt; last_modified_date = #&#123;lastModifiedDate,jdbcType=TIMESTAMP&#125;, &lt;/if&gt; &lt;if test=\"lastModifiedBy != null\" &gt; last_modified_by = #&#123;lastModifiedBy,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"remarks != null\" &gt; remarks = #&#123;remarks,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"status != null\" &gt; status = #&#123;status,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;if test=\"enable != null\" &gt; enable = #&#123;enable,jdbcType=BIT&#125;, &lt;/if&gt; &lt;/set&gt; where id = #&#123;id,jdbcType=INTEGER&#125;&lt;/update&gt; image 总结 SqlNode 是 Mybatis 实现动态sql的核心，各种动态标签是通过不同的SqlNode子类来实现的，可以看到Mybatis会将xml的sql语句封装为一个个Node节点，不同的节点有不同的处理方式","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(九)MapperXML映射文件构建SqlSource","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(九)MapperXML映射文件构建SqlSource","date":"2018-12-01T02:40:00.000Z","updated":"2019-12-05T12:19:35.186Z","comments":true,"path":"2018/12/01/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(九)MapperXML映射文件构建SqlSource/","link":"","permalink":"http://www.songshuiyang.com/2018/12/01/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(九)MapperXML映射文件构建SqlSource/","excerpt":"","text":"前言 上一章节介绍了select|insert|update|delete 这些sql标签会解析成MappedStatement对象，MappedStatement 对象的重点属性是SqlSource，本章来介绍SqlSource的构造过程，其最终执行的sql字符串就是由SqlSource提供的。 源码解析SqlSource 类下图可以看到其实现类，主要有4种类型 image DynamicSqlSource:处理动态sql语句。 RawSqlSource：处理静态sql语句，其内部装饰StaticSqlSource。 StaticSqlSource：处理静态sql，无论是静态sql，还是动态sql，最终的处理结果，都是静态sql。 ProviderSqlSource:处理注解Annotation形式的sql。 VelocitySqlSource:只是Mybatis的一个测试类 DynamicSqlSource和StaticSqlSource的最大区别在于：StaticSqlSource的String sql，可以直接获取使用，而DynamicSqlSource的String sql需要逐一根据条件解析并拼接出最终的sql，方能使用。 Mybatis解析sql的时机，Mybatis对于用户在XXMapper.xml文件中配置的sql解析主要分为2个时机 1、静态sql：程序启动的时候解析 2、动态sql：用户进行查询等sql相关操作的时候解析 什么是静态sql，动态sql？ 1、如果select|insert|update|delete标签体内包含XML标签或者select|insert|update|delete标签体内的sql文本中包含${}参数占位符则为动态sql，否则为静态sql。 2、如下面的2个sql中，第一个为动态sql，第二个为静态sql 1234567891011&lt;select id=\"selectUser\" parameterType=\"com.fit.bean.User\" resultType=\"com.fit.bean.User\" useCache=\"true\"&gt; select id, name from tab_user where id = $&#123;id&#125; &lt;if test=\"name!=null and name!=''\"&gt; and name=#&#123;name&#125; &lt;/if&gt; and 1 = 1&lt;/select&gt; &lt;select id=\"selectUserById\" parameterType=\"int\" resultType=\"com.fit.bean.User\" useCache=\"true\"&gt; select id, name from tab_user where id = #&#123;id&#125;&lt;/select&gt; 进入 parseStatementNode 方法，关注SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass);这一行，打好断点进入langDriver.createSqlSource(configuration, context, parameterTypeClass); 方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public void parseStatementNode() &#123; String id = context.getStringAttribute(\"id\"); String databaseId = context.getStringAttribute(\"databaseId\"); //如果databaseId不匹配，退出 if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) &#123; return; &#125; //暗示驱动程序每次批量返回的结果行数 Integer fetchSize = context.getIntAttribute(\"fetchSize\"); //超时时间 Integer timeout = context.getIntAttribute(\"timeout\"); //引用外部 parameterMap,已废弃 String parameterMap = context.getStringAttribute(\"parameterMap\"); //参数类型 String parameterType = context.getStringAttribute(\"parameterType\"); Class&lt;?&gt; parameterTypeClass = resolveClass(parameterType); //引用外部的 resultMap(高级功能) String resultMap = context.getStringAttribute(\"resultMap\"); //结果类型 String resultType = context.getStringAttribute(\"resultType\"); //脚本语言,mybatis3.2的新功能 String lang = context.getStringAttribute(\"lang\"); //得到语言驱动 LanguageDriver langDriver = getLanguageDriver(lang); Class&lt;?&gt; resultTypeClass = resolveClass(resultType); //结果集类型，FORWARD_ONLY|SCROLL_SENSITIVE|SCROLL_INSENSITIVE 中的一种 String resultSetType = context.getStringAttribute(\"resultSetType\"); //语句类型, STATEMENT|PREPARED|CALLABLE 的一种 StatementType statementType = StatementType.valueOf(context.getStringAttribute(\"statementType\", StatementType.PREPARED.toString())); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); //获取命令类型(select|insert|update|delete) String nodeName = context.getNode().getNodeName(); SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; boolean flushCache = context.getBooleanAttribute(\"flushCache\", !isSelect); //是否要缓存select结果 boolean useCache = context.getBooleanAttribute(\"useCache\", isSelect); //仅针对嵌套结果 select 语句适用：如果为 true，就是假设包含了嵌套结果集或是分组了，这样的话当返回一个主结果行的时候，就不会发生有对前面结果集的引用的情况。 //这就使得在获取嵌套的结果集的时候不至于导致内存不够用。默认值：false。 boolean resultOrdered = context.getBooleanAttribute(\"resultOrdered\", false); // Include Fragments before parsing //解析之前先解析&lt;include&gt;SQL片段 XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); // Parse selectKey after includes and remove them. //解析之前先解析&lt;selectKey&gt; processSelectKeyNodes(id, parameterTypeClass, langDriver); // Parse the SQL (pre: &lt;selectKey&gt; and &lt;include&gt; were parsed and removed) //解析成SqlSource，一般是DynamicSqlSource SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); String resultSets = context.getStringAttribute(\"resultSets\"); //(仅对 insert 有用) 标记一个属性, MyBatis 会通过 getGeneratedKeys 或者通过 insert 语句的 selectKey 子元素设置它的值 String keyProperty = context.getStringAttribute(\"keyProperty\"); //(仅对 insert 有用) 标记一个属性, MyBatis 会通过 getGeneratedKeys 或者通过 insert 语句的 selectKey 子元素设置它的值 String keyColumn = context.getStringAttribute(\"keyColumn\"); KeyGenerator keyGenerator; String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); if (configuration.hasKeyGenerator(keyStatementId)) &#123; keyGenerator = configuration.getKeyGenerator(keyStatementId); &#125; else &#123; keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\", configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? new Jdbc3KeyGenerator() : new NoKeyGenerator(); &#125; //又去调助手类 builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets); &#125; 进入langDriver.createSqlSource方法后默认是进入 XMLLanguageDriver类 createSqlSource 方法，可以看到又调用了XMLScriptBuilder 类的builder.parseScriptNode() 方法 1234567891011121314151617181920212223242526272829303132333435public class XMLLanguageDriver implements LanguageDriver &#123; @Override public ParameterHandler createParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; //返回默认的参数处理器 return new DefaultParameterHandler(mappedStatement, parameterObject, boundSql); &#125; @Override public SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType) &#123; //用XML脚本构建器解析 XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType); return builder.parseScriptNode(); &#125; //注解方式构建mapper @Override public SqlSource createSqlSource(Configuration configuration, String script, Class&lt;?&gt; parameterType) &#123; // issue #3 if (script.startsWith(\"&lt;script&gt;\")) &#123; XPathParser parser = new XPathParser(script, false, configuration.getVariables(), new XMLMapperEntityResolver()); return createSqlSource(configuration, parser.evalNode(\"/script\"), parameterType); &#125; else &#123; // issue #127 script = PropertyParser.parse(script, configuration.getVariables()); TextSqlNode textSqlNode = new TextSqlNode(script); //一种是动态，一种是原始 if (textSqlNode.isDynamic()) &#123; return new DynamicSqlSource(configuration, textSqlNode); &#125; else &#123; return new RawSqlSource(configuration, script, parameterType); &#125; &#125; &#125;&#125; 进入XMLScriptBuilder类 根据 isDynamic 变量来返回 DynamicSqlSource 对象和 RawSqlSource 对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224public class XMLScriptBuilder extends BaseBuilder &#123; private XNode context; private boolean isDynamic; private Class&lt;?&gt; parameterType; public XMLScriptBuilder(Configuration configuration, XNode context) &#123; this(configuration, context, null); &#125; public XMLScriptBuilder(Configuration configuration, XNode context, Class&lt;?&gt; parameterType) &#123; super(configuration); this.context = context; this.parameterType = parameterType; &#125; public SqlSource parseScriptNode() &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(context); MixedSqlNode rootSqlNode = new MixedSqlNode(contents); SqlSource sqlSource = null; if (isDynamic) &#123; sqlSource = new DynamicSqlSource(configuration, rootSqlNode); &#125; else &#123; sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); &#125; return sqlSource; &#125; List&lt;SqlNode&gt; parseDynamicTags(XNode node) &#123; // 一行一个SqlNode List&lt;SqlNode&gt; contents = new ArrayList&lt;SqlNode&gt;(); NodeList children = node.getNode().getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) &#123; XNode child = node.newXNode(children.item(i)); // 如果节点类型CDATA或者是文本，构造一个TextSqlNode或StaticTextSqlNode if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE || child.getNode().getNodeType() == Node.TEXT_NODE) &#123; String data = child.getStringBody(\"\"); TextSqlNode textSqlNode = new TextSqlNode(data); if (textSqlNode.isDynamic()) &#123; contents.add(textSqlNode); isDynamic = true; &#125; else &#123; contents.add(new StaticTextSqlNode(data)); &#125; &#125; else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) &#123; // 如果是xml标签 trim|where|set... String nodeName = child.getNode().getNodeName(); // 得到动态sql标签处理类 trim|where|set... NodeHandler handler = nodeHandlers(nodeName); if (handler == null) &#123; throw new BuilderException(\"Unknown element &lt;\" + nodeName + \"&gt; in SQL statement.\"); &#125; // 解析动态结点 handler.handleNode(child, contents); isDynamic = true; &#125; &#125; return contents; &#125; NodeHandler nodeHandlers(String nodeName) &#123; Map&lt;String, NodeHandler&gt; map = new HashMap&lt;String, NodeHandler&gt;(); map.put(\"trim\", new TrimHandler()); map.put(\"where\", new WhereHandler()); map.put(\"set\", new SetHandler()); map.put(\"foreach\", new ForEachHandler()); map.put(\"if\", new IfHandler()); map.put(\"choose\", new ChooseHandler()); map.put(\"when\", new IfHandler()); map.put(\"otherwise\", new OtherwiseHandler()); map.put(\"bind\", new BindHandler()); return map.get(nodeName); &#125; private interface NodeHandler &#123; void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents); &#125; private class BindHandler implements NodeHandler &#123; public BindHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; final String name = nodeToHandle.getStringAttribute(\"name\"); final String expression = nodeToHandle.getStringAttribute(\"value\"); final VarDeclSqlNode node = new VarDeclSqlNode(name, expression); targetContents.add(node); &#125; &#125; private class TrimHandler implements NodeHandler &#123; public TrimHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(nodeToHandle); MixedSqlNode mixedSqlNode = new MixedSqlNode(contents); String prefix = nodeToHandle.getStringAttribute(\"prefix\"); String prefixOverrides = nodeToHandle.getStringAttribute(\"prefixOverrides\"); String suffix = nodeToHandle.getStringAttribute(\"suffix\"); String suffixOverrides = nodeToHandle.getStringAttribute(\"suffixOverrides\"); TrimSqlNode trim = new TrimSqlNode(configuration, mixedSqlNode, prefix, prefixOverrides, suffix, suffixOverrides); targetContents.add(trim); &#125; &#125; private class WhereHandler implements NodeHandler &#123; public WhereHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(nodeToHandle); MixedSqlNode mixedSqlNode = new MixedSqlNode(contents); WhereSqlNode where = new WhereSqlNode(configuration, mixedSqlNode); targetContents.add(where); &#125; &#125; private class SetHandler implements NodeHandler &#123; public SetHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(nodeToHandle); MixedSqlNode mixedSqlNode = new MixedSqlNode(contents); SetSqlNode set = new SetSqlNode(configuration, mixedSqlNode); targetContents.add(set); &#125; &#125; private class ForEachHandler implements NodeHandler &#123; public ForEachHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(nodeToHandle); MixedSqlNode mixedSqlNode = new MixedSqlNode(contents); String collection = nodeToHandle.getStringAttribute(\"collection\"); String item = nodeToHandle.getStringAttribute(\"item\"); String index = nodeToHandle.getStringAttribute(\"index\"); String open = nodeToHandle.getStringAttribute(\"open\"); String close = nodeToHandle.getStringAttribute(\"close\"); String separator = nodeToHandle.getStringAttribute(\"separator\"); ForEachSqlNode forEachSqlNode = new ForEachSqlNode(configuration, mixedSqlNode, collection, index, item, open, close, separator); targetContents.add(forEachSqlNode); &#125; &#125; private class IfHandler implements NodeHandler &#123; public IfHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(nodeToHandle); MixedSqlNode mixedSqlNode = new MixedSqlNode(contents); String test = nodeToHandle.getStringAttribute(\"test\"); IfSqlNode ifSqlNode = new IfSqlNode(mixedSqlNode, test); targetContents.add(ifSqlNode); &#125; &#125; private class OtherwiseHandler implements NodeHandler &#123; public OtherwiseHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(nodeToHandle); MixedSqlNode mixedSqlNode = new MixedSqlNode(contents); targetContents.add(mixedSqlNode); &#125; &#125; private class ChooseHandler implements NodeHandler &#123; public ChooseHandler() &#123; // Prevent Synthetic Access &#125; @Override public void handleNode(XNode nodeToHandle, List&lt;SqlNode&gt; targetContents) &#123; List&lt;SqlNode&gt; whenSqlNodes = new ArrayList&lt;SqlNode&gt;(); List&lt;SqlNode&gt; otherwiseSqlNodes = new ArrayList&lt;SqlNode&gt;(); handleWhenOtherwiseNodes(nodeToHandle, whenSqlNodes, otherwiseSqlNodes); SqlNode defaultSqlNode = getDefaultSqlNode(otherwiseSqlNodes); ChooseSqlNode chooseSqlNode = new ChooseSqlNode(whenSqlNodes, defaultSqlNode); targetContents.add(chooseSqlNode); &#125; private void handleWhenOtherwiseNodes(XNode chooseSqlNode, List&lt;SqlNode&gt; ifSqlNodes, List&lt;SqlNode&gt; defaultSqlNodes) &#123; List&lt;XNode&gt; children = chooseSqlNode.getChildren(); for (XNode child : children) &#123; String nodeName = child.getNode().getNodeName(); NodeHandler handler = nodeHandlers(nodeName); if (handler instanceof IfHandler) &#123; handler.handleNode(child, ifSqlNodes); &#125; else if (handler instanceof OtherwiseHandler) &#123; handler.handleNode(child, defaultSqlNodes); &#125; &#125; &#125; private SqlNode getDefaultSqlNode(List&lt;SqlNode&gt; defaultSqlNodes) &#123; SqlNode defaultSqlNode = null; if (defaultSqlNodes.size() == 1) &#123; defaultSqlNode = defaultSqlNodes.get(0); &#125; else if (defaultSqlNodes.size() &gt; 1) &#123; throw new BuilderException(\"Too many default (otherwise) elements in choose statement.\"); &#125; return defaultSqlNode; &#125; &#125;&#125; 重点是这个方法List&lt;SqlNode&gt; parseDynamicTags(XNode node) ，下面几行代码是处理动态sql的操作 12345678// 得到动态sql标签处理类 trim|where|set...NodeHandler handler = nodeHandlers(nodeName);if (handler == null) &#123; throw new BuilderException(\"Unknown element &lt;\" + nodeName + \"&gt; in SQL statement.\");&#125;// 解析动态结点handler.handleNode(child, contents);isDynamic = true; 通过 nodeHandlers (nodeName) 方法来获取相应的处理类 12345678910111213NodeHandler nodeHandlers(String nodeName) &#123; Map&lt;String, NodeHandler&gt; map = new HashMap&lt;String, NodeHandler&gt;(); map.put(\"trim\", new TrimHandler()); map.put(\"where\", new WhereHandler()); map.put(\"set\", new SetHandler()); map.put(\"foreach\", new ForEachHandler()); map.put(\"if\", new IfHandler()); map.put(\"choose\", new ChooseHandler()); map.put(\"when\", new IfHandler()); map.put(\"otherwise\", new OtherwiseHandler()); map.put(\"bind\", new BindHandler()); return map.get(nodeName);&#125; 各个Handler 处理类是 XMLScriptBuilder 的子类，实际上会转到各个SqlNode 处理类 总结 XMLScriptBuilder类是解析mapper文件中的每个&lt;select/&gt;,&lt;insert/&gt;,&lt;update/&gt;,&lt;delete/&gt;节点内的SQL字符串(其中可能包含动态SQL部分,诸如&lt;if/&gt;,&lt;where/&gt;等) DynamicSqlSource和StaticSqlSource的最大区别在于：StaticSqlSource的String sql，可以直接获取使用，而DynamicSqlSource的String sql需要逐一根据条件解析并拼接出最终的sql方能使用。","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(八)MapperXML映射文件构建MappedStatement","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(八)MapperXML映射文件构建MappedStatement","date":"2018-11-27T14:00:44.000Z","updated":"2019-12-05T12:19:35.213Z","comments":true,"path":"2018/11/27/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(八)MapperXML映射文件构建MappedStatement/","link":"","permalink":"http://www.songshuiyang.com/2018/11/27/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(八)MapperXML映射文件构建MappedStatement/","excerpt":"","text":"前言 上一章节介绍了ResultMap标签的解析过程，这一章节来介绍select|insert|update|delete 这些sql标签的解析，这些节点会构造成MappedStatement类对象 源码解析 还是从 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 作为入口找到 configurationElement(XNode context) 方法，如下所示，按照步骤节点一步步解析，最后才是处理select|insert|update|delete节点 123456789101112131415161718192021222324private void configurationElement(XNode context) &#123; try &#123; //1.配置namespace String namespace = context.getStringAttribute(\"namespace\"); if (namespace.equals(\"\")) &#123; throw new BuilderException(\"Mapper's namespace cannot be empty\"); &#125; builderAssistant.setCurrentNamespace(namespace); //2.配置cache-ref cacheRefElement(context.evalNode(\"cache-ref\")); //3.配置cache cacheElement(context.evalNode(\"cache\")); //4.配置parameterMap(已经废弃,老式风格的参数映射) parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); //5.配置resultMap(高级功能) resultMapElements(context.evalNodes(\"/mapper/resultMap\")); //6.配置sql(定义可重用的 SQL 代码段) sqlElement(context.evalNodes(\"/mapper/sql\")); //7.配置select|insert|update|delete TODO buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing Mapper XML. Cause: \" + e, e); &#125;&#125; 打好断点进入 buildStatementFromContext(context.evalNodes(&quot;select|insert|update|delete&quot;)); 方法，可以看到是一个或的匹配，匹配所有的select|insert|update|delete这些标签 123456789101112131415161718192021222324//7.配置select|insert|update|deleteprivate void buildStatementFromContext(List&lt;XNode&gt; list) &#123; //调用7.1构建语句 if (configuration.getDatabaseId() != null) &#123; buildStatementFromContext(list, configuration.getDatabaseId()); &#125; buildStatementFromContext(list, null);&#125;// 7.1构建语句private void buildStatementFromContext(List&lt;XNode&gt; list, String requiredDatabaseId) &#123; for (XNode context : list) &#123; // 构建所有语句,一个mapper下可以有很多select // 语句比较复杂，核心都在这里面，所以调用XMLStatementBuilder final XMLStatementBuilder statementParser = new XMLStatementBuilder(configuration, builderAssistant, context, requiredDatabaseId); try &#123; // 核心XMLStatementBuilder.parseStatementNode statementParser.parseStatementNode(); &#125; catch (IncompleteElementException e) &#123; // 如果出现SQL语句不完整，把它记下来，塞到configuration去 configuration.addIncompleteStatement(statementParser); &#125; &#125;&#125; 可以看到又涉及到了一个XMLStatementBuilder.java 来对这些标签进行解析，进入statementParser.parseStatementNode(); 方法，可以看到xml标签的一些属性解析，最后是builderAssistant.addMappedStatement(...) 方法将构建好的MappedStatement对象添加到Configuration这个大佬身上 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394 //解析语句(select|insert|update|delete)//&lt;select// id=\"selectPerson\"// parameterType=\"int\"// parameterMap=\"deprecated\"// resultType=\"hashmap\"// resultMap=\"personResultMap\"// flushCache=\"false\"// useCache=\"true\"// timeout=\"10000\"// fetchSize=\"256\"// statementType=\"PREPARED\"// resultSetType=\"FORWARD_ONLY\"&gt;// SELECT * FROM PERSON WHERE ID = #&#123;id&#125;//&lt;/select&gt; public void parseStatementNode() &#123; String id = context.getStringAttribute(\"id\"); String databaseId = context.getStringAttribute(\"databaseId\"); //如果databaseId不匹配，退出 if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) &#123; return; &#125; //暗示驱动程序每次批量返回的结果行数 Integer fetchSize = context.getIntAttribute(\"fetchSize\"); //超时时间 Integer timeout = context.getIntAttribute(\"timeout\"); //引用外部 parameterMap,已废弃 String parameterMap = context.getStringAttribute(\"parameterMap\"); //参数类型 String parameterType = context.getStringAttribute(\"parameterType\"); Class&lt;?&gt; parameterTypeClass = resolveClass(parameterType); //引用外部的 resultMap(高级功能) String resultMap = context.getStringAttribute(\"resultMap\"); //结果类型 String resultType = context.getStringAttribute(\"resultType\"); //脚本语言,mybatis3.2的新功能 String lang = context.getStringAttribute(\"lang\"); //得到语言驱动 LanguageDriver langDriver = getLanguageDriver(lang); Class&lt;?&gt; resultTypeClass = resolveClass(resultType); //结果集类型，FORWARD_ONLY|SCROLL_SENSITIVE|SCROLL_INSENSITIVE 中的一种 String resultSetType = context.getStringAttribute(\"resultSetType\"); //语句类型, STATEMENT|PREPARED|CALLABLE 的一种 StatementType statementType = StatementType.valueOf(context.getStringAttribute(\"statementType\", StatementType.PREPARED.toString())); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); //获取命令类型(select|insert|update|delete) String nodeName = context.getNode().getNodeName(); SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; boolean flushCache = context.getBooleanAttribute(\"flushCache\", !isSelect); //是否要缓存select结果 boolean useCache = context.getBooleanAttribute(\"useCache\", isSelect); //仅针对嵌套结果 select 语句适用：如果为 true，就是假设包含了嵌套结果集或是分组了，这样的话当返回一个主结果行的时候，就不会发生有对前面结果集的引用的情况。 //这就使得在获取嵌套的结果集的时候不至于导致内存不够用。默认值：false。 boolean resultOrdered = context.getBooleanAttribute(\"resultOrdered\", false); // Include Fragments before parsing //解析之前先解析&lt;include&gt;SQL片段 XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); // Parse selectKey after includes and remove them. //解析之前先解析&lt;selectKey&gt; processSelectKeyNodes(id, parameterTypeClass, langDriver); // Parse the SQL (pre: &lt;selectKey&gt; and &lt;include&gt; were parsed and removed) //解析成SqlSource，一般是DynamicSqlSource SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); String resultSets = context.getStringAttribute(\"resultSets\"); //(仅对 insert 有用) 标记一个属性, MyBatis 会通过 getGeneratedKeys 或者通过 insert 语句的 selectKey 子元素设置它的值 String keyProperty = context.getStringAttribute(\"keyProperty\"); //(仅对 insert 有用) 标记一个属性, MyBatis 会通过 getGeneratedKeys 或者通过 insert 语句的 selectKey 子元素设置它的值 String keyColumn = context.getStringAttribute(\"keyColumn\"); KeyGenerator keyGenerator; String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); if (configuration.hasKeyGenerator(keyStatementId)) &#123; keyGenerator = configuration.getKeyGenerator(keyStatementId); &#125; else &#123; keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\", configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? new Jdbc3KeyGenerator() : new NoKeyGenerator(); &#125; //又去调助手类 builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets); &#125; MappedStatement类在Mybatis框架中用于表示XML文件中一个sql语句节点，即一个&lt;select&gt;或者&lt;update&gt;标签。Mybatis框架在初始化阶段会对XML配置文件进行读取，将其中的sql语句节点对象化为一个个MappedStatement对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public final class MappedStatement &#123; // xml文件位置 private String resource; private Configuration configuration; // 节点中的id属性加要命名空间比如 org.apache.songsy.mapper.RoleMapper.selectByPrimaryKey private String id; private Integer fetchSize; private Integer timeout; private StatementType statementType; private ResultSetType resultSetType; // SQL源码，实现动态sql private SqlSource sqlSource; private Cache cache; private ParameterMap parameterMap; private List&lt;ResultMap&gt; resultMaps; private boolean flushCacheRequired; private boolean useCache; private boolean resultOrdered; private SqlCommandType sqlCommandType; private KeyGenerator keyGenerator; private String[] keyProperties; private String[] keyColumns; private boolean hasNestedResultMaps; private String databaseId; private Log statementLog; private LanguageDriver lang; private String[] resultSets; MappedStatement() &#123; // constructor disabled &#125; //静态内部类，建造者模式 public static class Builder &#123; private MappedStatement mappedStatement = new MappedStatement(); public Builder(Configuration configuration, String id, SqlSource sqlSource, SqlCommandType sqlCommandType) &#123; mappedStatement.configuration = configuration; mappedStatement.id = id; mappedStatement.sqlSource = sqlSource; mappedStatement.statementType = StatementType.PREPARED; mappedStatement.parameterMap = new ParameterMap.Builder(configuration, \"defaultParameterMap\", null, new ArrayList&lt;ParameterMapping&gt;()).build(); mappedStatement.resultMaps = new ArrayList&lt;ResultMap&gt;(); mappedStatement.timeout = configuration.getDefaultStatementTimeout(); mappedStatement.sqlCommandType = sqlCommandType; mappedStatement.keyGenerator = configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType) ? new Jdbc3KeyGenerator() : new NoKeyGenerator(); String logId = id; if (configuration.getLogPrefix() != null) &#123; logId = configuration.getLogPrefix() + id; &#125; mappedStatement.statementLog = LogFactory.getLog(logId); mappedStatement.lang = configuration.getDefaultScriptingLanuageInstance(); &#125; ... MappedStatement.java 在哪里会调用呢，可以回顾一些第六章节使用MapperProxy来执行方法，下面是方法 // 核心selectList @Override public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) { try { // 根据statement id找到对应的MappedStatement MappedStatement ms = configuration.getMappedStatement(statement); // 转而用执行器来查询结果,注意这里传入的ResultHandler是null return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); } catch (Exception e) { throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); } finally { ErrorContext.instance().reset(); } }","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(七)MapperXML映射文件解析ResultMap","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(七)MapperXML映射文件解析ResultMap","date":"2018-11-26T14:00:44.000Z","updated":"2019-12-05T12:19:35.181Z","comments":true,"path":"2018/11/26/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(七)MapperXML映射文件解析ResultMap/","link":"","permalink":"http://www.songshuiyang.com/2018/11/26/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(七)MapperXML映射文件解析ResultMap/","excerpt":"","text":"前言 MyBatis的真正强大在于它的映射语句，也是它的魔力所在。由于它的异常强大，映射器的 XML 文件就显得相对简单，第三章节已经介绍了Mapper XML 文件解析的整体过程，这一章节来介绍Mapper 映射文件下 select|insert|update|delete 这些节点的解析 源码解析 从 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 作为入口找到 configurationElement(XNode context) 方法，如下所示，按照步骤节点一步步解析，最后才是处理select|insert|update|delete节点 123456789101112131415161718192021222324private void configurationElement(XNode context) &#123; try &#123; //1.配置namespace String namespace = context.getStringAttribute(\"namespace\"); if (namespace.equals(\"\")) &#123; throw new BuilderException(\"Mapper's namespace cannot be empty\"); &#125; builderAssistant.setCurrentNamespace(namespace); //2.配置cache-ref cacheRefElement(context.evalNode(\"cache-ref\")); //3.配置cache cacheElement(context.evalNode(\"cache\")); //4.配置parameterMap(已经废弃,老式风格的参数映射) parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); //5.配置resultMap(高级功能) resultMapElements(context.evalNodes(\"/mapper/resultMap\")); //6.配置sql(定义可重用的 SQL 代码段) sqlElement(context.evalNodes(\"/mapper/sql\")); //7.配置select|insert|update|delete TODO buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing Mapper XML. Cause: \" + e, e); &#125;&#125; 配置resultMap 解析，进入 resultMapElements(context.evalNodes(&quot;/mapper/resultMap&quot;)); 方法 123456789private void resultMapElements(List&lt;XNode&gt; list) throws Exception &#123; for (XNode resultMapNode : list) &#123; try &#123; // 循环遍历resultMap节点 resultMapElement(resultMapNode); &#125; catch (IncompleteElementException e) &#123; // ignore, it will be retried &#125; &#125; 进入 resultMapElement(resultMapNode); 方法, 这里就是构造ResultMap的主要方法了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 private ResultMap resultMapElement(XNode resultMapNode, List&lt;ResultMapping&gt; additionalResultMappings) throws Exception &#123;//错误上下文//取得标示符 (\"resultMap[userResultMap]\")// &lt;resultMap id=\"userResultMap\" type=\"User\"&gt;// &lt;id property=\"id\" column=\"user_id\" /&gt;// &lt;result property=\"username\" column=\"username\"/&gt;// &lt;result property=\"password\" column=\"password\"/&gt;// &lt;/resultMap&gt; ErrorContext.instance().activity(\"processing \" + resultMapNode.getValueBasedIdentifier()); String id = resultMapNode.getStringAttribute(\"id\", resultMapNode.getValueBasedIdentifier()); String type = resultMapNode.getStringAttribute(\"type\", resultMapNode.getStringAttribute(\"ofType\", resultMapNode.getStringAttribute(\"resultType\", resultMapNode.getStringAttribute(\"javaType\")))); String extend = resultMapNode.getStringAttribute(\"extends\"); //autoMapping Boolean autoMapping = resultMapNode.getBooleanAttribute(\"autoMapping\"); Class&lt;?&gt; typeClass = resolveClass(type); Discriminator discriminator = null; List&lt;ResultMapping&gt; resultMappings = new ArrayList&lt;ResultMapping&gt;(); resultMappings.addAll(additionalResultMappings); // 遍历resultMap 的子节点 List&lt;XNode&gt; resultChildren = resultMapNode.getChildren(); for (XNode resultChild : resultChildren) &#123; if (\"constructor\".equals(resultChild.getName())) &#123; //解析result map的constructor processConstructorElement(resultChild, typeClass, resultMappings); &#125; else if (\"discriminator\".equals(resultChild.getName())) &#123; //解析result map的discriminator discriminator = processDiscriminatorElement(resultChild, typeClass, resultMappings); &#125; else &#123; List&lt;ResultFlag&gt; flags = new ArrayList&lt;ResultFlag&gt;(); if (\"id\".equals(resultChild.getName())) &#123; flags.add(ResultFlag.ID); &#125; // 调5.1.1 buildResultMappingFromContext,得到ResultMapping resultMappings.add(buildResultMappingFromContext(resultChild, typeClass, flags)); &#125; &#125; // 最后再调ResultMapResolver得到ResultMap ResultMapResolver resultMapResolver = new ResultMapResolver(builderAssistant, id, typeClass, extend, discriminator, resultMappings, autoMapping); try &#123; return resultMapResolver.resolve(); &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteResultMap(resultMapResolver); throw e; &#125; &#125; 下面来看看ResultMap 这个类，可以看到一层套一层 12345678910111213141516171819202122232425262728293031323334353637public class ResultMap &#123; private String id; private Class&lt;?&gt; type; private List&lt;ResultMapping&gt; resultMappings; private List&lt;ResultMapping&gt; idResultMappings; private List&lt;ResultMapping&gt; constructorResultMappings; private List&lt;ResultMapping&gt; propertyResultMappings; private Set&lt;String&gt; mappedColumns; private Discriminator discriminator; private boolean hasNestedResultMaps; private boolean hasNestedQueries; private Boolean autoMapping; private ResultMap() &#123; &#125; // 静态内部类，建造者模式 public static class Builder &#123; private ResultMap resultMap = new ResultMap(); public Builder(Configuration configuration, String id, Class&lt;?&gt; type, List&lt;ResultMapping&gt; resultMappings) &#123; this(configuration, id, type, resultMappings, null); &#125; public Builder(Configuration configuration, String id, Class&lt;?&gt; type, List&lt;ResultMapping&gt; resultMappings, Boolean autoMapping) &#123; resultMap.id = id; resultMap.type = type; resultMap.resultMappings = resultMappings; resultMap.autoMapping = autoMapping; &#125; public Builder discriminator(Discriminator discriminator) &#123; resultMap.discriminator = discriminator; return this; &#125; ... ResultMap 由多个 ResultMapping.java 构造成，下面看看这个类，和我们的mapper文件是一一对应的 12345&lt;resultMap id=\"BaseResultMap\" type=\"com.songsy.imybatis.test.entity.User\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"username\" property=\"username\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"password\" property=\"password\" jdbcType=\"VARCHAR\"/&gt; &lt;result column=\"nickname\" property=\"nickname\" jdbcType=\"VARCHAR\"/&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class ResultMapping &#123; private Configuration configuration; private String property; private String column; private Class&lt;?&gt; javaType; private JdbcType jdbcType; private TypeHandler&lt;?&gt; typeHandler; private String nestedResultMapId; private String nestedQueryId; private Set&lt;String&gt; notNullColumns; private String columnPrefix; private List&lt;ResultFlag&gt; flags; private List&lt;ResultMapping&gt; composites; private String resultSet; private String foreignColumn; private boolean lazy; ResultMapping() &#123; &#125; // 静态内部类，建造者模式 public static class Builder &#123; private ResultMapping resultMapping = new ResultMapping(); public Builder(Configuration configuration, String property, String column, TypeHandler&lt;?&gt; typeHandler) &#123; this(configuration, property); resultMapping.column = column; resultMapping.typeHandler = typeHandler; &#125; public Builder(Configuration configuration, String property, String column, Class&lt;?&gt; javaType) &#123; this(configuration, property); resultMapping.column = column; resultMapping.javaType = javaType; &#125; public Builder(Configuration configuration, String property) &#123; resultMapping.configuration = configuration; resultMapping.property = property; resultMapping.flags = new ArrayList&lt;ResultFlag&gt;(); resultMapping.composites = new ArrayList&lt;ResultMapping&gt;(); resultMapping.lazy = configuration.isLazyLoadingEnabled(); &#125; public Builder javaType(Class&lt;?&gt; javaType) &#123; resultMapping.javaType = javaType; return this; &#125; public Builder jdbcType(JdbcType jdbcType) &#123; resultMapping.jdbcType = jdbcType; return this; &#125; public Builder nestedResultMapId(String nestedResultMapId) &#123; resultMapping.nestedResultMapId = nestedResultMapId; return this; &#125; .... 总结 resultMap是Mybatis中重要元素，它可以将查询到的复杂数据（比如查询到几个表中数据）映射到一个结果集当中。 当返回类型直接是一个ResultMap的时候也是非常有用的，这主要用在进行复杂联合查询上，因为进行简单查询是没有什么必要的，可以使用ResultType来处理","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(六)使用MapperProxy来执行方法","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(六)使用MapperProxy来执行方法","date":"2018-11-23T06:10:44.000Z","updated":"2019-12-05T12:19:35.218Z","comments":true,"path":"2018/11/23/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(六)使用MapperProxy来执行方法/","link":"","permalink":"http://www.songshuiyang.com/2018/11/23/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(六)使用MapperProxy来执行方法/","excerpt":"","text":"前言上一章节通过SqlSession来获取Mapper的代理类MapperProxy， 有了代理类之后就可以执行里面的方法了 MapperProxy 执行方法 MapperProxy 继承 InvocationHandler 实现了动态代理，只要是调用的Mapper接口的方法都会进入到 里面的invoke 方法中，具体解释如下代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 映射器代理，代理模式 * @author Clinton Begin * @author Eduardo Macarron */public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; private static final long serialVersionUID = -6424540398559729838L; private final SqlSession sqlSession; private final Class&lt;T&gt; mapperInterface; // 使用了缓存 private final Map&lt;Method, MapperMethod&gt; methodCache; public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.sqlSession = sqlSession; this.mapperInterface = mapperInterface; this.methodCache = methodCache; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 代理以后，所有Mapper的方法调用时，都会调用这个invoke方法 // 并不是任何一个方法都需要执行调用代理对象进行执行，如果这个方法是Object中通用的方法（toString、hashCode等）无需执行 if (Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, args); &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125; // 这里优化了，去缓存中找MapperMethod final MapperMethod mapperMethod = cachedMapperMethod(method); // 真正的方法执行 return mapperMethod.execute(sqlSession, args); &#125; // 去缓存中找MapperMethod private MapperMethod cachedMapperMethod(Method method) &#123; MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) &#123; // 找不到才去new mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); &#125; return mapperMethod; &#125;&#125; 接下来关注这一行mapperMethod.execute(sqlSession, args); 这里是重头戏，我们打开 MapperMethod 这个类，重点关注execute 方法，可以看到在这里进行了一些路由转发(insert|update|delete|select，分别调用SqlSession的4大类方法，又回到了SqlSession中), 还有就是对查询参数的一些处理封装。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 映射器方法 * @author Clinton Begin * @author Eduardo Macarron * @author Lasse Voss */public class MapperMethod &#123; private final SqlCommand command; private final MethodSignature method; public MapperMethod(Class&lt;?&gt; mapperInterface, Method method, Configuration config) &#123; this.command = new SqlCommand(config, mapperInterface, method); this.method = new MethodSignature(config, method); &#125; //执行 public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; //可以看到执行时就是4种情况，insert|update|delete|select，分别调用SqlSession的4大类方法 if (SqlCommandType.INSERT == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); &#125; else if (SqlCommandType.UPDATE == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); &#125; else if (SqlCommandType.DELETE == command.getType()) &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); &#125; else if (SqlCommandType.SELECT == command.getType()) &#123; if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; //如果有结果处理器 executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; //如果结果有多条记录 result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; //如果结果是map result = executeForMap(sqlSession, args); &#125; else &#123; //否则就是一条记录 Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; &#125; else &#123; throw new BindingException(\"Unknown execution method for: \" + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(\"Mapper method '\" + command.getName() + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\"); &#125; return result; &#125; ... 放不下 现在来执行一条查询，根据断点一步步发掘 12UserMapper userMapper = sqlSession.getMapper(UserMapper.class);System.out.println(userMapper.selectByPrimaryKey(1)); 一大堆if判断进入到这里， 12Object param = method.convertArgsToSqlCommandParam(args);result = sqlSession.selectOne(command.getName(), param); 进入 sqlSession.selectOne(command.getName(), param); 方法 12345678910111213@Overridepublic &lt;T&gt; T selectOne(String statement, Object parameter) &#123; // Popular vote was to return null on 0 results and throw exception on too many. // 转而去调用selectList,很简单的，如果得到0条则返回null，得到1条则返回1条，得到多条报TooManyResultsException错 List&lt;T&gt; list = this.&lt;T&gt;selectList(statement, parameter); if (list.size() == 1) &#123; return list.get(0); &#125; else if (list.size() &gt; 1) &#123; throw new TooManyResultsException(\"Expected one result (or null) to be returned by selectOne(), but found: \" + list.size()); &#125; else &#123; return null; &#125;&#125; selectOne 调用的是 selectList 方法，在这里可以看到 MappedStatement 及 Executor 1234567891011121314// 核心selectList@Overridepublic &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; // 根据statement id找到对应的MappedStatement MappedStatement ms = configuration.getMappedStatement(statement); // 转而用执行器来查询结果,注意这里传入的ResultHandler是null return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 查看 MappedStatement 这里可以看到我们的sql image 继续跳入 executor.query 方法，这里面跳到 CachingExecutor 执行，这里面使用了装饰器模式，里面有个private Executor delegate;，装饰SimpleExecutor , 在SimpleExecutor基础的上添加了二级缓存的功能 123456789101112131415161718192021@Overridepublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); // 默认情况下是没有开启缓存的(二级缓存).要开启二级缓存,你需要在你的 SQL 映射文件中添加一行: &lt;cache/&gt; // 简单的说，就是先查CacheKey，查不到再委托给实际的执行器去查 if (cache != null) &#123; flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, parameterObject, boundSql); @SuppressWarnings(\"unchecked\") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125; 因为二级缓存是需要配置开启的，所以继续跳入 delegate.&lt;E&gt; query 方法，进入到BaseExecutor 方法，在这里可以看到一级缓存的处理 12345678910111213141516171819202122232425262728293031323334353637383940414243public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); // 如果已经关闭，报错 if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; // 先清局部缓存，再查询.但仅查询堆栈为0，才清。为了处理递归调用 if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; // 加一,这样递归调用到上面的时候就不会再清局部缓存了 queryStack++; // 先根据cachekey从localCache去查 list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; // 若查到localCache缓存，处理localOutputParameterCache handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; // 从数据库查 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; // 清空堆栈 queryStack--; &#125; if (queryStack == 0) &#123; // 延迟加载队列中所有元素 for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 // 清空延迟加载队列 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 // 如果是STATEMENT，清本地缓存 clearLocalCache(); &#125; &#125; return list;&#125; 继续跳入queryFromDatabase() 方法，从数据库查， 跳入到SimpleExecutor类 12345678910111213141516@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // 新建一个StatementHandler // 这里看到ResultHandler传入了 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 准备语句 stmt = prepareStatement(handler, ms.getStatementLog()); //StatementHandler.query return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 继续跳入 doQuery()方法，可以看到这里构造了StatementHandler对象，并通过此对象来完成query操作 1234567891011121314151617//select@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); //新建一个StatementHandler //这里看到ResultHandler传入了 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //准备语句 stmt = prepareStatement(handler, ms.getStatementLog()); //StatementHandler.query return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 继续跳入 handler.query(), 这里又从SimpleExecutor类 跳入 PreparedStatementHandler 类中，终于在这里看到了我们的JDBC的代码 ,通过 ResultSetHandler 类来处理我们的结果123456@Overridepublic &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; ps.execute(); return resultSetHandler.&lt;E&gt; handleResultSets(ps);&#125; 时序图 image 总结 可以看到一个方法的执行涉及到一大堆类，为什么要那么多类的，就是为了解耦，高内聚，低耦合，每个类都有其独有的功能，就像工厂流水线一样，一个部门做一个部门的事，专人做专事，这样也方便以后添加功能","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(五)通过SqlSession来获取Mapper的代理类","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(五)通过SqlSession来获取MapperProxy","date":"2018-11-23T02:10:44.000Z","updated":"2019-12-05T12:19:35.208Z","comments":true,"path":"2018/11/23/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(五)通过SqlSession来获取MapperProxy/","link":"","permalink":"http://www.songshuiyang.com/2018/11/23/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(五)通过SqlSession来获取MapperProxy/","excerpt":"","text":"前言有了SqlSession 这个类之后，就可以通过sqlSession.getMapper(UserMapper.class);来获取UserMapper了 12345678910// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper = sqlSession.getMapper(UserMapper.class);System.out.println(userMapper.selectByPrimaryKey(1)); 获取Mapper 查看代码又可以发现 Configuration 这个类的影子，哪里都有它的影子，当然因为Mapper的映射关系数据存在这里 12345@Overridepublic &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; // 最后会去调用MapperRegistry.getMapper return configuration.&lt;T&gt;getMapper(type, this);&#125; 继续跟进 configuration.&lt;T&gt;getMapper(type, this); 方法，进入到Configuration 类中，可以发现是MapperRegistry 类维护了Mapper的映射关系 123public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; return mapperRegistry.getMapper(type, sqlSession);&#125; 继续跟进mapperRegistry.getMapper(type, sqlSession); 方法，进入到 MapperRegistry 类中，可以看到里面的映射关系就是用Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers 一个Map来存放，Key是 Class对象，Value就是MapperProxyFactory 是Mapper代理类的生成工厂 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/** * 映射器注册机 * @author Clinton Begin * @author Eduardo Macarron * @author Lasse Voss */public class MapperRegistry &#123; private Configuration config; // 将已经添加的映射都放入HashMap private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt;(); public MapperRegistry(Configuration config) &#123; this.config = config; &#125; @SuppressWarnings(\"unchecked\") // 返回代理类 public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125; &#125; public &lt;T&gt; boolean hasMapper(Class&lt;T&gt; type) &#123; return knownMappers.containsKey(type); &#125; // 看一下如何添加一个映射 public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; // mapper必须是接口！才会添加 if (type.isInterface()) &#123; if (hasMapper(type)) &#123; // 如果重复添加了，报错 throw new BindingException(\"Type \" + type + \" is already known to the MapperRegistry.\"); &#125; boolean loadCompleted = false; try &#123; knownMappers.put(type, new MapperProxyFactory&lt;T&gt;(type)); // It's important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won't try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; // 如果加载过程中出现异常需要再将这个mapper从mybatis中删除,这种方式比较丑陋吧，难道是不得已而为之？ if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125; &#125; /** * @since 3.2.2 */ public Collection&lt;Class&lt;?&gt;&gt; getMappers() &#123; return Collections.unmodifiableCollection(knownMappers.keySet()); &#125; /** * @since 3.2.2 */ public void addMappers(String packageName, Class&lt;?&gt; superType) &#123; // 查找包下所有是superType的类 ResolverUtil&lt;Class&lt;?&gt;&gt; resolverUtil = new ResolverUtil&lt;Class&lt;?&gt;&gt;(); resolverUtil.find(new ResolverUtil.IsA(superType), packageName); Set&lt;Class&lt;? extends Class&lt;?&gt;&gt;&gt; mapperSet = resolverUtil.getClasses(); for (Class&lt;?&gt; mapperClass : mapperSet) &#123; addMapper(mapperClass); &#125; &#125; /** * @since 3.2.2 */ // 查找包下所有类 public void addMappers(String packageName) &#123; addMappers(packageName, Object.class); &#125; &#125; 查看该类可以发现 knownMappers 是通过 addMapper()方法来添加的，那么addMapper()是哪里调用的呢，大家还记得之前的XMLConfigBuilder这个类吗，就是这里来解析mapper节点的 123&lt;mappers&gt; &lt;mapper resource=\"resources/mapper/UserMapper.xml\"/&gt; &lt;/mappers&gt; 回到XMLConfigBuilder类可以找到这个方法mapperElement，可以发现是通过 configuration.addMappers(mapperPackage); 及configuration.addMapper(mapperInterface); 来添加mapper映射的 1234567891011121314151617181920212223242526272829303132333435363738private void mapperElement(XNode parent) throws Exception &#123; if (parent != null) &#123; for (XNode child : parent.getChildren()) &#123; if (\"package\".equals(child.getName())) &#123; //10.4自动扫描包下所有映射器 String mapperPackage = child.getStringAttribute(\"name\"); configuration.addMappers(mapperPackage); &#125; else &#123; String resource = child.getStringAttribute(\"resource\"); String url = child.getStringAttribute(\"url\"); String mapperClass = child.getStringAttribute(\"class\"); if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) &#123; //10.1使用类路径 ErrorContext.instance().resource(resource); InputStream inputStream = Resources.getResourceAsStream(resource); //映射器比较复杂，调用XMLMapperBuilder //注意在for循环里每个mapper都重新new一个XMLMapperBuilder，来解析 XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); &#125; else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) &#123; //10.2使用绝对url路径 ErrorContext.instance().resource(url); InputStream inputStream = Resources.getUrlAsStream(url); //映射器比较复杂，调用XMLMapperBuilder XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments()); mapperParser.parse(); &#125; else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) &#123; //10.3使用java类名 Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass); //直接把这个映射加入配置 configuration.addMapper(mapperInterface); &#125; else &#123; throw new BuilderException(\"A mapper element may only specify a url, resource or class, but not more than one.\"); &#125; &#125; &#125; &#125;&#125; 回归主线，在 MapperRegistry 类的 getMapper 方法，可以发现是通过mapperProxyFactory.newInstance(sqlSession); 是通过Mapper代理类工厂来获取Mapper的 123456789101112// 返回代理类public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125;&#125; 继续跟进 mapperProxyFactory.newInstance(sqlSession) 进入到 MapperProxyFactory类中，没错就是在这里生成代理Mapper的，是用JDK自带的动态代理生成映射器 123456789101112131415161718192021222324252627282930313233/** * 映射器代理工厂 * @author Lasse Voss */public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;Method, MapperMethod&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public Map&lt;Method, MapperMethod&gt; getMethodCache() &#123; return methodCache; &#125; @SuppressWarnings(\"unchecked\") protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; // 用JDK自带的动态代理生成映射器 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125; 看一下MapperProxy.java 的真面目，这就是真正的实现类，这个类实现了JDK动态代理接口InvocationHandler，关注invoke()方法里面有一行是 mapperMethod.execute(sqlSession, args); 这一句，这是真正的执行者 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 映射器代理，代理模式 * @author Clinton Begin * @author Eduardo Macarron */public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; private static final long serialVersionUID = -6424540398559729838L; private final SqlSession sqlSession; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache; public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.sqlSession = sqlSession; this.mapperInterface = mapperInterface; this.methodCache = methodCache; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 代理以后，所有Mapper的方法调用时，都会调用这个invoke方法 // 并不是任何一个方法都需要执行调用代理对象进行执行，如果这个方法是Object中通用的方法（toString、hashCode等）无需执行 if (Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, args); &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125; // 这里优化了，去缓存中找MapperMethod final MapperMethod mapperMethod = cachedMapperMethod(method); // 真正的执行方法 return mapperMethod.execute(sqlSession, args); &#125; // 去缓存中找MapperMethod private MapperMethod cachedMapperMethod(Method method) &#123; MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) &#123; // 找不到才去new mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); &#125; return mapperMethod; &#125;&#125; 时序图 image 总结 Mapper接口的实现类是Mybatis生成的代理类MapperProxy.java，所有接口的代理类是通过MapperProxyFactory.java 方法来生成的，这里可以看到Mybatis的高明之处就是所有Mapper接口的代理类都是通过MapperProxy.java来实现 因为是Mapper接口，所以Mybatis代理类的实现运用的是JDK的动态代理","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(四)构建SqlSession","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(四)构建SqlSession","date":"2018-11-22T08:10:44.000Z","updated":"2019-09-16T13:11:04.823Z","comments":true,"path":"2018/11/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(四)构建SqlSession/","link":"","permalink":"http://www.songshuiyang.com/2018/11/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(四)构建SqlSession/","excerpt":"","text":"前言有了SqlSessionFactory会话工厂 这个类之后，就可以通过sqlSessionFactory.openSession();来生成SqlSession了12345678910// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper = sqlSession.getMapper(UserMapper.class);System.out.println(userMapper.selectByPrimaryKey(1)); SqlSession 简介Sqlsession对应着一次数据库会话。由于数据库会话不是永久的，因此Sqlsession的生命周期也不应该是永久的，相反，在你每次访问数据库时都需要创建它（当然并不是说在Sqlsession里只能执行一次sql，你可以执行多次，当一旦关闭了Sqlsession就需要重新创建它）。创建Sqlsession的地方只有一个，那就是SqlsessionFactory的openSession方法 构建 SqlSession SqlSession.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263/** * 这是MyBatis主要的一个类，用来执行SQL，获取映射器，管理事务 * The primary Java interface for working with MyBatis. * Through this interface you can execute commands, get mappers and manage transactions. * * @author Clinton Begin */public interface SqlSession extends Closeable &#123; // 语句执行方法 // 这些方法被用来执行SELECT，INSERT，UPDATE和DELETE语句。 /** * Retrieve a single row mapped from the statement key * 获取一条记录 * @param &lt;T&gt; the returned object type * @param statement * @return Mapped object */ &lt;T&gt; T selectOne(String statement); /** * Retrieve a single row mapped from the statement key and parameter. * 获取一条记录 * @param &lt;T&gt; the returned object type * @param statement Unique identifier matching the statement to use. * @param parameter A parameter object to pass to the statement. * @return Mapped object */ &lt;T&gt; T selectOne(String statement, Object parameter); /** * Retrieve a list of mapped objects from the statement key and parameter. * 获取多条记录 * @param &lt;E&gt; the returned list element type * @param statement Unique identifier matching the statement to use. * @return List of mapped object */ &lt;E&gt; List&lt;E&gt; selectList(String statement); /** * Retrieve a list of mapped objects from the statement key and parameter. * 获取多条记录 * @param &lt;E&gt; the returned list element type * @param statement Unique identifier matching the statement to use. * @param parameter A parameter object to pass to the statement. * @return List of mapped object */ &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter); /** * Retrieve a list of mapped objects from the statement key and parameter, * within the specified row bounds. * 获取多条记录,加上分页 * @param &lt;E&gt; the returned list element type * @param statement Unique identifier matching the statement to use. * @param parameter A parameter object to pass to the statement. * @param rowBounds Bounds to limit object retrieval * @return List of mapped object */ &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds); /** * The selectMap is a special case in that it is designed to convert a list * of results into a Map based on one of the properties in the resulting * objects. * Eg. Return a of Map[Integer,Author] for selectMap(\"selectAuthors\",\"id\") * 获取多条记录,并存入Map * @param &lt;K&gt; the returned Map keys type * @param &lt;V&gt; the returned Map values type * @param statement Unique identifier matching the statement to use. * @param mapKey The property to use as key for each value in the list. * @return Map containing key pair data. */ &lt;K, V&gt; Map&lt;K, V&gt; selectMap(String statement, String mapKey); /** * The selectMap is a special case in that it is designed to convert a list * of results into a Map based on one of the properties in the resulting * objects. * 获取多条记录,并存入Map * @param &lt;K&gt; the returned Map keys type * @param &lt;V&gt; the returned Map values type * @param statement Unique identifier matching the statement to use. * @param parameter A parameter object to pass to the statement. * @param mapKey The property to use as key for each value in the list. * @return Map containing key pair data. */ &lt;K, V&gt; Map&lt;K, V&gt; selectMap(String statement, Object parameter, String mapKey); /** * The selectMap is a special case in that it is designed to convert a list * of results into a Map based on one of the properties in the resulting * objects. * 获取多条记录,加上分页,并存入Map * @param &lt;K&gt; the returned Map keys type * @param &lt;V&gt; the returned Map values type * @param statement Unique identifier matching the statement to use. * @param parameter A parameter object to pass to the statement. * @param mapKey The property to use as key for each value in the list. * @param rowBounds Bounds to limit object retrieval * @return Map containing key pair data. */ &lt;K, V&gt; Map&lt;K, V&gt; selectMap(String statement, Object parameter, String mapKey, RowBounds rowBounds); /** * Retrieve a single row mapped from the statement key and parameter * using a &#123;@code ResultHandler&#125;. * 获取一条记录,并转交给ResultHandler处理 * @param statement Unique identifier matching the statement to use. * @param parameter A parameter object to pass to the statement. * @param handler ResultHandler that will handle each retrieved row * @return Mapped object */ void select(String statement, Object parameter, ResultHandler handler); /** * Retrieve a single row mapped from the statement * using a &#123;@code ResultHandler&#125;. * 获取一条记录,并转交给ResultHandler处理 * @param statement Unique identifier matching the statement to use. * @param handler ResultHandler that will handle each retrieved row * @return Mapped object */ void select(String statement, ResultHandler handler); /** * Retrieve a single row mapped from the statement key and parameter * using a &#123;@code ResultHandler&#125; and &#123;@code RowBounds&#125; * 获取一条记录,加上分页,并转交给ResultHandler处理 * @param statement Unique identifier matching the statement to use. * @param rowBounds RowBound instance to limit the query results * @param handler ResultHandler that will handle each retrieved row * @return Mapped object */ void select(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler); /** * Execute an insert statement. * 插入记录 * @param statement Unique identifier matching the statement to execute. * @return int The number of rows affected by the insert. */ int insert(String statement); /** * Execute an insert statement with the given parameter object. Any generated * autoincrement values or selectKey entries will modify the given parameter * object properties. Only the number of rows affected will be returned. * 插入记录 * @param statement Unique identifier matching the statement to execute. * @param parameter A parameter object to pass to the statement. * @return int The number of rows affected by the insert. */ int insert(String statement, Object parameter); /** * Execute an update statement. The number of rows affected will be returned. * 更新记录 * @param statement Unique identifier matching the statement to execute. * @return int The number of rows affected by the update. */ int update(String statement); /** * Execute an update statement. The number of rows affected will be returned. * 更新记录 * @param statement Unique identifier matching the statement to execute. * @param parameter A parameter object to pass to the statement. * @return int The number of rows affected by the update. */ int update(String statement, Object parameter); /** * Execute a delete statement. The number of rows affected will be returned. * 删除记录 * @param statement Unique identifier matching the statement to execute. * @return int The number of rows affected by the delete. */ int delete(String statement); /** * Execute a delete statement. The number of rows affected will be returned. * 删除记录 * @param statement Unique identifier matching the statement to execute. * @param parameter A parameter object to pass to the statement. * @return int The number of rows affected by the delete. */ int delete(String statement, Object parameter); //以下是事务控制方法,commit,rollback /** * Flushes batch statements and commits database connection. * Note that database connection will not be committed if no updates/deletes/inserts were called. * To force the commit call &#123;@link SqlSession#commit(boolean)&#125; */ void commit(); /** * Flushes batch statements and commits database connection. * @param force forces connection commit */ void commit(boolean force); /** * Discards pending batch statements and rolls database connection back. * Note that database connection will not be rolled back if no updates/deletes/inserts were called. * To force the rollback call &#123;@link SqlSession#rollback(boolean)&#125; */ void rollback(); /** * Discards pending batch statements and rolls database connection back. * Note that database connection will not be rolled back if no updates/deletes/inserts were called. * @param force forces connection rollback */ void rollback(boolean force); /** * Flushes batch statements. * 刷新批处理语句,返回批处理结果 * @return BatchResult list of updated records * @since 3.0.6 */ List&lt;BatchResult&gt; flushStatements(); /** * Closes the session * 关闭Session */ @Override void close(); /** * Clears local session cache * 清理Session缓存 */ void clearCache(); /** * Retrieves current configuration * 得到配置 * @return Configuration */ Configuration getConfiguration(); /** * Retrieves a mapper. * 得到映射器 * 这个巧妙的使用了泛型，使得类型安全 * 到了MyBatis 3，还可以用注解,这样xml都不用写了 * @param &lt;T&gt; the mapper type * @param type Mapper interface class * @return a mapper bound to this SqlSession */ &lt;T&gt; T getMapper(Class&lt;T&gt; type); /** * Retrieves inner database connection * 得到数据库连接 * @return Connection */ Connection getConnection();&#125; DefaultSqlSession.java 是 SqlSession.java 接口的默认实现，从DefaultSqlSessionFactory构建的是DefaultSqlSession, 查看DefaultSqlSession.java类成员又可以发现Configuration的影子，Executor成员是MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296/** * 默认SqlSession * @author Clinton Begin */public class DefaultSqlSession implements SqlSession &#123; private Configuration configuration; private Executor executor; private boolean autoCommit; private boolean dirty; public DefaultSqlSession(Configuration configuration, Executor executor, boolean autoCommit) &#123; this.configuration = configuration; this.executor = executor; this.dirty = false; this.autoCommit = autoCommit; &#125; public DefaultSqlSession(Configuration configuration, Executor executor) &#123; this(configuration, executor, false); &#125; @Override public &lt;T&gt; T selectOne(String statement) &#123; return this.&lt;T&gt;selectOne(statement, null); &#125; // 核心selectOne @Override public &lt;T&gt; T selectOne(String statement, Object parameter) &#123; // Popular vote was to return null on 0 results and throw exception on too many. // 转而去调用selectList,很简单的，如果得到0条则返回null，得到1条则返回1条，得到多条报TooManyResultsException错 List&lt;T&gt; list = this.&lt;T&gt;selectList(statement, parameter); if (list.size() == 1) &#123; return list.get(0); &#125; else if (list.size() &gt; 1) &#123; throw new TooManyResultsException(\"Expected one result (or null) to be returned by selectOne(), but found: \" + list.size()); &#125; else &#123; return null; &#125; &#125; @Override public &lt;K, V&gt; Map&lt;K, V&gt; selectMap(String statement, String mapKey) &#123; return this.selectMap(statement, null, mapKey, RowBounds.DEFAULT); &#125; @Override public &lt;K, V&gt; Map&lt;K, V&gt; selectMap(String statement, Object parameter, String mapKey) &#123; return this.selectMap(statement, parameter, mapKey, RowBounds.DEFAULT); &#125; // 核心selectMap @Override public &lt;K, V&gt; Map&lt;K, V&gt; selectMap(String statement, Object parameter, String mapKey, RowBounds rowBounds) &#123; //转而去调用selectList final List&lt;?&gt; list = selectList(statement, parameter, rowBounds); final DefaultMapResultHandler&lt;K, V&gt; mapResultHandler = new DefaultMapResultHandler&lt;K, V&gt;(mapKey, configuration.getObjectFactory(), configuration.getObjectWrapperFactory()); final DefaultResultContext context = new DefaultResultContext(); for (Object o : list) &#123; // 循环用DefaultMapResultHandler处理每条记录 context.nextResultObject(o); mapResultHandler.handleResult(context); &#125; // 注意这个DefaultMapResultHandler里面存了所有已处理的记录(内部实现可能就是一个Map)，最后再返回一个Map return mapResultHandler.getMappedResults(); &#125; @Override public &lt;E&gt; List&lt;E&gt; selectList(String statement) &#123; return this.selectList(statement, null); &#125; @Override public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) &#123; return this.selectList(statement, parameter, RowBounds.DEFAULT); &#125; // 核心selectList @Override public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; // 根据statement id找到对应的MappedStatement MappedStatement ms = configuration.getMappedStatement(statement); // 转而用执行器来查询结果,注意这里传入的ResultHandler是null return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; @Override public void select(String statement, Object parameter, ResultHandler handler) &#123; select(statement, parameter, RowBounds.DEFAULT, handler); &#125; @Override public void select(String statement, ResultHandler handler) &#123; select(statement, null, RowBounds.DEFAULT, handler); &#125; //核心select,带有ResultHandler，和selectList代码差不多的，区别就一个ResultHandler @Override public void select(String statement, Object parameter, RowBounds rowBounds, ResultHandler handler) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); executor.query(ms, wrapCollection(parameter), rowBounds, handler); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; @Override public int insert(String statement) &#123; return insert(statement, null); &#125; @Override public int insert(String statement, Object parameter) &#123; //insert也是调用update return update(statement, parameter); &#125; @Override public int update(String statement) &#123; return update(statement, null); &#125; // 核心update @Override public int update(String statement, Object parameter) &#123; try &#123; // 每次要更新之前，dirty标志设为true dirty = true; MappedStatement ms = configuration.getMappedStatement(statement); // 转而用执行器来update结果 return executor.update(ms, wrapCollection(parameter)); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error updating database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; @Override public int delete(String statement) &#123; //delete也是调用update return update(statement, null); &#125; @Override public int delete(String statement, Object parameter) &#123; return update(statement, parameter); &#125; @Override public void commit() &#123; commit(false); &#125; // 核心commit @Override public void commit(boolean force) &#123; try &#123; // 转而用执行器来commit executor.commit(isCommitOrRollbackRequired(force)); // 每次commit之后，dirty标志设为false dirty = false; &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error committing transaction. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; @Override public void rollback() &#123; rollback(false); &#125; // 核心rollback @Override public void rollback(boolean force) &#123; try &#123; // 转而用执行器来rollback executor.rollback(isCommitOrRollbackRequired(force)); // 每次rollback之后，dirty标志设为false dirty = false; &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error rolling back transaction. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; // 核心flushStatements @Override public List&lt;BatchResult&gt; flushStatements() &#123; try &#123; // 转而用执行器来flushStatements return executor.flushStatements(); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error flushing statements. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; // 核心close @Override public void close() &#123; try &#123; // 转而用执行器来close executor.close(isCommitOrRollbackRequired(false)); // 每次close之后，dirty标志设为false dirty = false; &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; @Override public Configuration getConfiguration() &#123; return configuration; &#125; @Override public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; // 最后会去调用MapperRegistry.getMapper return configuration.&lt;T&gt;getMapper(type, this); &#125; @Override public Connection getConnection() &#123; try &#123; return executor.getTransaction().getConnection(); &#125; catch (SQLException e) &#123; throw ExceptionFactory.wrapException(\"Error getting a new connection. Cause: \" + e, e); &#125; &#125; // 核心clearCache @Override public void clearCache() &#123; // 转而用执行器来clearLocalCache executor.clearLocalCache(); &#125; // 检查是否需要强制commit或rollback private boolean isCommitOrRollbackRequired(boolean force) &#123; return (!autoCommit &amp;&amp; dirty) || force; &#125; // 把参数包装成Collection private Object wrapCollection(final Object object) &#123; if (object instanceof Collection) &#123; // 参数若是Collection型，做collection标记 StrictMap&lt;Object&gt; map = new StrictMap&lt;Object&gt;(); map.put(\"collection\", object); if (object instanceof List) &#123; // 参数若是List型，做list标记 map.put(\"list\", object); &#125; return map; &#125; else if (object != null &amp;&amp; object.getClass().isArray()) &#123; // 参数若是数组型，，做array标记 StrictMap&lt;Object&gt; map = new StrictMap&lt;Object&gt;(); map.put(\"array\", object); return map; &#125; // 参数若不是集合型，直接返回原来值 return object; &#125; // 严格的Map，如果找不到对应的key，直接抛BindingException例外，而不是返回null public static class StrictMap&lt;V&gt; extends HashMap&lt;String, V&gt; &#123; private static final long serialVersionUID = -5741767162221585340L; @Override public V get(Object key) &#123; if (!super.containsKey(key)) &#123; throw new BindingException(\"Parameter '\" + key + \"' not found. Available parameters are \" + this.keySet()); &#125; return super.get(key); &#125; &#125;&#125; 时序图 iamge 总结 通过源码可以看到SqlSession就像是公司的前台人员，正在干活的是 Executor ，人家来找公司谈合作，首先先和前台人员联系，然后再通过前台将人指到真正的实施者","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(三)构建SqlSessionFactory会话工厂","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(三)构建SqlSessionFactory会话工厂","date":"2018-11-22T06:10:44.000Z","updated":"2019-09-16T13:11:04.391Z","comments":true,"path":"2018/11/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(三)构建SqlSessionFactory会话工厂/","link":"","permalink":"http://www.songshuiyang.com/2018/11/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(三)构建SqlSessionFactory会话工厂/","excerpt":"","text":"前言有了Mybatis整体脉络概念之后，现在就是来构建 SqlSessionFactory会话工厂 这个类了12345678910// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactorySqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 得到SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 得到MapperUserMapper userMapper = sqlSession.getMapper(UserMapper.class);System.out.println(userMapper.selectByPrimaryKey(1)); SqlSessionFactory 简介SqlSessionFactory 是Mybatis的关键对象， 是创建SqlSession的工厂，工厂模式，SqlSessionFactory 由 SqlSessionFactoryBuilder 构建，每一个MyBatis的应用程序都以一个SqlSessionFactory对象的实例为核心 logo SqlSessionFactory是个接口，它有两个实现类 DefaultSqlSessionFactory.java, SqlSessionManager.java ，Mybatis使用的是DefaultSqlSessionFactory.java 来作为其默认实现1234567891011public interface SqlSessionFactory &#123; SqlSession openSession(); SqlSession openSession(boolean autoCommit); SqlSession openSession(Connection connection); SqlSession openSession(TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType); SqlSession openSession(ExecutorType execType, boolean autoCommit); SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType, Connection connection); Configuration getConfiguration();&#125; 构建 SqlSessionFactory SqlSessionFactory 是通过SqlSessionFactoryBuilder.java 来构建的，build方法传入了一个配置文件的输入流 打开SqlSessionFactoryBuilder.java类，可以发现都是build的重载方法，主要有有俩种配置文件的输入方式，一个是Reader ，另一个是通过InputStream，可以看到里面是通过XMLConfigBuilder.java来解析xml文件的， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class SqlSessionFactoryBuilder &#123; public SqlSessionFactory build(Reader reader) &#123; return build(reader, null, null); &#125; public SqlSessionFactory build(Reader reader, String environment) &#123; return build(reader, environment, null); &#125; public SqlSessionFactory build(Reader reader, Properties properties) &#123; return build(reader, null, properties); &#125; // 第4种方法是最常用的，它使用了一个参照了XML文档或更特定的SqlMapConfig.xml文件的Reader实例。 public SqlSessionFactory build(Reader reader, String environment, Properties properties) &#123; try &#123; // 委托XMLConfigBuilder来解析xml文件，并构建 XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties); return build(parser.parse()); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; reader.close(); &#125; catch (IOException e) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125; &#125; //以下3个方法都是调用下面第8种方法 public SqlSessionFactory build(InputStream inputStream) &#123; return build(inputStream, null, null); &#125; public SqlSessionFactory build(InputStream inputStream, String environment) &#123; return build(inputStream, environment, null); &#125; public SqlSessionFactory build(InputStream inputStream, Properties properties) &#123; return build(inputStream, null, properties); &#125; // 第8种方法和第4种方法差不多，Reader换成了InputStream // 可选的参数是environment和properties。Environment决定加载哪种环境(开发环境/生产环境)，包括数据源和事务管理器。 // 如果使用properties，那么就会加载那些properties（属性配置文件），那些属性可以用$&#123;propName&#125;语法形式多次用在配置文件中。和Spring很像，一个思想？ public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; try &#123; // 委托XMLConfigBuilder来解析xml文件 XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); return build(parser.parse()); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; inputStream.close(); &#125; catch (IOException e) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125; &#125; //最后一个build方法使用了一个Configuration作为参数,并返回DefaultSqlSessionFactory public SqlSessionFactory build(Configuration config) &#123; return new DefaultSqlSessionFactory(config); &#125;&#125; 打开XMLConfigBuilder.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/** * XML配置构建器，建造者模式,继承BaseBuilder * @author Clinton Begin */public class XMLConfigBuilder extends BaseBuilder &#123; // 是否已解析，XPath解析器 private boolean parsed; // XPath解析器 private XPathParser parser; // 环境 private String environment; // 以下3个一组 public XMLConfigBuilder(Reader reader) &#123; this(reader, null, null); &#125; public XMLConfigBuilder(Reader reader, String environment) &#123; this(reader, environment, null); &#125; // 构造函数，转换成XPathParser再去调用构造函数 public XMLConfigBuilder(Reader reader, String environment, Properties props) &#123; // 构造一个需要验证，XMLMapperEntityResolver的XPathParser this(new XPathParser(reader, true, props, new XMLMapperEntityResolver()), environment, props); &#125; // 以下3个一组 public XMLConfigBuilder(InputStream inputStream) &#123; this(inputStream, null, null); &#125; public XMLConfigBuilder(InputStream inputStream, String environment) &#123; this(inputStream, environment, null); &#125; public XMLConfigBuilder(InputStream inputStream, String environment, Properties props) &#123; this(new XPathParser(inputStream, true, props, new XMLMapperEntityResolver()), environment, props); &#125; // 上面6个构造函数最后都合流到这个函数，传入XPathParser private XMLConfigBuilder(XPathParser parser, String environment, Properties props) &#123; // 首先调用父类初始化Configuration super(new Configuration()); // 错误上下文设置成SQL Mapper Configuration(XML文件配置),以便后面出错了报错用 ErrorContext.instance().resource(\"SQL Mapper Configuration\"); // 将Properties全部设置到Configuration里面去 this.configuration.setVariables(props); this.parsed = false; this.environment = environment; this.parser = parser; &#125; // 解析配置 public Configuration parse() &#123; // 如果已经解析过了，报错 if (parsed) &#123; throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); &#125; parsed = true;// &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; // &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" // \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; // &lt;configuration&gt; // &lt;environments default=\"development\"&gt; // &lt;environment id=\"development\"&gt; // &lt;transactionManager type=\"JDBC\"/&gt; // &lt;dataSource type=\"POOLED\"&gt; // &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/&gt; // &lt;property name=\"url\" value=\"$&#123;url&#125;\"/&gt; // &lt;property name=\"username\" value=\"$&#123;username&#125;\"/&gt; // &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; // &lt;/dataSource&gt; // &lt;/environment&gt; // &lt;/environments&gt; // &lt;mappers&gt; // &lt;mapper resource=\"org/mybatis/ex ample/BlogMapper.xml\"/&gt; // &lt;/mappers&gt; // &lt;/configuration&gt; // 根节点是configuration parseConfiguration(parser.evalNode(\"/configuration\")); return configuration; &#125; // 解析配置 private void parseConfiguration(XNode root) &#123; try &#123; // 分步骤解析 //issue #117 read properties first //1.properties propertiesElement(root.evalNode(\"properties\")); // 2.类型别名 typeAliasesElement(root.evalNode(\"typeAliases\")); // 3.插件 pluginElement(root.evalNode(\"plugins\")); // 4.对象工厂 objectFactoryElement(root.evalNode(\"objectFactory\")); // 5.对象包装工厂 objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); // 6.设置 settingsElement(root.evalNode(\"settings\")); // read it after objectFactory and objectWrapperFactory issue #631 // 7.环境 environmentsElement(root.evalNode(\"environments\")); // 8.databaseIdProvider databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); // 9.类型处理器 typeHandlerElement(root.evalNode(\"typeHandlers\")); // 10.映射器 mapperElement(root.evalNode(\"mappers\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); &#125; &#125; ..... 未完 XMLMapperBuilder.java 这个类是解析sql映射文件的 ，下面是核心代码， 可以看到Mybatis是将select|insert|update|delete这些都作为一个单独的节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 // 解析 public void parse() &#123; // 如果没有加载过再加载，防止重复加载 if (!configuration.isResourceLoaded(resource)) &#123; // 解析mapper节点 configurationElement(parser.evalNode(\"/mapper\")); // 标记一下，已经加载过了 configuration.addLoadedResource(resource); // 绑定映射器到namespace bindMapperForNamespace(); &#125; parsePendingResultMaps(); parsePendingChacheRefs(); parsePendingStatements(); &#125; public XNode getSqlFragment(String refid) &#123; return sqlFragments.get(refid); &#125; //配置mapper元素// &lt;mapper namespace=\"org.mybatis.example.BlogMapper\"&gt;// &lt;select id=\"selectBlog\" parameterType=\"int\" resultType=\"Blog\"&gt;// select * from Blog where id = #&#123;id&#125;// &lt;/select&gt;// &lt;/mapper&gt; private void configurationElement(XNode context) &#123; try &#123; //1.配置namespace String namespace = context.getStringAttribute(\"namespace\"); if (namespace.equals(\"\")) &#123; throw new BuilderException(\"Mapper's namespace cannot be empty\"); &#125; builderAssistant.setCurrentNamespace(namespace); //2.配置cache-ref cacheRefElement(context.evalNode(\"cache-ref\")); //3.配置cache cacheElement(context.evalNode(\"cache\")); //4.配置parameterMap(已经废弃,老式风格的参数映射) parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); //5.配置resultMap(高级功能) resultMapElements(context.evalNodes(\"/mapper/resultMap\")); //6.配置sql(定义可重用的 SQL 代码段) sqlElement(context.evalNodes(\"/mapper/sql\")); //7.配置select|insert|update|delete TODO buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing Mapper XML. Cause: \" + e, e); &#125; &#125; DefaultSqlSessionFactory.java 是构造SqlSession的默认实现，可以看到实现都是通过configuration该对象来获取配置信息，从而构造SqlSession 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * 默认实现的SqlSessionFactory * @author Clinton Begin */public class DefaultSqlSessionFactory implements SqlSessionFactory &#123; private final Configuration configuration; public DefaultSqlSessionFactory(Configuration configuration) &#123; this.configuration = configuration; &#125; // 最终都会调用2种方法：openSessionFromDataSource,openSessionFromConnection // 以下6个方法都会调用openSessionFromDataSource @Override public SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false); &#125; @Override public SqlSession openSession(boolean autoCommit) &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, autoCommit); &#125; @Override public SqlSession openSession(ExecutorType execType) &#123; return openSessionFromDataSource(execType, null, false); &#125; @Override public SqlSession openSession(TransactionIsolationLevel level) &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), level, false); &#125; @Override public SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level) &#123; return openSessionFromDataSource(execType, level, false); &#125; @Override public SqlSession openSession(ExecutorType execType, boolean autoCommit) &#123; return openSessionFromDataSource(execType, null, autoCommit); &#125; //以下2个方法都会调用openSessionFromConnection @Override public SqlSession openSession(Connection connection) &#123; return openSessionFromConnection(configuration.getDefaultExecutorType(), connection); &#125; @Override public SqlSession openSession(ExecutorType execType, Connection connection) &#123; return openSessionFromConnection(execType, connection); &#125; @Override public Configuration getConfiguration() &#123; return configuration; &#125; private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); // 通过事务工厂来产生一个事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 生成一个执行器(事务包含在执行器里) final Executor executor = configuration.newExecutor(tx, execType); // 然后产生一个DefaultSqlSession return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; // 如果打开事务出错，则关闭它 closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; //最后清空错误上下文 ErrorContext.instance().reset(); &#125; &#125; private SqlSession openSessionFromConnection(ExecutorType execType, Connection connection) &#123; try &#123; boolean autoCommit; try &#123; autoCommit = connection.getAutoCommit(); &#125; catch (SQLException e) &#123; // Failover to true, as most poor drivers // or databases won't support transactions autoCommit = true; &#125; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); final Transaction tx = transactionFactory.newTransaction(connection); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; private TransactionFactory getTransactionFactoryFromEnvironment(Environment environment) &#123; // 如果没有配置事务工厂，则返回托管事务工厂 if (environment == null || environment.getTransactionFactory() == null) &#123; return new ManagedTransactionFactory(); &#125; return environment.getTransactionFactory(); &#125; private void closeTransaction(Transaction tx) &#123; if (tx != null) &#123; try &#123; tx.close(); &#125; catch (SQLException ignore) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125; &#125;&#125; 时序图 iamge 总结 涉及到两种设计模式：工厂模式(SqlSessionFactory.java)及建造者模式(XMLConfigBuilder.java)，通过命名可以发现其设计思想，学习大佬的命名规范 SqlSessionFactory接口的默认实现是DefaultSqlSessionFactory.java DefaultSqlSessionFactory只有一个成员变量 Configuration ，所以构建SqlSessionFactory其实就是解析xml文件，构建Configuration的过程，Configuration是Mybatis的大头，所有的配置信息都存在里面 通过其运行流程可以看到每个类都有其独有的用途，各司其职，有生产SqlSession的类，又解析xml的类，有生产SqlSessionFactory的类，各个模块相互配合","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(二)Mybatis框架架构","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二)Mybatis框架架构","date":"2018-11-22T03:10:44.000Z","updated":"2019-09-16T13:11:04.414Z","comments":true,"path":"2018/11/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二)Mybatis框架架构/","link":"","permalink":"http://www.songshuiyang.com/2018/11/22/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(二)Mybatis框架架构/","excerpt":"","text":"引言本文主要讲解Mybatis的整体程序设计，理清楚框架的主要脉络，这样才能对源码有个整体的了解，先主干后分支，如果没有这些概念那么直接看源码的话肯定会很吃力的 整体设计整体架构图 logo 运作流程(1)、加载配置并初始化Mybatis配置包括两种配置，一种是Mybatis自身的框架配置，另一种是sql映射配置，Mybatis自身的框架配置有两种方式可以配置， 一处是配置文件，另一处是通过Java注解进行配置， 比如说Spring Boot项目整合Mybatis都是通过Java代码的方式来进行配置 初始化是初始化框架基本配置，然后解析sql映射文件，将SQL的配置信息加载成为一个个MappedStatement对象（包括了传入参数映射配置、执行的SQL语句、结果映射配置），存储在内存中。 (2)、接收调用请求通过接口来接收调用请求，真实企业环境一般都是通过接口的方式来进行调用，通过该接口将请求传递给下层的请求处理层进行处理。 传统Mybatis工作模式，是创建一个和数据库打交道的SqlSession对象，然后根据Statement Id 和参数来操作数据库，这种方式固然很简单和实用，但是它不符合面向对象语言的概念和面向接口编程的编程习惯。由于面向接口的编程是面向对象的大趋势，MyBatis 为了适应这一趋势，增加了第二种使用MyBatis 支持接口（Interface）调用方式。 image 接口工作模式，MyBatis 将配置文件中的每一个 节点抽象为一个 Mapper 接口，而这个接口中声明的方法和跟 节点中的 节点项对应，即 节点的id值为Mapper 接口中的方法名称，parameterType 值表示Mapper 对应方法的入参类型，而resultMap 值则对应了Mapper 接口表示的返回值类型或者返回结果集的元素类型。 image (3)、处理操作请求处理操作包括参数映射，sql解析，sql执行操作 (4)、返回请求结果将操作数据库的结果按照映射的配置进行转换，可以转换成HashMap、JavaBean或者基本数据类型，并将最终结果返回。 MyBatis的主要的核心部件 logo 类名 描述 SqlSession 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能 Executor MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护 StatementHandler 封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。 ParameterHandler 负责对用户传递的参数转换成JDBC Statement 所需要的参数 ResultSetHandler 负责将JDBC返回的ResultSet结果集对象转换成List类型的集合 TypeHandler 负责java数据类型和jdbc数据类型之间的映射和转换 MappedStatement MappedStatement维护了一条select update delete insert节点的封装 SqlSource 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中并返回 BoundSql 表示动态生成的SQL语句以及相应的参数信息 Configuration MyBatis所有的配置信息都维持在Configuration对象之中。 参考： https://blog.csdn.net/luanlouis/article/details/40422941 http://chenjc-it.iteye.com/blog/1460990","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis源码(一)本地编译Mybatis的源码","slug":"backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(一)本地编译Mybatis的源码","date":"2018-11-21T07:59:44.000Z","updated":"2019-09-16T13:11:04.355Z","comments":true,"path":"2018/11/21/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(一)本地编译Mybatis的源码/","link":"","permalink":"http://www.songshuiyang.com/2018/11/21/backend/framework/mybatis/sourceCodeAnalysis/Mybatis源码(一)本地编译Mybatis的源码/","excerpt":"","text":"引言在开发过程中，对于Mybatis框架一直都是在使用阶段，对于其底层实现的细节不是十分清楚，所以利用空余时间学习Mybatis的源码，学习其设计思想，看看大佬是怎样设计一个框架的，提升自己的代码能力 下载源码 地址 网站 中文官网 http://www.mybatis.org/mybatis-3/zh/index.html 源码地址 https://github.com/mybatis/mybatis-3 下载完源码包后使用maven进行编译 mvn clean install 可以发现会报error 查看pom.xml 发现又一个父级依赖 12345&lt;parent&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-parent&lt;/artifactId&gt; &lt;version&gt;33-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 所以需要把这些依赖下载下来 12345// 下载代码git clone https://github.com/mybatis/parent.git// 编译代码mvn clean install 父级依赖完成之后更改Mybatis的源码，注意版本号需要一致 123456&lt;parent&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-parent&lt;/artifactId&gt; &lt;version&gt;33-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; 解决部分插件版本问题 告诉我们部分插件没有指定的相应的版本号，出于工程的稳定性考虑需要对使用的插件指定其版本号，并给出了合适的版本号，如图红色方框中的文字。我们只要在mybatisg工程的pom.xml文件中找到相对应的插件处添加$NUM 标签即可， $NUM代表具体的版本号。到这我们再执行mvn clean install 指令就可以将mybatis工程构建成功了。 源码基本结构打开源码可以发现如下目录，通过包名就可以大概知道其模块功能 image 解析以下章节将从下面的示例代码来一步步解析Mybatis的源码，分析其实现过程12345678910// 读取配置文件File file = new File(\"src/test/java/resources/mybatis-config.xml\");InputStream inputStream = new FileInputStream(file);// 构建SqlSessionFactory会话工厂SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);// 构建SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession();// 通过SqlSession来获取MapperUserMapper userMapper = sqlSession.getMapper(UserMapper.class);System.out.println(userMapper.selectByPrimaryKey(1));~ 参考：https://blog.csdn.net/yums467/article/details/52801288","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"Mybatis()Mybatis笔记","slug":"backend/framework/mybatis/mybatis笔记","date":"2018-11-20T16:00:00.000Z","updated":"2019-09-16T13:11:04.323Z","comments":true,"path":"2018/11/21/backend/framework/mybatis/mybatis笔记/","link":"","permalink":"http://www.songshuiyang.com/2018/11/21/backend/framework/mybatis/mybatis笔记/","excerpt":"","text":"mybatis foreach标签 foreach 标签中 item属性名如果和其他参数中同名(如以下代码:item=”id” 和 if test=”id != null” 同名),即使没有传入id参数,SQL也会执行 AND id = #{id} mapper文件:123456789101112131415&lt;select id=\"findPageList\" parameterType=\"map\" resultType=\"user\"&gt; SELECT * FROM user &lt;where&gt; &lt;if test=\"IN_id != null\"&gt; id IN &lt;foreach collection=\"IN_id\" index=\"index\" item=\"id\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;id&#125; &lt;/foreach&gt; &lt;/if&gt; &lt;if test=\"id != null\"&gt; AND id = #&#123;id&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; dao层1List&lt;User&gt; findPageList(Map&lt;String, Object&gt; map); 测试方法12345678910@Testpublic void test2() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); List&lt;Integer&gt; idList = new ArrayList&lt;Integer&gt;(); idList.add(1); idList.add(4); idList.add(5); map.put(\"IN_id\", idList); userMapper.findPageList(map);&#125; 结果123==&gt; Preparing: SELECT * FROM user WHERE id IN ( ? , ? , ? ) AND id = ? ==&gt; Parameters: 1(Integer), 4(Integer), 5(Integer), 5(Integer)&lt;== Total: 1","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://www.songshuiyang.com/categories/Mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.songshuiyang.com/tags/mybatis/"}]},{"title":"设计模式(二一)行为型模式-备忘录模式","slug":"backend/designPatterns/设计模式(二一)行为型模式-备忘录模式","date":"2018-10-31T16:00:21.000Z","updated":"2019-09-16T13:11:04.041Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(二一)行为型模式-备忘录模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(二一)行为型模式-备忘录模式/","excerpt":"","text":"备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。 意图在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 主要解决所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。 什么时候使用很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有”后悔药”可吃。 如何解决通过一个备忘录类专门存储对象状态。 关键代码客户不与备忘录类耦合，与备忘录管理类耦合。 应用实例1、后悔药。 2、打游戏时的存档。 3、Windows 里的 ctri + z。 4、IE 中的后退。 5、数据库的事务管理。 开发中常见场景 聊天服务器 消息推送 Servlet 监听器的实现 代码例子备忘录模式使用三个类 Memento、Originator 和 CareTaker。Memento 包含了要被恢复的对象的状态。Originator 创建并在 Memento 对象中存储状态。Caretaker 对象负责从 Memento 中恢复对象的状态。 MementoPatternDemo，我们的演示类使用 CareTaker 和 Originator 对象来显示对象的状态恢复。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 创建 Memento 类。public class Memento &#123; private String state; public Memento(String state)&#123; this.state = state; &#125; public String getState()&#123; return state; &#125; &#125;// 创建 Originator 类。public class Originator &#123; private String state; public void setState(String state)&#123; this.state = state; &#125; public String getState()&#123; return state; &#125; public Memento saveStateToMemento()&#123; return new Memento(state); &#125; public void getStateFromMemento(Memento Memento)&#123; state = Memento.getState(); &#125;&#125;// 创建 CareTaker 类。import java.util.ArrayList;import java.util.List; public class CareTaker &#123; private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;(); public void add(Memento state)&#123; mementoList.add(state); &#125; public Memento get(int index)&#123; return mementoList.get(index); &#125;&#125;// 使用 CareTaker 和 Originator 对象。public class MementoPatternDemo &#123; public static void main(String[] args) &#123; Originator originator = new Originator(); CareTaker careTaker = new CareTaker(); originator.setState(\"State #1\"); originator.setState(\"State #2\"); careTaker.add(originator.saveStateToMemento()); originator.setState(\"State #3\"); careTaker.add(originator.saveStateToMemento()); originator.setState(\"State #4\"); System.out.println(\"Current State: \" + originator.getState()); originator.getStateFromMemento(careTaker.get(0)); System.out.println(\"First saved State: \" + originator.getState()); originator.getStateFromMemento(careTaker.get(1)); System.out.println(\"Second saved State: \" + originator.getState()); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(二十)行为型模式-观察者模式","slug":"backend/designPatterns/设计模式(二十)行为型模式-观察者模式","date":"2018-10-31T16:00:20.000Z","updated":"2019-09-16T13:11:04.045Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(二十)行为型模式-观察者模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(二十)行为型模式-观察者模式/","excerpt":"","text":"当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。观察者模式属于行为型模式。 意图定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 什么时候使用一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决使用面向对象技术，可以将这种依赖关系弱化。 关键代码在抽象类里有一个 ArrayList 存放观察者们。 应用实例、1、拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 开发中常见场景 聊天服务器 消息推送 Servlet 监听器的实现 代码例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 观察者接口public abstract class Observer &#123; public abstract void update(String msg);&#125;// 第一个观察者public class F_Observer extends Observer &#123; public void update(String msg) &#123; System.out.println(F_Observer.class.getName() + \" : \" + msg); &#125;&#125;// 第二个观察者public class S_Observer extends Observer &#123; public void update(String msg) &#123; System.out.println(S_Observer.class.getName() + \" : \" + msg); &#125;&#125;// 第三个观察者public class T_Observer extends Observer &#123; public void update(String msg) &#123; System.out.println(T_Observer.class.getName() + \" : \" + msg); &#125;&#125;// 被观察者public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); //状态改变 public void setMsg(String msg) &#123; notifyAll(msg); &#125; //订阅 public void addAttach(Observer observer) &#123; observers.add(observer); &#125; //通知所有订阅的观察者 private void notifyAll(String msg) &#123; for (Observer observer : observers) &#123; observer.update(msg); &#125; &#125;&#125;// 使用方法public class Main &#123; public static void main(String[] args) &#123; F_Observer fObserver = new F_Observer(); S_Observer sObserver = new S_Observer(); T_Observer tObserver = new T_Observer(); Subject subject = new Subject(); subject.addAttach(fObserver); subject.addAttach(sObserver); subject.addAttach(tObserver); subject.setMsg(\"msg change\"); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十九)行为型模式-状态方法模式","slug":"backend/designPatterns/设计模式(十九)行为型模式-状态方法模式","date":"2018-10-31T16:00:19.000Z","updated":"2019-09-16T13:11:04.185Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十九)行为型模式-状态方法模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十九)行为型模式-状态方法模式/","excerpt":"","text":"在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。 在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。 意图允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。 主要解决对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。 什么时候使用代码中包含大量与对象状态有关的条件语句。 如何解决将各种具体的状态类抽象出来。 开发中常见场景代码例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 创建一个接口。public interface State &#123; public void doAction(Context context);&#125;// 创建实现接口的实体类。public class StartState implements State &#123; public void doAction(Context context) &#123; System.out.println(\"Player is in start state\"); context.setState(this); &#125; public String toString()&#123; return \"Start State\"; &#125;&#125;// 创建实现接口的实体类。public class StopState implements State &#123; public void doAction(Context context) &#123; System.out.println(\"Player is in stop state\"); context.setState(this); &#125; public String toString()&#123; return \"Stop State\"; &#125;&#125;// 环境类，维护一个State对象，定义了当前的状态public class Context &#123; private State state; public Context()&#123; state = null; &#125; public void setState(State state)&#123; this.state = state; &#125; public State getState()&#123; return state; &#125;&#125;// 使用 Context 来查看当状态 State 改变时的行为变化。public class StatePatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(); StartState startState = new StartState(); startState.doAction(context); System.out.println(context.getState().toString()); StopState stopState = new StopState(); stopState.doAction(context); System.out.println(context.getState().toString()); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十八)行为型模式-模板方法模式","slug":"backend/designPatterns/设计模式(十八)行为型模式-模板方法模式","date":"2018-10-31T16:00:18.000Z","updated":"2019-09-16T13:11:04.216Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十八)行为型模式-模板方法模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十八)行为型模式-模板方法模式/","excerpt":"","text":"在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板、一个骨架，但某些步骤延迟到子类中实现，调用将以抽象类中定义的方式进行。 即：处理步骤父类中定义好，具体实现延迟到子类中定义 意图定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 主要解决一些方法通用，却在每一个子类都重新写了这一方法。 什么时候使用实现一个算法，整体步骤都很固定，但某些部分易变，易变部分可以抽象出来 开发中常见场景 数据库访问的封装 Junit单元测试 代码例子1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// 创建一个抽象类，它的模板方法被设置为 final。public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125;// 创建扩展了上述类的实体类。public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Cricket Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Cricket Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Cricket Game Started. Enjoy the game!\"); &#125;&#125;public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Football Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Football Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Football Game Started. Enjoy the game!\"); &#125;&#125;// 使用 Game 的模板方法 play() 来演示游戏的定义方式。public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十七)行为型模式-策略模式","slug":"backend/designPatterns/设计模式(十七)行为型模式-策略模式","date":"2018-10-31T16:00:17.000Z","updated":"2019-09-16T13:11:04.141Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十七)行为型模式-策略模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十七)行为型模式-策略模式/","excerpt":"","text":"在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 意图定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 主要解决在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 一个系统有许多许多类，而区分它们的只是他们直接的行为。 应用实例1、诸葛亮的锦囊妙计，每一个锦囊就是一个策略。2、旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。3、JAVA AWT 中的 LayoutManager。 开发中常见场景 Spring框架 Resource接口，资源访问策略 HttpServlet service 代码例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// 策略接口public interface Strategy &#123; public double getPrice(double standardPrice);&#125;// 很少来的新用户public class NewCustomerFewStrategy implements Strategy &#123; @Override public double getPrice(double standardPrice) &#123; System.out.println(\"不打折，原价\"); return standardPrice; &#125;&#125;// 多次来的新用户public class NewCustomerManyStrategy implements Strategy &#123; @Override public double getPrice(double standardPrice) &#123; System.out.println(\"打九折\"); return standardPrice*0.9; &#125;&#125;// 很少来的老用户public class OldCustomerFewStrategy implements Strategy &#123; @Override public double getPrice(double standardPrice) &#123; System.out.println(\"打八五折\"); return standardPrice*0.85; &#125;&#125;// 经常来的老用户public class OldCustomerManyStrategy implements Strategy &#123; @Override public double getPrice(double standardPrice) &#123; System.out.println(\"打八折\"); return standardPrice*0.8; &#125;&#125;/** * 负责和具体的策略类交互 * 这样的话，具体的算法和直接的客户端调用分离了，使得算法可以独立于客户端独立的变化。 * 如果使用spring的依赖注入功能，还可以通过配置文件，动态的注入不同策略对象，动态的切换不同的算法. * @author Administrator * */public class Context &#123; // 当前采用的算法对象 private Strategy strategy; // 可以通过构造器来注入 public Context(Strategy strategy) &#123; super(); this.strategy = strategy; &#125; //可以通过set方法来注入 public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125; public void pringPrice(double s)&#123; System.out.println(\"您该报价：\"+strategy.getPrice(s)); &#125; &#125;public class Client &#123; public static void main(String[] args) &#123; Strategy s1 = new OldCustomerManyStrategy(); Context ctx = new Context(s1); ctx.pringPrice(998); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十六)行为型模式-解释器模式","slug":"backend/designPatterns/设计模式(十六)行为型模式-解释器模式","date":"2018-10-31T16:00:16.000Z","updated":"2019-09-16T13:11:04.225Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十六)行为型模式-解释器模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十六)行为型模式-解释器模式/","excerpt":"","text":"介绍解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 意图给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决对于一些固定文法构建一个解释句子的解释器。 EL表达式 正则表达式 SQL语法 数学表达式 何时使用如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决构件语法树，定义终结符与非终结符。 关键代码构件环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例编译器、运算表达式计算。 优点1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。 缺点1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。 使用场景1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。 注意事项可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十五)行为型模式-命令模式","slug":"backend/designPatterns/设计模式(十五)行为型模式-命令模式","date":"2018-10-31T16:00:15.000Z","updated":"2019-09-16T13:11:04.202Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十五)行为型模式-命令模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十五)行为型模式-命令模式/","excerpt":"","text":"核心命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 主要解决在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 场景 数据库事务机制的底层实现 命令的撤销和恢复 何时使用在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 例子","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十四)行为型模式-中介模式","slug":"backend/designPatterns/设计模式(十四)行为型模式-中介模式","date":"2018-10-31T16:00:14.000Z","updated":"2019-09-16T13:11:04.254Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十四)行为型模式-中介模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十四)行为型模式-中介模式/","excerpt":"","text":"核心如果一个系统中对象之间的联系呈现为网状结构，对象之前存在大量多对多关系，将导致关系及其复杂，我们可以引入一个中介者对象，使各个同事对象只和中介者打交道 中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 场景 公司都有总经理，各个部门有什么事都通报到总经理这里，总经理再通知各个相关部门，在这里总经理起到了一个中介、协调的作用 中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 机场调度系统。 MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。 例子我们通过聊天室实例来演示中介者模式。实例中，多个用户可以向聊天室发送消息，聊天室向所有的用户显示消息。我们将创建两个类 ChatRoom 和 User。User 对象使用 ChatRoom 方法来分享他们的消息。1234567891011121314151617181920212223242526272829303132333435363738394041// 创建中介类。import java.util.Date; public class ChatRoom &#123; public static void showMessage(User user, String message)&#123; System.out.println(new Date().toString() + \" [\" + user.getName() +\"] : \" + message); &#125;&#125;// 创建 user 类。public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(String name)&#123; this.name = name; &#125; public void sendMessage(String message)&#123; ChatRoom.showMessage(this,message); &#125;&#125;// 使用 User 对象来显示他们之间的通信。public class MediatorPatternDemo &#123; public static void main(String[] args) &#123; User robert = new User(\"Robert\"); User john = new User(\"John\"); robert.sendMessage(\"Hi! John!\"); john.sendMessage(\"Hello! Robert!\"); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十三)行为型模式-迭代器模式","slug":"backend/designPatterns/设计模式(十三)行为型模式-迭代器模式","date":"2018-10-31T16:00:13.000Z","updated":"2019-09-16T13:11:04.174Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十三)行为型模式-迭代器模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十三)行为型模式-迭代器模式/","excerpt":"","text":"定义迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 场景 提供一种可以遍历聚合对象的方式，又称游标cursor模式 聚合对象：存储数据 迭代器：遍历数据 例子1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495// 自定义的迭代器接口public interface MyIterator &#123; // 将游标指向第一个元素 void first(); // 将游标指向下一个元素 void next(); // 判断是否存在下一个元素 boolean hasNext(); boolean isFirst(); boolean isLast(); // 获取当前游标指向的对象 Object getCurrentObj(); &#125;// 自定义的聚合类public class ConcreteMyAggregate &#123; private List&lt;Object&gt; list = new ArrayList&lt;&gt;(); public void addObject(Object obj)&#123; this.list.add(obj); &#125; public void removeObject(Object obj)&#123; this.list.remove(obj); &#125; public List&lt;Object&gt; getList() &#123; return list; &#125; public void setList(List&lt;Object&gt; list) &#123; this.list = list; &#125; // 获得迭代器 public MyIterator createIterator()&#123; return new ConcreteIterator(); &#125; // 使用内部类定义迭代器，可以直接使用外部类的属性 private class ConcreteIterator implements MyIterator &#123; private int cursor; //定义游标用于记录遍历时的位置 @Override public void first() &#123; cursor = 0; &#125; @Override public Object getCurrentObj() &#123; return list.get(cursor); &#125; @Override public boolean hasNext() &#123; if(cursor &lt; list.size())&#123; return true; &#125; return false; &#125; @Override public boolean isFirst() &#123; return cursor==0?true:false; &#125; @Override public boolean isLast() &#123; return cursor==(list.size()-1)?true:false; &#125; @Override public void next() &#123; if(cursor &lt; list.size())&#123; cursor++; &#125; &#125; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; ConcreteMyAggregate cma = new ConcreteMyAggregate(); cma.addObject(\"aa\"); cma.addObject(\"bb\"); cma.addObject(\"cc\"); MyIterator iter = cma.createIterator(); while(iter.hasNext())&#123; System.out.println(iter.getCurrentObj()); iter.next(); &#125; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十二)行为型模式-责任链模式","slug":"backend/designPatterns/设计模式(十二)行为型模式-责任链模式","date":"2018-10-31T16:00:12.000Z","updated":"2019-09-16T13:11:04.195Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十二)行为型模式-责任链模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十二)行为型模式-责任链模式/","excerpt":"","text":"定义将能够处理同一类请求的对象连成一条链，所提交的请求沿着链传递，链上的对象逐个判断是否有能力处理该请求，如果能则处理，如果不能则传递给链上的下一个对象 使用场景 Java异常机制，catch的匹配 Servlet， 过滤器的链式处理 分类 链表方式定义职责链 非链表方式定义职责链（集合，数组） 场景 打牌 轮流出牌 接力赛跑 公司盖章审批 例子请假流程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133// 领导抽象类public abstract class Leader &#123; protected String name; // 责任链上的后继对象 protected Leader nextLeader; public Leader(String name) &#123; super(); this.name = name; &#125; // 设定责任链上的后继对象 public void setNextLeader(Leader nextLeader) &#123; this.nextLeader = nextLeader; &#125; // 处理请求的核心的业务方法 public abstract void handleRequest(LeaveRequest request);&#125;// 封装请假的基本信息public class LeaveRequest &#123; private String empName; private int leaveDays; private String reason; public LeaveRequest(String empName, int leaveDays, String reason) &#123; super(); this.empName = empName; this.leaveDays = leaveDays; this.reason = reason; &#125;&#125;// 主任public class Director extends Leader &#123; public Director(String name) &#123; super(name); &#125; @Override public void handleRequest(LeaveRequest request) &#123; if(request.getLeaveDays()&lt;3)&#123; System.out.println(\"员工：\"+request.getEmpName()+\"请假，天数：\"+request.getLeaveDays()+\",理由：\"+request.getReason()); System.out.println(\"主任：\"+this.name+\",审批通过！\"); &#125;else&#123; if(this.nextLeader!=null)&#123; this.nextLeader.handleRequest(request); &#125; &#125; &#125;&#125;// 总经理public class GeneralManager extends Leader &#123; public GeneralManager(String name) &#123; super(name); &#125; @Override public void handleRequest(LeaveRequest request) &#123; if(request.getLeaveDays()&lt;30)&#123; System.out.println(\"员工：\"+request.getEmpName()+\"请假，天数：\"+request.getLeaveDays()+\",理由：\"+request.getReason()); System.out.println(\"总经理：\"+this.name+\",审批通过！\"); &#125;else&#123; System.out.println(\"莫非\"+request.getEmpName()+\"想辞职，居然请假\"+request.getLeaveDays()+\"天！\"); &#125; &#125;&#125;// 经理public class Manager extends Leader &#123; public Manager(String name) &#123; super(name); &#125; @Override public void handleRequest(LeaveRequest request) &#123; if(request.getLeaveDays()&lt;10)&#123; System.out.println(\"员工：\"+request.getEmpName()+\"请假，天数：\"+request.getLeaveDays()+\",理由：\"+request.getReason()); System.out.println(\"经理：\"+this.name+\",审批通过！\"); &#125;else&#123; if(this.nextLeader!=null)&#123; this.nextLeader.handleRequest(request); &#125; &#125; &#125;&#125;// 副总经理public class ViceGeneralManager extends Leader &#123; public ViceGeneralManager(String name) &#123; super(name); &#125; @Override public void handleRequest(LeaveRequest request) &#123; if(request.getLeaveDays()&lt;20)&#123; System.out.println(\"员工：\"+request.getEmpName()+\"请假，天数：\"+request.getLeaveDays()+\",理由：\"+request.getReason()); System.out.println(\"副总经理：\"+this.name+\",审批通过！\"); &#125;else&#123; if(this.nextLeader!=null)&#123; this.nextLeader.handleRequest(request); &#125; &#125; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; Leader a = new Director(\"张三\"); Leader b = new Manager(\"李四\"); Leader b2 = new ViceGeneralManager(\"李小四\"); Leader c = new GeneralManager(\"王五\"); //组织责任链对象的关系 a.setNextLeader(b); b.setNextLeader(b2); b2.setNextLeader(c); //开始请假操作 LeaveRequest req1 = new LeaveRequest(\"TOM\", 15, \"回江西老家探亲！\"); a.handleRequest(req1); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十一)结构型模式-享元模式","slug":"backend/designPatterns/设计模式(十一)结构型模式-享元模式","date":"2018-10-31T16:00:11.000Z","updated":"2019-09-16T13:11:04.133Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十一)结构型模式-享元模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十一)结构型模式-享元模式/","excerpt":"","text":"核心 享元模式以共享的方式高效的支持大量细粒度对象的重用 享元对象能做到共享的关键是区分了内部状态和外部状态 内部状态：可以共享，不会随环境变化而变化 外部状态：不可以共享，会随环境的变化而变化 场景内存属于稀缺资源，不要随便浪费，如果有很多和完全相同或相似的对象，我们可以通过享元模式，节省内存 享元模式由于其共享的特性，可以在任何“池”中操作，比如线程池、数据库连接池 String 类的设计也是享元模式 例子围棋软件设计 每一个围棋棋子都是一个对象，有如下属性：颜色，形状，大小，这些是可以共享的，称之为内部状态 棋子位置不能共享，称之为外部状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// 享元类public interface ChessFlyWeight &#123; void setColor(String c); String getColor(); void display(Coordinate c);&#125;// 棋子类class ConcreteChess implements ChessFlyWeight &#123; // 内部状态-颜色 private String color; public ConcreteChess(String color) &#123; super(); this.color = color; &#125; @Override public void display(Coordinate c) &#123; System.out.println(\"棋子颜色：\"+color); System.out.println(\"棋子位置：\"+c.getX()+\"----\"+c.getY()); &#125; @Override public String getColor() &#123; return color; &#125; @Override public void setColor(String c) &#123; this.color = c; &#125; &#125;// 外部状态-用于棋子定位public class Coordinate &#123; private int x,y; public Coordinate(int x, int y) &#123; super(); this.x = x; this.y = y; &#125; public int getX() &#123; return x; &#125; public void setX(int x) &#123; this.x = x; &#125; public int getY() &#123; return y; &#125; public void setY(int y) &#123; this.y = y; &#125; &#125;// 享元工厂类public class ChessFlyWeightFactory &#123; // 享元池 private static Map&lt;String,ChessFlyWeight&gt; map = new HashMap&lt;String, ChessFlyWeight&gt;(); public static ChessFlyWeight getChess(String color)&#123; if(map.get(color)!=null)&#123; return map.get(color); &#125;else&#123; ChessFlyWeight cfw = new ConcreteChess(color); map.put(color, cfw); return cfw; &#125; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; ChessFlyWeight chess1 = ChessFlyWeightFactory.getChess(\"黑色\"); ChessFlyWeight chess2 = ChessFlyWeightFactory.getChess(\"黑色\"); // 共享同一个状态 System.out.println(chess1); System.out.println(chess2); System.out.println(\"增加外部状态的处理===========\"); chess1.display(new Coordinate(10, 10)); chess2.display(new Coordinate(20, 20)); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(十)结构型模式-外观模式","slug":"backend/designPatterns/设计模式(十)结构型模式-外观模式","date":"2018-10-31T16:00:10.000Z","updated":"2019-09-16T13:11:04.122Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(十)结构型模式-外观模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(十)结构型模式-外观模式/","excerpt":"","text":"遵循迪米特法则(最少知识法则) 一个软件实体应当尽可能少的与其他实体发生相互作用 外观模式也称蒙面模式 核心为子系统提供统一的入口，封装子系统的复杂性，便于客户端调用 例子感觉电脑的例子更形象： 电脑整机是 CPU、内存、硬盘的外观。有了外观以后，启动电脑和关闭电脑都简化了。 直接 new 一个电脑。 在 new 电脑的同时把 cpu、内存、硬盘都初始化好并且接好线。 对外暴露方法（启动电脑，关闭电脑）。 启动电脑（按一下电源键）：启动CPU、启动内存、启动硬盘 关闭电脑（按一下电源键）：关闭硬盘、关闭内存、关闭CPU","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(九)结构型模式-装饰器模式","slug":"backend/designPatterns/设计模式(九)结构型模式-装饰器模式","date":"2018-10-31T16:00:09.000Z","updated":"2019-09-16T13:11:04.034Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(九)结构型模式-装饰器模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(九)结构型模式-装饰器模式/","excerpt":"","text":"职责 动态的为一个对象增加新的功能，也叫包装器模式 装饰模式是一种用于代替继承的技术，无需通过继承增加子类就能扩展对象的新功能，使用对象的关联关系代替继承关系，更加灵活，同时避免类型体系的快速膨胀 降低系统的耦合度，可以动态的增加或删除对象的职责 实现细节Component 抽象构件角色 真实对象与装饰对象有相同的接口，这样，客户端对象就能够以真实对象相同的方式同装饰对象交互 ConcreteComponent 具体构件角色(真实对象) io流中的FileInputStream FileOutputStream Decorator 装饰角色 持有一个抽象构件的引用，装饰对象接受所有客户端的请求，并把这些请求转发给真实的对象，这样才能真实对象调用前后增加新的功能 ConcreteDecorator 具体装饰角色 负责给构件对象增加新的责任 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// 抽象构建public interface ICar &#123; void move();&#125;// ConcreteComponent 具体构件角色(真实对象)class Car implements ICar &#123; @Override public void move() &#123; System.out.println(\"陆地上跑！\"); &#125;&#125;// Decorator装饰角色class SuperCar implements ICar &#123; protected ICar car; public SuperCar(ICar car) &#123; super(); this.car = car; &#125; @Override public void move() &#123; car.move(); &#125;&#125;// ConcreteDecorator具体装饰角色class FlyCar extends SuperCar &#123; public FlyCar(ICar car) &#123; super(car); &#125; public void fly()&#123; System.out.println(\"天上飞！\"); &#125; @Override public void move() &#123; super.move(); fly(); &#125; &#125;// ConcreteDecorator具体装饰角色class WaterCar extends SuperCar &#123; public WaterCar(ICar car) &#123; super(car); &#125; public void swim()&#123; System.out.println(\"水上游！\"); &#125; @Override public void move() &#123; super.move(); swim(); &#125; &#125;// ConcreteDecorator具体装饰角色class AICar extends SuperCar &#123; public AICar(ICar car) &#123; super(car); &#125; public void autoMove()&#123; System.out.println(\"自动跑！\"); &#125; @Override public void move() &#123; super.move(); autoMove(); &#125; &#125; public static void main(String[] args) &#123; Car car = new Car(); car.move(); System.out.println(\"增加新的功能，飞行----------\"); FlyCar flycar = new FlyCar(car); flycar.move(); System.out.println(\"增加新的功能，水里游---------\"); WaterCar waterCar = new WaterCar(car); waterCar.move(); System.out.println(\"增加两个新的功能，飞行，水里游-------\"); WaterCar waterCar2 = new WaterCar(new FlyCar(car)); waterCar2.move(); &#125; 应用场景 操作系统的资源管理器 XML文件解析 Junit单元测试框架","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(八)结构型模式-组合模式","slug":"backend/designPatterns/设计模式(八)结构型模式-组合模式","date":"2018-10-31T16:00:08.000Z","updated":"2019-09-16T13:11:04.100Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(八)结构型模式-组合模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(八)结构型模式-组合模式/","excerpt":"","text":"组合模式，就是在一个对象中包含其他对象，这些被包含的对象可能是终点对象（不再包含别的对象），也有可能是非终点对象（其内部还包含其他对象，或叫组对象），我们将对象称为节点，即一个根节点包含许多子节点，这些子节点有的不再包含子节点，而有的仍然包含子节点，以此类推。 组合模式核心 抽象构件(Component)角色，定义了叶子与容器构件的共同点 叶子(Leaf)构件角色：无子节点 容器（Composite）构件角色：有容器特征，可以包括子节点1234567891011121314// 抽象组件public interface Component &#123; void operation();&#125;// 叶子组件interface Leaf extends Component &#123;&#125;// 容器组件interface Composite extends Component &#123; void add(Component c); void remove(Component c); Component getChild(int index);&#125; 应用场景 操作系统的资源管理器 XML文件解析 Junit单元测试框架 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// 使用组合模式，模拟杀毒软件架构设计public interface AbstractFile &#123; void killVirus(); //杀毒&#125;// 图片文件class ImageFile implements AbstractFile &#123; private String name; public ImageFile(String name) &#123; super(); this.name = name; &#125; @Override public void killVirus() &#123; System.out.println(\"---图像文件：\"+name+\",进行查杀！\"); &#125; &#125;// 文本文件class TextFile implements AbstractFile &#123; private String name; public TextFile(String name) &#123; super(); this.name = name; &#125; @Override public void killVirus() &#123; System.out.println(\"---文本文件：\"+name+\",进行查杀！\"); &#125;&#125;// 视频文件class VideoFile implements AbstractFile &#123; private String name; public VideoFile(String name) &#123; super(); this.name = name; &#125; @Override public void killVirus() &#123; System.out.println(\"---视频文件：\"+name+\",进行查杀！\"); &#125;&#125;// 文件夹class Folder implements AbstractFile &#123; private String name; //定义容器，用来存放本容器构建下的子节点 private List&lt;AbstractFile&gt; list = new ArrayList&lt;&gt;(); public Folder(String name) &#123; super(); this.name = name; &#125; public void add(AbstractFile file)&#123; list.add(file); &#125; public void remove(AbstractFile file)&#123; list.remove(file); &#125; public AbstractFile getChild(int index)&#123; return list.get(index); &#125; // 递归查杀子文件夹的文件 @Override public void killVirus() &#123; System.out.println(\"---文件夹：\"+name+\",进行查杀\"); for (AbstractFile file : list) &#123; file.killVirus(); &#125; &#125;&#125;// 开始杀毒 public static void main(String[] args) &#123; AbstractFile f2,f3,f4,f5; // D盘文件夹, 有以下俩个文件，和一个视频文件夹vidio Folder f1 = new Folder(\"D:/\"); f2 = new ImageFile(\"老高的大头像.jpg\"); f3 = new TextFile(\"Hello.txt\"); f1.add(f2); f1.add(f3); // 视频文件夹vidio Folder f11 = new Folder(\"vidio\"); f4 = new VideoFile(\"笑傲江湖.avi\"); f5 = new VideoFile(\"神雕侠侣.avi\"); f11.add(f4); f11.add(f5); f1.add(f11); // 开始杀毒 f1.killVirus(); &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(七)结构型模式-桥接模式","slug":"backend/designPatterns/设计模式(七)结构型模式-桥接模式","date":"2018-10-31T16:00:07.000Z","updated":"2019-09-16T13:11:03.962Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(七)结构型模式-桥接模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(七)结构型模式-桥接模式/","excerpt":"","text":"核心本质 处理多层继承结构，处理多维度变化的场景，将各个维度设计成独立的继承结构，使各个维度可以独立的扩展在抽象层建立关联 桥接模式可以取代多层继承的方案，多层继承违背了单一职责原则，复用性差，类的个数也非常多。桥接模式可以极大减少子类的个数，从而降低管理和维护的成本 极大提高了系统可扩展性，从俩个变化维度中任意扩展一个维度，都不需要修改原有的系统。符合开闭原则 就像一个桥，将俩个变化维度连接起来，各个维度都可以独立的变化，故称之为：桥模式 应用场景 JDBC驱动程序 OA系统中的消息处理，普通消息，加急消息，特急消息 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 品牌维度public interface Brand &#123; void sale();&#125;class Lenovo implements Brand &#123; @Override public void sale() &#123; System.out.println(\"销售联想电脑\"); &#125; &#125;class Dell implements Brand &#123; @Override public void sale() &#123; System.out.println(\"销售Dell电脑\"); &#125;&#125;class Shenzhou implements Brand &#123; @Override public void sale() &#123; System.out.println(\"销售神舟电脑\"); &#125;&#125;// 电脑类型-通过组合将品牌桥接过来public class Computer &#123; protected Brand brand; public Computer(Brand b) &#123; this.brand = b; &#125; public void sale()&#123; brand.sale(); &#125;&#125;class Desktop extends Computer &#123; public Desktop(Brand b) &#123; super(b); &#125; @Override public void sale() &#123; super.sale(); System.out.println(\"销售台式机\"); &#125;&#125;class Laptop extends Computer &#123; public Laptop(Brand b) &#123; super(b); &#125; @Override public void sale() &#123; super.sale(); System.out.println(\"销售笔记本\"); &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; //销售联想的笔记本电脑 Computer c = new Laptop(new Lenovo()); c.sale(); //销售神舟的台式机 Computer c2 = new Desktop(new Shenzhou()); c2.sale(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(六)结构型模式-代理模式","slug":"backend/designPatterns/设计模式(六)结构型模式-代理模式","date":"2018-10-31T16:00:06.000Z","updated":"2020-01-04T12:21:52.069Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(六)结构型模式-代理模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(六)结构型模式-代理模式/","excerpt":"","text":"通过代理，控制对对象的访问，可以详细控制访问某个类对象的方法，在调用这个方法前做前置处理或者在方法之后做后置处理 核心本质在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 应用场景 代理模式是程序开发中经常使用，使用代理模式可以很方便的满足我们一些特定的需求，代理分为静态代理和动态代理，下面是具体栗子： 静态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105// 明星接口public interface Star &#123; /** * 面谈 */ void confer(); /** * 签合同 */ void signContract(); /** * 订票 */ void bookTicket(); /** * 唱歌 */ void sing(); /** * 收钱 */ void collectMoney();&#125;// 真实明星public class RealStar implements Star &#123; @Override public void bookTicket() &#123; System.out.println(\"RealStar.bookTicket()\"); &#125; @Override public void collectMoney() &#123; System.out.println(\"RealStar.collectMoney()\"); &#125; @Override public void confer() &#123; System.out.println(\"RealStar.confer()\"); &#125; @Override public void signContract() &#123; System.out.println(\"RealStar.signContract()\"); &#125; @Override public void sing() &#123; System.out.println(\"RealStar(周杰伦本人).sing()\"); &#125;&#125;// 明星经纪人public class ProxyStar implements Star &#123; private Star star; public ProxyStar(Star star) &#123; super(); this.star = star; &#125; @Override public void bookTicket() &#123; System.out.println(\"ProxyStar.bookTicket()\"); &#125; @Override public void collectMoney() &#123; System.out.println(\"ProxyStar.collectMoney()\"); &#125; @Override public void confer() &#123; System.out.println(\"ProxyStar.confer()\"); &#125; @Override public void signContract() &#123; System.out.println(\"ProxyStar.signContract()\"); &#125; @Override public void sing() &#123; star.sing(); &#125;&#125;// 商演执行类public class Client &#123; public static void main(String[] args) &#123; // 需要找周杰伦来进行一次商演，直接找他的经纪人处理 Star real = new RealStar(); Star proxy = new ProxyStar(real); proxy.confer(); proxy.signContract(); proxy.bookTicket(); // 经纪人不会唱歌需要他找到周杰伦来唱 proxy.sing(); proxy.collectMoney(); &#125;&#125; 可以看到静态代理实现起来很简单，代理类和被代理类都实现了相同的接口，代理类作为中介提供了对委托资源的访问。 因为代理类和被代理类都实现了相同的接口，所以当接口变化时相应的代理类就需要对应的修改，这样的话维护起来就很繁琐，所以动态代理出现了 动态代理 动态代理的实现有很多种方式： JDK 自带的动态代理 Java assist 字节码操作库实现 Cglib Asm 底层使用指令，可维护性差 我们来看一下JDK自带的动态代理是怎么实现的 JDK动态代理涉及到两个类 Proxy: 此类用来动态生成代理类和对象 InvocationHandler：处理器接口，此类用来定义具体要代理的内容、执行的动作 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public interface Star &#123; /** * 面谈 */ void confer(); /** * 签合同 */ void signContract(); /** * 订票 */ void bookTicket(); /** * 唱歌 */ void sing(); /** * 收钱 */ void collectMoney();&#125;// 周杰伦public class RealStar implements Star &#123; @Override public void bookTicket() &#123; System.out.println(\"RealStar.bookTicket()\"); &#125; @Override public void collectMoney() &#123; System.out.println(\"RealStar.collectMoney()\"); &#125; @Override public void confer() &#123; System.out.println(\"RealStar.confer()\"); &#125; @Override public void signContract() &#123; System.out.println(\"RealStar.signContract()\"); &#125; @Override public void sing() &#123; System.out.println(\"RealStar(周杰伦本人).sing()\"); &#125;&#125;// 增强处理类public class StarHandler implements InvocationHandler &#123; Star realStar; public StarHandler(Star realStar) &#123; super(); this.realStar = realStar; &#125; // 只要调用了被代理的方法都会执行该方法 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object object = null; System.out.println(\"真正的方法执行前！\"); System.out.println(\"面谈，签合同，预付款，订机票\"); if(method.getName().equals(\"sing\"))&#123; object = method.invoke(realStar, args); &#125; System.out.println(\"真正的方法执行后！\"); System.out.println(\"收尾款\"); return object; &#125;&#125;// 演出开始public static void main(String[] args) &#123; Star realStar = new RealStar(); StarHandler handler = new StarHandler(realStar); Star proxy = (Star) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;Star.class&#125;, handler); proxy.sing(); &#125; 从上面的例子可以看到，代理类和被代理类并没有像静态代理那样实现相同接口，但是一样将Star realStar引用通过代理类的构造函数传入具体的实施者（这个是代理类与被代理类能联通的关键），有联系了才能叫人做事嘛 动态代理的代理类StarHandler虽然没有和被代理类实现相同的接口，但它需要实现InvocationHandler接口，这个类就一个对象Star realStar，一个方法invoke()，有了明星引用是不是可以在invoke()直接叫明星唱歌了，而且还可以替明星做额外的事情 总结 静态代理 1.可以做到在不修改目标对象的功能前提下,对目标功能扩展. 2.缺点:因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护. 3.由程序员创建或由特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了所以说是静态代理，而动态代理是程序在运行过程中利用反射生成代理类 动态代理 1.在程序运行时，运用反射机制动态创建而成。由此可见，代理类可以为委托类预处理消息、把消息转发给委托类和事后处理消息等","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(五)结构型模式-适配器模式","slug":"backend/designPatterns/设计模式(五)结构型模式-适配器模式","date":"2018-10-31T16:00:05.000Z","updated":"2019-09-16T13:11:04.094Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(五)结构型模式-适配器模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(五)结构型模式-适配器模式/","excerpt":"","text":"结构型模式核心作用是从程序的结构实现松解耦，从而可以扩大整体的类结构，用来解决更大的问题 核心本质适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。 分类 类适配器，通过继承 对象适配器，通过组合的方式 代码实现 在只有usb接口的电脑能够使用ps2接口的鼠标键盘，需要一个适配器将ps2的接口和usb的接口连接起来 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 需要适配的对象public class Ps2Mouse &#123; public void use()&#123; System.out.println(\"正在使用ps2接口类型的鼠标！\"); &#125;&#125;// 原对象处理接口public interface Target &#123; // 处理方法 public void handle();&#125;// 基于继承被适配类实现适配public class TargetPs2Impl1 extends Ps2Mouse implements Target &#123; // 继承Ps2Mouse直接调用use方法 @Override public void handle() &#123; super.use(); &#125;&#125;// 基于组合被适配类实现适配public class TargetPs2Impl2 implements Target &#123; private Ps2Mouse ps2Mouse; // 需要在构造函数的时候传入被适配类对象 public TargetPs2Impl2(Ps2Mouse ps2Mouse) &#123; this.ps2Mouse = ps2Mouse; &#125; @Override public void handle() &#123; ps2Mouse.use(); &#125;&#125;// 使用者public class Person &#123; /** * 使用鼠标 * @param target */ public void useMouse(Target target) &#123; target.handle(); &#125; public static void main(String[] args) &#123; Person person = new Person(); // 使用适配器1可以使用ps2键盘了 Target target1 = new TargetPs2Impl1(); person.useMouse(target1); // 使用适配器2可以使用ps2键盘了 Ps2Mouse ps2Mouse = new Ps2Mouse(); Target target2 = new TargetPs2Impl2(ps2Mouse); person.useMouse(target2); &#125;&#125; 应用场景 美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V JAVA 中的 jdbc。 鼠标有usb接口和 ps2接口转化器 旧系统改造和升级 Spring MVC的HandlerAdapter 总结","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(四)创建型模式-原型模式","slug":"backend/designPatterns/设计模式(四)创建型模式-原型模式","date":"2018-10-31T16:00:04.000Z","updated":"2019-09-16T13:11:04.275Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(四)创建型模式-原型模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(四)创建型模式-原型模式/","excerpt":"","text":"核心本质 当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 克隆类似于new, 但是不同于new, new创建新的对象属性采用的是默认值，克隆出的对象属性值完全和原型对象相同，并且克隆出的新对象改变并不会影响原型对象 应用场景 Cloneable接口和clone方法 去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐”。 JAVA 中的 StringBuilder。 原型模式很少单独出现，一般是和工厂方法模式一起出现，通过clone 的方法创建一个对象，然后由工厂方法提供给调用者，比如Spring中Bean的创建实际就两种单例模式和原型模式，当然原型模式需要和工厂模式搭配起来 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145/** * 浅复制 * 1997,英国的克隆羊，多利！ * 实现 Cloneable接口 */public class DeepCopySheep implements Cloneable,Serializable &#123; private String sname; private Date birthday; /** * 直接调用object对象的clone()方法！ * @return * @throws CloneNotSupportedException */ @Override protected Object clone() throws CloneNotSupportedException &#123; Object obj = super.clone(); return obj; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public DeepCopySheep(String sname, Date birthday) &#123; super(); this.sname = sname; this.birthday = birthday; &#125; public DeepCopySheep() &#123; &#125; &#125;/** * 深复制 * 1997,英国的克隆羊，多利！ */public class ShallowCopySheep implements Cloneable &#123; private String sname; private Date birthday; /** * 直接调用object对象的clone()方法！ * @return * @throws CloneNotSupportedException */ @Override protected Object clone() throws CloneNotSupportedException &#123; Object obj = super.clone(); // 添加如下代码实现深复制(deep Clone) ShallowCopySheep s = (ShallowCopySheep) obj; // 把属性也进行克隆！ s.birthday = (Date) this.birthday.clone(); return obj; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public ShallowCopySheep(String sname, Date birthday) &#123; super(); this.sname = sname; this.birthday = birthday; &#125; public ShallowCopySheep() &#123; &#125; &#125;/** * 原型模式(深复制,使用序列化和反序列化的方式实现深复制) */public class Client3 &#123; public static void main(String[] args) throws CloneNotSupportedException, Exception &#123; Date date = new Date(12312321331L); DeepCopySheep s1 = new DeepCopySheep(\"少利\",date); System.out.println(s1); System.out.println(s1.getSname()); System.out.println(s1.getBirthday()); // 使用序列化和反序列化实现深复制 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(s1); byte[] bytes = bos.toByteArray(); ByteArrayInputStream bis = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bis); // 克隆好的对象！ DeepCopySheep s2 = (DeepCopySheep) ois.readObject(); System.out.println(\"修改原型对象的属性值\"); date.setTime(23432432423L); System.out.println(s1.getBirthday()); s2.setSname(\"多利\"); System.out.println(s2); System.out.println(s2.getSname()); System.out.println(s2.getBirthday()); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(三)创建型模式-建造者模式","slug":"backend/designPatterns/设计模式(三)创建型模式-建造者模式","date":"2018-10-31T16:00:03.000Z","updated":"2019-09-16T13:11:03.975Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(三)创建型模式-建造者模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(三)创建型模式-建造者模式/","excerpt":"","text":"核心本质 复杂对象的构建过程，分离了对象子组件的单独构造(builder)和装配(director) 构造子对象 装配子对象 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161// 创建一个表示食物条目和食物包装的接口。public interface Item &#123; public String name(); public Packing packing(); public float price(); &#125;public interface Packing &#123; public String pack();&#125;// 创建实现 Packing 接口的实体类。public class Wrapper implements Packing &#123; @Override public String pack() &#123; return \"Wrapper\"; &#125;&#125;public class Bottle implements Packing &#123; @Override public String pack() &#123; return \"Bottle\"; &#125;&#125;// 创建实现 Item 接口的抽象类，该类提供了默认的功能。public abstract class Burger implements Item &#123; @Override public Packing packing() &#123; return new Wrapper(); &#125; @Override public abstract float price();&#125;public abstract class ColdDrink implements Item &#123; @Override public Packing packing() &#123; return new Bottle(); &#125; @Override public abstract float price();&#125;// 创建扩展了 Burger 和 ColdDrink 的实体类。public class VegBurger extends Burger &#123; @Override public float price() &#123; return 25.0f; &#125; @Override public String name() &#123; return \"Veg Burger\"; &#125;&#125;public class ChickenBurger extends Burger &#123; @Override public float price() &#123; return 50.5f; &#125; @Override public String name() &#123; return \"Chicken Burger\"; &#125;&#125;public class Coke extends ColdDrink &#123; @Override public float price() &#123; return 30.0f; &#125; @Override public String name() &#123; return \"Coke\"; &#125;&#125;public class Pepsi extends ColdDrink &#123; @Override public float price() &#123; return 35.0f; &#125; @Override public String name() &#123; return \"Pepsi\"; &#125;&#125;// 创建一个 Meal 类，带有上面定义的 Item 对象。import java.util.ArrayList;import java.util.List; public class Meal &#123; private List&lt;Item&gt; items = new ArrayList&lt;Item&gt;(); public void addItem(Item item)&#123; items.add(item); &#125; public float getCost()&#123; float cost = 0.0f; for (Item item : items) &#123; cost += item.price(); &#125; return cost; &#125; public void showItems()&#123; for (Item item : items) &#123; System.out.print(\"Item : \"+item.name()); System.out.print(\", Packing : \"+item.packing().pack()); System.out.println(\", Price : \"+item.price()); &#125; &#125; &#125;// 创建一个 MealBuilder 类，实际的 builder 类负责创建 Meal 对象。public class MealBuilder &#123; public Meal prepareVegMeal ()&#123; Meal meal = new Meal(); meal.addItem(new VegBurger()); meal.addItem(new Coke()); return meal; &#125; public Meal prepareNonVegMeal ()&#123; Meal meal = new Meal(); meal.addItem(new ChickenBurger()); meal.addItem(new Pepsi()); return meal; &#125;&#125;// BuiderPatternDemo 使用 MealBuider 来演示建造者模式（Builder Pattern）。public class BuilderPatternDemo &#123; public static void main(String[] args) &#123; MealBuilder mealBuilder = new MealBuilder(); Meal vegMeal = mealBuilder.prepareVegMeal(); System.out.println(\"Veg Meal\"); vegMeal.showItems(); System.out.println(\"Total Cost: \" +vegMeal.getCost()); Meal nonVegMeal = mealBuilder.prepareNonVegMeal(); System.out.println(\"\\n\\nNon-Veg Meal\"); nonVegMeal.showItems(); System.out.println(\"Total Cost: \" +nonVegMeal.getCost()); &#125;&#125; 应用场景 构建一个复杂的产品，比如生产一台手机，电脑是不是有多个组件，各个组件的装配是不是有步骤问题 去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐”。 JAVA 中的 StringBuilder。 Spring中BeanDefinitionBuilder BeanDefinitionBuilder1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class BeanDefinitionBuilder &#123; /** * The &#123;@code BeanDefinition&#125; instance we are creating. */ private AbstractBeanDefinition beanDefinition; // ... some not important methods for this article // Some of building methods /** * Set the name of the parent definition of this bean definition. */ public BeanDefinitionBuilder setParentName(String parentName) &#123; this.beanDefinition.setParentName(parentName); return this; &#125; /** * Set the name of the factory method to use for this definition. */ public BeanDefinitionBuilder setFactoryMethod(String factoryMethod) &#123; this.beanDefinition.setFactoryMethodName(factoryMethod); return this; &#125; /** * Add an indexed constructor arg value. The current index is tracked internally * and all additions are at the present point. * @deprecated since Spring 2.5, in favor of &#123;@link #addConstructorArgValue&#125; */ @Deprecated public BeanDefinitionBuilder addConstructorArg(Object value) &#123; return addConstructorArgValue(value); &#125; /** * Add an indexed constructor arg value. The current index is tracked internally * and all additions are at the present point. */ public BeanDefinitionBuilder addConstructorArgValue(Object value) &#123; this.beanDefinition.getConstructorArgumentValues().addIndexedArgumentValue( this.constructorArgIndex++, value); return this; &#125; /** * Add a reference to a named bean as a constructor arg. * @see #addConstructorArgValue(Object) */ public BeanDefinitionBuilder addConstructorArgReference(String beanName) &#123; this.beanDefinition.getConstructorArgumentValues().addIndexedArgumentValue( this.constructorArgIndex++, new RuntimeBeanReference(beanName)); return this; &#125; /** * Add the supplied property value under the given name. */ public BeanDefinitionBuilder addPropertyValue(String name, Object value) &#123; this.beanDefinition.getPropertyValues().add(name, value); return this; &#125; /** * Add a reference to the specified bean name under the property specified. * @param name the name of the property to add the reference to * @param beanName the name of the bean being referenced */ public BeanDefinitionBuilder addPropertyReference(String name, String beanName) &#123; this.beanDefinition.getPropertyValues().add(name, new RuntimeBeanReference(beanName)); return this; &#125; /** * Set the init method for this definition. */ public BeanDefinitionBuilder setInitMethodName(String methodName) &#123; this.beanDefinition.setInitMethodName(methodName); return this; &#125; // Methods that can be used to construct BeanDefinition /** * Return the current BeanDefinition object in its raw (unvalidated) form. * @see #getBeanDefinition() */ public AbstractBeanDefinition getRawBeanDefinition() &#123; return this.beanDefinition; &#125; /** * Validate and return the created BeanDefinition object. */ public AbstractBeanDefinition getBeanDefinition() &#123; this.beanDefinition.validate(); return this.beanDefinition; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(二)创建型模式-工厂模式","slug":"backend/designPatterns/设计模式(二)创建型模式-工厂模式","date":"2018-10-31T16:00:02.000Z","updated":"2019-09-16T13:11:04.038Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(二)创建型模式-工厂模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(二)创建型模式-工厂模式/","excerpt":"","text":"核心本质 实例化对象，用工厂方法代替new操作 将选择实现类、创建对象统一管理和控制，从而将调用者跟我们的实现类解耦 分类 简单工厂模式 工厂方法模式 抽象工厂模式 简单工厂模式要点： 实际项目中使用最多 简单工厂模式也叫静态工厂模式，就是工厂类一般使用的是静态方法，通过接受不同的参数的不同来返回不同的实例对象 对于增加新产品无能为力，不修改代码的话是无法进行扩展的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public interface Car &#123; void run();&#125;public class Audi implements Car &#123; @Override public void run() &#123; System.out.println(\"奥迪再跑！\"); &#125;&#125;public class Byd implements Car &#123; @Override public void run() &#123; System.out.println(\"比亚迪再跑！\"); &#125;&#125;public class CarFactory &#123; public static Car createCar(String type)&#123; if(\"奥迪\".equals(type))&#123; return new Audi(); &#125;else if(\"比亚迪\".equals(type))&#123; return new Byd(); &#125;else&#123; return null; &#125; &#125; &#125;public class CarFactory2 &#123; public static Car createAudi()&#123; return new Audi(); &#125; public static Car createByd()&#123; return new Byd(); &#125; &#125; 工厂方法模式要点： 简单工厂模式只有一个工厂类，而工厂方法模式有一组实现了相同接口的工厂类，方便扩展1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public interface Car &#123; void run();&#125;public interface CarFactory &#123; Car createCar();&#125;public class Audi implements Car &#123; @Override public void run() &#123; System.out.println(\"奥迪再跑！\"); &#125;&#125;public class AudiFactory implements CarFactory &#123; @Override public Car createCar() &#123; return new Audi(); &#125;&#125;public class Benz implements Car &#123; @Override public void run() &#123; System.out.println(\"奔驰再跑！\"); &#125;&#125;public class BenzFactory implements CarFactory &#123; @Override public Car createCar() &#123; return new Benz(); &#125;&#125;public class Byd implements Car &#123; @Override public void run() &#123; System.out.println(\"比亚迪再跑！\"); &#125;&#125;public class BydFactory implements CarFactory &#123; @Override public Car createCar() &#123; return new Byd(); &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; Car c1 = new AudiFactory().createCar(); Car c2 = new BydFactory().createCar(); c1.run(); c2.run(); &#125;&#125; 抽象工厂模式 用来生产不同产品族的全部产品。但对于增加新的产品无能为力，支持增加产品族 抽象工厂模式是工厂方法模式的升级版本，在有多个业务品种，业务分类时，使用抽象工厂模式产生需要对象是一种非常好的解决方式 例子一123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131// 引擎接口public interface Engine &#123; void run(); void start();&#125;// 好引擎class LuxuryEngine implements Engine&#123; @Override public void run() &#123; System.out.println(\"转的快！\"); &#125; @Override public void start() &#123; System.out.println(\"启动快!可以自动启停！\"); &#125; &#125;// 差引擎class LowEngine implements Engine&#123; @Override public void run() &#123; System.out.println(\"转的慢！\"); &#125; @Override public void start() &#123; System.out.println(\"启动慢!\"); &#125; &#125;// 座椅接口类public interface Seat &#123; void massage();&#125;// 可以按摩的接口class LuxurySeat implements Seat &#123; @Override public void massage() &#123; System.out.println(\"可以自动按摩！\"); &#125; &#125;// 不能按摩的接口class LowSeat implements Seat &#123; @Override public void massage() &#123; System.out.println(\"不能按摩！\"); &#125; &#125;// 轮胎public interface Tyre &#123; void revolve();&#125;// 好轮胎class LuxuryTyre implements Tyre &#123; @Override public void revolve() &#123; System.out.println(\"旋转不磨损！\"); &#125; &#125;// 差轮胎class LowTyre implements Tyre &#123; @Override public void revolve() &#123; System.out.println(\"旋转磨损快！\"); &#125; &#125;// 抽象工厂接口public interface CarFactory &#123; Engine createEngine(); Seat createSeat(); Tyre createTyre();&#125;// 抽象工厂实现类（奢饰汽车）public class LuxuryCarFactory implements CarFactory &#123; @Override public Engine createEngine() &#123; return new LuxuryEngine(); &#125; @Override public Seat createSeat() &#123; return new LuxurySeat(); &#125; @Override public Tyre createTyre() &#123; return new LuxuryTyre(); &#125;&#125;// 抽象工厂实现类（普通汽车）public class LowCarFactory implements CarFactory &#123; @Override public Engine createEngine() &#123; return new LowEngine(); &#125; @Override public Seat createSeat() &#123; return new LowSeat(); &#125; @Override public Tyre createTyre() &#123; return new LowTyre(); &#125;&#125;public static void main(String[] args) &#123; CarFactory factory = new LuxuryCarFactory(); Engine e = factory.createEngine(); e.run(); e.start(); &#125; 应用场景 JDK中Calendar的getInstance方法 JDBC中Connection对象的获取 Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定 Spring中的FactoryBean就是典型的工厂方法模式 数据库连接池 项目中读取配置文件的类 总结","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"设计模式(一)创建型模式-单例模式","slug":"backend/designPatterns/设计模式(一)创建型模式-单例模式","date":"2018-10-31T16:00:01.000Z","updated":"2019-11-10T02:08:41.864Z","comments":true,"path":"2018/11/01/backend/designPatterns/设计模式(一)创建型模式-单例模式/","link":"","permalink":"http://www.songshuiyang.com/2018/11/01/backend/designPatterns/设计模式(一)创建型模式-单例模式/","excerpt":"","text":"设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 设计模式是一种思想、思维，将设计模式运用到工作实践中可以解决许多问题，也可以使项目变得更加健壮，更加可扩展性 核心作用 保证一个类只有一个实例，并且提供一个访问该实例的全局访问点 单例模式的优点 只生成一个实例，减少了系统性能开销，当一个对象的产生需要比较多的资源时，如读取配置，产生其他依赖对象时，则可以通过在应用启动时直接产生一个单例对象，然后永久驻留内存的方式来解决 常见的五种单例模式实现方式 主要： 饿汉式 懒汉式 其他 双重检测锁式 静态内部类式 枚举单例 饿汉式 （线程安全，调用效率高，但是不能延时加载） 1234567891011121314151617181920212223242526package com.pattern.singleton;/** * 饿汉式单例模式 */public class SingletonDemo1 &#123; /** * 类初始化时，立即加载这个static对象（没有延时加载的优势） * 不会涉及多个线程对象访问该对象的问题，Java虚拟机只会装载一次该类 */ private static SingletonDemo1 instance = new SingletonDemo1(); /** * 私有构造函数 */ private SingletonDemo1()&#123; &#125; /** * 方法没有同步，调用效率高！ * @return */ public static SingletonDemo1 getInstance()&#123; return instance; &#125;&#125; 懒汉式 （线程安全，调用效率不高，但是可以延时加载） 12345678910111213141516171819202122232425262728293031package com.pattern.singleton;/** * 懒汉式单例模式 * */public class SingletonDemo2 &#123; /** * 类初始化时，不初始化这个对象（延时加载，真正用的时候再创建）资源利用率高了。 */ private static SingletonDemo2 instance; /** * 私有化构造器 */ private SingletonDemo2()&#123; &#125; /** * 方法同步，调用效率低！ * @return */ public static synchronized SingletonDemo2 getInstance()&#123; if(instance==null)&#123; instance = new SingletonDemo2(); &#125; return instance; &#125; &#125; 双重检测锁式 （由于JVM底层内部模型原因，偶尔会出问题，不建议使用） 1234567891011121314151617181920212223242526272829303132package com.pattern.singleton;/** * 双重检查锁实现单例模式 */public class SingletonDemo3 &#123; private static SingletonDemo3 instance = null; // 将同步内容下方到if内部，提高了执行的效率，不用每次获取对象都进行同步，只有第一次才同步创建了以后就没必要了 public static SingletonDemo3 getInstance() &#123; if (instance == null) &#123; SingletonDemo3 sc; synchronized (SingletonDemo3.class) &#123; sc = instance; if (sc == null) &#123; synchronized (SingletonDemo3.class) &#123; if(sc == null) &#123; sc = new SingletonDemo3(); &#125; &#125; instance = sc; &#125; &#125; &#125; return instance; &#125; private SingletonDemo3() &#123; &#125; &#125; 静态内部类式 （线程安全，调用效率高，可以延时加载） 12345678910111213141516171819202122232425package com.pattern.singleton;/** * 测试静态内部类实现单例模式 * 这种方式：线程安全，调用效率高，并且实现了延时加载！ */public class SingletonDemo4 &#123; private static class SingletonClassInstance &#123; private static final SingletonDemo4 instance = new SingletonDemo4(); &#125; private SingletonDemo4()&#123; &#125; /** * 只有真正调用getInstance() 才会加载静态内部类，加载类时是线程安全的 * 方法没有同步，调用效率高，兼备了并发和延时加载的优势 * @return */ public static SingletonDemo4 getInstance()&#123; return SingletonClassInstance.instance; &#125; &#125; 枚举单例 （线程安全，调用效率高，不能延时加载） 123456789101112131415package com.pattern.singleton;/** * 测试枚举式实现单例模式(没有延时加载) * */public enum SingletonDemo5 &#123; //这个枚举元素，本身就是单例对象！ INSTANCE; //添加自己需要的操作！ public void singletonOperation()&#123; &#125;&#125; 常用应用场景 Spring中的Bean Spring框架对单例的支持不是采用上面的这些方式，而是采用单例注册表的方式进行实现的 12/** Cache of singleton objects created by FactoryBeans: FactoryBean name --&gt; object */private final Map&lt;String, Object&gt; factoryBeanObjectCache = new ConcurrentHashMap&lt;String, Object&gt;(16); Servlet，每个Servlet也是单例 windows 的任务管理器 数据库连接池 项目中读取配置文件的类 总结 一般建议使用饿汉式，只有在要明确实现 lazy loading 效果时，则使用静态内部类式，如果涉及到反序列化创建对象时，可以尝试使用枚举方式。如果有其他特殊的需求，可以考虑使用双检锁方式。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.songshuiyang.com/tags/设计模式/"}]},{"title":"IO-Netty-基础概念","slug":"backend/java/io/IO-Netty-基础概念","date":"2018-10-29T16:03:00.000Z","updated":"2019-11-27T15:11:32.607Z","comments":true,"path":"2018/10/30/backend/java/io/IO-Netty-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-Netty-基础概念/","excerpt":"","text":"概念Netty 是一款提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。 也就是说，Netty 是一个基于 NIO 的客户、服务器端编程框架。使用 Netty 可以确保你快速和简单地开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty 相当简化和流线化了网络应用的编程开发过程，例如，TCP 和 UDP 的 socket 服务开发。 （以上摘自百度百科）。 解析Netty特性 Netty 具有如下特性( 摘自《Netty in Action》 ) 分类 Netty的特性 设计 1. 统一的 API ，支持多种传输类型( 阻塞和非阻塞的 ) 2. 简单而强大的线程模型 3. 真正的无连接数据报套接字( UDP )支持 4. 连接逻辑组件( ChannelHander 中顺序处理消息 )以及组件复用( 一个 ChannelHandel 可以被多个ChannelPipeLine 复用 ) 易于使用 1. 详实的 Javadoc 和大量的示例集 2. 不需要超过 JDK 1.6+ 的依赖 性能 拥有比 Java 的核心 API 更高的吞吐量以及更低的延迟( 得益于池化和复用 )，更低的资源消耗以及最少的内存复制 健壮性 1. 不会因为慢速、快速或者超载的连接而导致 OutOfMemoryError 2. 消除在高速网络中 NIO 应用程序常见的不公平读 / 写比率 安全性 完整的 SSL/TLS 以及 StartTLs 支持，可用于受限环境下，如 Applet 和 OSGI 社区驱动 发布快速而且频繁 Netty 的使用场景 构建高性能、低时延的各种 Java 中间件，Netty 主要作为基础通信框架提供高性能、低时延的通信服务。例如： RocketMQ ，分布式消息队列。 Dubbo ，服务调用框架。 Spring WebFlux ，基于响应式的 Web 框架。 HDFS ，分布式文件系统。 公有或者私有协议栈的基础通信框架，例如可以基于 Netty 构建异步、高性能的 WebSocket、Protobuf 等协议的支持。 各领域应用，例如大数据、游戏等，Netty 作为高性能的通信框架用于内部各模块的数据分发、传输和汇总等，实现模块之间高性能通信。 Netty 如何实现高性能 性能是设计出来的，而不是测试出来的。那么，Netty 的架构设计是如何实现高性能的呢？ 线程模型 ：采用异步非阻塞的 I/O 类库，基于 Reactor 模式实现，解决了传统同步阻塞 I/O 模式下服务端无法平滑处理客户端线性增长的问题。 堆外内存 ：TCP 接收和发送缓冲区采用直接内存代替堆内存，避免了内存复制，提升了 I/O 读取和写入性能。 内存池设计 ：支持通过内存池的方式循环利用 ByteBuf，避免了频繁创建和销毁 ByteBuf 带来的性能消耗。 参数配置 ：可配置的 I/O 线程数目和 TCP 参数等，为不同用户提供定制化的调优参数，满足不同的性能场景。 队列优化 ：采用环形数组缓冲区，实现无锁化并发编程，代替传统的线程安全容器或锁。 并发能力 ：合理使用线程安全容器、原子类等，提升系统的并发能力。 降低锁竞争 ：关键资源的使用采用单线程串行化的方式，避免多线程并发访问带来的锁竞争和额外的 CPU 资源消耗问题。 内存泄露检测 ：通过引用计数器及时地释放不再被引用的对象，细粒度的内存管理降低了 GC 的频率，减少频繁 GC 带来的时延增大和 CPU 损耗。 Netty 如何实现高可靠 链路有效性检测：由于长连接不需要每次发送消息都创建链路，也不需要在消息完成交互时关闭链路，因此相对于短连接性能更高。为了保证长连接的链路有效性，往往需要通过心跳机制周期性地进行链路检测。使用心跳机制的原因是，避免在系统空闲时因网络闪断而断开连接，之后又遇到海量业务冲击导致消息积压无法处理。为了解决这个问题，需要周期性地对链路进行有效性检测，一旦发现问题，可以及时关闭链路，重建 TCP 连接。为了支持心跳，Netty 提供了两种链路空闲检测机制： 读空闲超时机制：连续 T 周期没有消息可读时，发送心跳消息，进行链路检测。如果连续 N 个周期没有读取到心跳消息，可以主动关闭链路，重建连接。 写空闲超时机制：连续 T 周期没有消息需要发送时，发送心跳消息，进行链路检测。如果连续 N 个周期没有读取对方发回的心跳消息，可以主动关闭链路，重建连接。 内存保护机制：Netty 提供多种机制对内存进行保护，包括以下几个方面： 通过对象引用计数器对 ByteBuf 进行细粒度的内存申请和释放，对非法的对象引用进行检测和保护。 可设置的内存容量上限，包括 ByteBuf、线程池线程数等，避免异常请求耗光内存。 优雅停机：优雅停机功能指的是当系统推出时，JVM 通过注册的 Shutdown Hook 拦截到退出信号量，然后执行推出操作，释放相关模块的资源占用，将缓冲区的消息处理完成或清空，将待刷新的数据持久化到磁盘和数据库中，等到资源回收和缓冲区消息处理完成之后，再退出。 总结 Netty 是一个基于 NIO 的客户、服务器端编程框架，拥有比 Java 的核心 API 更高的吞吐量以及更低的延迟，所以在技术上没有最好只有更好 Netty 主要作为基础通信框架提供高性能、低时延的通信服务，比如 RocketMQ、Dubbo都有使用。 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-AIO-基础概念","slug":"backend/java/io/IO-AIO-基础概念","date":"2018-10-29T16:02:00.000Z","updated":"2020-03-16T11:43:55.469Z","comments":true,"path":"2018/10/30/backend/java/io/IO-AIO-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-AIO-基础概念/","excerpt":"","text":"概念 AIO ，全称 Asynchronous IO ，也叫 NIO2,jdk1.7开始应用 ，是一种非阻塞 + 异步的通信模式。在 NIO 的基础上，引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。 解析 AIO 并没有采用 NIO 的多路复用器，而是使用异步通道的概念。其 read，write 方法的返回类型，都是 Future 对象。而 Future 模型是异步的，其核心思想是：去主函数等待时间。 异步 IO 是基于事件和回调机制实现的: 也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作 总结 查阅网上相关资料，发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。 参考 芋道源码 http://www.iocoder.cn https://snailclimb.gitee.io/javaguide/#/docs/java/Java基础知识","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-NIO-通道Channel","slug":"backend/java/io/IO-NIO-通道Channel","date":"2018-10-29T16:01:02.000Z","updated":"2019-11-19T14:39:08.846Z","comments":true,"path":"2018/10/30/backend/java/io/IO-NIO-通道Channel/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-NIO-通道Channel/","excerpt":"","text":"概念 由 java.nio.channels.Channels 包定义的，通道Channel表示IO源与目标打开的连接，Channel类似于传统的流，但Channel本身不能直接访问数据，Channel只能与Buffer进行交互 通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。 Channel相比IO中的Stream更加高效，可以异步双向传输，但是必须和buffer一起使用。 主要实现类 FileChannel，读写文件中的数据。 SocketChannel，通过TCP读写网络中的数据。 ServerSockectChannel，监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 DatagramChannel，通过UDP读写网络中的数据。 补充 FileChannel不能切换成非阻塞模式 参考 https://blog.csdn.net/l18637220680/article/details/79360451 芋道源码 http://www.iocoder.cn","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-NIO-缓冲区Buffer","slug":"backend/java/io/IO-NIO-缓冲区Buffer","date":"2018-10-29T16:01:01.000Z","updated":"2019-11-19T13:54:45.299Z","comments":true,"path":"2018/10/30/backend/java/io/IO-NIO-缓冲区Buffer/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-NIO-缓冲区Buffer/","excerpt":"","text":"概念 缓冲区Buffer本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 NIO 的数据操作都是在 Buffer 中进行的，Buffer 实际上是一个数组。 解析Buffer的类型 Java NIO 有以下Buffer类型，Buffer 最常见的类型是ByteBuffer ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 如你所见，这些Buffer类型代表了不同的数据类型。换句话说，就是可以通过char，short，int，long，float 或 double类型来操作缓冲区中的字节。 现在挑一个最常见的类型是ByteBuffer，可以发现此类位于rt.jar的java.nio包下，此类是个抽象类，继承Buffer及实现了Comparable接口 ByteBuffer.java 1234567891011121314151617181920212223242526272829public abstract class ByteBuffer extends Buffer implements Comparable&lt;ByteBuffer&gt;&#123; // These fields are declared here rather than in Heap-X-Buffer in order to // reduce the number of virtual method invocations needed to access these // values, which is especially costly when coding small buffers. // final byte[] hb; // Non-null only for heap buffers final int offset; boolean isReadOnly; // Valid only for heap buffers // Creates a new buffer with the given mark, position, limit, capacity, // backing array, and array offset // ByteBuffer(int mark, int pos, int lim, int cap, // package-private byte[] hb, int offset) &#123; super(mark, pos, lim, cap); this.hb = hb; this.offset = offset; &#125; // Creates a new buffer with the given mark, position, limit, and capacity // ByteBuffer(int mark, int pos, int lim, int cap) &#123; // package-private this(mark, pos, lim, cap, null, 0); &#125; Buffer.java 1234567891011121314public abstract class Buffer &#123; /** * The characteristics of Spliterators that traverse and split elements * maintained in Buffers. */ static final int SPLITERATOR_CHARACTERISTICS = Spliterator.SIZED | Spliterator.SUBSIZED | Spliterator.ORDERED; // Invariants: mark &lt;= position &lt;= limit &lt;= capacity private int mark = -1; private int position = 0; private int limit; private int capacity; 基本属性 为了理解Buffer的工作原理，需要熟悉它的三个属性： capacity 作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。 position 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1. 当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0. 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。 limit 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。 当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position） 基本用法 使用Buffer读写数据一般遵循以下四个步骤： 1、写入数据到Buffer 2、调用flip()方法 3、从Buffer中读取数据 4、调用clear()方法或者compact()方法 当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 直接缓冲区与非直接缓冲区 字节缓冲区可以是放在直接内存中（放在堆外，直接调用函数操作机器内存，一般情况下性能比另一种方式会好些），也可以放在非直接内存（放在堆上，受JVM控制）中 使用方式如下，见名知意 java.nio.ByteBuffer#allocateDirect(int capacity) java.nio.ByteBuffer#allocate(int capacity) 可以调用其isDirect()来确定是那种方式 总结参考 芋道源码 http://www.iocoder.cn https://ifeve.com/buffers/","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-NIO-基础概念","slug":"backend/java/io/IO-NIO-基础概念","date":"2018-10-29T16:01:00.000Z","updated":"2020-03-16T11:43:55.472Z","comments":true,"path":"2018/10/30/backend/java/io/IO-NIO-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-NIO-基础概念/","excerpt":"","text":"概念 NIO ( New I/O 也称为 Non-blocking I/O) 是从 Java 1.4 版本开始引入的一种同步 + 非阻塞的通信模式 IO API，可以替代标准的Java IO API，NIO和原来的IO有相同的作用和目的，但使用方式完全不一样，NIO将以更高效的方式进行文件的读写操作 NIO 相对于 BIO 来说一大进步，和BIO的区别就是 阻塞变成了非阻塞 解析为什么会出现？ Java IO 的各种流是阻塞的 IO 操作。这就意味着，当一个线程执行读或写 IO 操作时，该线程会被阻塞，直到有一些数据被读取，或者数据完全写入 那为什么会阻塞呢？ 因为在一般的 Java IO 操作中，我们以流式的方式，顺序的从一个 Stream 中读取一个或者多个字节，直至读取所有字节。因为它没有缓存区，所以我们就不能随意改变读取指针的位置。 怎么实现非阻塞的？ 由上面我们知道BIO 是面向字节流或者字符流的，而在 NIO 中，它摒弃了传统的 IO 流，而是引入了下面三个概念： 通道Channel（可以比作铁轨，用于连接两地） 客户端和服务器之间通过 Channel 通信，和流 Stream 不同，通道是双向的。NIO可以通过 Channel 进行数据的读、写和同时读写操作。 Channel 可以非阻塞的读写 IO 操作，而 Stream 只能阻塞的读写 IO 操作。 Channel 必须配合 Buffer 使用，总是先读取到一个 Buffer 中，又或者是向一个 Buffer 写入。也就是说，我们无法绕过 Buffer ，直接向 Channel 写入数据。 Channel 有非常多的实现类，最为重要的四个 Channel 实现类如下： SocketChannel ：一个客户端用来发起 TCP 的 Channel 。 ServerSocketChannel ：一个服务端用来监听新进来的连接的 TCP 的 Channel 。对于每一个新进来的连接，都会创建一个对应的 SocketChannel 。 DatagramChannel ：通过 UDP 读写数据。 FileChannel ：从文件中，读写数据。 缓冲区Buffer（可以比作火车，用于装货） Buffer ，本质上是内存中的一块，我们可以将数据写入这块内存，之后从这块内存获取数据。通过将这块内存封装成 NIO Buffer 对象，并提供了一组常用的方法，方便我们对该块内存的读写。 BIO 是将数据直接写入或读取到流 Stream 对象中。 NIO 的数据操作都是在 Buffer 中进行的。Buffer 实际上是一个数组。Buffer 最常见的类型是ByteBuffer，另外还有 CharBuffer，ShortBuffer，IntBuffer，LongBuffer，FloatBuffer，DoubleBuffer 多路复用器Selector 它是 Java NIO 得以实现非阻塞 IO 操作的最最最关键。 Channel 都会被注册在 Selector 多路复用器上。Selector 通过一个线程不停的轮询这些 Channel ，找出已经准备就绪的 Channel 执行 IO 操作，这样就可以接入成千上万个客户端，这就是 JDK NIO 库的巨大进步。 阻塞与非阻塞 IO Java IO 的各种流是阻塞的 IO 操作。这就意味着，当一个线程执行读或写 IO 操作时，该线程会被阻塞，直到有一些数据被读取，或者数据完全写入。 Java NIO 可以让我们非阻塞的使用 IO 操作。例如： 当一个线程执行从 Channel 执行读取 IO 操作时，当此时有数据，则读取数据并返回；当此时无数据，则直接返回而不会阻塞当前线程。 当一个线程执行向 Channel 执行写入 IO 操作时，不需要阻塞等待它完全写入，这个线程同时可以做别的事情。 也就是说，线程可以将非阻塞 IO 的空闲时间用于在其他 Channel 上执行 IO 操作。所以，一个单独的线程，可以管理多个 Channel 的读取和写入 IO 操作。 补充BIO、NIO 有什么区别 BIO NIO 面向流( Stream ) 面向缓冲区( Buffer ) 阻塞的 非阻塞的 Socket 是单向的（不能同时读写） Channel 是双向的 （可以同时读写） 一个连接一个线程，客户端有连接请求时服务器端就需要启动一个线程进行处理。所以，线程开销大。可改良为用线程池的方式代替新创建线程，被称为伪异步 IO 。 一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有新的 I/O 请求时，才启动一个线程进行处理。可改良为一个线程处理多个请求，基于 多 Reactor 模型。 总结 它的特点是要不断主动地去询问数据有没有处理完，一般只适用于连接数目较大但连接时间短的应用，如聊天应用等。 对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发 Java提供的NIO的api使用比较复杂，一般建议使用像netty这样的框架，而不要使用jdk自带的api。 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-BIO-基础概念","slug":"backend/java/io/IO-BIO-基础概念","date":"2018-10-29T16:00:00.000Z","updated":"2019-11-27T15:11:32.594Z","comments":true,"path":"2018/10/30/backend/java/io/IO-BIO-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-BIO-基础概念/","excerpt":"","text":"概念 BIO就是指IO，即传统的Blocking IO,即同步并阻塞的IO。这也是jdk1.4之前的唯一选择 解析 是一个比较传统的通信方式，模式简单，使用方便，面向字节流或者字符流，在一般的 Java IO 操作中，我们以流式的方式，顺序的从一个 Stream 中读取一个或者多个字节，直至读取所有字节。但并发处理能力低，通信耗时，依赖网速。 BIO 模型中，通过 Socket 和 ServerSocket 实现套接字通道的通信。阻塞，同步，建立连接耗时。 原理 服务器通过一个 Acceptor 线程，负责监听客户端请求和为每个客户端创建一个新的线程进行链路处理。典型的一请求一应答模式。 若客户端数量增多，频繁地创建和销毁线程会给服务器打开很大的压力。后改良为用线程池的方式代替新增线程，被称为伪异步 IO 。 补充总结参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-字节流及字符流","slug":"backend/java/io/IO-字节流及字符流","date":"2018-10-29T16:00:00.000Z","updated":"2020-03-16T11:43:55.477Z","comments":true,"path":"2018/10/30/backend/java/io/IO-字节流及字符流/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-字节流及字符流/","excerpt":"","text":"概念Java 中 IO 流划分按照操作单元划分，可以划分为字节流和字符流； 补充既然有了字节流,为什么还要有字符流? 问题本质想问：不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？ 回答：字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程还算是非常耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。 所以， I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。 参考 https://snailclimb.gitee.io/javaguide/#/docs/java/Java基础知识","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"IO-基础概念","slug":"backend/java/io/IO-基础概念","date":"2018-10-29T16:00:00.000Z","updated":"2020-03-22T04:06:10.386Z","comments":true,"path":"2018/10/30/backend/java/io/IO-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/10/30/backend/java/io/IO-基础概念/","excerpt":"","text":"概念 Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。 在讲 BIO,NIO,AIO 之前先来回顾一下这样几个概念：同步与异步，阻塞与非阻塞。 同步与异步 同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。 同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。 异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。 阻塞和非阻塞阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。 非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。 会用使用线程一直轮询，直到有IO资源准备好了 总结 举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在那里傻等着水开（同步阻塞）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（同步非阻塞）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声（事件通知）后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（异步非阻塞）。 参考 https://snailclimb.gitee.io/javaguide/#/docs/java/BIO-NIO-AIO","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Io","slug":"Io","permalink":"http://www.songshuiyang.com/tags/Io/"}]},{"title":"Java集合-Set-TreeSet源码解析及原理","slug":"backend/java/collection/Java集合-Set-TreeSet源码解析及原理","date":"2018-10-19T16:04:03.000Z","updated":"2019-11-27T14:45:47.682Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Set-TreeSet源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Set-TreeSet源码解析及原理/","excerpt":"","text":"前言 TreeSet也是个有序的集合类，不过和 LinkedHashSet的排序方式不一样，TreeSet并不是根据插入的顺序来排序，TreeSet可以自己定义排序规则，主要有两种方式： 第一种是在构造函数指定了队列比较器Comparator，那么元素排序是按照队列比较器Comparator的排序规则进行排序， 第二种就是按照元素实现的Comparator接口方法进行排序 解析类继承关系图 由下图可以看到这个图和TreeSet的类继承关系图 TreeSet 类成员变量 由下面可以看到有两个成员变量 NavigableMap&lt;E,Object&gt; m来存放元素的map对象，从构造函数可以知道这里是TreeMap，所以TreeSet的底层就是通过TreeMap来实现的 Object PRESENT 是存放在Map的value值 123456789101112131415public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable &#123; // 序列化版本号 private static final long serialVersionUID = -2479143000061671589L; /** * 存放元素的map对象 底层是通过`TreeMap`来实现的 * The backing map. */ private transient NavigableMap&lt;E,Object&gt; m; /** * 不同的键都会存相同的value值, value = PRESENT * Dummy value to associate with an Object in the backing Map */ private static final Object PRESENT = new Object(); 构造函数 从TreeSet的构造函数可以知道就是初始化一个TreeMap 123456789101112131415161718192021222324252627282930313233343536/** * 根据指定的集合来构造 */TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m;&#125;/** * 无参构造方法，初始化一个TreeMap对象 */public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;());&#125;/** * 指定比较器的构造函数 */public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; this(new TreeMap&lt;&gt;(comparator));&#125;/** * 将集合中的元素转化为TreeSet存储的构造函数 */public TreeSet(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;/** * SortedSet转化为TreeSet存储，并使用SortedSet的比较器 */public TreeSet(SortedSet&lt;E&gt; s) &#123; this(s.comparator()); addAll(s);&#125; 主要方法解析 由下面可以看到这里TreeSet的方法实际上都是调用的TreeMap的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431/** * 返回遍历元素的迭代器 * Returns an iterator over the elements in this set in ascending order. * * @return an iterator over the elements in this set in ascending order */public Iterator&lt;E&gt; iterator() &#123; return m.navigableKeySet().iterator();&#125;/** * 返回逆序遍历元素的迭代器 * Returns an iterator over the elements in this set in descending order. * * @return an iterator over the elements in this set in descending order * @since 1.6 */public Iterator&lt;E&gt; descendingIterator() &#123; return m.descendingKeySet().iterator();&#125;/** * @since 1.6 */public NavigableSet&lt;E&gt; descendingSet() &#123; return new TreeSet&lt;&gt;(m.descendingMap());&#125;/** * 返回元素个数 * Returns the number of elements in this set (its cardinality). * * @return the number of elements in this set (its cardinality) */public int size() &#123; return m.size();&#125;/** * 判断是否为空 * Returns &#123;@code true&#125; if this set contains no elements. * * @return &#123;@code true&#125; if this set contains no elements */public boolean isEmpty() &#123; return m.isEmpty();&#125;/** * 判断是否有值 * Returns &#123;@code true&#125; if this set contains the specified element. * More formally, returns &#123;@code true&#125; if and only if this set * contains an element &#123;@code e&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;e==null&amp;nbsp;:&amp;nbsp;o.equals(e))&lt;/tt&gt;. * * @param o object to be checked for containment in this set * @return &#123;@code true&#125; if this set contains the specified element * @throws ClassCastException if the specified object cannot be compared * with the elements currently in the set * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements */public boolean contains(Object o) &#123; return m.containsKey(o);&#125;/** * 添加元素 * Adds the specified element to this set if it is not already present. * More formally, adds the specified element &#123;@code e&#125; to this set if * the set contains no element &#123;@code e2&#125; such that * &lt;tt&gt;(e==null&amp;nbsp;?&amp;nbsp;e2==null&amp;nbsp;:&amp;nbsp;e.equals(e2))&lt;/tt&gt;. * If this set already contains the element, the call leaves the set * unchanged and returns &#123;@code false&#125;. * * @param e element to be added to this set * @return &#123;@code true&#125; if this set did not already contain the specified * element * @throws ClassCastException if the specified object cannot be compared * with the elements currently in this set * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements */public boolean add(E e) &#123; return m.put(e, PRESENT)==null;&#125;/** * 删除元素 * Removes the specified element from this set if it is present. * More formally, removes an element &#123;@code e&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;e==null&amp;nbsp;:&amp;nbsp;o.equals(e))&lt;/tt&gt;, * if this set contains such an element. Returns &#123;@code true&#125; if * this set contained the element (or equivalently, if this set * changed as a result of the call). (This set will not contain the * element once the call returns.) * * @param o object to be removed from this set, if present * @return &#123;@code true&#125; if this set contained the specified element * @throws ClassCastException if the specified object cannot be compared * with the elements currently in this set * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements */public boolean remove(Object o) &#123; return m.remove(o)==PRESENT;&#125;/** * 清除元素 * * Removes all of the elements from this set. * The set will be empty after this call returns. */public void clear() &#123; m.clear();&#125;/** * 将一个集合中的所有元素添加到TreeSet中 * * Adds all of the elements in the specified collection to this set. * * @param c collection containing elements to be added to this set * @return &#123;@code true&#125; if this set changed as a result of the call * @throws ClassCastException if the elements provided cannot be compared * with the elements currently in the set * @throws NullPointerException if the specified collection is null or * if any element is null and this set uses natural ordering, or * its comparator does not permit null elements */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; // Use linear-time version if applicable if (m.size()==0 &amp;&amp; c.size() &gt; 0 &amp;&amp; c instanceof SortedSet &amp;&amp; m instanceof TreeMap) &#123; SortedSet&lt;? extends E&gt; set = (SortedSet&lt;? extends E&gt;) c; TreeMap&lt;E,Object&gt; map = (TreeMap&lt;E, Object&gt;) m; Comparator&lt;?&gt; cc = set.comparator(); Comparator&lt;? super E&gt; mc = map.comparator(); if (cc==mc || (cc != null &amp;&amp; cc.equals(mc))) &#123; map.addAllForTreeSet(set, PRESENT); return true; &#125; &#125; return super.addAll(c);&#125;/** * 返回子集合 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if &#123;@code fromElement&#125; or &#123;@code toElement&#125; * is null and this set uses natural ordering, or its comparator * does not permit null elements * @throws IllegalArgumentException &#123;@inheritDoc&#125; * @since 1.6 */public NavigableSet&lt;E&gt; subSet(E fromElement, boolean fromInclusive, E toElement, boolean toInclusive) &#123; return new TreeSet&lt;&gt;(m.subMap(fromElement, fromInclusive, toElement, toInclusive));&#125;/** * 返回set的头部 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if &#123;@code toElement&#125; is null and * this set uses natural ordering, or its comparator does * not permit null elements * @throws IllegalArgumentException &#123;@inheritDoc&#125; * @since 1.6 */public NavigableSet&lt;E&gt; headSet(E toElement, boolean inclusive) &#123; return new TreeSet&lt;&gt;(m.headMap(toElement, inclusive));&#125;/** * 返回尾部 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if &#123;@code fromElement&#125; is null and * this set uses natural ordering, or its comparator does * not permit null elements * @throws IllegalArgumentException &#123;@inheritDoc&#125; * @since 1.6 */public NavigableSet&lt;E&gt; tailSet(E fromElement, boolean inclusive) &#123; return new TreeSet&lt;&gt;(m.tailMap(fromElement, inclusive));&#125;/** * 返回子Set * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if &#123;@code fromElement&#125; or * &#123;@code toElement&#125; is null and this set uses natural ordering, * or its comparator does not permit null elements * @throws IllegalArgumentException &#123;@inheritDoc&#125; */public SortedSet&lt;E&gt; subSet(E fromElement, E toElement) &#123; return subSet(fromElement, true, toElement, false);&#125;/** * 返回set的头部 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if &#123;@code toElement&#125; is null * and this set uses natural ordering, or its comparator does * not permit null elements * @throws IllegalArgumentException &#123;@inheritDoc&#125; */public SortedSet&lt;E&gt; headSet(E toElement) &#123; return headSet(toElement, false);&#125;/** * 返回set的尾部 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if &#123;@code fromElement&#125; is null * and this set uses natural ordering, or its comparator does * not permit null elements * @throws IllegalArgumentException &#123;@inheritDoc&#125; */public SortedSet&lt;E&gt; tailSet(E fromElement) &#123; return tailSet(fromElement, true);&#125;/** * 返回m使用的比较器 * @return */public Comparator&lt;? super E&gt; comparator() &#123; return m.comparator();&#125;/** * 返回第一个元素 * * @throws NoSuchElementException &#123;@inheritDoc&#125; */public E first() &#123; return m.firstKey();&#125;/** * 返回最后一个元素 * * @throws NoSuchElementException &#123;@inheritDoc&#125; */public E last() &#123; return m.lastKey();&#125;// NavigableSet API methods/** * 返回set中小于e的最大的元素 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements * @since 1.6 */public E lower(E e) &#123; return m.lowerKey(e);&#125;/** * 返回set中小于/等于e的最大元素 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements * @since 1.6 */public E floor(E e) &#123; return m.floorKey(e);&#125;/** * 返回set中大于/等于e的最大元素 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements * @since 1.6 */public E ceiling(E e) &#123; return m.ceilingKey(e);&#125;/** * 返回set中大于e的最小元素 * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified element is null * and this set uses natural ordering, or its comparator * does not permit null elements * @since 1.6 */public E higher(E e) &#123; return m.higherKey(e);&#125;/** * 获取TreeSet中第一个元素，并从Set中删除该元素 * * @since 1.6 */public E pollFirst() &#123; Map.Entry&lt;E,?&gt; e = m.pollFirstEntry(); return (e == null) ? null : e.getKey();&#125;/** * 获取TreeSet中最后一个元素，并从Set中删除该元素 * * @since 1.6 */public E pollLast() &#123; Map.Entry&lt;E,?&gt; e = m.pollLastEntry(); return (e == null) ? null : e.getKey();&#125;/** * 克隆方法 * * Returns a shallow copy of this &#123;@code TreeSet&#125; instance. (The elements * themselves are not cloned.) * * @return a shallow copy of this set */@SuppressWarnings(\"unchecked\")public Object clone() &#123; TreeSet&lt;E&gt; clone; try &#123; clone = (TreeSet&lt;E&gt;) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(e); &#125; clone.m = new TreeMap&lt;&gt;(m); return clone;&#125;/** * 将对象写入到输出流中 * * Save the state of the &#123;@code TreeSet&#125; instance to a stream (that is, * serialize it). * * @serialData Emits the comparator used to order this set, or * &#123;@code null&#125; if it obeys its elements' natural ordering * (Object), followed by the size of the set (the number of * elements it contains) (int), followed by all of its * elements (each an Object) in order (as determined by the * set's Comparator, or by the elements' natural ordering if * the set has no Comparator). */private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // Write out any hidden stuff s.defaultWriteObject(); // Write out Comparator s.writeObject(m.comparator()); // Write out size s.writeInt(m.size()); // Write out all elements in the proper order. for (E e : m.keySet()) s.writeObject(e);&#125;/** * 从输入流中读取对象的信息 * Reconstitute the &#123;@code TreeSet&#125; instance from a stream (that is, * deserialize it). */private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in any hidden stuff s.defaultReadObject(); // Read in Comparator @SuppressWarnings(\"unchecked\") Comparator&lt;? super E&gt; c = (Comparator&lt;? super E&gt;) s.readObject(); // Create backing TreeMap TreeMap&lt;E,Object&gt; tm = new TreeMap&lt;&gt;(c); m = tm; // Read in size int size = s.readInt(); tm.readTreeSet(size, s, PRESENT);&#125;/** * Creates a &lt;em&gt;&lt;a href=\"Spliterator.html#binding\"&gt;late-binding&lt;/a&gt;&lt;/em&gt; * and &lt;em&gt;fail-fast&lt;/em&gt; &#123;@link Spliterator&#125; over the elements in this * set. * * &lt;p&gt;The &#123;@code Spliterator&#125; reports &#123;@link Spliterator#SIZED&#125;, * &#123;@link Spliterator#DISTINCT&#125;, &#123;@link Spliterator#SORTED&#125;, and * &#123;@link Spliterator#ORDERED&#125;. Overriding implementations should document * the reporting of additional characteristic values. * * &lt;p&gt;The spliterator's comparator (see * &#123;@link java.util.Spliterator#getComparator()&#125;) is &#123;@code null&#125; if * the tree set's comparator (see &#123;@link #comparator()&#125;) is &#123;@code null&#125;. * Otherwise, the spliterator's comparator is the same as or imposes the * same total ordering as the tree set's comparator. * * @return a &#123;@code Spliterator&#125; over the elements in this set * @since 1.8 */public Spliterator&lt;E&gt; spliterator() &#123; return TreeMap.keySpliteratorFor(m);&#125; 补充 TreeSet 是用一个树形结构实现的，因此，它是有序的。添加，删除和 TreeSet 包含的方法的持续时间复杂度是 O(logn) 。 总结 上一章节我们知道LinkedHashSet搭了LinkedHashMap的顺风车，这一章节TreeSet也是一样，搭了TreeMap的顺风车，TreeMap的内容在这一章节Java集合-Map-TreeMap源码解析及原理有所介绍 参考 https://my.oschina.net/90888/blog/1625927","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Set-LinkedHashSet源码解析及原理","slug":"backend/java/collection/Java集合-Set-LinkedHashSet源码解析及原理","date":"2018-10-19T16:04:02.000Z","updated":"2019-09-24T14:21:38.567Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Set-LinkedHashSet源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Set-LinkedHashSet源码解析及原理/","excerpt":"","text":"前言 LinkedHashSet由类名可以知道它是链起来的HashSet，也就是说使用这个类可以维护元素的顺序，查看LinkedHashSet类的源码发现里面实现十分简单，就是借助了LinkedHashMap这趟顺风车 解析类继承关系图 由下图可以看到LinkedHashSet就是直接继承了HashSet，拿来主义 类成员变量1234567public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = -2851667679971038690L; ... &#125; 构造函数 从LinkedHashSet的构造函数可以看到就是直接调用了父类HashSet构造函数 12345678910111213141516public LinkedHashSet(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor, true);&#125;public LinkedHashSet(int initialCapacity) &#123; super(initialCapacity, .75f, true);&#125;public LinkedHashSet() &#123; super(16, .75f, true);&#125;public LinkedHashSet(Collection&lt;? extends E&gt; c) &#123; super(Math.max(2*c.size(), 11), .75f, true); addAll(c);&#125; 继续跟进父类HashSet构造函数，实际上构造元素的是 LinkedHashMap ，回顾上一章节 Java集合-Set-HashSet源码解析及原理中HashSet有个特殊的构造函数 12345678910111213141516/** * Constructs a new, empty linked hash set. (This package private * constructor is only used by LinkedHashSet.) The backing * HashMap instance is a LinkedHashMap with the specified initial * capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @param dummy ignored (distinguishes this * constructor from other int, float constructor.) * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; HashSet这个构造函数和其他几个构造函数不一样 HashSet的其他构造函数就是构造HashMap，这个构造函数是构造LinkedHashMap 这个构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet服务 指定的initialCapacity和loadFactor构造一个新的空链接哈希集合，实际底层会以指定的参数构造一个空LinkedHashMap实例来实现，，这里就是将LinkedHashMap实例赋值给了HashSet的map成员变量 主要方法解析 都是调用的HashSet方法 总结 LinkedHashSet是可以维护Set集合元素的顺序，底层原理是靠HashSet构造的LinkedHashMap来实现的，详情见Java集合-Map-LinkedHashMap源码解析及原理 参考","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Set-HashSet源码解析及原理","slug":"backend/java/collection/Java集合-Set-HashSet源码解析及原理","date":"2018-10-19T16:04:01.000Z","updated":"2019-11-27T14:45:10.412Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Set-HashSet源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Set-HashSet源码解析及原理/","excerpt":"","text":"前言 HashSet是Set接口的典型实现，HashSet按照Hash算法来存储集合中的元素，存在以下特点： 元素没有重复 不能保证元素的顺序，元素是无序的 HashSet不是同步的，需要外部保持线程之间的同步问题 集合元素值允许为null 解析类继承关系图 由上图可以看到HashSet继承了下面这些接口 AbstractSet 此类是Set接口的抽象实现类 Cloneable 覆盖了函数clone()，能被克隆。 Serializable 这意味着ArrayList支持序列化，能通过序列化去传输。 类成员变量 可以看到HashSet的成员变量很简洁 HashMap&lt;E,Object&gt; map 底层使用HashMap来保存HashSet中所有元素 Object PRESENT存放在HashMap的value值 1234567891011121314151617public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; static final long serialVersionUID = -5024744406713321676L; /** * 底层使用HashMap来保存HashSet中所有元素。 */ private transient HashMap&lt;E,Object&gt; map; /** * 定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final。 * Dummy value to associate with an Object in the backing Map */ private static final Object PRESENT = new Object(); ...&#125; 构造函数 HashSet的构造函数就是初始化一个HashMap 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * 默认的无参构造器，构造一个空的HashSet，实际底层会初始化一个空的HashMap，并使用默认初始容量为16和加载因子0.75。 * * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). */public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;/** * 构造一个包含指定collection中的元素的新set。 * * Constructs a new set containing the elements in the specified * collection. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with default load factor * (0.75) and an initial capacity sufficient to contain the elements in * the specified collection. * * @param c the collection whose elements are to be placed into this set * @throws NullPointerException if the specified collection is null */public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;/** * 以指定的initialCapacity和loadFactor构造一个空的HashSet。 * 实际底层以相应的参数构造一个空的HashMap * * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;/** * 以指定的initialCapacity构造一个空的HashSet。 * 实际底层以相应的参数及加载因子loadFactor为0.75构造一个空的HashMap。 * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and default load factor (0.75). * * @param initialCapacity the initial capacity of the hash table * @throws IllegalArgumentException if the initial capacity is less * than zero */public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;/** * 以指定的initialCapacity和loadFactor构造一个新的空链接哈希集合。 * 此构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet的支持。 * 实际底层会以指定的参数构造一个空LinkedHashMap实例来实现。 * * Constructs a new, empty linked hash set. (This package private * constructor is only used by LinkedHashSet.) The backing * HashMap instance is a LinkedHashMap with the specified initial * capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @param dummy ignored (distinguishes this * constructor from other int, float constructor.) * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 主要方法解析add(E e)添加元素 添加元素方法实际上也是调用了HashMap的put()方法，key是要插入的值，value是一个new Object()对象 如果添加了相同的元素，那么HashMap新添加的Node的value会将覆盖原来Node的value（HashSet这里的value都是相同的），但key不会有任何改变，所以借助这个特性可以保证元素不是重复的 HashMap在定位数据的时候会调用key的hashCode()及equels()方法来保证数据的唯一性，转化在HashMap的代码就是if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; remove(Object o)删除元素 删除元素实际上也是调用了HashMap的删除方法 123456789// 去除单个元素public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125;// 去除所有元素public void clear() &#123; map.clear();&#125; iterator()迭代器123public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125; 获取容器状态123456789101112public int size() &#123; return map.size();&#125;public boolean isEmpty() &#123; return map.isEmpty();&#125;public boolean contains(Object o) &#123; return map.containsKey(o);&#125; 补充 HashSet 是用一个 hash 表来实现的，因此，它的元素是无序的。添加，删除和HashSet包括的方法的持续时间复杂度是O(1) 。 总结 HashSet的底层通过HashMap实现的，操作HashSet实际上是操作的HashMap，搬运工呀 查看源码可以看到调用HashSet的方法，也是借助HashMap的方法来实现的 借助HashMap的key值特性，所以可以保证数据的不重复性，HashMap在定位数据的时候会调用key的hashCode()及equels()方法来保证数据的唯一性 key是存放的元素，value是固定存new Object()对象 因为HashMap是无序的，所以HashMap也是无序的 因为HashMap是非线程安全的，HashSet自身也没有处理线程安全问题，所以HashSet是非线程安全集合 参考 https://my.oschina.net/90888/blog/1625854","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Set-介绍","slug":"backend/java/collection/Java集合-Set-介绍","date":"2018-10-19T16:04:00.000Z","updated":"2019-09-24T13:32:47.116Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Set-介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Set-介绍/","excerpt":"","text":"前言 本系列是集合系列的最后一个专题，为什么放到最后，因为Set的子类HashSet、LinkedHashSet底层是基于HashMap来实现的 Set接口代表的元素是无序、不可重复的集合，是 Collection的三大金刚之一，这一专题系列将介绍集合Set子类的实现 再来回顾下集合框架图，可以看到Set主要有下面这些实现类，感觉和Map接口的子类一毛一样 HashSet 基于哈希值的无序不可重复集合 LinkedHashSet 基于哈希值的有序不可重复集合 TreeSet 可自定义排序规则的不可重复集合 解析Set接口定义了操作集合元素的基本方法，使用泛型T来代表元素12345678910111213141516171819202122232425262728293031323334353637public interface Set&lt;E&gt; extends Collection&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); Iterator&lt;E&gt; iterator(); Object[] toArray(); &lt;T&gt; T[] toArray(T[] a); boolean add(E e); boolean remove(Object o); boolean containsAll(Collection&lt;?&gt; c); boolean addAll(Collection&lt;? extends E&gt; c); boolean retainAll(Collection&lt;?&gt; c); boolean removeAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); @Override default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, Spliterator.DISTINCT); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-ConcurrentHashMap源码解析及原理","slug":"backend/java/collection/Java集合-Map-ConcurrentHashMap源码解析及原理","date":"2018-10-19T16:03:08.000Z","updated":"2019-09-24T13:32:47.102Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-ConcurrentHashMap源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-ConcurrentHashMap源码解析及原理/","excerpt":"","text":"前言 上一章节介绍了Hashtable是个线程安全类，但官方已不建议使用，建议是使用ConcurrentHashMap ，源码说明：it is recommended to use {@link java.util.concurrent.ConcurrentHashMap} in place of {@code Hashtable} ConcurrentHashMap也是个线程安全的Map集合，和Hashtable实现线程安全的方式不一样 HashTable是在方法头上用synchronized来保证线程安全的，因为synchronized属于悲观锁，悲观地认为程序中的并发情况严重， 所以效率灰常的低下 ConcurrentHashMap采用for自旋 + CAS + synchronized来保证并发更新的安全，CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新 CAS算法： CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。 CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B JDK 1.8之前ConcurrentHashMap使用锁分段技术，将数据分成一段段的存储，每一个数据段配置一把锁，相互之间不影响，而1.8之后摒弃了Segment（锁段）的概念，启用了全新的实现，也就是利用CAS + synchronized来保证并发更新的安全，底层采用的依然是数组+链表+红黑树。 解析类继承关系图 类成员变量 成员变量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* ---------------- Fields -------------- *//** * 哈希桶 * The array of bins. Lazily initialized upon first insertion. * Size is always a power of two. Accessed directly by iterators. */transient volatile Node&lt;K,V&gt;[] table;/** * 扩容用的下一个哈希桶 * The next table to use; non-null only while resizing. */private transient volatile Node&lt;K,V&gt;[] nextTable;/** * Base counter value, used mainly when there is no contention, * but also as a fallback during table initialization * races. Updated via CAS. */private transient volatile long baseCount;/** * 这个数值表示初始化或者下一次要扩容的大小，表初始化或者扩容的一个控制标识位 * 负数代表正在进行初始化或者扩容的操作 * -1 代表初始化 * -N 代表有n-1个线程在进行扩容操作 * 正数或者0表示没有进行初始化操作 * transient 修饰的属性不会被序列化，volatile保证可见性 * * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. */private transient volatile int sizeCtl;/** * The next table index (plus one) to split while resizing. */private transient volatile int transferIndex;/** * Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */private transient volatile int cellsBusy;/** * Table of counter cells. When non-null, size is a power of 2. */private transient volatile CounterCell[] counterCells;// viewsprivate transient KeySetView&lt;K,V&gt; keySet;private transient ValuesView&lt;K,V&gt; values;private transient EntrySetView&lt;K,V&gt; entrySet; 类常量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/* ---------------- Constants -------------- *//** * 集合最大容量 = 2的30次方 * The largest possible table capacity. This value must be * exactly 1&lt;&lt;30 to stay within Java array allocation and indexing * bounds for power of two table sizes, and is further required * because the top two bits of 32bit hash fields are used for * control purposes. */private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * 默认容量为16，为什么和HashMap一样都是16，这里不用 1 &lt;&lt; 4 * @see java.util.HashMap#DEFAULT_INITIAL_CAPACITY * The default initial table capacity. Must be a power of 2 * (i.e., at least 1) and at most MAXIMUM_CAPACITY. */private static final int DEFAULT_CAPACITY = 16;/** * 数组最大数量大小 * The largest possible (non-power of two) array size. * Needed by toArray and related methods. */static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * 该表的默认并发级别 未使用，但*定义为与此类的先前版本兼容。 * The default concurrency level for this table. Unused but * defined for compatibility with previous versions of this class. */private static final int DEFAULT_CONCURRENCY_LEVEL = 16;/** * 扩容负载因子 * * The load factor for this table. Overrides of this value in * constructors affect only the initial table capacity. The * actual floating point value isn't normally used -- it is * simpler to use expressions such as &#123;@code n - (n &gt;&gt;&gt; 2)&#125; for * the associated resizing threshold. */private static final float LOAD_FACTOR = 0.75f;/** * 阈值达到8 链表转为红黑树 * * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2, and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */static final int TREEIFY_THRESHOLD = 8;/** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */static final int UNTREEIFY_THRESHOLD = 6;/** * * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * The value should be at least 4 * TREEIFY_THRESHOLD to avoid * conflicts between resizing and treeification thresholds. */static final int MIN_TREEIFY_CAPACITY = 64;/** * Minimum number of rebinnings per transfer step. Ranges are * subdivided to allow multiple resizer threads. This value * serves as a lower bound to avoid resizers encountering * excessive memory contention. The value should be at least * DEFAULT_CAPACITY. */private static final int MIN_TRANSFER_STRIDE = 16;/** * The number of bits used for generation stamp in sizeCtl. * Must be at least 6 for 32bit arrays. */private static int RESIZE_STAMP_BITS = 16;/** * The maximum number of threads that can help resize. * Must fit in 32 - RESIZE_STAMP_BITS bits. */private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;/** * The bit shift for recording size stamp in sizeCtl. */private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;/* * Encodings for Node hash fields. See above for explanation. */static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash/** Number of CPUS, to place bounds on some sizings 可用处理器数量 */static final int NCPU = Runtime.getRuntime().availableProcessors();/** For serialization compatibility. */private static final ObjectStreamField[] serialPersistentFields = &#123; new ObjectStreamField(\"segments\", Segment[].class), new ObjectStreamField(\"segmentMask\", Integer.TYPE), new ObjectStreamField(\"segmentShift\", Integer.TYPE)&#125;; Node键值对节点 存放在哈希桶中最基础的元素，存放key及value value 和 next使用了volatile修饰，保证了线程之间的可见性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 键值对节点 * Key-value entry. This class is never exported out as a * user-mutable Map.Entry (i.e., one supporting setValue; see * MapEntry below), but can be used for read-only traversals used * in bulk tasks. Subclasses of Node with a negative hash field * are special, and contain null keys and values (but are never * exported). Otherwise, keys and vals are never null. */static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; // value 和 next使用了volatile修饰，保证了线程之间的可见性 volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + \"=\" + val; &#125; public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; /** * Virtualized support for map.get(); overridden in subclasses. */ Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null; &#125;&#125; TreeNode红黑树节点 当链表长度过长的时候，会将上面的Node元素转换为TreeNode 是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/* ---------------- TreeNodes -------------- *//** * Nodes for use in TreeBins */static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; return findTreeNode(h, k, null); &#125; /** * Returns the TreeNode (or null if not found) for the given key * starting at given root. */ final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.findTreeNode(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); &#125; return null; &#125;&#125; TreeBin红黑树节点的包装节点 这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。 它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap数组中， 存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* ---------------- TreeBins -------------- *//** * TreeNodes used at the heads of bins. TreeBins do not hold user * keys or values, but instead point to list of TreeNodes and * their root. They also maintain a parasitic read-write lock * forcing writers (who hold bin lock) to wait for readers (who do * not) to complete before tree restructuring operations. */static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. */ static int tieBreakOrder(Object a, Object b) &#123; int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; &#125; /** * Creates bin with initial set of nodes headed by b. */ TreeBin(TreeNode&lt;K,V&gt; b) &#123; super(TREEBIN, null, null, null); this.first = b; TreeNode&lt;K,V&gt; r = null; for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (r == null) &#123; x.parent = null; x.red = false; r = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = r;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; this.root = r; assert checkInvariants(root); &#125; ...&#125; 构造函数 下面是ConcurrentHashMap的构造函数，可以看到和HashMap的构造函数并没有太大区别 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 无参构造方法，没有进行任何操作 */public ConcurrentHashMap() &#123;&#125;/** * 指定初始化大小构造方法 */public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125;/** * 将指定的集合转化为ConcurrentHashMap */public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.sizeCtl = DEFAULT_CAPACITY; putAll(m);&#125;/** * 指定初始化大小和负载因子的构造方法 */public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1);&#125;/** * 指定初始化大小，负载因子和concurrentLevel并发更新线程的数量，也可以理解为segment的个数 */public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125; 主要方法解析put(K key, V value) 添加元素 ConcurrentHashMap添加元素依然沿用HashMap的思想 先用key的hashCode()再次散列计算出哈希值，然后再与数组长度进行位与运算算出新插入的节点在数组中的位置，注意这里key 和 value 都不允许为null 如果在数组中此位置没有元素则直接插入，注意这里没有加锁，谁先来谁先得 如果在数组中此位置有元素则判断占用位置的元素是链表还是红黑树，是链表的话就按链表的方式插入，是红黑树的话就按树的方式插入 下面逻辑可以看到put方法采用了for自旋 + CAS + synchronized方式来处理线程安全问题，不达目的不罢休，成功了才break，注意这里是用了synchronized对数组节点加了锁，也就是说同一时刻只有一个线程可以操作此数组节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Implementation for put and putIfAbsent * @param key 键 * @param value 值 * @param onlyIfAbsent key值相等是否覆盖value(默认是false会覆盖) * @return */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // key 和 value 都不允许为null if (key == null || value == null) throw new NullPointerException(); // 再次散列，让数据均匀分布，减少碰撞次数 int hash = spread(key.hashCode()); int binCount = 0; // 开始自旋 何时插入成功 何时跳出 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 如果table为空的话 if (tab == null || (n = tab.length) == 0) // 第一次put 开始初始化 tab = initTable(); // 数组在i的位置没有元素存在，直接放入 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 添加到table中，直接放进去，不需要加锁 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) // 退出循环 no lock when adding to empty bin break; &#125; // node的hash值为-1，则i的位置在进行MOVE操作，也就是在进行扩容操作，则多线程帮助扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; // 如果i的位置有元素存在，则在该节点加锁synchronized，判断是链表还是红黑树，按照相应的插入规则插入 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 说明这个节点是一个链表的节点 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // key 相等，使用新值替换旧值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 放在链表的尾部 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 如果这个节点是树节点，就按照树的方式插入值 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 如果链表长度已经达到阈值8 就需要把链表转换为树结构 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 将当前ConcurrentHashMap的元素数量+1 addCount(1L, binCount); return null;&#125; initTable() 初始化哈希表 initTable()方法是初始化哈希表，构造函数只是指定了一些参数，具体构造哈希表是第一次调用put方法的时候会触发（上面的if (tab == null || (n = tab.length) == 0)判断），可以看到下面主要逻辑也是CAS + while自旋来处理多线程安全问题 如果在构造函数没有指定参数，那么第一次调用put方法会构造一个长度为16、扩容阈值为12的数组 变量sizeCtl是初始化或者下一次要扩容的大小 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Initializes table, using the size recorded in sizeCtl. */private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // sizeCtl &lt; 0 表示有线程正在进行初始化操作，从运行状态变为就绪状态。 if ((sc = sizeCtl) &lt; 0) // 丢失了初始化资格；线程让步一下 lost initialization race; just spin Thread.yield(); /** * 设置SIZECTL的值为-1，阻塞其他线程的操作 * 该方法有四个参数 * 第一个参数：需要改变的对象 * 第二个参数：偏移量 * 第三个参数：期待的值 * 第四个参数：更新后的值 */ else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; // 再次检查是否有线程进行了初始化操作 if ((tab = table) == null || tab.length == 0) &#123; // 默认初始化大小为16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; // 初始化数组 @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; /** * 下面的位运算是将sc的值设置为n的0.75倍 * 第一次默认是 16 - (16 &gt;&gt;&gt; 2) = 16 - 4 = 12 * 16 &gt;&gt;&gt; 2 为 二进制10000右移2位 = 100 = 4 */ sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 更改sizeCtl的值 sizeCtl = sc; &#125; // 中断循坏返回 break; &#125; &#125; // 返回初始化的值 return tab;&#125; helpTransfer() 哈希表扩容 扩容方法分为两个部分： 1、创建扩容后的新数组，容量变为原来的两倍 ，新数组的创建时单线程完成 2、将原来的数组元素复制到新的数组中，这个是多线程操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183/** * 扩容函数 * Helps transfer if a resize is in progress. */final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; // 重点，这里开始扩容 transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125;/** * Moves and/or copies the nodes in each bin to new table. See * above for explanation. */private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; // n 是tab的长度 ， stride 初始值为0 int n = tab.length, stride; // 判断cpu处理多线程的能力，如果小于16就直接赋值为16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; // 构造一个容量是原来两倍的Node&lt;K ,V&gt; 类型新数组 @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; // 新数组引用赋值 nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME // 最大值 sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; // 获取新数组的长度 int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab // 使用for循环来处理每个槽位中的链表元素，CAS设置transferIndex属性值，并初始化i和bound值 // i 指当前的槽位序号，bound值需要处理的边界，先处理槽位为15的节点 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 更新nextIndex的值 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; // 如果table已经复制结束 if (finishing) &#123; // 清空nextTable nextTable = null; // 把nextTab 赋值给 table table = nextTab; // 阈值设置为容量的1.5倍 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; // CAS算法获取某个数组节点，为空就设置为fwd else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 如果某个节点的hash为-1，跳过 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 对头节点加锁，禁止其他线程进入 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 构造两个链表 ，将该节点的列表拆分为两个部分，一个是原链表的排列顺序，一个是反序 Node&lt;K,V&gt; ln, hn; // fh 当前节点的hash值 若 &gt;= 0 if (fh &gt;= 0) &#123; int runBit = fh &amp; n; // 将当前节点赋值给 lastRun 节点 Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; // 差分列表操作 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; // 对TreeBin对象进行处理，过程与上面有些类似 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 如果扩容后 不在需要tree结构，反向转换成链表结构 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; get(Object key) 获取元素 此方法也是根据传入的key，获取相应的哈希值并计算出此key在table中存储的位置 如果此数组索引位置的元素就是要找的元素则直接返回，否则判断是红黑树节点还是链表节点，则调用不同的方式来获取元素 123456789101112131415161718192021222324252627282930313233343536/** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code key.equals(k)&#125;, * then this method returns &#123;@code v&#125;; otherwise it returns * &#123;@code null&#125;. (There can be at most one such mapping.) * * @throws NullPointerException if the specified key is null */public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 根据传入的key,获取相应的hash值，并再次散列 int h = spread(key.hashCode()); // 然后判断当前的table数组是否为空 (n - 1) &amp; h 为数组索引位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 此数组索引位置的元素就是要找的元素则直接返回 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // eh&lt; 0 表示红黑树节点 则在红黑树中查找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 链表遍历 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; // 不存在则返回null return null;&#125; 总结 ConcurrentHashMap存储检索元素依然沿用HashMap的思想，使用数组 + 链表的方式来存储数据，并通过key的哈希值来计算数组的位置 ConcurrentHashMap采用了for自旋 + CAS + synchronized方式来处理线程安全问题，不达目的不罢休，成功了才break，CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新 只对Node进行synchronized加锁，减小了锁粒度，相比Hashtable来说性能更优 JDK6 及 7 中的ConcurrentHashMap主要使用Segment来实现减小锁粒度，把HashMap分割成若干个Segment 在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 JDK7中ConcurrentHashMap中，当长度过长，碰撞会很频繁，链表的增改删查操作都会消耗很长的时间，影响性能，所以JDK7 中完全重写了ConcurrentHashMap,代码量从原来的1000多行变成了6000多行，实现上也和原来的分段式存储有很大的区别。 没有最好只有更好 参考 https://my.oschina.net/90888/blog/1625528","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-HashTable源码解析及原理","slug":"backend/java/collection/Java集合-Map-HashTable源码解析及原理","date":"2018-10-19T16:03:07.000Z","updated":"2019-09-22T04:18:42.955Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-HashTable源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-HashTable源码解析及原理/","excerpt":"","text":"前言 前面介绍了HashMap、LinkedHashMap、TreeMap都是非线程安全类，这里我们来学习一下Map的一个线程安全的实现类Hashtable 此类官方已不推荐使用了 1234567891011* &lt;p&gt;As of the Java 2 platform v1.2, this class was retrofitted to* implement the &#123;@link Map&#125; interface, making it a member of the* &lt;a href=\"&#123;@docRoot&#125;/../technotes/guides/collections/index.html\"&gt;** Java Collections Framework&lt;/a&gt;. Unlike the new collection* implementations, &#123;@code Hashtable&#125; is synchronized. If a* thread-safe implementation is not needed, it is recommended to use* &#123;@link HashMap&#125; in place of &#123;@code Hashtable&#125;. If a thread-safe* highly-concurrent implementation is desired, then it is recommended* to use &#123;@link java.util.concurrent.ConcurrentHashMap&#125; in place of* &#123;@code Hashtable&#125; 从Java 2平台v1.2，这个类被改造为实现Map接口，使其成为成员Java Collections Framework 。 与新的集合实现不同，Hashtable是同步的。 如果不需要线程安全的实现，建议使用HashMap代替Hashtable 。 如果需要线程安全的并发实现，那么建议使用ConcurrentHashMap代替Hashtable 。 解析类继承关系图 类成员变量 由下面类成员变量可以发现Hashtable和HashMap十分相似，底层也是使用数组加链表来存放数据 123456789101112131415161718192021222324252627282930313233343536373839404142public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable &#123; /** * 存放元素的哈希桶 * The hash table data. */ private transient Entry&lt;?,?&gt;[] table; /** * 元素个数 * The total number of entries in the hash table. */ private transient int count; /** * 要调整大小的下一个大小值（容量*加载因子） * The table is rehashed when its size exceeds this threshold. (The * value of this field is (int)(capacity * loadFactor).) * * @serial */ private int threshold; /** * 加载因子 * The load factor for the hashtable. * * @serial */ private float loadFactor; /** * The number of times this Hashtable has been structurally modified * Structural modifications are those that change the number of entries in * the Hashtable or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the Hashtable fail-fast. (See ConcurrentModificationException). */ private transient int modCount = 0; /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = 1421746759512286392L; 构造函数 构造函数也是和HashMap相类似 1234567891011121314151617181920212223242526public Hashtable(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal Load: \"+loadFactor); if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry&lt;?,?&gt;[initialCapacity]; threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);&#125;public Hashtable(int initialCapacity) &#123; this(initialCapacity, 0.75f);&#125;public Hashtable() &#123; this(11, 0.75f);&#125;public Hashtable(Map&lt;? extends K, ? extends V&gt; t) &#123; this(Math.max(2*t.size(), 11), 0.75f); putAll(t);&#125; 主要方法解析put(K key, V value) 添加元素 下面是添加元素的逻辑，可以看到逻辑和HashMap相类似，只不过这里没有红黑树的操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public synchronized V put(K key, V value) &#123; // Make sure the value is not null // 不允许存放null值 if (value == null) &#123; throw new NullPointerException(); &#125; // Makes sure the key is not already in the hashtable. Entry&lt;?,?&gt; tab[] = table; // key的哈希值 int hash = key.hashCode(); // 元素在哈希桶的索引位置 int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\"unchecked\") Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; // 此索引位置在哈希桶里有元素了，发生哈希冲突 for(; entry != null ; entry = entry.next) &#123; if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; // 旧值替换为新值 entry.value = value; // 返回旧值 return old; &#125; &#125; // 此索引位置在哈希桶里没有元素 addEntry(hash, key, value, index); return null;&#125;private void addEntry(int hash, K key, V value, int index) &#123; modCount++; Entry&lt;?,?&gt; tab[] = table; // 判断数组大小是否到达阈值 if (count &gt;= threshold) &#123; // Rehash the table if the threshold is exceeded // 扩容 rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; // Creates the new entry. @SuppressWarnings(\"unchecked\") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; // 元素赋值 tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++;&#125; get(Object key) 获取元素1234567891011public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return (V)e.value; &#125; &#125; return null;&#125; 总结 HashTable功能和HashMap相类似，只不过里面的方法加了synchronized使此类是线程安全的（性能会影响），不过此类已经被官方抛弃了，如果需要线程安全的并发实现，那么建议使用ConcurrentHashMap 参考","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-TreeMap源码解析及原理","slug":"backend/java/collection/Java集合-Map-TreeMap源码解析及原理","date":"2018-10-19T16:03:05.000Z","updated":"2019-09-22T03:56:44.591Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-TreeMap源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-TreeMap源码解析及原理/","excerpt":"","text":"前言 通过前面几章我们知道HashMap可实现快速存储和检索，但其缺点是其包含的元素是无序的，后面的是LinkedHashMap保留了HashMap的优势，可以按照插入顺序来维护元素的顺序，可是如果我们要实现自定义排序怎么办呢，此类就不支持了，所以TreeMap类就出来了 解析类继承关系图 上图是TreeMap的类继承关系图，相比HashMap来说，TreeMap多实现了一个接口NavigableMap，接口NavigableMap添加了和排序相关的接口方法 可以看到NavigableMap继承了SortedMap接口 SortedMap就像其名字那样，说明这个Map是有序的，当我们在用集合视角（collection views，与HashMap一样，也是由entrySet、keySet与values方法提供）来迭代（iterate）一个SortedMap实例时会体现出key的顺序。 这个顺序一般是指由Comparable接口提供的keys的自然序（natural ordering），比如String就实现了Comparable，所将String元素作为key放到SortedMap实现类上，就可以按字母表排序来输出元素 或者也可以在创建SortedMap实例时，指定一个Comparator来决定。 上面的Comparable和Comparator是不是很熟悉，在之前的Java集合-Queue-PriorityQueue源码解析及原理章节已经有介绍，^_^，果然知识是互通的，有了这些知识再来了解TreeMap就很快理解了 类成员变量 可以看到TreeMap的成员变量，和HashMap不同这里没有出现数组变量，只是出现了Entry&lt;K,V&gt;红黑树节点，那TreeMap是用红黑树链表来存放数据的 Comparator&lt;? super K&gt; comparator;是比较器是自然排序，还是定制排序 Entry&lt;K,V&gt; root来存放红黑树的根节点 int size来存放元素个数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = 919286545866124006L; /** * 比较器，是自然排序，还是定制排序 ，使用final修饰，表明一旦赋值便不允许改变 * The comparator used to maintain order in this tree map, or * null if it uses the natural ordering of its keys. * * @serial */ private final Comparator&lt;? super K&gt; comparator; /** * 红黑树的根节点 */ private transient Entry&lt;K,V&gt; root; /** * TreeMap中存放的键值对的数量 * The number of entries in the tree */ private transient int size = 0; /** * 修改的次数 * The number of structural modifications to the tree. */ private transient int modCount = 0; /** * Fields initialized to contain an instance of the entry set view * the first time this view is requested. Views are stateless, so * there's no reason to create more than one. */ private transient EntrySet entrySet; private transient KeySet&lt;K&gt; navigableKeySet; private transient NavigableMap&lt;K,V&gt; descendingMap; // SubMaps /** * Dummy value serving as unmatchable fence key for unbounded * SubMapIterators */ private static final Object UNBOUNDED = new Object(); // Red-black mechanics private static final boolean RED = false; private static final boolean BLACK = true; /** * 红黑树节点 * Node in the Tree. Doubles as a means to pass key-value pairs back to * user (see Map.Entry). */ static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; K key; V value; Entry&lt;K,V&gt; left; Entry&lt;K,V&gt; right; Entry&lt;K,V&gt; parent; boolean color = BLACK; /** * Make a new cell with given key, value, and parent, and with * &#123;@code null&#125; child links, and BLACK color. */ Entry(K key, V value, Entry&lt;K,V&gt; parent) &#123; this.key = key; this.value = value; this.parent = parent; &#125; /** * Returns the key. * * @return the key */ public K getKey() &#123; return key; &#125; /** * Returns the value associated with the key. * * @return the value associated with the key */ public V getValue() &#123; return value; &#125; /** * Replaces the value currently associated with the key with the given * value. * * @return the value associated with the key before this method was * called */ public V setValue(V value) &#123; V oldValue = this.value; this.value = value; return oldValue; &#125; public boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; return valEquals(key,e.getKey()) &amp;&amp; valEquals(value,e.getValue()); &#125; public int hashCode() &#123; int keyHash = (key==null ? 0 : key.hashCode()); int valueHash = (value==null ? 0 : value.hashCode()); return keyHash ^ valueHash; &#125; public String toString() &#123; return key + \"=\" + value; &#125; &#125; ...&#125; 构造函数 可以看到构造函数十分简单，可以指定Comparator比较器，因为没有使用数组所以不需要考虑扩容设及的那些阈值变量和负载因子变量 1234567891011121314151617181920public TreeMap() &#123; comparator = null;&#125;public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator = comparator;&#125;public TreeMap(Map&lt;? extends K, ? extends V&gt; m) &#123; comparator = null; putAll(m);&#125;public TreeMap(SortedMap&lt;K, ? extends V&gt; m) &#123; comparator = m.comparator(); try &#123; buildFromSorted(m.size(), m.entrySet().iterator(), null, null); &#125; catch (java.io.IOException cannotHappen) &#123; &#125; catch (ClassNotFoundException cannotHappen) &#123; &#125;&#125; 主要方法解析主要方法解析put(K key, V value) 添加元素 可以看到put(K key, V value)方法就是维护一个红黑树，红黑树的知识在这Java集合-Map-红黑树介绍章节有整理 红黑树的排序规则有两种，使用Comparable或者Comparator进行排序 如果在构造函数指定了队列比较器Comparator，那么元素排序是按照队列比较器Comparator的排序规则进行排序，否则就是按照元素实现的Comparator接口方法进行排序 注意如果元素是按Comparator接口方法进行排序的话，那么存放元素是必须实现了Comparator接口，否则插入元素的话会报java.lang.ClassCastException: XXX cannot be cast to java.lang.Comparable异常 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public V put(K key, V value) &#123; // 红黑树的根节点 Entry&lt;K,V&gt; t = root; // 第一次插入所以红黑树的根节点为null if (t == null) &#123; compare(key, key); // type (and possibly null) check // 构造根节点，因为根节点没有父节点，传入null值。 root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; // 按Comparator排序规则来插入 if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) // 指向左子树 t = t.left; else if (cmp &gt; 0) // 指向右子树 t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; // 按元素Comparable排序规则来插入 if (key == null) // 不允许插入null值 throw new NullPointerException(); // 如果元素没有实现Comparable接口会报错 @SuppressWarnings(\"unchecked\") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) // 指向左子树 t = t.left; else if (cmp &gt; 0) // 指向右子树 t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // 创建新节点，并制定父节点 Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); // 根据比较结果，决定新节点为父节点的左孩子或者右孩子 if (cmp &lt; 0) parent.left = e; else parent.right = e; // 新插入节点后重新调整红黑树 fixAfterInsertion(e); size++; modCount++; return null;&#125; get(Object key) 获取元素 可以看到获取元素的逻辑就是遍历红黑树，这里也分Comparable或者Comparator两种形式来查找 1234567891011121314151617181920212223242526272829303132333435363738394041final Entry&lt;K,V&gt; getEntry(Object key) &#123; // 使用Comparator比较器规则来获取元素值 // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings(\"unchecked\") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; // 从根节点开始遍历 Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; // 在左子树查找 else if (cmp &gt; 0) p = p.right; // 右子树查找 else return p; &#125; return null;&#125;final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; @SuppressWarnings(\"unchecked\") K k = (K) key; Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = cpr.compare(k, p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; &#125; return null;&#125; 总结 通过源码我们可以知道TreeMap底层是用红黑树数据结构来存放数据，增删改查就是维护红黑树，红黑树的大小比较是通过Comparable或者Comparator来实现的 如果在构造函数指定了队列比较器Comparator，那么元素排序是按照队列比较器Comparator的排序规则进行排序，否则就是按照元素实现的Comparator接口方法进行排序 注意如果元素是按Comparator接口方法进行排序的话，那么存放元素是必须实现了Comparator接口，否则插入元素的话会报java.lang.ClassCastException: XXX cannot be cast to java.lang.Comparable异常 TreeMap没有对多线程进行处理，所以是非线程安全类 HashMap可实现快速存储和检索，但其缺点是其包含的元素是无序的，而 TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap。HashMap通常比TreeMap效率要高一些，一个是哈希表，一个是二叉树，建议多使用HashMap，在需要排序的Map时候才用TreeMap。 参考 https://blog.csdn.net/mbmispig/article/details/78750405","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-LinkedHashMap源码解析及原理","slug":"backend/java/collection/Java集合-Map-LinkedHashMap源码解析及原理","date":"2018-10-19T16:03:04.000Z","updated":"2019-09-22T02:36:12.405Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-LinkedHashMap源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-LinkedHashMap源码解析及原理/","excerpt":"","text":"前言 LinkedHashMap由类名可以知道它是链起来的HashMap，由下面测试类可以知道HashMap是无序的，当我们希望根据插入顺序来获取key-value时就需要使用LinkedHashMap了 HashMap测试类 123456789101112131415161718192021222324252627282930313233343536@Testpublic void test2 () &#123; HashMap hashMap = new HashMap(); hashMap.put(\"1\",\"1\"); hashMap.put(\"2\",\"2\"); hashMap.put(\"3\",\"3\"); hashMap.put(\"4\",\"4\"); hashMap.put(\"5\",\"5\"); hashMap.put(\"6\",\"6\"); hashMap.put(\"7\",\"7\"); hashMap.put(\"8\",\"8\"); hashMap.put(\"9\",\"9\"); hashMap.put(\"10\",\"10\"); hashMap.put(\"11\",\"11\"); hashMap.put(\"12\",\"12\"); Iterator iterator = hashMap.entrySet().iterator(); while (iterator.hasNext()) &#123; Map.Entry kvEntry = (Map.Entry)iterator.next(); System.out.println(kvEntry.getValue()); &#125;&#125;// 结果111122345678910 LinkedHashMap测试类 123456789101112131415161718192021222324252627282930313233343536@Testpublic void test1 () &#123; LinkedHashMap hashMap = new LinkedHashMap(); hashMap.put(\"1\",\"1\"); hashMap.put(\"2\",\"2\"); hashMap.put(\"3\",\"3\"); hashMap.put(\"4\",\"4\"); hashMap.put(\"5\",\"5\"); hashMap.put(\"6\",\"6\"); hashMap.put(\"7\",\"7\"); hashMap.put(\"8\",\"8\"); hashMap.put(\"9\",\"9\"); hashMap.put(\"10\",\"10\"); hashMap.put(\"11\",\"11\"); hashMap.put(\"12\",\"12\"); Iterator iterator = hashMap.entrySet().iterator(); while (iterator.hasNext()) &#123; Map.Entry kvEntry = (Map.Entry)iterator.next(); System.out.println(kvEntry.getValue()); &#125;&#125;// 结果123456789101112 解析类继承关系图 上图是LinkedHashMap的类继承关系图，哇，这不直接是继承HashMap吗 类成员变量 下面是LinkedHashMap的成员变量，有了下面变量就不难理解它是怎么来维护元素顺序的 Entry&lt;K,V&gt; 此键值对节点变量是在java.util.HashMap.Node的基础上添加了两个变量， 一个用于存放前驱节点，一个用于存放后驱节点 上图是java.util.LinkedHashMap.Entry键值对节点的继承关系图 java.util.LinkedHashMap.Entry 继承自 java.util.HashMap.Node，并新增了两个引用，分别是 before 和 after。这两个引用的用途不难理解，也就是用于维护双向链表 java.util.HashMap.TreeNode 继承 java.util.LinkedHashMap.Entry 后，就具备了和其他 Entry 一起组成链表的能 LinkedHashMap.Entry&lt;K,V&gt; head 用于存放双向链表的头结点 LinkedHashMap.Entry&lt;K,V&gt; tail 双向链表的尾节点 boolean accessOrder此变量用于控制按插入顺序维护链表还是按按访问顺序维护链表，由构造函数指定，默认是false，按插入顺序维护链表 123456789101112131415161718192021222324252627282930313233343536public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; /** * 键值对节点 * HashMap.Node subclass for normal LinkedHashMap entries. */ static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125; &#125; private static final long serialVersionUID = 3801124242820219131L; /** * 双向链表的头结点 * The head (eldest) of the doubly linked list. */ transient LinkedHashMap.Entry&lt;K,V&gt; head; /** * 双向链表的尾节点 * The tail (youngest) of the doubly linked list. */ transient LinkedHashMap.Entry&lt;K,V&gt; tail; /** * 按插入顺序维护链表 false * 按访问顺序维护链表 true * * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * * @serial */ final boolean accessOrder; 构造函数 LinkedHashMap的构造函数就是调用HashMap构造函数并可以指定插入顺序策略，如果没有指定这里默认是accessOrder = false，是按插入顺序来维护链表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 调用HashMap构造函数构造具有默认初始容量（16）和负载因子（0.75）的 LinkedHashMap实例。 * Constructs an empty insertion-ordered &lt;tt&gt;LinkedHashMap&lt;/tt&gt; instance * with the default initial capacity (16) and load factor (0.75). */public LinkedHashMap() &#123; super(); accessOrder = false;&#125;/** * 调用HashMap构造函数构造具有指定初始容量（16）和负载因子（0.75）的 LinkedHashMap实例。 * Constructs an empty insertion-ordered &lt;tt&gt;LinkedHashMap&lt;/tt&gt; instance * with the specified initial capacity and a default load factor (0.75). * * @param initialCapacity the initial capacity * @throws IllegalArgumentException if the initial capacity is negative */public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false;&#125;/** * 调用HashMap构造函数构造具有指定初始容量（16）和指定负载因子（0.75）的 LinkedHashMap实例。 * Constructs an empty insertion-ordered &lt;tt&gt;LinkedHashMap&lt;/tt&gt; instance * with the specified initial capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false;&#125;/** * 构造具有与指定地图相同映射的插入序列 LinkedHashMap实例。 * Constructs an insertion-ordered &lt;tt&gt;LinkedHashMap&lt;/tt&gt; instance with * the same mappings as the specified map. The &lt;tt&gt;LinkedHashMap&lt;/tt&gt; * instance is created with a default load factor (0.75) and an initial * capacity sufficient to hold the mappings in the specified map. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; putMapEntries(m, false);&#125;/** * 调用HashMap构造函数构造具有指定初始容量（16）和指定负载因子（0.75）和指定插入顺序的 LinkedHashMap实例。 * Constructs an empty &lt;tt&gt;LinkedHashMap&lt;/tt&gt; instance with the * specified initial capacity, load factor and ordering mode. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @param accessOrder the ordering mode - &lt;tt&gt;true&lt;/tt&gt; for * access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 主要方法解析 通过上面我们知道LinkedHashMap继承了HashMap，那么它是怎么在HashMap基础上来维护元素的顺序的呢 put(K key, V value) 添加元素 还是先看一下添加元素的方法，可以发现 LinkedHashMap并没重写这个方法，也就是说put()元素的时候还是调用的是HashMap类的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value 如果插入`key`键相同的元素则不会更改`value`值 * @param evict if false, the table is in creation mode. 如果true 则数组是创建模式 为了继承HashMap的LinkedHashMap类服务的。 * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // tab存放 当前的哈希桶， p用作临时链表节点，n是数组大小，i是插入元素在哈希桶数组中的位置 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果当前哈希表是空的，代表是初始化 if ((tab = table) == null || (n = tab.length) == 0) // 那么直接去扩容哈希表，并且将扩容后的哈希桶长度赋值给n n = (tab = resize()).length; // 获取要插入元素在 哈希桶中的位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 说明此时在对应的索引位置没有对象，没有发生哈希冲突 // 如果当前index的节点是空的， 直接构建一个新节点Node，挂载在index处即可 tab[i] = newNode(hash, key, value, null); else &#123; // 说明此时在对应的索引位置已经有对象了，发生哈希冲突 Node&lt;K,V&gt; e; K k; // 如果哈希值相等，key也相等，则是覆盖value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将当前节点引用赋值给e e = p; else if (p instanceof TreeNode) // 如果定位到的元素是一个TreeNode(Node的一个子类，也是HashMap的一个内部类) // 那么就插入一TreeNode节点 定位到这个hash桶了 但是这里面是链表（没有进行过树化） e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 不是覆盖操作，则插入一个普通链表节点 // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 遍历到尾部，追加新节点到尾部 p.next = newNode(hash, key, value, null); // 追加节点后，判断如果当前bucket的位置链表长度大于8的话就将此链表变成红黑树。 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果e不是null，原对象与插入的对象的key相同，说明有需要覆盖的节点 if (e != null) &#123; // 则覆盖节点值，并返回原oldValue V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) // 将新插入的entry的value覆盖掉原来的entry的value e.value = value; // 这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeAccess(e); return oldValue; &#125; &#125; // 如果执行到了这里，说明插入了一个新的节点，所以会修改modCount，以及返回null，和fastRemove()有关也和并发修改有关 ++modCount; // 如果HashMap中元素的数量大于了阙值，则需要扩容哈希表 if (++size &gt; threshold) // 重新设置hash桶的大小，也有可能进行树化 resize(); // 为了继承HashMap的LinkedHashMap类服务的。 afterNodeInsertion(evict); return null;&#125; 此方法的大概逻辑上一章节已经有所介绍，现在我们来关注和LinkedHashMap相关的操作 首先我们可以看看tab[i] = newNode(hash, key, value, null);这行代码，这行代码是构建一个Node，我们可以发现LinkedHashMap重写了该方法，也是应该要重写，因为要存放可以维护顺序的LinkedHashMap.Entry节点 LinkedHashMap重写newNode()方法，可以看到下面逻辑也很简单，直接构造的Node是LinkedHashMap.Entry对象，然后就是把元素链接到双向链表的尾节点，实现了双向链表的建立123456789101112131415161718192021Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; // 构建LinkedHashMap.Entry LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); // 把元素链接到双向链表的尾节点 linkNodeLast(p); return p;&#125;// link at the end of listprivate void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; // 把元素链接到双向链表的尾节点 tail = p; if (last == null) // 第一个元素存放到双向链表的头结点 head = p; else &#123; // 维护尾节点的前后关系 p.before = last; last.after = p; &#125;&#125; 在putVal()方法中我们还可以发现HashMap为LinkedHashMap提供了定制方法，这些方法是在HashMap中是空实现，LinkedHashMap对其进行了重写实现 12345// 为LinkedHashMap服务// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; get(Object key) 获取元素 LinkedHashMap重写了HashMap#get(Object key)方法，上面我们知道boolean accessOrder此变量用于控制按插入顺序维护链表还是按按访问顺序维护链表，在此方法可以看到此变量的逻辑用途 12345678910public V get(Object key) &#123; Node&lt;K,V&gt; e; // 调用HashMap方法 if ((e = getNode(hash(key), key)) == null) return null; // 如果 accessOrder 为 true，则调用 afterNodeAccess 将被访问节点移动到链表最后 if (accessOrder) afterNodeAccess(e); return e.value;&#125; 可以看到主要逻辑和HashMap的get方法一样，只不过添加了一个判断，此判断是来维护按访问顺序来调整链表元素位置 afterNodeAccess(e);1234567891011121314151617181920212223242526void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; // 如果 b 为 null，表明 p 为头节点 if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; // 将 p 接在链表的最后 p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; 总结 LinkedHashMap键值对节点变量是在java.util.HashMap.Node的基础上添加了两个变量， 一个用于存放前驱节点，一个用于存放后驱节点，通过此节点可以找到它上一元素或者下一个元素 ，然后LinkedHashMap通过新增两个变量用于存放头结点和尾节点来维护一条双向链表，实现了散列数据结构的有序遍历 boolean accessOrder此变量用于控制按插入顺序维护链表还是按按访问顺序维护链表，由构造函数指定，默认是false，按插入顺序维护链表元素位置 因为要额外维护一个双向链表所以LinkedHashMap性能比HashMap略低，线程也是不安全的。 参考 https://segmentfault.com/a/1190000012964859","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-红黑树介绍","slug":"backend/java/collection/Java集合-Map-红黑树介绍","date":"2018-10-19T16:03:03.000Z","updated":"2020-01-04T12:21:52.245Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-红黑树介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-红黑树介绍/","excerpt":"","text":"前言 上一章节我们知道JDK1.8的HashMap链表长度大于8的话就将此链表变成红黑树，使用红黑树可以提高查询效率 介绍红黑树介绍二叉查找树介绍 在介绍红黑树之前我们要先理解二叉查找树的数据结构，下面简单介绍一下。 上面这张图就是一个二叉查找树。二叉查找树有如下几条特性 （1）.左子树上所有结点的值均小于或等于它的根结点的值。 （2）.右子树上所有结点的值均大于或等于它的根结点的值。 （3）.左、右子树也分别为二叉排序树 那既然他名字中是有“查找”的，那么他是怎么查找的呢？比如我们要查找10这个元素，查找过程为：首先找到根节点，然后根据二叉查找树的第一二条特性，我们知道要查找的10 &gt; 9所以是在根节点的右边去查找，找到13，10 &lt; 13,所以接着在13的左边找，找到11,10 &lt; 11,继续在11的左边查找，这样就找到了10.这其实就是二分查找的思想。最后我们要查出结果所需的最大次数就是二叉树的高度！（二分查找的思想:找到数组的中间位置的元素v，将数组分成&gt;v和&lt;v两部分，然后将v和要查找的数据进行一个比较，如果大于v那么就在&gt;v的部分再次进行二分查找，否则就在&lt;v的部分进行二分查找，直到找到对应的元素。） 那既然要查出结果所需的最大次数就是二叉树的高度，那这个高度会不会有时候很长呢？ 比如我们依次插入 根节点为9如下五个节点：7,6,5,4,3。依照二叉查找树的特性，结果会变成什么样呢？7,6,5,4,3一个比一个小，那么就会成一条直线，也就是成为了线性的查询，时间复杂度变成了O（N）级别。为了解决这种情况，该红黑树出场了。 红黑树介绍 红黑树其实就是一种自平衡的二叉查找树，，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组，他这个自平衡的特性就是对HashMap中链表可能会很长做出的优化。 红黑树是每个节点都带有颜色属性的二叉查找树，颜色或红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求: 性质1. 节点是红色或黑色。 性质2. 根节点是黑色。 性质3 每个叶节点（NIL节点，空节点）是黑色的。 性质4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 下面这棵树就是一个典型的红黑树 红黑树那么多规则，那么在插入和删除元素会不会破坏红黑树的规则呢？什么情况下会破坏？什么情况下不会？ 比如我们向原红黑树插入为14的新节点就不会破坏规则 向原红黑树插入值为21的新节点就破坏了规则 那么红黑树是怎么维护这个二叉查找树的自平衡性的呢？ 红黑树通过变色和旋转来维护红黑树的规则，变色就是让黑的变成红的，红的变成黑的，旋转又分为“左旋转”和“右旋转”。这个比较复杂，容易晕，我们就只要知道红黑树就是通过这种方式来实现它的自平衡性就行了。 总结 为什么要使用红黑树呢，当然是提高查找效率 当元素小于8个，HashMap使用的是链表存放数据，链表查询成本高，新增成本低 至于为什么选 8 这个值呢？通过概率统计所得，这个值是综合查询成本和新增元素成本得出的最好的一个值。 当如果元素大于8个时HashMap会将链表转化成红黑树，虽然插入元素可能需要左旋右旋变色繁杂操作，但带来的效果是提高了查询效率 参考 https://www.jianshu.com/p/2c7a4a4e1f53","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-HashMap源码解析及原理","slug":"backend/java/collection/Java集合-Map-HashMap源码解析及原理","date":"2018-10-19T16:03:02.000Z","updated":"2019-09-21T15:35:34.479Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-HashMap源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-HashMap源码解析及原理/","excerpt":"","text":"前言 HashMap分为俩个词理解，一个是Hash，另一个是Map Hash: 是通过某种hash函数算法算出一个对象的哈希码值（将对象的内部地址转换为整数来实现） Map：可以理解为地图点的位置，我们如果想要找到地图上的某个点，就需要通过经纬度来定位，Hash就是这个值，我们可以通过这个值，找到我们所要的位置 HashMap是基于哈希表的Map接口的非同步实现，在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 下面将从HashMap的源码来分析其实现原理，代码采用JDK 1.8版本 HashMap源码大量用到了位运算符，位运算在这一章已整理 Java基础-Java位运算 解析类继承关系图 上图是HashMap类的继承关系图，HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。 AbstractMap是Map的抽象实现类，这个类在 Java集合-Collection及Map抽象实现类章节介绍过 Cloneable是标记型的接口，它们内部都没有方法和属性，实现Cloneable来表示该对象能被克隆 Serializable序列化接口 类成员变量 下面是HashMap类的成员变量 Node&lt;K,V&gt;[] table 数组变量存放集合数据，Node类是数据节点，哇这不是链表用的节点吗，这里我们可以知道HashMap是基于数组 + 链表来存放数据的，我们可以将这个数组称之为哈希桶，每个桶里面放的是链表，链表中的每个节点，就是哈希表中的每个元素。 Node&lt;K,V&gt;存储着key、value及hash值，还有此节点的下一个节点Node&lt;K,V&gt; next TreeNode&lt;K,V&gt; 红黑树节点，在JDK8中，当链表长度达到8，会转化成红黑树，以提升它的查询、插入效率，它实现了Map&lt;K,V&gt;, Cloneable, Serializable接口。 Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet是集合数据的Set缓存数据 int size用来记录元素的数量 int modCount记录map被修改的次数 int threshold记录要调整大小的下一个大小值（容量*加载因子），当HashMap的容量达到threshold域值时，就会触发扩容 float loadFactor计算数组扩容大小的加载因子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; ... /** * 存放数据的数组 * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ transient Node&lt;K,V&gt;[] table; /** * entrySet 缓存 * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; /** * HashMap中元素的数量 * * The number of key-value mappings contained in this map. */ transient int size; /** * 记录map被修改的次数 * * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; /** * 要调整大小的下一个大小值（容量*加载因子） * * The next size value at which to resize (capacity * load factor). * * @serial */ // (The javadoc description is true upon serialization. // Additionally, if the table array has not been allocated, this // field holds the initial array capacity, or zero signifying // DEFAULT_INITIAL_CAPACITY.) int threshold; /** * 加载因子 * * The load factor for the hash table. * * @serial */ final float loadFactor; /** * 元素节点 Node本质上是一个Map.存储着key-value * * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; // 保存该桶的hash值 final int hash; // 不可变的key final K key; // value值 V value; // 指向一个数据的指针 Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; /** * 树节点 * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * Returns root of tree containing this node. */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; ...&#125; 下面的类常量和数组大小扩容相关 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private static final long serialVersionUID = 362498820763181265L;/** * 默认初始容量，为16个 * The default initial capacity - MUST be a power of two. */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/** * 最大容量： 1073741824 * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * 加载因子，当容量达到3/4的时候进行容量扩容, 不是满的时候再扩容 * The load factor used when none specified in constructor. */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * 由链表转换成树的阈值TREEIFY_THRESHOLD 一个桶中bin（箱子）的存储方式由链表转换成树的阈值。 * 即当桶中bin的数量超过TREEIFY_THRESHOLD时使用树来代替链表。默认值是8 * * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */static final int TREEIFY_THRESHOLD = 8;/** * 当执行resize操作时，当桶中bin的数量少于UNTREEIFY_THRESHOLD时使用链表来代替树。默认值是6 * * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */static final int UNTREEIFY_THRESHOLD = 6;/** * 当桶中的bin被树化时最小的hash表容量。（如果没有达到这个阈值，即hash表容量小于MIN_TREEIFY_CAPACITY， * 当桶中bin的数量太多时会执行resize扩容操作）这个MIN_TREEIFY_CAPACITY的值至少是TREEIFY_THRESHOLD的4倍。 * * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */static final int MIN_TREEIFY_CAPACITY = 64; 构造函数 下面是HashMap的构造函数，可以看到前三个构造函数都是构造一个空的 HashMap（transient Node&lt;K,V&gt;[] table;没赋值）并指定初始容量和负载因子，猜测数组应该是put的时候会初始化 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 构造一个空的 HashMap ，默认初始容量（16）和默认负载系数（0.75）。 * * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;/** * 构造一个空的 HashMap具有指定的初始容量和默认负载因子（0.75）。 * * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;/** * 造一个空的 HashMap具有指定的初始容量和负载因子。 * * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;/** * 造一个新的 HashMap与指定的相同的映射 Map 。 * * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 主要方法解析put(K key, V value) 添加元素 进入put()方法，这里先根据key值调用hash()方法计算哈希值，HashMap是通过这个来查找key值对应的value值的，然后调用了java.util.HashMap#putVal()方法， 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 进入hash(key)，此方法是调用了key的hashCode()方法，并进行了移位和异或运算 方法源码: 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 为什么不直接使用hashCode作为hash值呢？为什么非要经过 h ^ (h &gt;&gt;&gt; 16) 这一步运算呢？查看源码注释是这样描述的： 寻址计算时，能够参与到计算的有效二进制位仅仅是右侧和数组长度值对应的那几位，意味着发生hash碰撞（hash值重复）的几率会高。 通过移位和异或运算让hashCode的高位能够参与到寻址计算中，采用这种方式是为了在性能、实用性、分布质量上取得一个平衡。 有很多hashCode算法都已经是分布合理的了，并且大量碰撞时，还可以通过树结构来解决查询性能问题。 所以用了性能比较高的位运算来让高位参与到寻址运算中，位运算对于系统损耗相对低廉。 所以结论是经过移位和异或运算可以使hash值更加均衡，因为hashCode()是int类型，取值范围是40多亿，只要哈希函数映射的比较均匀松散，碰撞几率是很小的，但就算原本的hashCode()取得很好，每个key的hashCode()不同，但是由于HashMap的哈希桶的长度远比hash取值范围小，默认是16，所以当对hash值以桶的长度取余，以找到存放该key的桶的下标时，由于取余是通过与操作完成的，会忽略hash值的高位。 继续进入putVal()方法，此方法是HashMap的核心方法，需要仔细研究 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value 如果插入`key`键相同的元素则不会更改`value`值 * @param evict if false, the table is in creation mode. 如果true 则数组是创建模式 为了继承HashMap的LinkedHashMap类服务的。 * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // tab存放 当前的哈希桶， p用作临时链表节点，n是数组大小，i是插入元素在哈希桶数组中的位置 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果当前哈希表是空的，代表是初始化 if ((tab = table) == null || (n = tab.length) == 0) // 那么直接去扩容哈希表，并且将扩容后的哈希桶长度赋值给n n = (tab = resize()).length; // 获取要插入元素在 哈希桶中的位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 说明此时在对应的索引位置没有对象，没有发生哈希冲突 // 如果当前index的节点是空的， 直接构建一个新节点Node，挂载在index处即可 tab[i] = newNode(hash, key, value, null); else &#123; // 说明此时在对应的索引位置已经有对象了，发生哈希冲突 Node&lt;K,V&gt; e; K k; // 如果哈希值相等，key也相等，则是覆盖value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将当前节点引用赋值给e e = p; else if (p instanceof TreeNode) // 如果定位到的元素是一个TreeNode(Node的一个子类，也是HashMap的一个内部类) // 那么就插入一TreeNode节点 定位到这个hash桶了 但是这里面是链表（没有进行过树化） e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 不是覆盖操作，则插入一个普通链表节点 // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 遍历到尾部，追加新节点到尾部 p.next = newNode(hash, key, value, null); // 追加节点后，判断如果当前bucket的位置链表长度大于8的话就将此链表变成红黑树。 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果e不是null，原对象与插入的对象的key相同，说明有需要覆盖的节点 if (e != null) &#123; // 则覆盖节点值，并返回原oldValue V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) // 将新插入的entry的value覆盖掉原来的entry的value e.value = value; // 这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeAccess(e); return oldValue; &#125; &#125; // 如果执行到了这里，说明插入了一个新的节点，所以会修改modCount，以及返回null，和fastRemove()有关也和并发修改有关 ++modCount; // 如果HashMap中元素的数量大于了阙值，则需要扩容哈希表 if (++size &gt; threshold) // 重新设置hash桶的大小，也有可能进行树化 resize(); // 为了继承HashMap的LinkedHashMap类服务的。 afterNodeInsertion(evict); return null;&#125; 先看方法参数final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) int hash 是key键的哈希值 K key 代表key键 V value 代表 value值 boolean onlyIfAbsent如果是true，如果插入key键相同的元素则不会更改value值，HashMap这里默认是false boolean evict 如果是true 则数组是创建模式，为了继承HashMap的LinkedHashMap类服务的，HashMap本身方法没有什么用 在看第一行声明的变量Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; tab存放当前的哈希桶 p用作临时链表节点 n是数组大小 i是插入元素在哈希桶数组中的位置 下面讲解方法主要逻辑 if ((tab = table) == null || (n = tab.length) == 0) 这行代码有多个操作，即完成了赋值操作，又要执行if操作，赋值是将table引用赋值给tab变量，然后将数组大小值赋值给n变量，如果数组为null或数组长度为0，也就是当前哈希表是空的，那么就要初始化这个哈希表了，就是会执行下面这行代码 n = (tab = resize()).length; 这行代码是new HashMap();之后第一次执行put方会执行 resize()方法会返回一个新数组 然后给n及tab赋值 这样的代码好精简 执行完上面的判断，现在哈希表就已经初始化了(第一次put)或者已经初始化了(非第一次put)，再进行下一个if代码if ((p = tab[i = (n - 1) &amp; hash]) == null)，下面按步骤解析 i = (n - 1) &amp; hash 这行代码是计算插入元素在哈希桶数组中的位置，并将其赋值给变量i，注意这里对数组长度及哈希值进行了位与运算，由于HashMap的哈希桶的长度远比hash取值范围小，默认是16，所以当对hash值以桶的长度取余，以找到存放该key的桶的下标时，由于取余是通过与操作完成的，会忽略hash值的高位。 得到插入元素在哈希桶数组中的位置之后将元素赋值给变量p，之后判断这个元素是否是null 如果为null则说明此位置原先没有值，没有发生哈希碰撞 如果不为null则说明此位置原先有值，现在发生了哈希碰撞 if ((p = tab[i = (n - 1) &amp; hash]) == null) 为true ，没有发生哈希碰撞，则直接构建一个新节点Node，挂载在index处即可。 tab[i] = newNode(hash, key, value, null); if ((p = tab[i = (n - 1) &amp; hash]) == null) 为false ，现在发生了哈希碰撞，则需要处理这个问题，那么链表就出场了 解决哈希碰撞的方法 1234567891011121314151617181920212223242526272829303132333435Node&lt;K,V&gt; e; K k;// 如果哈希值相等，key也相等，则是覆盖value操作if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将当前节点引用赋值给e e = p;else if (p instanceof TreeNode) // 如果 你定位到的元素是一个TreeNode(Node的一个子类，也是HashMap的一个内部类) // 那么就插入一TreeNode节点 定位到这个hash桶了 但是这里面是链表（没有进行过树化） e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);else &#123; // 不是覆盖操作，则插入一个普通链表节点 // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 遍历到尾部，追加新节点到尾部 p.next = newNode(hash, key, value, null); // 追加节点后，如果链表长度超过8转成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125;&#125;// 如果e不是null，原对象与插入的对象的key相同，说明有需要覆盖的节点if (e != null) &#123; // 则覆盖节点值，并返回原oldValue V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) // 将新插入的entry的value覆盖掉原来的entry的value e.value = value; // 这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeAccess(e); return oldValue;&#125; 由上面逻辑可以知道 1、如果哈希值相等，key也相等，则是覆盖value操作，将当前节点引用赋值给e 2、如果定位到的元素是一个TreeNode(Node的一个子类，也是HashMap的一个内部类)，那么就插入一TreeNode节点 3、上面的判断还是没有成立，则遍历链表将新节点添加到链表的最后位置，这里有个判断如果当前bucket的位置链表长度大于8的话就将此链表变成红黑树，这里是为了提高查询效率 4、如果e不是null，那就是说明原对象与插入的对象的key相同，这里onlyIfAbsent变量就发挥了作用，如果是true的话新插入的entry的value覆盖掉原来的entry的value，则putVal()方法会返回这个旧值 执行完上面的判断就是执行下面的逻辑了，记录修改变量++modCount，如果插完元素之后发现元素个数大于了阙值则需要扩容哈希桶的大小，也是调用resize();方法，afterNodeInsertion(evict);为了继承HashMap的LinkedHashMap类服务的 123456789// 如果执行到了这里，说明插入了一个新的节点，所以会修改modCount，以及返回null，和fastRemove()有关也和并发修改有关++modCount;// 如果HashMap中元素的数量大于了阙值，则需要扩容哈希表if (++size &gt; threshold) // 重新设置hash桶的大小，也有可能进行树化 resize();// 为了继承HashMap的LinkedHashMap类服务的。afterNodeInsertion(evict);return null; 最后putVal()方法返回个null值 由上面putVal()方法的执行逻辑可以得出下面的数据存储结构图 resize() 哈希表初始化及扩容 此方法主要有两个功能 哈希表初始化操作 初始化操作是new HashMap();之后哈希表是空的，第一次执行putVal()方法会执行这个resize()方法完成哈希表初始化操作 如果没有在构造函数指定初始容量和负载因子参数，则默认是初始化长度为16的数组，负载因子参数为0.75，那么扩容阈值就是12 = 16 * 0.75，数组元素达到12的时候就会执行扩容操作 扩容操作 扩容操作是每次调用putVal()方法，这个方法里面会进行判断if (++size &gt; threshold)，如果HashMap中元素的数量大于了阙值，则需要扩容哈希表 扩容操作会将构建一个大小比老数组大两倍的新数组，并完成新老数组的copy操作，这里会重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知hashmap中元素的个数，那么预设元素的个数能够有效的提高hashmap的性能 老数组长度超出最大容量，则老阈值取值为Integer.MAX_VALUE，这里直接返回老数组，不再扩容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; // 老数组 Node&lt;K,V&gt;[] oldTab = table; // 老数组长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 老阈值 int oldThr = threshold; // 新数组长度先初始为0，新阈值先初始为0 int newCap, newThr = 0; // 老数组已初始化 if (oldCap &gt; 0) &#123; // 老数组长度超出最大容量，则老阈值取值为Integer.MAX_VALUE，这里直接返回老数组，不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; // 这里直接返回老数组，不再扩容 return oldTab; &#125; // 否则新数组容量为旧数组容量的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 如果旧的容量大于等于默认初始容量16 // 那么新的阈值也等于旧的阈值的两倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // 如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况 initial capacity was placed in threshold // 那么新表的容量就等于旧的阈值 newCap = oldThr; else &#123; // 如果当前表是空的，而且也没有阈值。代表是初始化时没有任何容量/阈值参数的情况 zero initial threshold signifies using defaults // 默认初始容量为16 newCap = DEFAULT_INITIAL_CAPACITY; // 新阈值 = 容量 * 加载因子(12 = 16 * 0.75) newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; // 如果新的阈值是0，对应的是 当前表是空的，但是有阈值的情况 // 根据新表容量 和 加载因子 求出新的阈值 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 更新阈值 threshold = newThr; // 构建新数组直接赋值 @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 下面开始新老王朝更替了 if (oldTab != null) &#123; // for循环老数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; // 如果数组节点有元素,则将链表赋值给e if ((e = oldTab[j]) != null) &#123; // 将原哈希桶置空以便GC oldTab[j] = null; // 如果当前链表中就一个元素，（没有发生哈希碰撞） if (e.next == null) /** * 直接将这个元素放置在新的哈希桶里 * 注意这里取下标 是用 哈希值 与 桶的长度-1 。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高 * 位与运算符（&amp;）: 两个数都转为二进制，然后从高位开始比较，如果两个数都为1则为1，否则为0。 */ newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 元素是红黑树节点 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， 或者扩容后的下标，即high位。 high位= low位+原哈希桶容量 // 低位链表的头结点、尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; // 高位链表的头节点、尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; // 临时节点 存放e的下一个节点 Node&lt;K,V&gt; next; do &#123; next = e.next; // 这里又是一个利用位运算 代替常规运算的高效点： 利用哈希值 与 旧的容量，可以得到哈希值去模后，是大于等于oldCap还是小于oldCap， // 等于0代表小于oldCap，应该存放在低位，否则存放在高位 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将低位链表存放在原index处 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 将高位链表存放在新index处 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; get(Object key) 获取元素 了解完putVal()方法之后再来看get(Object key)方法就很简单了，还是先计算调用hash(key)方法计算key键的哈希值，然后就是调用getNode(int hash, Object key)方法 1234567891011121314151617181920212223242526272829303132333435363738394041public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; /** * tab 指向哈希表 * first node为在数组中的元素，这个元素是根据哈希值算出索引并定位在数组的元素，这个不一定是我们要的元素，因为有哈希碰撞的情况 * e node是发生了哈希碰撞情况并在链表里找出的元素 * n 是数组元素大小，计算元素在数组中的位置要用 * key变量是键值 */ Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 1、哈希表不为空 2、哈希表长度不为零 3、根据哈希值算出数组索引并定位在数组的元素不为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // always check first node // 在数组中的元素 各种元素比较，注意这里执行了key.equals(k)方法，哈哈哈，看到这里就可以理解为什么重写了hashCode()方法需要重写equals方法 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 各种比较通过之后，那么这个元素就是我们要的元素 return first; // 上面数组位置的元素并不是我们要的数据，说明发生了哈希碰撞，需要遍历链表来获取 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) // 在红黑树中找到了我们的元素 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 在链表里找到了元素 return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 遍历map 既然Java中的所有map都实现了Map接口，以下方法适用于任何map实现（HashMap, TreeMap, LinkedHashMap, Hashtable, 等等） 方法一: 在for-each循环中使用entries来遍历 这是最常见的并且在大多数情况下也是最可取的遍历方式。在键值都需要时使用 注意：for-each循环在Java 5中被引入所以该方法只能应用于Java 5或更高的版本中。如果你遍历的是一个空的map对象，for-each循环将抛出NullPointerException，因此在遍历前你总是应该检查空引用。 1234567Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123; System.out.println(\"Key = \" + entry.getKey() + \", Value = \" + entry.getValue()); &#125; 方法二: 在for-each循环中遍历keys或values。 如果只需要map中的键或者值，你可以通过keySet或values来实现遍历，而不是用entrySet，该方法比entrySet遍历在性能上稍好（快了10%），而且代码更加干净。 1234567891011121314151617Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); //遍历map中的键 for (Integer key : map.keySet()) &#123; System.out.println(\"Key = \" + key); &#125; //遍历map中的值 for (Integer value : map.values()) &#123; System.out.println(\"Value = \" + value); &#125; 方法三: 使用Iterator遍历 使用迭代器来遍历，该种方式看起来冗余却有其优点所在。首先，在老版本java中这是惟一遍历map的方式。另一个好处是，你可以在遍历时调用iterator.remove()来删除entries，另两个方法则不能。根据javadoc的说明，如果在for-each遍历中尝试使用此方法，结果是不可预测的。 从性能方面看，该方法类同于for-each遍历（即方法二）的性能。 123456789101112// 使用泛型：Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; entries = map.entrySet().iterator(); while (entries.hasNext()) &#123; Map.Entry&lt;Integer, Integer&gt; entry = entries.next(); System.out.println(\"Key = \" + entry.getKey() + \", Value = \" + entry.getValue()); &#125; 12345678910111213141516// 不使用泛型:Map map = new HashMap(); Iterator entries = map.entrySet().iterator(); while (entries.hasNext()) &#123; Map.Entry entry = (Map.Entry) entries.next(); Integer key = (Integer)entry.getKey(); Integer value = (Integer)entry.getValue(); System.out.println(\"Key = \" + key + \", Value = \" + value); &#125; 方法四: 通过键找值遍历（效率低） 作为方法一的替代，这个代码看上去更加干净；但实际上它相当慢且无效率。因为从键取值是耗时的操作（与方法一相比，在不同的Map实现中该方法慢了20%~200%）。如果你安装了FindBugs，它会做出检查并警告你关于哪些是低效率的遍历。所以尽量避免使用。123456789Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (Integer key : map.keySet()) &#123; Integer value = map.get(key); System.out.println(\"Key = \" + key + \", Value = \" + value); &#125; 总结 由上面我们知道HashMap存放的数据是一个键值对，key元素用来查找定位数据，value元素来存放具体数据，键值对数据会封装成一个Node并存放在数组，有数组的话就需要扩容，数组元素存放的是链表节点，链表是为了解决哈希冲突的，而当链表长度大于8的话就将此链表变成红黑树，这里是为了提高查询效率 存储元素时，HashMap利用key的hashCode()方法并进行位运算计算出当前对象的元素在数组中的下标，，然后就将元素存放在数据中，如果出现hash值相同的key，此时有两种情况。 (1)如果key相同，则覆盖原始值 (2)如果key不同（出现哈希冲突），则将当前的key-value放入链表中 获取元素时，它之所以有相当快的查询速度主要是因为它是通过计算散列码来决定存储的位置，利用key的hashCode()方法并进行位运算计算出当前对象的元素在数组中的下标，然后就获取元素 (1)如果key相同，则返回数据 (2)如果key不同（出现哈希冲突），则循环链表找出元素 理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。 HashMap 的实现不是同步的，这意味着它不是线程安全的。它的key、value都可以为null。此外，HashMap中的映射不是有序的。 HashMap 的实例有两个参数影响其性能：“初始容量” 和 “加载因子”。容量 是哈希表中桶的数量，初始容量 只是哈希表在创建时的容量。加载因子 是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 resize 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。 通常，默认加载因子是0.75, 这是在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get和 put 操作，都反映了这一点）。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少resize 操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生 resize操作。 HashMap并允许使用 null 值和 null 键，在计算哈键的哈希值时，null 键哈希值为0，也就是说存放在数组第一个位置（除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）参考 http://www.cnblogs.com/yuanblog/p/4441017.html https://blog.csdn.net/zxt0601/article/details/77413921 https://blog.csdn.net/weixin_42340670/article/details/80574965","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Map-介绍","slug":"backend/java/collection/Java集合-Map-介绍","date":"2018-10-19T16:03:01.000Z","updated":"2019-09-24T13:32:47.108Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Map-介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Map-介绍/","excerpt":"","text":"前言 再来回顾下集合框架图，可以看到Map主要有下面这些实现类 HashMap 键值对集合 LinkedHashMap 有序的键值对集合 TreeMap 可自定义排序规则的键值对集合 前面章节介绍的都是Collection的三大金刚的实现类，采用线性列表的存储方式存储单元素，这一专题系列将介绍集合了另一体系Map子类的实现 什么是Map Map 是一个散列表，它存储的内容是键值对(key-value)映射，可以理解为地图点的位置，我们如果想要找到地图上的某个点，就需要通过经纬度来定位，Hash就是这个值，我们可以通过这个值，找到我们所要的位置。 转化到我们编程环境里如果要找出一个对象在怎么定位呢，我们知道Object类有个方法就是public native int hashCode();，这个方法是返回一个int类型的数字（对应我们上面地图定位的经纬度信息），通过这个数字可以找到我们要的元素 java.lang.Object#hashCode方法介绍 此方法是返回对象的哈希码值（将对象的内部地址转换为整数来实现），hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap查找元素就是通过此方法 java.lang.Object#hashCode方法实现约定： 只要在执行Java应用程序时多次在同一个对象上调用该方法， hashCode方法必须始终返回相同的整数 如果根据equals(Object)方法两个对象相等，则在两个对象中的每个对象上调用hashCode方法必须产生相同的整数结果。 不要求如果两个对象根据equals(java.lang.Object)方法不相等，那么在两个对象中的每个对象上调用hashCode方法必须产生不同的整数结果。 但是，程序开发人员应该意识到，为不等对象生成不同的整数结果可以提高哈希表的性能，因为可以减少Hash碰撞 尽可能多的合理实用，由类别Object定义的hashCode方法确实为不同对象返回不同的整数 java.lang.Object#hashCode方法与java.lang.Object#Object obj方法联系 如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同 如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面那点 两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里“ 再归纳一下就是hashCode是用于查找使用的，而equals是用于比较两个对象的是否相等的。 以下对hashCode的解读摘自其他博客： hashcode是用来查找数据的，如果你学过数据结构就应该知道，在查找和排序这一章有：例如内存中有这样的位置0 1 2 3 4 5 6 7，而我有个类，这个类有个字段叫ID,我要把这个类存放在以上8个位置之一，如果不用hashcode而任意存放，那么当查找时就需要到这八个位置里挨个去找，或者用二分法一类的算法。 但如果用hashcode那就会使效率提高很多。我们这个类中有个字段叫ID,那么我们就定义我们的hashcode为ID％8，然后把我们的类存放在取得得余数那个位置。比如我们的ID为9，9除8的余数为1，那么我们就把该类存在1这个位置，如果ID是13，求得的余数是5，那么我们就把该类放在5这个位置。这样，以后在查找该类时就可以通过ID除8求余数直接找到存放的位置了。 但是如果两个类有相同的hashcode怎么办呢（我们假设上面的类的ID不是唯一的），例如9除以8和17除以8的余数都是1，那么这是不是合法的，回答是：可以这样。那么如何判断呢？在这个时候就需要定义 equals了。 也就是说，我们先通过 hashcode来判断两个类是否存放某个桶里，但这个桶里可能有很多类，那么我们就需要再通过 equals 来在这个桶里找到我们要的类。 想想，你要在一个桶里找东西，你必须先要找到这个桶啊，你不通过重写hashcode()来找到桶，光重写equals()有什么用啊 解析 查看Map接口可以发现使用两个泛型（K）指定为键，（V）指定为值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221public interface Map&lt;K,V&gt; &#123; int size(); boolean isEmpty(); boolean containsKey(Object key); boolean containsValue(Object value); V get(Object key); V put(K key, V value); V remove(Object key); void putAll(Map&lt;? extends K, ? extends V&gt; m); void clear(); Set&lt;K&gt; keySet(); Collection&lt;V&gt; values(); Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); interface Entry&lt;K,V&gt; &#123; K getKey(); V getValue(); V setValue(V value); boolean equals(Object o); int hashCode(); public static &lt;K extends Comparable&lt;? super K&gt;, V&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByKey() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getKey().compareTo(c2.getKey()); &#125; public static &lt;K, V extends Comparable&lt;? super V&gt;&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByValue() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getValue().compareTo(c2.getValue()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByKey(Comparator&lt;? super K&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getKey(), c2.getKey()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByValue(Comparator&lt;? super V&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getValue(), c2.getValue()); &#125; &#125; boolean equals(Object o); int hashCode(); default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue; &#125; default void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Objects.requireNonNull(action); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; action.accept(k, v); &#125; &#125; default void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Objects.requireNonNull(function); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; // ise thrown from function is not a cme. v = function.apply(k, v); try &#123; entry.setValue(v); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; &#125; &#125; default V putIfAbsent(K key, V value) &#123; V v = get(key); if (v == null) &#123; v = put(key, value); &#125; return v; &#125; default boolean remove(Object key, Object value) &#123; Object curValue = get(key); if (!Objects.equals(curValue, value) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; remove(key); return true; &#125; default boolean replace(K key, V oldValue, V newValue) &#123; Object curValue = get(key); if (!Objects.equals(curValue, oldValue) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; put(key, newValue); return true; &#125; default V replace(K key, V value) &#123; V curValue; if (((curValue = get(key)) != null) || containsKey(key)) &#123; curValue = put(key, value); &#125; return curValue; &#125; default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) &#123; V newValue; if ((newValue = mappingFunction.apply(key)) != null) &#123; put(key, newValue); return newValue; &#125; &#125; return v; &#125; default V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue; if ((oldValue = get(key)) != null) &#123; V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) &#123; put(key, newValue); return newValue; &#125; else &#123; remove(key); return null; &#125; &#125; else &#123; return null; &#125; &#125; default V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue = get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue == null) &#123; // delete mapping if (oldValue != null || containsKey(key)) &#123; // something to remove remove(key); return null; &#125; else &#123; // nothing to do. Leave things as they were. return null; &#125; &#125; else &#123; // add or replace old mapping put(key, newValue); return newValue; &#125; &#125; default V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) &#123; remove(key); &#125; else &#123; put(key, newValue); &#125; return newValue; &#125;&#125; 总结参考 http://www.cnblogs.com/yuanblog/p/4441017.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Queue-LinkedBlockingQueue阻塞队列","slug":"backend/java/collection/Java集合-Queue-LinkedBlockingQueue阻塞队列","date":"2018-10-19T16:02:05.000Z","updated":"2019-09-19T12:25:24.272Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Queue-LinkedBlockingQueue阻塞队列/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Queue-LinkedBlockingQueue阻塞队列/","excerpt":"","text":"前言 LinkedBlockingQueue由类名可以知道他是个基于链表实现的阻塞队列，下面来看看这个类的具体实现 代码采用JDK 1.8版本 解析类继承关系图 类继承关系图 上图可以看到LinkedBlockingQueue类继承关系图，可以看到和ArrayBlockingQueue类的继承关系图差不多 BlockingQueue在Queue接口的基础上对入队和出队两个操作分别又增加了阻塞方法，如下： 阻塞入队put(E e) 阻塞出队E take() 定时入队offer(E e,long timeout,TimeUnit unit) 定时出队E poll(long timeout,TimeUnit unit) AbstractQueue类是队列的抽象实现类 Serializable序列化接口 类成员变量 下面可以看到LinkedBlockingQueue的成员变量 Node&lt;E&gt;类是链表节点， Node&lt;E&gt; head变量用来存放头结点，Node&lt;E&gt; last变量用来存放尾节点 int capacity变量来存放队列容量，可以看到只有在构造函数有对此值进行赋值，如果没有指定，该值为Integer.MAX_VALUE AtomicInteger count来记录队列中元素的个数 由ReentrantLock类可以知道此队列是线程安全的，这里有两个锁，和ArrayBlockingQueue类不一样这里更细化了 ReentrantLock takeLock用于出队的锁 ReentrantLock putLock用于入队的锁 Condition notEmpty及Condition notFull用于队列实现阻塞 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; private static final long serialVersionUID = -6903933977591709194L; /** * 链表节点 * Linked list node class */ static class Node&lt;E&gt; &#123; E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125; &#125; /** * 队列容量，如果没有指定，该值为Integer.MAX_VALUE * The capacity bound, or Integer.MAX_VALUE if none */ private final int capacity; /** * 当前队列中的元素 * Current number of elements */ private final AtomicInteger count = new AtomicInteger(); /** * 队列头节点，始终满足head.item==null * Head of linked list. * Invariant: head.item == null */ transient Node&lt;E&gt; head; /** * 队列的尾节点，始终满足last.next==null * Tail of linked list. * Invariant: last.next == null */ private transient Node&lt;E&gt; last; /** * 用于出队的锁 * Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** * 当队列为空时，保存执行出队的线程 * Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** * 用于入队的锁 * Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** * 当队列满时，保存执行入队的线程 * Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition(); 构造函数 下面可以看到构造函数，默认构造函数是指定队列大小为Integer.MAX_VALUE并构造将头节点及尾节点都赋值了一个元素为null的Node节点 int capacity变量来存放队列容量，可以看到只有在构造函数有对此值进行赋值，如果没有指定，该值为Integer.MAX_VALUE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 创建一个 LinkedBlockingQueue ，容量为 Integer.MAX_VALUE 。 * * Creates a &#123;@code LinkedBlockingQueue&#125; with a capacity of * &#123;@link Integer#MAX_VALUE&#125;. */public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125;/** * 创建一个具有给定（固定）容量的 LinkedBlockingQueue 。 * * Creates a &#123;@code LinkedBlockingQueue&#125; with the given (fixed) capacity. * * @param capacity the capacity of this queue * @throws IllegalArgumentException if &#123;@code capacity&#125; is not greater * than zero */public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; // last和head在队列为空时都存在，所以队列中至少有一个节点 last = head = new Node&lt;E&gt;(null);&#125;/** * 创建一个 LinkedBlockingQueue ，容量为 Integer.MAX_VALUE ，最初包含给定集合的元素，以集合的迭代器的遍历顺序添加。 * * Creates a &#123;@code LinkedBlockingQueue&#125; with a capacity of * &#123;@link Integer#MAX_VALUE&#125;, initially containing the elements of the * given collection, * added in traversal order of the collection's iterator. * * @param c the collection of elements to initially contain * @throws NullPointerException if the specified collection or any * of its elements are null */public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) &#123; this(Integer.MAX_VALUE); final ReentrantLock putLock = this.putLock; putLock.lock(); // Never contended, but necessary for visibility try &#123; int n = 0; for (E e : c) &#123; if (e == null) throw new NullPointerException(); if (n == capacity) throw new IllegalStateException(\"Queue full\"); enqueue(new Node&lt;E&gt;(e)); ++n; &#125; count.set(n); &#125; finally &#123; putLock.unlock(); &#125;&#125; 主要方法解析入队方法offer(E e)方法 如果可以在不超过队列的容量的情况下立即将其指定的元素插入到队列的尾部，如果队列已满，则返回 true和 false ，非阻塞方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 如果可以在不超过队列的容量的情况下立即将其指定的元素插入到队列的尾部，如果队列已满，则返回 true和 false 。 * * Inserts the specified element at the tail of this queue if it is * possible to do so immediately without exceeding the queue's capacity, * returning &#123;@code true&#125; upon success and &#123;@code false&#125; if this queue * is full. * When using a capacity-restricted queue, this method is generally * preferable to method &#123;@link BlockingQueue#add add&#125;, which can fail to * insert an element only by throwing an exception. * * @throws NullPointerException if the specified element is null */public boolean offer(E e) &#123; // 不允许null值 if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; // 队列满了的话直接返回false if (count.get() == capacity) return false; int c = -1; // 构造新节点 Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; // 队列没满那可以插入 if (count.get() &lt; capacity) &#123; // 将节点入队 enqueue(node); // 得到插入之前队列的元素个数 c = count.getAndIncrement(); // 如果还可以插入元素，那么释放等待的入队线程 if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; // 解锁 putLock.unlock(); &#125; // 通知出队线程队列非空 if (c == 0) signalNotEmpty(); return c &gt;= 0;&#125; put(E e)方法 在该队列的尾部插入指定的元素，如果需要，等待空格变为可用，阻塞方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 在该队列的尾部插入指定的元素，如果需要，等待空格变为可用。 * * Inserts the specified element at the tail of this queue, waiting if * necessary for space to become available. * * @throws InterruptedException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public void put(E e) throws InterruptedException &#123; // 不允许元素为null if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; // 构建新元素节点 Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; /* 如果队列已满，那么将该线程加入到Condition的等待队列中 * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from capacity. Similarly * for all other uses of count in other wait guards. */ while (count.get() == capacity) &#123; notFull.await(); &#125; // 将节点入队 enqueue(node); // 得到插入之前队列的元素个数 c = count.getAndIncrement(); // 如果还可以插入元素，那么释放等待的入队线程 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; // 解锁 putLock.unlock(); &#125; // 通知出队线程队列非空 if (c == 0) signalNotEmpty();&#125; 出队方法poll() 检索并删除此队列的头部，如果此队列为空，则返回 null，非阻塞方法 12345678910111213141516171819202122232425262728/** * 检索并删除此队列的头部，如果此队列为空，则返回 null 。 * @return */public E poll() &#123; final AtomicInteger count = this.count; if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; if (count.get() &gt; 0) &#123; // 出队 x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; &#125; finally &#123; takeLock.unlock(); &#125; // 如果队列中的元素从满到非满，通知put线程 if (c == capacity) signalNotFull(); return x;&#125; take() 检索并删除此队列的头，如有必要，等待元素可用，阻塞方法 123456789101112131415161718192021222324252627282930/** * 检索并删除此队列的头，如有必要，等待元素可用。 * @return * @throws InterruptedException */public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; // 没元素了，阻塞了 while (count.get() == 0) &#123; notEmpty.await(); &#125; // 得到队头元素 x = dequeue(); c = count.getAndDecrement(); // 如果队列中还有数据可取，释放notEmpty条件等待队列中的第一个线程 if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; // 如果队列中的元素从满到非满，通知put线程 if (c == capacity) signalNotFull(); return x;&#125; 总结 有上面可以看到LinkedBlockingQueue是线程安全类，底层基于链表实现队列，所以容量可选，如果不设置，那么容量是int的最大值，ArrayBlockingQueue底层基于定长的数组，所以容量限制了 LinkedBlockingQueue是允许两个线程同时在两端进行入队或出队的操作的，但一端同时只能有一个线程进行操作，这是通过两把锁来区分的 为了维持底部数据的统一，引入了AtomicInteger的一个count变量，表示队列中元素的个数。count只能在两个地方变化，一个是入队的方法（可以+1），另一个是出队的方法（可以-1），而AtomicInteger是原子安全的，所以也就确保了底层队列的数据同步。 参考 https://my.oschina.net/90888/blog/1624758","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Queue-ArrayBlockingQueue阻塞队列","slug":"backend/java/collection/Java集合-Queue-ArrayBlockingQueue阻塞队列","date":"2018-10-19T16:02:04.000Z","updated":"2020-03-21T07:59:13.566Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Queue-ArrayBlockingQueue阻塞队列/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Queue-ArrayBlockingQueue阻塞队列/","excerpt":"","text":"前言 ArrayBlockingQueue由类名可以知道他是个基于数组实现的阻塞队列，下面来看看这个类的具体实现 代码采用JDK 1.8版本 解析类继承关系图 类继承关系图 上图可以看到ArrayBlockingQueue类继承关系图 BlockingQueue在Queue接口的基础上对入队和出队两个操作分别又增加了阻塞方法，如下： 阻塞入队put(E e) 阻塞出队E take() 定时入队offer(E e,long timeout,TimeUnit unit) 定时出队E poll(long timeout,TimeUnit unit) AbstractQueue类是队列的抽象实现类 Serializable序列化接口 类成员变量 下面可以看到ArrayBlockingQueue的成员变量 基于Object[] items数组来存放数据的 int takeIndex及int putIndex来记录下一个出队或者入队的索引位置，这个将会在下面的方法介绍 int count来记录队列中元素的个数 final ReentrantLock lock;这个变量是控制线程安全的关键 Condition notEmpty及Condition notFull是队列实现阻塞的关键123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; /** * Serialization ID. This class relies on default serialization * even for the items array, which is default-serialized, even if * it is empty. Otherwise it could not be declared final, which is * necessary here. */ private static final long serialVersionUID = -817911632652898426L; /** * 存放元素的数组 * The queued items */ final Object[] items; /** * 记录下一个take、remove、peek出队的索引 * items index for next take, poll, peek or remove */ int takeIndex; /** * 记录下一个put、offer、add入队的索引 * items index for next put, offer, or add */ int putIndex; /** * 队列中元素的个数 * Number of elements in the queue */ int count; /* * Concurrency control uses the classic two-condition algorithm * found in any textbook. */ /** * 数据访问的重入锁 用来保证多线程操作共享变量的安全问题 * Main lock guarding all access */ final ReentrantLock lock; /** * 当队列为空时，就会调用notEmpty的wait方法，让当前线程等待 * Condition for waiting takes */ private final Condition notEmpty; /** * 当队列为满时，就会调用notFull的wait方法，让当前线程等待 * Condition for waiting puts */ private final Condition notFull; /** * Shared state for currently active iterators, or null if there * are known not to be any. Allows queue operations to update * iterator state. */ transient Itrs itrs = null; ...&#125; 构造函数 下面可以看到构造函数主要有两个参数 int capacity用于指定数组的容量大小 boolean fair用于指定构造的ReentrantLock是公平锁还是非公平锁 ReentrantLock 默认采用非公平锁，除非在构造方法中传入参数 true ，所谓非公平锁，就是不管执行顺序，每个线程获取锁的几率都是相同的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 构造指定容量的数组，默认初始化ReentrantLock是非公平锁 * * Creates an &#123;@code ArrayBlockingQueue&#125; with the given (fixed) * capacity and default access policy. * * @param capacity the capacity of this queue * @throws IllegalArgumentException if &#123;@code capacity &lt; 1&#125; */public ArrayBlockingQueue(int capacity) &#123; this(capacity, false);&#125;/** * 构造指定容量的数组，并可以指定ReentrantLock是公平锁还是非公平锁 * * Creates an &#123;@code ArrayBlockingQueue&#125; with the given (fixed) * capacity and the specified access policy. * * @param capacity the capacity of this queue * @param fair if &#123;@code true&#125; then queue accesses for threads blocked * on insertion or removal, are processed in FIFO order; * if &#123;@code false&#125; the access order is unspecified. * @throws IllegalArgumentException if &#123;@code capacity &lt; 1&#125; */public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125;/** * 构造指定容量的数组，并可以指定ReentrantLock是公平锁还是非公平锁，并将已存在的集合数据赋值到这里 * * Creates an &#123;@code ArrayBlockingQueue&#125; with the given (fixed) * capacity, the specified access policy and initially containing the * elements of the given collection, * added in traversal order of the collection's iterator. * * @param capacity the capacity of this queue * @param fair if &#123;@code true&#125; then queue accesses for threads blocked * on insertion or removal, are processed in FIFO order; * if &#123;@code false&#125; the access order is unspecified. * @param c the collection of elements to initially contain * @throws IllegalArgumentException if &#123;@code capacity&#125; is less than * &#123;@code c.size()&#125;, or less than 1. * @throws NullPointerException if the specified collection or any * of its elements are null */public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) &#123; this(capacity, fair); final ReentrantLock lock = this.lock; lock.lock(); // Lock only for visibility, not mutual exclusion try &#123; int i = 0; try &#123; for (E e : c) &#123; checkNotNull(e); items[i++] = e; &#125; &#125; catch (ArrayIndexOutOfBoundsException ex) &#123; throw new IllegalArgumentException(); &#125; count = i; putIndex = (i == capacity) ? 0 : i; &#125; finally &#123; lock.unlock(); &#125;&#125; 主要方法解析普通入队方法offer(E e)方法 下面可以看到是不允许插入null值的，然后使用ReentrantLock进行并发加锁解锁处理，所以当很多线程一起插入时，这里是线程安全的，这里需要注意的是如果count == items.length数组满了之后就插入不了，这里也没有进行数组扩容操作，满了就直接是返回false，如果没满则插入元素返回true ReentrantLock 获取锁方法lock() 是拿不到lock就不罢休，不然线程就一直block。 比较无赖的做法。 12345678910111213141516171819202122232425262728293031/** * 如果可以在不超过队列容量的情况下立即将其指定的元素插入该队列的尾部，如果成功时则返回 true，如果该队列已满则返回 false * * Inserts the specified element at the tail of this queue if it is * possible to do so immediately without exceeding the queue's capacity, * returning &#123;@code true&#125; upon success and &#123;@code false&#125; if this queue * is full. This method is generally preferable to method &#123;@link #add&#125;, * which can fail to insert an element only by throwing an exception. * * @throws NullPointerException if the specified element is null */public boolean offer(E e) &#123; // 不允许插入null值 checkNotNull(e); final ReentrantLock lock = this.lock; // 首先对Lock加锁，然后再执行插入，所以当很多线程一起插入时，是线程安全的 lock.lock(); try &#123; // 满了就插不了 if (count == items.length) return false; else &#123; // 插入元素 enqueue(e); return true; &#125; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 进入enqueue(e)方法，下面可以看到items[putIndex] = x是直接赋值，并计算下一个put、offer、add入队的索引位置，现在有数据了然后调用notEmpty.signal()通知因为空而阻塞的线程继续执行取数据的操作 123456789101112131415161718/** * Inserts element at current put position, advances, and signals. * Call only when holding lock. */private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; // 赋值 putIndex默认为0 items[putIndex] = x; // 下一个入队的索引putIndex + 1 if (++putIndex == items.length) // 如果索引位置到了数组最后则归为0开始，循环入队列 putIndex = 0; count++; // 一旦插入一个元素后，将调用notEmpty.signal()，通知因为空而阻塞的线程重新执行，现在有数据了 notEmpty.signal();&#125; add(E e)方法 此方法也是调用offer(e)方法 12345678910public boolean add(E e) &#123; return super.add(e);&#125;// java.util.AbstractQueue#addpublic boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\");&#125; 阻塞式入队方法put(E e)方法 可以看到主要逻辑和offer(E e)方法差不多，只不过这里如果是队列已满时不是返回false，而是将会调用notFull的await()方法将线程置于阻塞状态，然后就是等待通知了，如果数组不是满员的状态，就将元素入队 ReentrantLock lockInterruptibly()方法能够中断等待获取锁的线程。当两个线程同时通过lock.lockInterruptibly()获取某个锁时，假若此时线程A获取到了锁，而线程B只有等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 123456789101112131415161718192021222324/** * Inserts the specified element at the tail of this queue, waiting * for space to become available if the queue is full. * * @throws InterruptedException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public void put(E e) throws InterruptedException &#123; // 不允许元素为null checkNotNull(e); final ReentrantLock lock = this.lock; // 加锁 lock.lockInterruptibly(); try &#123; // 在队列已满时将会调用notFull的await()方法释放锁并处于阻塞状态 while (count == items.length) notFull.await(); // 不为满的状态，就将元素入队 enqueue(e); &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 普通出队方法poll() poll()方法是出队方法，有数据的话就返回，没有数据的话就是返回null，注意此方法是没有阻塞线程的 12345678910public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 有数据的话调用dequeue() 否则是返回null return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; dequeue()方法，从下面可以看到主要逻辑是直接使用索引takeIndex从数组里面取数据，并计算下一个take、remove、peek出队的索引，元素赋为null，那么GC就会回收元素数据，最后就是调用notFull.signal();通知因为数组满员而阻塞的线程继续执行插入数据的操作 123456789101112131415161718192021222324/** * Extracts element at current take position, advances, and signals. * Call only when holding lock. */private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\"unchecked\") // 取走数据 E x = (E) items[takeIndex]; // 元素赋null 以助GC items[takeIndex] = null; // 下一个出队的索引takeIndex + 1 if (++takeIndex == items.length) // 如果索引位置到了数组最后则归为0开始，循环出队列 takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); // 现在有位子了，通知因队列满而阻塞的线程执行 notFull.signal(); return x;&#125; 阻塞式出队方法take() take()方法用于取走队头的元素，当队列为空时将会阻塞，直到队列中有元素可取走时将会被释放 123456789101112131415public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; // 首先加锁 lock.lockInterruptibly(); try &#123; // 如果队列为空，阻塞 while (count == 0) notEmpty.await(); // 队列不为空，调用dequeue()出队 return dequeue(); &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 总结 由源码可以知道ArrayBlockingQueue的底层是用数组来存放数据的，但不像ArrayList那样会对数组进行扩容，也就是说队列长度是固定的，，并通过int takeIndex;int putIndex;变量来控制出队及入队的数组位置 ArrayBlockingQueue的并发阻塞是通过ReentrantLock和Condition来实现的，ArrayBlockingQueue内部只有一把锁，意味着同一时刻只有一个线程能进行入队或者出队的操作。 需要注意的是如果数组满了之后就插入不了或者阻塞，这里也没有进行数组扩容操作 参考 https://my.oschina.net/90888/blog/1624500","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Queue-BlockingQueue阻塞队列接口","slug":"backend/java/collection/Java集合-Queue-BlockingQueue阻塞队列接口","date":"2018-10-19T16:02:03.000Z","updated":"2019-09-22T02:01:38.825Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Queue-BlockingQueue阻塞队列接口/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Queue-BlockingQueue阻塞队列接口/","excerpt":"","text":"前言 前面两个章节介绍了PriorityQueue及ConcurrentLinkedQueue队列，这两个队列是非阻塞队列，那么什么是阻塞队列呢？主要有下面两点 就是在队列为空时从队头取数据线程将会被阻塞，因为此时还没有数据可取，一旦队列中有数据了，取到数据之后线程就会得到释放 如果队列有容量限制且满了，那么插入数据的线程将会阻塞，直到队列中有空闲位置可以插入数据了，线程才会释放 代码采用JDK 1.8版本 解析 BlockingQueue是阻塞队列的顶层接口 类继承关系图 整个BlockingQueue的结构都是在Queue的接口上扩展的 类继承关系图 BlockingQueue在Queue接口的基础上对入队和出队两个操作分别又增加了阻塞方法，如下： 阻塞入队 阻塞出队 定时入队 定时出队 put(E e) E take() offer(E e,long timeout,TimeUnit unit) E poll(long timeout,TimeUnit unit) BlockingQueue 方法 各个实现类ArrayBlockingQueue 一个基于数组实现的有界阻塞队列，必须设置容量 LinkedBlockingQueue 基于链表实现的阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列 PriorityBlockingQueue 一个无界的阻塞队列，使用的排序规则和PriorityQueue类似并提供了阻塞操作 LinkedBlockingDeque 一个基于双端链表的双端阻塞队列，容量可以选择进行设置 总结 Java提供的线程安全的Queue可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是BlockingQueue，非阻塞队列的典型例子是ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 参考 https://my.oschina.net/90888/blog/1604266 https://www.cnblogs.com/Joe-Go/p/9757394.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Queue-ConcurrentLinkedQueue源码解析及原理","slug":"backend/java/collection/Java集合-Queue-ConcurrentLinkedQueue源码解析及原理","date":"2018-10-19T16:02:02.000Z","updated":"2019-09-19T12:25:24.267Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Queue-ConcurrentLinkedQueue源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Queue-ConcurrentLinkedQueue源码解析及原理/","excerpt":"","text":"前言 上一章节中PriorityQueue是非线程安全队列，这里的ConcurrentLinkedQueue是线程安全队列集合，此类是基于链接节点的无界线程安全队列，这个队列排列元素FIFO（先进先出） 代码采用JDK 1.8版本 解析简单示例类继承关系图 下图是ConcurrentLinkedQueue的类继承关系图，可以看到也是继承了AbstractQueue类，继承了一些队列操作方法 类继承关系图 类成员变量 由下面可以看到ConcurrentLinkedQueue是基于链表结构来实现数据存储的 Node&lt;E&gt;此类代表链表元素节点 volatile E item;用于保存存放的元素 Node&lt;E&gt; next用于存放下一个元素 可以看到Node&lt;E&gt;里面的方法都是基于sun.misc.Unsafe来操作实现的 Node&lt;E&gt; head 用于存放链表头节点 Node&lt;E&gt; tail 用于存放链表尾节点 sun.misc.Unsafe UNSAFE 作用： sun.misc.Unsafe类可以用来在任意内存地址位置处读写数据，可见，对于普通用户来说，使用起来还是比较危险的 除了获取内存偏移量以外，提供的最重要的功能了——因为Java中很多基于“无同步锁”方式的功能实现原理都是基于CAS过程，它是Java中对大多数锁机制实现的最基础类 CAS操作的方法：compareAndSwapInt，compareAndSwapLong等，主要逻辑是将内存值与预期值作比较，判断是否相等，相等的话，写入数据，不相等不做操作，返回旧数据； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements Queue&lt;E&gt;, java.io.Serializable &#123; private static final long serialVersionUID = 196745693267521676L; private static class Node&lt;E&gt; &#123; /** * 存放元素 用volatile进行修饰的，以保证内存可见性 */ volatile E item; /** * next指针 */ volatile Node&lt;E&gt; next; /** * Constructs a new node. Uses relaxed write because item can * only be seen after publication via casNext. */ Node(E item) &#123; UNSAFE.putObject(this, itemOffset, item); &#125; boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; void lazySetNext(Node&lt;E&gt; val) &#123; UNSAFE.putOrderedObject(this, nextOffset, val); &#125; boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long itemOffset; private static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = Node.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"item\")); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"next\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; /** * 链表的头部 * * A node from which the first live (non-deleted) node (if any) * can be reached in O(1) time. * Invariants: * - all live nodes are reachable from head via succ() * - head != null * - (tmp = head).next != tmp || tmp != head * Non-invariants: * - head.item may or may not be null. * - it is permitted for tail to lag behind head, that is, for tail * to not be reachable from head! */ private transient volatile Node&lt;E&gt; head; /** * 链表的尾部 * * A node from which the last node on list (that is, the unique * node with node.next == null) can be reached in O(1) time. * Invariants: * - the last node is always reachable from tail via succ() * - tail != null * Non-invariants: * - tail.item may or may not be null. * - it is permitted for tail to lag behind head, that is, for tail * to not be reachable from head! * - tail.next may or may not be self-pointing to tail. */ private transient volatile Node&lt;E&gt; tail; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long headOffset; private static final long tailOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = ConcurrentLinkedQueue.class; headOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"head\")); tailOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"tail\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; 构造函数 由下面可以看到有两个构造函数 默认构造函数是构造一个首尾节点都指向一个空值节点(哨兵结点)，如下图： 12345678/** * 创建一个 ConcurrentLinkedQueue为空的ConcurrentLinkedQueue。 * * Creates a &#123;@code ConcurrentLinkedQueue&#125; that is initially empty. */public ConcurrentLinkedQueue() &#123; head = tail = new Node&lt;E&gt;(null);&#125; 第二个构造函数是根据已有集合来构造一个队列12345678910111213141516171819202122232425262728/** * 创建一个 ConcurrentLinkedQueue最初包含给定集合的元素，以集合的迭代器的遍历顺序添加。 * * Creates a &#123;@code ConcurrentLinkedQueue&#125; * initially containing the elements of the given collection, * added in traversal order of the collection's iterator. * * @param c the collection of elements to initially contain * @throws NullPointerException if the specified collection or any * of its elements are null */public ConcurrentLinkedQueue(Collection&lt;? extends E&gt; c) &#123; Node&lt;E&gt; h = null, t = null; for (E e : c) &#123; checkNotNull(e); Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); if (h == null) h = t = newNode; else &#123; t.lazySetNext(newNode); t = newNode; &#125; &#125; if (h == null) h = t = new Node&lt;E&gt;(null); head = h; tail = t;&#125; 主要方法解析添加元素offer(E e)入队操作 元素的入队是在队尾插入元素，下面方法可以看到是主要逻辑是有个for循环自旋，如果循环体CAS操作成功会直接return返回，如果CAS操作失败的话就在for循环中不断重试直至成功 ConcurrentLinkedQueue的入队操作整体逻辑如下图所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Inserts the specified element at the tail of this queue. * As the queue is unbounded, this method will never return &#123;@code false&#125;. * * @return &#123;@code true&#125; (as specified by &#123;@link Queue#offer&#125;) * @throws NullPointerException if the specified element is null */public boolean offer(E e) &#123; // 为null的话就直接抛出空指针异常 checkNotNull(e); // 将e包装成一个Node类 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); /** * 循环体CAS操作成功会直接return返回 * 如果CAS操作失败的话就在for循环中不断重试直至成功 */ for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; // p是最后一个节点 // p is last node if (p.casNext(null, newNode)) &#123; // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become \"live\". if (p != t) // hop two nodes at a time 每两次更新一下tail casTail(t, newNode); // Failure is OK. return true; &#125; // CAS竞争失败，再次尝试 // Lost CAS race to another thread; re-read next &#125; else if (p == q) // 遇到哨兵节点，从head开始遍历 // 但是如果tail被修改，则使用tail（因为可能被修改正确了） // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; else // 每两次更新后，确认tail更新 定位队列真正的对尾节点 // Check for tail updates after two hops. p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 删除元素poll()出队操作 队列中元素的出队是从队首移除元素，出队也是和入队逻辑差不多，也是采用自旋 + CAS的方式处理 12345678910111213141516171819202122232425262728293031public E poll() &#123; restartFromHead: for (;;) &#123; // p节点表示首节点，即需要出队的节点 for (Node&lt;E&gt; h = head, p = h, q;;) &#123; E item = p.item; // 如果p节点的元素不为null，则通过CAS来设置p节点引用的元素为null，如果成功则返回p节点的元素 if (item != null &amp;&amp; p.casItem(item, null)) &#123; // 如果p != h，则更新head // Successful CAS is the linearization point // for item to be removed from this queue. if (p != h) // hop two nodes at a time updateHead(h, ((q = p.next) != null) ? q : p); return item; &#125; // 如果头节点的元素为空或头节点发生了变化，这说明头节点已经被另外一个线程修改了。 // 那么获取p节点的下一个节点，如果p节点的下一节点为null，则表明队列已经空了 else if ((q = p.next) == null) &#123; // 更新头结点 updateHead(h, p); return null; &#125; // p == q，则使用新的head重新开始 else if (p == q) continue restartFromHead; // 如果下一个元素不为空，则将头节点的下一个节点设置成头节点 else p = q; &#125; &#125;&#125; 总结 ConcurrentLinkedQueue是线程安全队列，底层采用链表节点来存放数据，这个队列按照FIFO（先进先出）策略来排列元素 我们查看ConcurrentLinkedQueue源码可以看到它并没有利用Lock或synchronized来处理线程安全问题，而是完全基于自旋 + CAS的方式来处理线程安全问题，虽然大大增加了程序的设计和实现的难度，但是它带来的好处就是可以得到性能的飞速提升 此队列是非阻塞队列，关于阻塞队列的介绍将在下面的章节介绍 参考 https://www.cnblogs.com/Joe-Go/p/9757394.html https://segmentfault.com/a/1190000016248143 https://www.cnblogs.com/gxyandwmm/p/9418915.html https://www.cnblogs.com/chenpi/p/5389254.html https://blog.csdn.net/qq_38293564/article/details/80798310","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Queue-PriorityQueue源码解析及原理","slug":"backend/java/collection/Java集合-Queue-PriorityQueue源码解析及原理","date":"2018-10-19T16:02:01.000Z","updated":"2019-11-27T15:11:32.586Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Queue-PriorityQueue源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Queue-PriorityQueue源码解析及原理/","excerpt":"","text":"前言 PriorityQueue 一个基于优先级的无界优先级队列，优先队列的作用是能保证每次取出的元素都是队列中权值最小的，这里牵涉到了大小关系判断，具体判断策略有下面几种 1、元素大小的评判可以按照其自然顺序进行排序 2、按照元素自身实现了Comparable接口进行排序 3、或者根据构造队列时提供的 Comparator 进行排序，具体取决于所使用的构造方法 代码采用JDK 1.8版本 解析简单示例 下面将用3个例子来演示PriorityQueue的使用 1、按照其自然顺序进行排序，这里是按照数字大小来排序 123456789101112131415161718192021222324252627@Testpublic void test0 () &#123; PriorityQueue q = new PriorityQueue&lt;&gt;(); // 入队 q.offer(32); q.offer(57); q.offer(10); q.offer(34); q.offer(44); q.offer(17); // 出队 System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll());&#125;// 结果101732344457 2、按照元素自身实现了Comparable接口进行排序，我们这里String是实现了Comparable接口的，所以排序规则是按照其实现的方法规则进行排序的 123456789101112131415161718192021222324252627@Testpublic void test1 () &#123; PriorityQueue q = new PriorityQueue&lt;&gt;(); // 入队 q.offer(\"ea\"); q.offer(\"ec\"); q.offer(\"a\"); q.offer(\"b1\"); q.offer(\"c\"); q.offer(\"b2\"); // 出队 System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll());&#125;// 结果ab1b2ceaec 3、通过构造器指定Comparator排序规则进行排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class Student &#123; /** * 名字 */ private String name; /** * 分数 */ private int score; public Student(String name, int score) &#123; this.name = name; this.score = score; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getScore() &#123; return score; &#125; public void setScore(int score) &#123; this.score = score; &#125; @Override public String toString() &#123; return \"Student&#123;\" + \"name='\" + name + '\\'' + \", score=\" + score + '&#125;'; &#125;&#125;@Testpublic void test2 () &#123; // 通过构造器指定Comparator排序规则 PriorityQueue&lt;Student&gt; q = new PriorityQueue&lt;Student&gt;(new Comparator&lt;Student&gt;() &#123; public int compare(Student o1, Student o2) &#123; // 按照分数低到高，分数相等按名字 if(o1.getScore() == o2.getScore())&#123; return o1.getName().compareTo(o2.getName()); &#125; return o1.getScore() - o2.getScore(); &#125; &#125;); //入列 q.offer(new Student(\"dafei\", 20)); q.offer(new Student(\"will\", 17)); q.offer(new Student(\"setf\", 30)); q.offer(new Student(\"bunny\", 20)); //出列 System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll()); System.out.println(q.poll());&#125;// 结果Student&#123;name='will', score=17&#125;Student&#123;name='bunny', score=20&#125;Student&#123;name='dafei', score=20&#125;Student&#123;name='setf', score=30&#125; 类继承关系图 类继承关系图 上图是PriorityQueue的继承关系图，可以看到主要就是继承了AbstractQueue类，继承了一些队列操作方法 类成员变量 下面也可以看到PriorityQueue的组成 Object[] queue就是一个数组，模拟初始大小为11，size变量记录元素个数，如果是数组的话那就是和ArrayList那样需要对数组进行动态扩容 Comparator&lt;? super E&gt; comparator是队列比较器，用于排序判断，下图可以看到此变量是在构造函数赋值的，上面的例子中有所介绍*int modCount = 0变量前面也接触过，该字段表示集合结构上被修改的次数，该字段被Iterator以及ListIterator的实现类所使用，如果该值被意外更改，Iterator或者ListIterator将抛出ConcurrentModificationException异常 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class PriorityQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements java.io.Serializable &#123; private static final long serialVersionUID = -7720805057305804111L; /** * 默认初始大小 */ private static final int DEFAULT_INITIAL_CAPACITY = 11; /** * 队列容器 * * Priority queue represented as a balanced binary heap: the two * children of queue[n] are queue[2*n+1] and queue[2*(n+1)]. The * priority queue is ordered by comparator, or by the elements' * natural ordering, if comparator is null: For each node n in the * heap and each descendant d of n, n &lt;= d. The element with the * lowest value is in queue[0], assuming the queue is nonempty. */ transient Object[] queue; // non-private to simplify nested class access /** * 队列长度 * The number of elements in the priority queue. */ private int size = 0; /** * 队列比较器， 为null使用自然排序 * The comparator, or null if priority queue uses elements' * natural ordering. */ private final Comparator&lt;? super E&gt; comparator; /** * 记录修改次数 迭代器迭代使用 * The number of times this priority queue has been * &lt;i&gt;structurally modified&lt;/i&gt;. See AbstractList for gory details. */ transient int modCount = 0; // non-private to simplify nested class access ... &#125; 构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 默认创建一个长度为11的数组 */public PriorityQueue() &#123; this(DEFAULT_INITIAL_CAPACITY, null);&#125;/** * 创建一个指定长度的数组 */public PriorityQueue(int initialCapacity) &#123; this(initialCapacity, null);&#125;/** * 默认创建一个长度为11的数组，并指定队列比较器 */public PriorityQueue(Comparator&lt;? super E&gt; comparator) &#123; this(DEFAULT_INITIAL_CAPACITY, comparator);&#125;/** * 创建一个指定长度的数组，并指定队列比较器 */public PriorityQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) &#123; // Note: This restriction of at least one is not actually needed, // but continues for 1.5 compatibility if (initialCapacity &lt; 1) throw new IllegalArgumentException(); this.queue = new Object[initialCapacity]; this.comparator = comparator;&#125;/** * 从其他集合中创建一个PriorityQueue */@SuppressWarnings(\"unchecked\")public PriorityQueue(Collection&lt;? extends E&gt; c) &#123; if (c instanceof SortedSet&lt;?&gt;) &#123; SortedSet&lt;? extends E&gt; ss = (SortedSet&lt;? extends E&gt;) c; this.comparator = (Comparator&lt;? super E&gt;) ss.comparator(); initElementsFromCollection(ss); &#125; else if (c instanceof PriorityQueue&lt;?&gt;) &#123; PriorityQueue&lt;? extends E&gt; pq = (PriorityQueue&lt;? extends E&gt;) c; this.comparator = (Comparator&lt;? super E&gt;) pq.comparator(); initFromPriorityQueue(pq); &#125; else &#123; this.comparator = null; initFromCollection(c); &#125;&#125;/** * 从PriorityQueue集合中构造PriorityQueue */@SuppressWarnings(\"unchecked\")public PriorityQueue(PriorityQueue&lt;? extends E&gt; c) &#123; this.comparator = (Comparator&lt;? super E&gt;) c.comparator(); initFromPriorityQueue(c);&#125;/** * 从SortedSet集合中构造PriorityQueue */@SuppressWarnings(\"unchecked\")public PriorityQueue(SortedSet&lt;? extends E&gt; c) &#123; this.comparator = (Comparator&lt;? super E&gt;) c.comparator(); initElementsFromCollection(c);&#125; 主要方法解析 通过上面我们知道PriorityQueue的底层就是个数组，并且核心是可以对元素进行排序，所以我们需要关注的是它的入队及出队方法 添加元素offer(E e) 入队方法 下面可以看到PriorityQueue是不支持存放null值的，如果数组存放的元素大小大于或等于数组大小了，就是调用grow(i + 1)进行扩容，扩容之后就是插入新值了 1234567891011121314151617public boolean offer(E e) &#123; // 不允许添加null值 if (e == null) throw new NullPointerException(); // 记录修改了 modCount++; int i = size; // 扩容 if (i &gt;= queue.length) grow(i + 1); size = i + 1; if (i == 0) // 第一个 queue[0] = e; else // 开始插入并排序了 siftUp(i, e); return true;&#125; grow(i + 1)扩容方法，下面可以看到扩容处理，如果原数组容量小于64，那么就是扩容100%左右，否则就是扩容50% 12345678910111213141516171819202122/** * Increases the capacity of the array. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123; // 原数组容量大小 int oldCapacity = queue.length; // Double size if small; else grow by 50% /** * 如果原数组容量小于64，那么就是扩容`100%`左右，否则就是扩容`50%` * 为什么+2？ */ int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // copy数组 queue = Arrays.copyOf(queue, newCapacity);&#125; siftUp(i, e);开始插入并排序了，这里有两个路线，一个是指定了队列比较器的话就是走比较器的插入排序方法siftUpUsingComparator(k, x);，否则就是走元素自带排序方法的siftUpComparable(k, x) 1234567private void siftUp(int k, E x) &#123; // 指定了比较器 if (comparator != null) siftUpUsingComparator(k, x); else // 没有指定比较器 siftUpComparable(k, x);&#125; siftUp(i, e);方法 siftUpComparable(k, x);没有指定比较器的插入排序方法 可以看到下面排序比较是调用了元素自己的key.compareTo((E) e方法进行大小比较 123456789101112private void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (key.compareTo((E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = key;&#125; 注意这里Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x;这行代码是要求元素是实现了Comparable接口，否则的话就是报java.lang.ClassCastException: XXX cannot be cast to java.lang.Comparable siftUpUsingComparator(k, x); 指定了比较器的插入排序方法 可以看到下面排序比较是调用了comparator的comparator.compare(x, (E) e)方法进行大小比较1234567891011private void siftUpUsingComparator(int k, E x) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (comparator.compare(x, (E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = x;&#125; add(E e) 调用offer(E e)方法 123public boolean add(E e) &#123; return offer(e);&#125; 删除元素poll()出队方法 可以看到出队方法就是和上面的入队方法反着来了 1234567891011121314@SuppressWarnings(\"unchecked\")public E poll() &#123; // 没有元素的话返回null if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0]; E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x); return result;&#125; 删除元素并重新排序 1234567891011121314151617181920212223242526272829303132333435363738394041private void siftDown(int k, E x) &#123; if (comparator != null) siftDownUsingComparator(k, x); else siftDownComparable(k, x);&#125;private void siftDownUsingComparator(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c; k = child; &#125; queue[k] = x;&#125;private void siftDownComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; int half = size &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; // assume left child is least Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) c = queue[child = right]; if (key.compareTo((E) c) &lt;= 0) break; queue[k] = c; k = child; &#125; queue[k] = key;&#125; 总结 通过上面源码可以知道PriorityQueue是一种通过数组实现的并拥有优先级的队列，使用Comparable或者Comparator进行排序 如果在构造PriorityQueue的时候指定了队列比较器Comparator，那么元素排序是按照队列比较器Comparator的排序规则进行排序，否则就是按照元素实现的Comparator接口方法进行排序 注意如果元素是按Comparable接口方法进行排序的话，那么存放元素是必须实现了Comparable接口，否则插入元素的话会报java.lang.ClassCastException: XXX cannot be cast to java.lang.Comparable异常 通过入队出队方法也可看出PriorityQueue并不是线程安全的，并没有对操作进行加锁 此队列是非阻塞队列，关于阻塞队列的介绍将在下面的章节介绍 参考 https://my.oschina.net/90888/blog/1625489 https://www.jianshu.com/p/f1fd9b82cb72","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Queue-介绍","slug":"backend/java/collection/Java集合-Queue-介绍","date":"2018-10-19T16:02:00.000Z","updated":"2019-09-16T13:11:06.508Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Queue-介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Queue-介绍/","excerpt":"","text":"前言 Queue接口与List、Set同一级别，都是继承了Collection接口，Queue的意思是队列的意思，排队打饭就是这种场景，先来先打。Queue 用来存放等待处理元素的集合，这种场景一般用于缓冲、并发访问 由下图可以看到主要Queue接口的实现类 Queue接口方法 代码采用JDK 1.8版本 解析 由上图可以知道Queue分为阻塞队列和非阻塞队列 什么是阻塞队列呢？ 简单来说，就是在在队列为空时从队头取数据将会被阻塞，因为此时还没有数据可取，一旦队列中有数据了，取数据的线程就会释放得到了数据；如果队列有容量限制且满了，那么插入数据的线程将会阻塞，知道队列中有空闲位置可以插入数据了，才会释放。经过上面一段描述，可以发现这不就是一个生产者-消费者模型吗？ 非阻塞队列PriorityQueue PriorityQueue 一个基于优先级的无界优先级队列，优先队列的作用是能保证每次取出的元素都是队列中权值最小的，这里牵涉到了大小关系，元素大小的评判可以按照其自然顺序进行排序，或者根据构造队列时提供的 Comparator 进行排序，具体取决于所使用的构造方法。 ConcurrentLinkedQueue 是基于链接节点的、线程安全的队列。并发访问不需要同步 阻塞队列DelayQueue 一个由数组支持的有界队列。 SynchronousQueue 一个利用 BlockingQueue 接口的简单聚集（rendezvous）机制。 PriorityBlockingQueue 一个由优先级堆支持的无界优先级队列。 LinkedBlockingQueue 一个由链接节点支持的可选有界队列。 ArrayBlockingQueue 一个由数组支持的有界队列。 参考 https://my.oschina.net/90888/blog/1625489 https://www.cnblogs.com/lemon-flm/p/7877898.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-List-Stack源码解析及原理","slug":"backend/java/collection/Java集合-List-Stack源码解析及原理","date":"2018-10-19T16:01:03.000Z","updated":"2019-09-16T13:11:06.492Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-List-Stack源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-List-Stack源码解析及原理/","excerpt":"","text":"前言 Stack类代表最先进先出（LIFO）堆栈的对象，它是在Vector类的基础上添加了入栈出栈的操作 代码采用JDK 1.8版本 解析类继承关系图 类继承关系图 主要方法解析 由下面可以看到Stack继承了Vector类，所以说此类拥有Vector类的所有功能，@since JDK1.0说明年代久远呀 这个类的逻辑很简单，主要有以下方法 push(E item)入栈 pop()出栈 peek()查看此堆栈顶部的对象而不删除它123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120/** * The &lt;code&gt;Stack&lt;/code&gt; class represents a last-in-first-out * (LIFO) stack of objects. It extends class &lt;tt&gt;Vector&lt;/tt&gt; with five * operations that allow a vector to be treated as a stack. The usual * &lt;tt&gt;push&lt;/tt&gt; and &lt;tt&gt;pop&lt;/tt&gt; operations are provided, as well as a * method to &lt;tt&gt;peek&lt;/tt&gt; at the top item on the stack, a method to test * for whether the stack is &lt;tt&gt;empty&lt;/tt&gt;, and a method to &lt;tt&gt;search&lt;/tt&gt; * the stack for an item and discover how far it is from the top. * &lt;p&gt; * When a stack is first created, it contains no items. * * &lt;p&gt;A more complete and consistent set of LIFO stack operations is * provided by the &#123;@link Deque&#125; interface and its implementations, which * should be used in preference to this class. For example: * &lt;pre&gt; &#123;@code * Deque&lt;Integer&gt; stack = new ArrayDeque&lt;Integer&gt;();&#125;&lt;/pre&gt; * * @author Jonathan Payne * @since JDK1.0 */public class Stack&lt;E&gt; extends Vector&lt;E&gt; &#123; /** * Creates an empty Stack. */ public Stack() &#123; &#125; /** * 入栈 * * Pushes an item onto the top of this stack. This has exactly * the same effect as: * &lt;blockquote&gt;&lt;pre&gt; * addElement(item)&lt;/pre&gt;&lt;/blockquote&gt; * * @param item the item to be pushed onto this stack. * @return the &lt;code&gt;item&lt;/code&gt; argument. * @see java.util.Vector#addElement */ public E push(E item) &#123; // 直接在尾部添加元素 addElement(item); return item; &#125; /** * 出栈 * * Removes the object at the top of this stack and returns that * object as the value of this function. * * @return The object at the top of this stack (the last item * of the &lt;tt&gt;Vector&lt;/tt&gt; object). * @throws EmptyStackException if this stack is empty. */ public synchronized E pop() &#123; E obj; int len = size(); // 得到最后一个元素 obj = peek(); // 删除最后一个元素 removeElementAt(len - 1); return obj; &#125; /** * 查看此堆栈顶部的对象而不删除它 * * Looks at the object at the top of this stack without removing it * from the stack. * * @return the object at the top of this stack (the last item * of the &lt;tt&gt;Vector&lt;/tt&gt; object). * @throws EmptyStackException if this stack is empty. */ public synchronized E peek() &#123; int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); &#125; /** * Tests if this stack is empty. * * @return &lt;code&gt;true&lt;/code&gt; if and only if this stack contains * no items; &lt;code&gt;false&lt;/code&gt; otherwise. */ public boolean empty() &#123; return size() == 0; &#125; /** * Returns the 1-based position where an object is on this stack. * If the object &lt;tt&gt;o&lt;/tt&gt; occurs as an item in this stack, this * method returns the distance from the top of the stack of the * occurrence nearest the top of the stack; the topmost item on the * stack is considered to be at distance &lt;tt&gt;1&lt;/tt&gt;. The &lt;tt&gt;equals&lt;/tt&gt; * method is used to compare &lt;tt&gt;o&lt;/tt&gt; to the * items in this stack. * * @param o the desired object. * @return the 1-based position from the top of the stack where * the object is located; the return value &lt;code&gt;-1&lt;/code&gt; * indicates that the object is not on the stack. */ public synchronized int search(Object o) &#123; int i = lastIndexOf(o); if (i &gt;= 0) &#123; return size() - i; &#125; return -1; &#125; /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = 1224463164541339165L;&#125; 总结 这个类和Vector一样是老古董，如果要使用堆栈集合，官方是不建议使用此类，它推荐了Deque接口，这个接口及其实现提供了更完整和一致的LIFO堆栈操作集，这些接口应优先于此类 参考 https://it.baiked.com/jdkapi1.8/java/util/Stack.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-List-Vector源码解析及原理","slug":"backend/java/collection/Java集合-List-Vector源码解析及原理","date":"2018-10-19T16:01:02.000Z","updated":"2019-09-16T13:11:06.495Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-List-Vector源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-List-Vector源码解析及原理/","excerpt":"","text":"前言 Vector作为List的另外一个典型实现类，完全支持List的全部功能，Vector类也封装了一个动态的，允许在分配的Object[]数组，Vector是一个比较古老的集合，JDK1.0就已经存在，建议尽量不要使用这个集合，Vector与ArrayList的主要是区别是，Vector是线程安全的，但是性能比ArrayList要低。 代码采用JDK 1.8版本 解析类继承关系图 类继承关系图 先来看一下Vector的继承关系图，可以看到继承及实现了下面这些类，和ArrayList的继承关系是一样的 AbstractList及List 继承了相关的添加、删除、修改、遍历等方法。 RandomAccess 这个接口只是个标志接口，没有提供方法定义，用于标明实现该接口的List支持快速随机访问，主要目的是使算法能够在随机和顺序访问的list中表现的更加高效。 Cloneable 覆盖了函数clone()，能被克隆。 Serializable 这意味着ArrayList支持序列化，能通过序列化去传输。 成员变量 由下面可以看到Vector也是使用了数组Object[] elementData来存放对象，elementCount属性来存放元素个数，和ArrayList有点区别的是这里多个一个capacityIncrement参数，这个是来控制数组扩增用的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; /** * 存放List元素的数组 * * The array buffer into which the components of the vector are * stored. The capacity of the vector is the length of this array buffer, * and is at least large enough to contain all the vector's elements. * * &lt;p&gt;Any array elements following the last element in the Vector are null. * * @serial */ protected Object[] elementData; /** * 该 Vector对象中有效组件的数量 * * The number of valid components in this &#123;@code Vector&#125; object. * Components &#123;@code elementData[0]&#125; through * &#123;@code elementData[elementCount-1]&#125; are the actual items. * * @serial */ protected int elementCount; /** * 当数组的大小大于其容量时，数组的容量自动增加的量。 * * The amount by which the capacity of the vector is automatically * incremented when its size becomes greater than its capacity. If * the capacity increment is less than or equal to zero, the capacity * of the vector is doubled each time it needs to grow. * * @serial */ protected int capacityIncrement; /** * 可序列化版本号 * * use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = -2767605614048989439L; /** * 最大容量 * * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; ... &#125; 构造函数 下面构造函数是可以指定数组的初始大小及数组大小增长系数， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 构造方法，提供初始大小，和增长系数 * * Constructs an empty vector with the specified initial capacity and * capacity increment. * * @param initialCapacity the initial capacity of the vector * @param capacityIncrement the amount by which the capacity is * increased when the vector overflows * @throws IllegalArgumentException if the specified initial capacity * is negative */public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125;/** * 构造方法，提供初始大小，增长系数为零 * * Constructs an empty vector with the specified initial capacity and * with its capacity increment equal to zero. * * @param initialCapacity the initial capacity of the vector * @throws IllegalArgumentException if the specified initial capacity * is negative */public Vector(int initialCapacity) &#123; this(initialCapacity, 0);&#125;/** * 无参构造方法 * * Constructs an empty vector so that its internal data array * has size &#123;@code 10&#125; and its standard capacity increment is * zero. */public Vector() &#123; this(10);&#125;/** * 构造方法，将指定的集合元素转化为Vector * * Constructs a vector containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this * vector * @throws NullPointerException if the specified collection is null * @since 1.2 */public Vector(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, elementCount, Object[].class);&#125; 主要方法解析1、新增元素 下面逻辑可以看到插入新元素首先也是先检查数组容量大小会不会溢出，然后在元素最后面添加新值 1234567891011121314151617181920212223/** * Appends the specified element to the end of this Vector. * * @param e element to be appended to this Vector * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) * @since 1.2 */public synchronized boolean add(E e) &#123; /** * @see AbstractList#modCount * 用于记录对象的修改次数，比如增、删、改，有一点版本控制的意思，可以理解成version，在特定的操作下需要对version进行检查 * 也基本存在于非线程安全的集合类中，这是一种Fail-Fast机制： * 1、当多个线程对同一集合的内容进行操作时，可能就会产生此类异常。 * 2、比如当A通过iterator去遍历某集合的过程中，其他线程修改了此集合，此时会抛出ConcurrentModificationException异常。 * 3、此类机制就是通过modCount实现的，在迭代器初始化时，会赋值expectedModCount，在迭代过程中判断modCount和expectedModCount是否一致。 */ modCount++; // 扩充容量帮助函数 ensureCapacityHelper(elementCount + 1); // 在元素最后面添加新值 elementData[elementCount++] = e; return true;&#125; 进入ensureCapacityHelper(int minCapacity)方法，这个方法是检查是否需要扩容，如果需要的话就是生成一个新的数组，那么这个新数组大小是怎么定义的呢，可以看到有下面这几种情况 如果指定了capacityIncrement，新数组大小 = 老数组大小 + capacityIncrement 没有指定了capacityIncrement，新数组大小 = 老数组大小 + 老数组大小 如果超出了数组能容纳的最大元素个数，数组大小则取Integer最大值，否则去数组规定的最大值 1234567891011121314151617181920212223242526272829303132333435363738/** * 扩充容量帮助函数 * * This implements the unsynchronized semantics of ensureCapacity. * Synchronized methods in this class can internally call this * method for ensuring capacity without incurring the cost of an * extra synchronization. * * @see #ensureCapacity(int) */private void ensureCapacityHelper(int minCapacity) &#123; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * 扩充容量函数 * @param minCapacity */private void grow(int minCapacity) &#123; // overflow-conscious code // 老数组大小 int oldCapacity = elementData.length; /** * 1、指定capacityIncrement了就是 老数组大小 + capacityIncrement * 2、不指定capacityIncrement，每次扩展为原来的2倍 */ int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); // 如果newCapacity小于指定的minCapacity，newCapacity取minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果超出了数组能容纳的最大元素个数，数组大小则取`Integer`最大值，否则去数组规定的最大值 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 生成一个长度为newCapacity数组，并将elementData数组中元素拷贝到新数组中，并将新数组的引用赋值给elementData elementData = Arrays.copyOf(elementData, newCapacity);&#125; 2、获取元素get(int index)123456789101112131415161718/** * Returns the element at the specified position in this Vector. * * @param index index of the element to return * @return object at the specified index * @throws ArrayIndexOutOfBoundsException if the index is out of range * (&#123;@code index &lt; 0 || index &gt;= size()&#125;) * @since 1.2 */public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; 3、修改元素set(int index, E element) 可以看到修改元素的逻辑很简单，就是直接赋值 12345678910111213141516171819/** * Replaces the element at the specified position in this Vector with the * specified element. * * @param index index of the element to replace * @param element element to be stored at the specified position * @return the element previously at the specified position * @throws ArrayIndexOutOfBoundsException if the index is out of range * (&#123;@code index &lt; 0 || index &gt;= size()&#125;) * @since 1.2 */public synchronized E set(int index, E element) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 4、删除元素remove(Object o) 由下面代码可以看到主要逻辑是indexOf(obj)函数来找到元素的位置，之后就是将删除点之后的元素向前移动一个位置，最后将空出来的位置赋值为null，让GC回收 1234567891011121314151617181920212223242526272829303132public boolean remove(Object o) &#123; return removeElement(o);&#125;public synchronized boolean removeElement(Object obj) &#123; modCount++; int i = indexOf(obj); if (i &gt;= 0) &#123; removeElementAt(i); return true; &#125; return false;&#125;public synchronized void removeElementAt(int index) &#123; modCount++; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + \" &gt;= \" + elementCount); &#125; else if (index &lt; 0) &#123; throw new ArrayIndexOutOfBoundsException(index); &#125; int j = elementCount - index - 1; // 移位 if (j &gt; 0) &#123; System.arraycopy(elementData, index + 1, elementData, index, j); &#125; elementCount--; elementData[elementCount] = null; /* to let gc do its work */&#125; 总结 从上面可以发现Vector和ArrayList的实现方式可以看出非常的类似，由源码可以看到每个方法中都添加了synchronized的关键字来保证同步，所以它是线程安全的，但正是这些方法的同步，让它的效率大大的降低了，比ArrayList的效率要慢。 If a thread-safe implementation is not needed, it is recommended to use {@link ArrayList} in place of {@code Vector}，既然Vector类建议尽量少的使用，还是最好不要用了 参考 https://it.baiked.com/jdkapi1.8/java/util/Collection.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-List-LinkedList源码解析及原理","slug":"backend/java/collection/Java集合-List-LinkedList源码解析及原理","date":"2018-10-19T16:01:01.000Z","updated":"2019-09-16T13:11:06.482Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-List-LinkedList源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-List-LinkedList源码解析及原理/","excerpt":"","text":"前言 LinkedList也是List接口的实现类，与ArrayList不同之处是采用的存储结构不同，ArrayList的数据结构为线性表，而LinkedList数据结构是链表。链表数据结构的特点是每个元素分配的空间不必连续、插入和删除元素时速度非常快、但访问元素的速度较慢。 什么是链表 链表是由一系列非连续的节点组成的存储结构，简单分下类的话，链表又分为单向链表和双向链表，而单向/双向链表又可以分为循环链表和非循环链表，下面简单就这四种链表进行图解说明。 1.单向链表 单向链表就是通过每个结点的指针指向下一个结点从而链接起来的结构，最后一个节点的next指向null。 2.单向循环链表 单向循环链表和单向列表的不同是，最后一个节点的next不是指向null，而是指向head节点，形成一个“环”。 3.双向链表 从名字就可以看出，双向链表是包含两个指针的，pre指向前一个节点，next指向后一个节点，但是第一个节点head的pre指向null，最后一个节点的tail指向null。 4.双向循环链表 双向循环链表和双向链表的不同在于，第一个节点的pre指向最后一个节点，最后一个节点的next指向第一个节点，也形成一个“环” 代码采用JDK 1.8版本 解析类继承关系图 类继承关系图 先来看一下LinkedList的继承关系图，可以看到继承及实现了下面这些类 AbstractSequentialList、AbstractList、List Sequential 是序列的意思，对于支持随机访问数据的List比如数组，应该优先使用AbstractList，AbstractSequentialList 只支持按次序访问，而不像 AbstractList 那样支持随机访问。 Deque 添加了队列的操作 Cloneable 覆盖了函数clone()，能被克隆。 Serializable 这意味着ArrayList支持序列化，能通过序列化去传输。 类成员变量 下面可以看到LinkedList是用Node类来存放元素节点，Node&lt;E&gt; first存放第一个节点，Node&lt;E&gt; last存放最后一个节点，size用于记录元素个数 Node&lt;E&gt;节点一共有三个属性 E item; 代表节点元素值 Node&lt;E&gt; next; 存放本节点的上一个节点 Node&lt;E&gt; prev; 存放本节点的下一个节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable &#123; /** * LinkedList中存放的元素个数 */ transient int size = 0; /** * 头节点 * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * 尾节点 * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; /** * 静态内部类，创建节点 * * @param &lt;E&gt; */ private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; private static final long serialVersionUID = 876323262645176354L; ...&#125; 构造函数 LinkedList没有长度的概念，不像ArrayList那样是用数组来存放数据，所以不存在容量不足的问题，因此不需要提供初始化大小的构造方法，因此值提供了两个方法 一个是无参构造方法，初始一个LinkedList对象， 第二个是将指定的集合元素转化为LinkedList构造方法。 12345678910111213141516171819202122/** * 构造一个空列表。 * * Constructs an empty list. */public LinkedList() &#123;&#125;/** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 * * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 主要方法解析添加元素 LinkedList提供了多个添加元素的方法： add(E e) 此方法在链表尾部添加一个元素，如果成功，返回true ，下面可以看到就是将新元素构造为Node&lt;E&gt; newNode并设置到最后一个节点，然后设置各自的前后驱节点 123456789101112131415161718192021222324252627282930313233/** * 在LinkedList的尾部添加元素 * Appends the specified element to the end of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addLast&#125;. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * 插入新元素到尾节点 * Links e as last element. */void linkLast(E e) &#123; // 首先将当前最后的节点赋值给l节点 final Node&lt;E&gt; l = last; // 新建节点newNode，节点数据为e，节点前驱节点为l，节点后驱节点为null final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 新节点newNode赋值为最后的节点 last = newNode; if (l == null) // 此情况为第一次add first = newNode; else // 之前的最后节点的后驱节点设置为新节点newNode l.next = newNode; // 节点数量加一 size++; // iterator 并发控制变量 modCount++;&#125; void addFirst(E e) 在链表头部插入一个元素。 addLast(E e) 在链表尾部添加一个元素。 void add(int index, E element) 在指定位置插入一个元素。 删除元素 LinkedList提供了多个删除元素的方法： remove(Object o) 从当前链表中移除指定的元素，删除元素的逻辑先是找到这个元素所属的节点，然后调用unlink(Node&lt;E&gt; x)方法来将其节点在链表里剔除 123456789101112131415161718192021public boolean remove(Object o) &#123; // 如果参数给定的对象为null，则从前向后遍历链表，当查找到某个node的item为null时将该node从链表中移除，并返回true if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; // 如果参数给定的对象不为null，则从前向后表里链表，当查找到某个node的item equals给定对象的值，则将该node从链表中移除，并返回true &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; // 没有找到指定对象，返回false return false;&#125; unlink(Node&lt;E&gt; x)方法 12345678910111213141516171819202122232425262728293031/** * Unlinks non-null node x. * 将指定node从list的“锁链”中解除 */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; // 获取指定节点的前驱 final Node&lt;E&gt; next = x.next; // 获取指定节点的后继 final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; // 指定node的前一个node为null，说明该node为第一个node，将first指向node的next &#125; else &#123; prev.next = next; // 否则指定node的前一个node的next指针指向指定node的next node x.prev = null; // 指定node的prev指针至空 &#125; if (next == null) &#123; last = prev; // 指定node的后一个node为null，说明该node为最后一个node，将last指向node的prev &#125; else &#123; next.prev = prev; // 否则指定node的后一个node的prev指针指向node的prev node x.next = null; // 指定node的next指针至空 &#125; x.item = null; // 指定node的item值至空 size--; modCount++; return element;&#125; E remove(int index)) 从当前链表中移除指定位置的元素。 E remove(int index) 从当前链表中移除指定位置的元素。 E removeFirst() 从当前链表中移除第一个元素。 E removeLast() 从当前链表中移除最后一个元素。 E remove()从当前链表中移除第一个元素，同removeLast()相同。 获取元素 LinkedList提供了多个获取元素的方法： E get(int index) 从当前链表中获取指定位置的元素。 E getFirst() 从当前链表中获取第一个元素。 E getLast() 从当前链表中获取最后一个元素。 遍历元素 同前面介绍的集合类遍历方式一样，LinkedList可以通过迭代器、foreach语句、for循环语句等方法遍历集合的所有元素。 队列操作E pop() 入队列函数，可以看到就是逻辑就是将添加的元素设置为LinkedList的头节点 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 如队列，添加到头部 * * Pushes an element onto the stack represented by this list. In other * words, inserts the element at the front of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addFirst&#125;. * * @param e the element to push * @since 1.6 */public void push(E e) &#123; addFirst(e);&#125;/** * 将添加的元素设置为LinkedList的头节点 * * Inserts the specified element at the beginning of this list. * * @param e the element to add */public void addFirst(E e) &#123; linkFirst(e);&#125;/** * 插入头节点 * Links e as first element. */private void linkFirst(E e) &#123; // 记录第一个node final Node&lt;E&gt; f = first; // 新建node，prev为null，next为之前记录的第一个node，item为传入的参数e final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); // 第一个node指向新建的node：newNode first = newNode; // 如果记录的第一个node为null，说明原来的list为空list，将last也执行新建的node if (f == null) last = newNode; else// 否则原来的first node的prev指向新建node f.prev = newNode; size++; // list的size+1 modCount++; // 结构修改记录数+1&#125; E pop() 出队列会删除节点 12345678910111213141516/** * 出队列删除第一个节点 * * Pops an element from the stack represented by this list. In other * words, removes and returns the first element of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #removeFirst()&#125;. * * @return the element at the front of this list (which is the top * of the stack represented by this list) * @throws NoSuchElementException if this list is empty * @since 1.6 */public E pop() &#123; return removeFirst();&#125; E peek() 出队列不会删除节点 123456789101112/** * 弹出第一个元素的值 不会删除元素 * * Retrieves, but does not remove, the head (first element) of this list. * * @return the head of this list, or &#123;@code null&#125; if this list is empty * @since 1.5 */public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125; 总结 由LinkedList的继承关系图可以看到它既实现了List接口又实现了Deque接口，所以它是一个功能很强大的类，可以被当作List集合，双端队列和栈来使用。 由上面LinkedList的添加元素及删除元素方法可以知道它是一个双向链表，由存储元素的结点连接而成，每一个节点都包含前一个节点的引用，后一个节点的引用和节点存储的值，当一个新节点插入时，只需要修改其中保持先后关系的节点的引用即可，所以LinkedList的工作重心就是维护节点先后引用关系 因为LinkedList使用双向链表来存放数据，因此随机访问的性能较差， 当数据量很大或者操作很频繁的情况下，添加和删除元素时具有比ArrayList更好的性能 LinkedList是基于链表实现的，因此不存在容量不足的问题，所以这里没有扩容的方法 LinkedList并不是线程安全的类，如果有多个线程需要同时访问List集合中的元素，开发者可以考虑使用Collections将集合包装成线程安全的集合。 最后我们总结一下，List 集合最为关键的几个实现类是： ArrayList：列表集合经典实现。 Vector：列表集合经典实现，线程安全，与 ArrayList 对应。 Stack：栈结构的经典实现，先进后出的数据结构。继承了 Vector，线程安全。 LinkedList：链表结构的经典实现。 参考 https://my.oschina.net/90888/blog/1625489","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-List-Arrays","slug":"backend/java/collection/Java集合-List-Arrays","date":"2018-10-19T16:01:00.000Z","updated":"2020-03-16T11:43:55.425Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-List-Arrays/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-List-Arrays/","excerpt":"","text":"前言Arrays.asList() Arrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。 下图是java.util.Arrays$ArrayList的简易源码，我们可以看到这个类重写的方法有哪些。 123456789101112131415161718192021222324252627282930313233343536373839private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable &#123; ... @Override public E get(int index) &#123; ... &#125; @Override public E set(int index, E element) &#123; ... &#125; @Override public int indexOf(Object o) &#123; ... &#125; @Override public boolean contains(Object o) &#123; ... &#125; @Override public void forEach(Consumer&lt;? super E&gt; action) &#123; ... &#125; @Override public void replaceAll(UnaryOperator&lt;E&gt; operator) &#123; ... &#125; @Override public void sort(Comparator&lt;? super E&gt; c) &#123; ... &#125;&#125; 集合转数组的方法 【强制】使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一样的数组，大小就是 list.size()。 说明：使用 toArray 带参方法，入参分配的数组空间不够大时，toArray 方法内部将重新分配内存空间，并返回新数组地址；如果数组元素个数大于实际所需，下标为[ list.size() ]的数组元素将被置为 null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素个数一致。 正例： 12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(2); list.add(\"guan\"); list.add(\"bao\"); String[] array = new String[list.size()]; array = list.toArray(array); 反例：直接使用 toArray 无参方法存在问题，此方法返回值只能是 Object[]类，若强转其它类型数组将出现 ClassCastException 错误。 数组转换成集合 【强制】使用工具类 Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。 说明：asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。 12String[] str = new String[] &#123; \"you\", \"wu\" &#125;;List list = Arrays.asList(str); 第一种情况：list.add(“yangguanbao”); 运行时异常。 第二种情况：str[0] = “gujin”; 那么 list.get(0)也会随之修改。 最简便的方法(推荐)1List list = new ArrayList&lt;&gt;(Arrays.asList(\"a\", \"b\", \"c\")) 总结参考 《阿里巴巴Java 开发手册》 https://snailclimb.gitee.io/javaguide/#/docs/java/Java疑难点?id=_212-《阿里巴巴java-开发手册》对其的描述","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-List-ArrayList源码解析及原理","slug":"backend/java/collection/Java集合-List-ArrayList源码解析及原理","date":"2018-10-19T16:01:00.000Z","updated":"2019-11-27T15:11:32.582Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-List-ArrayList源码解析及原理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-List-ArrayList源码解析及原理/","excerpt":"","text":"前言 上一章节介绍了Collection及Map的抽象实现类，这些类是不能创建实例的，它们只是抽象了一些功能方法，那么具体实现是通过子类来实现的，这一章节我们来学习Collection的一个具体实现子类ArrayList ArrayList是一个数组集合，相当于动态数组，与Java中的数组相比，它的容量能动态增长 代码采用JDK 1.8版本 解析类继承关系图 类继承关系图 先来看一下ArrayList的继承关系图，可以看到继承及实现了下面这些类 AbstractList及List 继承了相关的添加、删除、修改、遍历等方法。 RandomAccess 这个接口只是个标志接口，没有提供方法定义，用于标明实现该接口的List支持快速随机访问，主要目的是使算法能够在随机和顺序访问的list中表现的更加高效。 12public interface RandomAccess &#123;&#125; 查看java.util.Collections#binarySearch(java.util.List&lt;? extends java.lang.Comparable&lt;? super T&gt;&gt;, T)这里二分查找方法发现这里有使用，具体逻辑是判断该类有没有实现RandomAccess接口 如果有的话是走indexedBinarySearch()方法通过数组索引的方式来查询 如果没有的话是走iteratorBinarySearch()方法通过迭代器的方式来查询123456public static &lt;T&gt; int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key) &#123; if (list instanceof RandomAccess || list.size()&lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key);&#125; 为什么要这么区分呢，下面来看下面这个例子 1234567891011121314151617181920212223242526272829303132private List&lt;Integer&gt; getData () &#123; List&lt;Integer&gt; objects = new ArrayList&lt;&gt;(); for (int i = 0 ; i &lt; 1000000 ; i++) &#123; objects.add(i); &#125; return objects;&#125;/** * 测试for循环及迭代器循环性能 */@Testpublic void test2() &#123; long startTimeIndexed = System.currentTimeMillis(); List&lt;Integer&gt; forIntegerList = getData(); for (int i = 0; i &lt; forIntegerList.size(); i++) &#123; forIntegerList.get(i); &#125; long endTimeIndexed = System.currentTimeMillis(); System.out.println(\"for循环耗时:\" + (endTimeIndexed - startTimeIndexed)); long startTimeIterator = System.currentTimeMillis(); List&lt;Integer&gt; iteratorIntegerList = getData(); Iterator iterator = iteratorIntegerList.iterator(); while (iterator.hasNext()) &#123; iterator.next(); &#125; long endTimeIterator = System.currentTimeMillis(); System.out.println(\"iterator循环耗时:\" + (endTimeIterator - startTimeIterator));&#125; // 结果for循环耗时:35iterator循环耗时:82 由上面可以得到ArrayList用for循环遍历比iterator迭代器遍历快，经其他测试LinkedList用iterator迭代器遍历比for循环遍历快，所以当我们在做项目时，应该考虑到List集合的不同子类采用不同的遍历方式，能够提高性能 Cloneable 覆盖了函数clone()，能被克隆。 注意这里是浅拷贝，示例代码123456789101112131415public static void main(String[] args) &#123; ArrayList &lt;UserDO&gt; userDOS1 = new ArrayList&lt;&gt;(); UserDO queryDO1 = new UserDO(); UserDO queryDO2 = new UserDO(); queryDO1.setName(\"001\"); queryDO2.setName(\"002\"); userDOS1.add(queryDO1); userDOS1.add(queryDO2); ArrayList &lt;UserDO&gt; userDOS2 = (ArrayList &lt;UserDO&gt;)userDOS1.clone(); System.out.println(userDOS1); System.out.println(userDOS2); userDOS1.get(0).setName(\"0001\"); System.out.println(userDOS1); System.out.println(userDOS2);&#125; Serializable 这意味着ArrayList支持序列化，能通过序列化去传输。 成员变量 下面是ArrayList的成员变量，可以看到主要成员是 Object[] elementData来存放我们的数据 size变量来存放数据元素的数量，需要注意的是它必定小于等于数组对象 elementData 的长度。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; /** * 可序列化版本号 */ private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始化数组大小 为10 注意调用add()方法时会触发使用，并不是new ArrayList&lt;&gt;(); * Default initial capacity. */ private static final int DEFAULT_CAPACITY = 10; /** * 实例化一个空数组 * Shared empty array instance used for empty instances. */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * 默认实例化的一个空数组 比如 new ArrayList&lt;&gt;(); * Shared empty array instance used for default sized empty instances. We * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when * first element is added. */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 存放List元素的数组 * * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */ transient Object[] elementData; // non-private to simplify nested class access /** * size 字段表示着当前添加到 ArrayList 的元素个数，需要注意的是它必定小于等于数组对象 elementData 的长度。 * 一旦当 size 与 elementData 长度相同，并且还在往列表里添加元素时，ArrayList 就会执行扩容操作， * 用一个更长的数组对象存储先前的元素。 * * The size of the ArrayList (the number of elements it contains). * * @serial */ private int size; /** * 数组的最大容量 * 为什么是Integer.MAX_VALUE - 8 ，因为有些VM虚拟机会在一个数组中存储一些头部信息，所以采用这个值 * * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 构造函数 默认构造函数，可以看到只是赋值了一个空数据{}，这种方式是我们最常使用的，注意这里还是空数组，只有add()数据的时候才会构建大小为10数组 123456/** * Constructs an empty list with an initial capacity of ten. */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 构造具有指定初始容量的集合，可以看到逻辑很简单就是构造一个容量为initialCapacity的数组 1234567891011121314151617181920/** * Constructs an empty list with the specified initial capacity. * * @param initialCapacity the initial capacity of the list * @throws IllegalArgumentException if the specified initial capacity * is negative */public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; // 创建指定大小的ArrayList this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 为0的话还是空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; // 参数异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125;&#125; 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 12345678910111213141516171819/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 主要方法解析 上面我们可以知道ArrayList是基于数组实现的，那么ArrayList是怎样处理这个数组的呢，下面我们将通过它的一些方法来跟进 1、新增元素add()不指定位置添加元素 由ArrayList的构造函数我们知道List&lt;Integer&gt; objects = new ArrayList&lt;&gt;();，这行语句会构造一个空数组，那我们添加往里面添加元素会怎么样呢？ 由下面可以看到是先检查数组容量是否足够，然后第二行代码就是在数组最后添加元素了（注意这里是size，不是elementData.length） 1234567public boolean add(E e) &#123; // 是否扩容检查 ensureCapacityInternal(size + 1); // Increments modCount!! // 直接赋值 elementData[size++] = e; return true;&#125; 我们进入ensureCapacityInternal(size + 1)方法 可以看到这里判断elementData是否是空数组，如果是的话minCapacity就是取最小的数组大小为10 modCount++变量用于迭代器并发安全控制1234567891011121314151617181920212223private void ensureCapacityInternal(int minCapacity) &#123; // 当前位置和默认大小之间取最大值，也就是说数组最小也是10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; /** * @see AbstractList#modCount * 用于记录对象的修改次数，比如增、删、改，有一点版本控制的意思，可以理解成version，在特定的操作下需要对version进行检查 * 也基本存在于非线程安全的集合类中，这是一种Fail-Fast机制： * 1、当多个线程对同一集合的内容进行操作时，可能就会产生此类异常。 * 2、比如当A通过iterator去遍历某集合的过程中，其他线程修改了此集合，此时会抛出ConcurrentModificationException异常。 * 3、此类机制就是通过modCount实现的，在迭代器初始化时，会赋值expectedModCount，在迭代过程中判断modCount和expectedModCount是否一致。 */ modCount++; // overflow-conscious code // 检查是否需要扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; 关注grow(minCapacity);方法，可以看到主要逻辑就是构造一个新的数组，并将elementData数组中元素拷贝到新数组中 1、先要确定新数组大小 这里新数组容量 = 老数组长度的1.5倍（oldCapacity &gt;&gt; 1 相当于除以2），这个是自动扩展数组大小的算法 如果新数组容量小于要存放的数组大小，则最更大的 如果超出了数组能容纳的最大元素个数，数组大小则取Integer最大值，否则取数组规定的最大值 2、将elementData数组中元素拷贝到新数组中12345678910111213141516171819202122232425/** * 扩容操作 * * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123; // overflow-conscious code // 目前数组大小 int oldCapacity = elementData.length; // 新的数组容量 = 老的数组长度的1.5倍。oldCapacity &gt;&gt; 1 相当于除以2，这个是自动扩展数组大小的算法 // 当newCapacity大于minCapacity时并且没有到达数组最大值，都会将数组扩展为newCapacity大小 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果newCapacity小于指定的minCapacity，newCapacity取minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新的数组容量newCapacity大于数组能容纳的最大元素个数 MAX_ARRAY_SIZE 2^&#123;31&#125;-1-8 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 生成一个长度为newCapacity数组，并将elementData数组中元素拷贝到新数组中，并将新数组的引用赋值给elementData elementData = Arrays.copyOf(elementData, newCapacity);&#125; 由下图可以看到当添加第11个元素之后就会构造一个大小为15的新数组 add(int index, E element)指定位置时添加元素 指定位置时，就是将新元素存在到数组的指定位置。若该位置不是数组末尾（即该位置后面还存有元素），则需要将该位置及之后的元素后移一位，以腾出空间来存放新元素。 123456789101112public void add(int index, E element) &#123; // 检查索引 rangeCheckForAdd(index); // 是否扩容检查 ensureCapacityInternal(size + 1); // Increments modCount!! // 将elementData中从index开始的元素向后移动一个位置 System.arraycopy(elementData, index, elementData, index + 1, size - index); // index位置的元素赋值为指定element elementData[index] = element; size++;&#125; 2、获取元素get(int index) 由下面代码可以看到逻辑也是十分简单，先是检查索引十分越界，然后就是按照数组索引位置直接取值 1234567891011121314public E get(int index) &#123; // 越界检查 rangeCheck(index); return elementData(index);&#125;private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; 3、修改元素set(int index, E element) 可以看到修改元素的逻辑很简单，就是直接赋值 12345678public E set(int index, E element) &#123; // 越界检查 rangeCheck(index); E oldValue = elementData(index); // 直接赋值 elementData[index] = element; return oldValue;&#125; 4、删除元素remove(Object o) 由下面代码可以看到主要逻辑是for循环数组找到元素的位置，之后就是将删除点之后的元素向前移动一个位置，最后将空出来的位置赋值为null，让GC回收 12345678910111213141516171819202122232425262728293031public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;/* * Private remove method that skips bounds checking and does not * return the value removed. */private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; // 这里只是移动位置，将删除点之后的元素向前移动一个位置 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); // 然后将空出来的位置赋值为null，让GC回收 elementData[--size] = null; // clear to let GC do its work&#125; 5、遍历元素1234567891011121314151617181920List&lt;String&gt; list = new ArrayList&lt;&gt;() ;//第一种for (int i = 0; i &lt; list.size(); i++) &#123; list.get(i);&#125;//第二种for (Iterator iter = list.iterator(); iter.hasNext(); ) &#123; iter.next();&#125;//第三种for (Object obj : list) ;//第四种 ， 只支持JDK1.8+list.forEach( e-&gt;&#123; ; &#125;); 在集合的数量非常小的情况的，第一二三种的遍历速度没有显著的差别，但是随之数量的增加，第一种方式最快，第三种方法第二，第二种第三，第四种最慢。 其他subList(int fromIndex, int toIndex) 方法 此方法是返回此列表中指定的 fromIndex （包括）和 toIndex之间的视图数据，但subList方法虽然返回的是list的子列表，但其实是对list中一部分元素的操作，当向subList中插入或删除元素，list也会相应改变 123456789/** * 返回指定的fromIndex （含）和toIndex之间的列表部分的视图 * subList方法虽然返回的是list的子列表，但其实是对list中一部分元素的操作，当向subList中插入或删除元素，list也会相应改变 */ public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; // 验证参数范围 subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); &#125; 补充Array 和 ArrayList 有何区别？什么时候更适合用 Array？ Array 可以容纳基本类型和对象，而 ArrayList 只能容纳对象。 Array 是指定大小的，而 ArrayList 大小是固定的，可自动扩容。 Array 没有提供 ArrayList 那么多功能，比如 addAll、removeAll 和 iterator 等。 尽管 ArrayList 明显是更好的选择，但也有些时候 Array 比较好用，比如下面的三种情况。 1、如果列表的大小已经指定，大部分情况下是存储和遍历它们 2、对于遍历基本数据类型，尽管 Collections 使用自动装箱来减轻编码任务，在指定大小的基本类型的列表上工作也会变得很慢。 3、如果你要使用多维数组，使用 [][] 比 List 会方便。 总结 通过上面的分析，可以了解到针对 ArrayList 增加改查其实本质就是操作数组，ArrayList 的添加操作，也就是往其内部数组添加元素的过程。首先要确保就是数组有足够的空间来存放元素，因此也就有了扩容检测这一步骤。 为了追求效率，ArrayList没有实现同步（synchronized），如果需要多个线程并发访问，用户可以手动同步，也可使用其他线程安全的集合类 总结下ArrayList特点 如果一开始就知道集合元素的具体数量，可以在构造函数ArrayList(int initialCapacity)指定数组大小，这样可以减少扩容带来的性能消耗 因为底层使用了数组来存放数据，数组是一块连续内存区来保存所有的数组元素，所以数组在随机访问时性能最好，这种存储方式的优点是查询的时间复杂度为O(1)，通过首地址和偏移量就可以直接访问到某元素。 因为数组大小固定的，所以在插入及删除数据的时候需要调整数组大小，插入和删除的时间复杂度最坏能达到O(n)，如果涉及到大量更新操作的最好不要使用此类，可以使用LinkedList 参考 https://it.baiked.com/jdkapi1.8/java/util/Collection.html https://blog.csdn.net/weixin_39148512/article/details/79234817 https://www.jianshu.com/p/4a403049a4a2","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-Collection及Map抽象实现类","slug":"backend/java/collection/Java集合-Collection及Map抽象实现类","date":"2018-10-19T16:00:01.000Z","updated":"2019-09-19T12:47:40.504Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-Collection及Map抽象实现类/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-Collection及Map抽象实现类/","excerpt":"","text":"前言 从下面集合框架图可以看到Collection的抽象实现类有AbstractCollection、AbstractList、AbstractSet等、，Map接口的抽象实现类有AbstractMap，这些类提供了Collection接口的抽象实现，抽取出了一些公共方法，下面将学习这些抽象实现类 代码采用JDK 1.8版本 解析AbstractCollection 类继承结构图 AbstractCollection 是 Java 集合框架中 Collection 接口 的一个直接实现类， Collection 下的大多数子类都继承 AbstractCollection ，比如 List 的实现类, Set的实现类。 此类提供 Collection 接口的基础实现，以最大限度地减少了实现此接口所需的工作。 要实现一个不可修改的 collection，开发人员只需扩展此类，并提供 iterator() 和 size() 方法的实现。（iterator 方法返回的迭代器必须实现 hasNext 和 next。） 要实现可修改的 collection，编程人员必须另外重写此类的 add 方法（否则，会抛出 UnsupportedOperationException），iterator 方法返回的迭代器还必须另外实现其 remove 方法。 AbstractCollection 类解析 可以看到这个类定义了两个抽象方法iterator()，size()，其他方法的实现逻辑需要依赖这两个方法 这里就是发挥了抽象方法的作用了，抽象类可以定义大体框架方法，提供具体数据的方法由子类来实现 比如下面的contains(Object o)方法就是先调用抽象方法iterator()来获取迭代数据，然后就是it.next()进行遍历1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public abstract class AbstractCollection&lt;E&gt; implements Collection&lt;E&gt; &#123; /** * Sole constructor. (For invocation by subclass constructors, typically * implicit.) */ protected AbstractCollection() &#123; &#125; // Query Operations /** * Returns an iterator over the elements contained in this collection. * * @return an iterator over the elements contained in this collection */ public abstract Iterator&lt;E&gt; iterator(); public abstract int size(); /** * &#123;@inheritDoc&#125; * * &lt;p&gt;This implementation returns &lt;tt&gt;size() == 0&lt;/tt&gt;. */ public boolean isEmpty() &#123; return size() == 0; &#125; /** * &#123;@inheritDoc&#125; * * &lt;p&gt;This implementation iterates over the elements in the collection, * checking each element in turn for equality with the specified element. * * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */ public boolean contains(Object o) &#123; Iterator&lt;E&gt; it = iterator(); if (o==null) &#123; while (it.hasNext()) if (it.next()==null) return true; &#125; else &#123; while (it.hasNext()) if (o.equals(it.next())) return true; &#125; return false; &#125; ...&#125; AbstractList 类继承结构图 从上图可以看到 AbstractList继承了AbstractCollection抽象类及实现了List接口，也就是说拥有AbstractCollection抽象类的功能，并针对List接口给出了一些默认的实现。而且它是针对随机访问储存数据的方式的，如果需要使用顺序访问储存数据方式，还有一个AbstractSequentialList是AbstractList的子类，顺序访问时应该优先使用它。 要实现一个不可修改的集合，开发人员只需要扩展这个类并提供get(int)和size()方法的实现。 要实现可修改的集合，程序员必须另外覆盖set(int, E)方法（否则会抛出一个UnsupportedOperationException）。 如果集合是可变大小，则程序员必须另外覆盖add(int, E)和remove(int)方法。 不像其他的抽象集合实现，程序员不必提供迭代器实现; 迭代器和集合迭代器由此类实现的 AbstractList 类解析 只提供了一个protected修饰的无参构造器，供子类使用。 可以看到这个类只定义了一个抽象方法get()，需要子类去实现，根据索引值获取集合中的某个元素(随机访问) 由于该集合是不可变的，所以一切可能会改变集合元素的操作set()、add()、remove()都会抛出一个UnsupportedOperationException()，如果要实现一个可修改的集合可以重写此方法，可以学习一下这种设计思路 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; &#123; protected AbstractList() &#123; &#125; public boolean add(E e) &#123; add(size(), e); return true; &#125; abstract public E get(int index); public E set(int index, E element) &#123; throw new UnsupportedOperationException(); &#125; public void add(int index, E element) &#123; throw new UnsupportedOperationException(); &#125; public E remove(int index) &#123; throw new UnsupportedOperationException(); &#125; public int indexOf(Object o) &#123; ListIterator&lt;E&gt; it = listIterator(); if (o==null) &#123; while (it.hasNext()) if (it.next()==null) return it.previousIndex(); &#125; else &#123; while (it.hasNext()) if (o.equals(it.next())) return it.previousIndex(); &#125; return -1; &#125; public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; ...&#125; AbstractList类内部实现了iterator()方法，构造的迭代器是其内部类Itr.class 可以看到逻辑很简单，就是通过cursor来控制遍历位置，通过索引位置来获取元素get(i)由子类实现 modCount变量 用于记录对象的修改次数，比如增、删、改，有一点版本控制的意思，可以理解成version，在特定的操作下需要对version进行检查 也基本存在于非线程安全的集合类中，这是一种Fail-Fast机制： 1、当多个线程对同一集合的内容进行操作时，可能就会产生此类异常。 2、比如当A通过iterator去遍历某集合的过程中，其他线程修改了此集合，此时会抛出ConcurrentModificationException异常。 3、此类机制就是通过modCount实现的，在迭代器初始化时，会赋值expectedModCount，在迭代过程中判断modCount和expectedModCount是否一致。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/** * 内部实现了Iterator接口的实现类Itr */private class Itr implements Iterator&lt;E&gt; &#123; /** * 光标位置 * Index of element to be returned by subsequent call to next. */ int cursor = 0; /** * 上一次迭代到的元素的光标位置，如果是末尾会置为-1 * Index of element returned by most recent call to next or * previous. Reset to -1 if this element is deleted by a call * to remove. */ int lastRet = -1; /** * 并发标志，如果两个值不一致，说明发生了并发操作，就会报错 * The modCount value that the iterator believes that the backing * List should have. If this expectation is violated, the iterator * has detected concurrent modification. */ int expectedModCount = modCount; /** * 判断是否存在下一条数据，即迭代器的位置是否走到尾 * @return */ public boolean hasNext() &#123; /** * 如果光标位置不等于集合个数，说明迭代器没有走到末尾，返回true */ return cursor != size(); &#125; /** * 获取下一个元素 * @return */ public E next() &#123; // 判断是否有并发操作 checkForComodification(); try &#123; int i = cursor; // 通过索引位置来获取元素 E next = get(i); lastRet = i; // 每次将+1，将迭代器位置向后移动一位 cursor = i + 1; return next; &#125; catch (IndexOutOfBoundsException e) &#123; // 时刻检查是否有并发操作 checkForComodification(); throw new NoSuchElementException(); &#125; &#125; /** * 删除上一次迭代器越过的元素 */ public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; // 调用需要子类去实现的remove方法 AbstractList.this.remove(lastRet); if (lastRet &lt; cursor) cursor--; // 每次删除后，将lastRet置为-1，防止连续的删除 lastRet = -1; // 将修改次数赋给迭代器对对象的结构修改次数 expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException e) &#123; // 如果出现索引越界，说明发生了并发的操作导致，所以抛出一个并发操作异常。 throw new ConcurrentModificationException(); &#125; &#125; /** * 判断是否发生了并发操作 */ final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; AbstractSet 类继承结构图 从上图可以看到 AbstractSet也是继承了AbstractCollection抽象类及实现了Set接口 通过扩展此类实现集合的过程与通过扩展AbstractCollection实现集合的过程相同，除了此类的子类中的所有方法和构造函数必须遵守Set接口施加的附加约束（例如，添加方法不能允许将一个对象的多个实例添加到集合中）。 请注意，此类不会覆盖AbstractCollection类中的任何实现, 它只是添加了equals()和hashCode()的实现 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public abstract class AbstractSet&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Set&lt;E&gt; &#123; protected AbstractSet() &#123; &#125; public boolean equals(Object o) &#123; if (o == this) return true; if (!(o instanceof Set)) return false; Collection&lt;?&gt; c = (Collection&lt;?&gt;) o; if (c.size() != size()) return false; try &#123; return containsAll(c); &#125; catch (ClassCastException unused) &#123; return false; &#125; catch (NullPointerException unused) &#123; return false; &#125; &#125; public int hashCode() &#123; int h = 0; Iterator&lt;E&gt; i = iterator(); while (i.hasNext()) &#123; E obj = i.next(); if (obj != null) h += obj.hashCode(); &#125; return h; &#125; public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); boolean modified = false; if (size() &gt; c.size()) &#123; for (Iterator&lt;?&gt; i = c.iterator(); i.hasNext(); ) modified |= remove(i.next()); &#125; else &#123; for (Iterator&lt;?&gt; i = iterator(); i.hasNext(); ) &#123; if (c.contains(i.next())) &#123; i.remove(); modified = true; &#125; &#125; &#125; return modified; &#125;&#125; AbstractQueue 类继承结构图 从上图可以看到 AbstractQueue也是继承了AbstractCollection抽象类及实现了Queue接口，这个类是对队列集合的抽象实现 方法add、remove和element是基于offer poll和peek来实现的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractQueue&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Queue&lt;E&gt; &#123; protected AbstractQueue() &#123; &#125; public boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\"); &#125; public E remove() &#123; E x = poll(); if (x != null) return x; else throw new NoSuchElementException(); &#125; public E element() &#123; E x = peek(); if (x != null) return x; else throw new NoSuchElementException(); &#125; public void clear() &#123; while (poll() != null) ; &#125; public boolean addAll(Collection&lt;? extends E&gt; c) &#123; if (c == null) throw new NullPointerException(); if (c == this) throw new IllegalArgumentException(); boolean modified = false; for (E e : c) if (add(e)) modified = true; return modified; &#125;&#125; AbstractMap 类继承结构图 此类提供了Map接口的骨架实现，以尽量减少实现此接口所需的工作量。 注意这个类是Map的子类，并不是Collection的子类 为了实现一个不可修改的Map，只需要扩展这个类并为entrySet方法提供一个实现，该方法返回Map映射的设置视图。 通常，返回的集合又将在AbstractSet顶部实现 。 这个集合不应该支持add或remove方法，而且它的迭代器不应该支持remove方法。 要实现可修改的Map，程序员必须另外覆盖此类的put方法（否则将抛出UnsupportedOperationException ），由entrySet().iterator()返回的迭代器必须另外实现其remove方法。 AbstractMap 类解析 可以看到AbstractMap的设计和AbstractCollection类似，抽象了一些公共方法，并依赖迭代器entrySet().iterator()，这个方法由子类实现 此类只有一个public abstract Set&lt;Entry&lt;K,V&gt;&gt; entrySet();抽象方法 实现此类默认是不可修改的Map，如果要实现可修改的Map，必须另外覆盖此类的put方法 除此之外还添加了transient Set&lt;K&gt; keySet、transient Collection&lt;V&gt; values来存放键值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; protected AbstractMap() &#123; &#125; public int size() &#123; return entrySet().size(); &#125; public boolean isEmpty() &#123; return size() == 0; &#125; public boolean containsValue(Object value) &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (value==null) &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getValue()==null) return true; &#125; &#125; else &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (value.equals(e.getValue())) return true; &#125; &#125; return false; &#125; public boolean containsKey(Object key) &#123; Iterator&lt;Map.Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (key==null) &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) return true; &#125; &#125; else &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) return true; &#125; &#125; return false; &#125; public V get(Object key) &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (key==null) &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) return e.getValue(); &#125; &#125; else &#123; while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) return e.getValue(); &#125; &#125; return null; &#125; public V put(K key, V value) &#123; throw new UnsupportedOperationException(); &#125; public V remove(Object key) &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); Entry&lt;K,V&gt; correctEntry = null; if (key==null) &#123; while (correctEntry==null &amp;&amp; i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (e.getKey()==null) correctEntry = e; &#125; &#125; else &#123; while (correctEntry==null &amp;&amp; i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); if (key.equals(e.getKey())) correctEntry = e; &#125; &#125; V oldValue = null; if (correctEntry !=null) &#123; oldValue = correctEntry.getValue(); i.remove(); &#125; return oldValue; &#125; public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue()); &#125; public void clear() &#123; entrySet().clear(); &#125; transient Set&lt;K&gt; keySet; transient Collection&lt;V&gt; values; public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new AbstractSet&lt;K&gt;() &#123; public Iterator&lt;K&gt; iterator() &#123; return new Iterator&lt;K&gt;() &#123; private Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); public boolean hasNext() &#123; return i.hasNext(); &#125; public K next() &#123; return i.next().getKey(); &#125; public void remove() &#123; i.remove(); &#125; &#125;; &#125; public int size() &#123; return AbstractMap.this.size(); &#125; public boolean isEmpty() &#123; return AbstractMap.this.isEmpty(); &#125; public void clear() &#123; AbstractMap.this.clear(); &#125; public boolean contains(Object k) &#123; return AbstractMap.this.containsKey(k); &#125; &#125;; keySet = ks; &#125; return ks; &#125; public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vals = values; if (vals == null) &#123; vals = new AbstractCollection&lt;V&gt;() &#123; public Iterator&lt;V&gt; iterator() &#123; return new Iterator&lt;V&gt;() &#123; private Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); public boolean hasNext() &#123; return i.hasNext(); &#125; public V next() &#123; return i.next().getValue(); &#125; public void remove() &#123; i.remove(); &#125; &#125;; &#125; public int size() &#123; return AbstractMap.this.size(); &#125; public boolean isEmpty() &#123; return AbstractMap.this.isEmpty(); &#125; public void clear() &#123; AbstractMap.this.clear(); &#125; public boolean contains(Object v) &#123; return AbstractMap.this.containsValue(v); &#125; &#125;; values = vals; &#125; return vals; &#125; public abstract Set&lt;Entry&lt;K,V&gt;&gt; entrySet(); public boolean equals(Object o) &#123; if (o == this) return true; if (!(o instanceof Map)) return false; Map&lt;?,?&gt; m = (Map&lt;?,?&gt;) o; if (m.size() != size()) return false; try &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); K key = e.getKey(); V value = e.getValue(); if (value == null) &#123; if (!(m.get(key)==null &amp;&amp; m.containsKey(key))) return false; &#125; else &#123; if (!value.equals(m.get(key))) return false; &#125; &#125; &#125; catch (ClassCastException unused) &#123; return false; &#125; catch (NullPointerException unused) &#123; return false; &#125; return true; &#125; public int hashCode() &#123; int h = 0; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); while (i.hasNext()) h += i.next().hashCode(); return h; &#125; public String toString() &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); if (! i.hasNext()) return \"&#123;&#125;\"; StringBuilder sb = new StringBuilder(); sb.append('&#123;'); for (;;) &#123; Entry&lt;K,V&gt; e = i.next(); K key = e.getKey(); V value = e.getValue(); sb.append(key == this ? \"(this Map)\" : key); sb.append('='); sb.append(value == this ? \"(this Map)\" : value); if (! i.hasNext()) return sb.append('&#125;').toString(); sb.append(',').append(' '); &#125; &#125; protected Object clone() throws CloneNotSupportedException &#123; AbstractMap&lt;?,?&gt; result = (AbstractMap&lt;?,?&gt;)super.clone(); result.keySet = null; result.values = null; return result; &#125; private static boolean eq(Object o1, Object o2) &#123; return o1 == null ? o2 == null : o1.equals(o2); &#125; ... &#125; 其他总结 通过上面的抽象实现类的实现我们可以知道抽象类是抽象了一些公共方法，这些公共方法是定义了方法的主体逻辑，并嵌入抽象方法（由子类实现）来实现（模板方法设计模式也是这样设计的），从而达到封装抽象的效果，这样可以减少重复代码的出现，易于对外扩展 抽象类不能通过new关键字直接创建抽象类的实例，但它可以有构造方法，AbstractCollection及AbstractMap都是提供了一个protected修饰的无参构造方法，意味着只有它的子类才能访问（当然它本身就是一个抽象类，其他类也不能直接对其实例化），也就是说只有它的子类才能调用这个无参的构造方法。 从AbstractCollection及AbstractMap的实现我们可以知道它们默认设计的集合是不可修改的，只要调用了操作方法就是throw new UnsupportedOperationException();，如果要设计成可修改的集合只要重写这些方法就可以实现 参考https://it.baiked.com/jdkapi1.8/java/util/Collection.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-集合框架体系及主要接口","slug":"backend/java/collection/Java集合-集合框架体系及主要接口","date":"2018-10-19T16:00:00.000Z","updated":"2020-03-16T14:10:29.643Z","comments":true,"path":"2018/10/20/backend/java/collection/Java集合-集合框架体系及主要接口/","link":"","permalink":"http://www.songshuiyang.com/2018/10/20/backend/java/collection/Java集合-集合框架体系及主要接口/","excerpt":"","text":"前言 Java集合在我们日常开发中是经常用到的， 所以有必要对其进行整理归纳 代码采用JDK 1.8版本 为什么需要集合？ 在学习Java集合之前，我们先想这么一个问题，为什么要设计Java集合，它能给带来什么好处？ 我们知道Java是一个面向对象的语言，既然是面向对象就需要存储与检索对象，那么我们可以用什么数据结构来存放这些数据呢？比如Array(数组)、Linked(链表)、Tree(树)、Hash(哈希表) 我们可以使用Array（数组），但使用Array（数组）存储对象方面具有一些弊端，需要提前对数组进行容量大小的设定 如果是使用链表或者哈希表那么我们是不是要写一大堆额外代码 为了解决上面的问题，集合出现了，集合还是基于这些基础的数据结构进行存放数据，只不过添加了一些额外操作，可以方便有效的存储与检索数据 解析集合框架体系 集合类存放于java.util包中，先来看下集合框架图 从上面的集合框架图可以看到，Java 集合框架主要包括两种类型的容器 集合Collection，采用线性列表的存储方式，长度可动态改变，存储一个元素的集合，Collection 接口又有 3 种子类型 List Set Queue 图Map，采用键/值对的存储方式，长度可动态改变 集合接口 接口是代表集合的抽象数据类型，例如Collection、List、Set、Map 等。之所以定义多个接口，是为了以不同的方式操作集合对象 Collection Collection是Queue,List,Set的根类 ，是一个高度抽象出来的接口，包含了集合的基本操作 1、增加（add/addAll） 2、删除（remove/removeAll/clear/retainAll） 3、查询（contain/containAll/iterator/size/isEmpty） 4、转数组（toArray/toArray(T[])） 5、流Stream方法（） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; // 返回此集合中的元素数。 如果此收藏包含超过Integer.MAX_VALUE个元素，则返回Integer.MAX_VALUE 。 int size(); // 如果此集合不包含元素，则返回 true 。 boolean isEmpty(); // 如果此集合包含指定的元素，则返回true boolean contains(Object o); // 返回此集合中的元素的迭代器。 没有关于元素返回顺序的保证（除非这个集合是提供保证的某个类的实例）。 Iterator&lt;E&gt; iterator(); // 返回一个包含此集合中所有元素的数组。 如果此集合对其迭代器返回的元素的顺序做出任何保证，则此方法必须以相同的顺序返回元素。 // 返回的数组将是“安全的”，因为该集合不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组，即使这个集合是由数组支持的）。 因此，调用者可以自由地修改返回的数组。 // 此方法充当基于数组和基于集合的API之间的桥梁。 Object[] toArray(); // 像toArray()方法一样，此方法充当基于数组和基于集合的API之间的桥梁。 此外，该方法允许精确地控制输出阵列的运行时类型，并且在某些情况下可以用于节省分配成本。 &lt;T&gt; T[] toArray(T[] a); // 添加元素 boolean add(E e); // 从该集合中删除指定元素的单个实例 boolean remove(Object o); // 如果此集合包含指定 集合中的所有元素，则返回true。 boolean containsAll(Collection&lt;?&gt; c); // 将指定集合中的所有元素添加到此集合（可选操作）。 如果在操作进行中修改了指定的集合，则此操作的行为是未定义的。 （这意味着如果指定的集合是此集合，此调用的行为是未定义的，并且此集合是非空的。） boolean addAll(Collection&lt;? extends E&gt; c); // 删除指定集合中包含的所有此集合的元素（可选操作）。 此调用返回后，此集合将不包含与指定集合相同的元素。 boolean removeAll(Collection&lt;?&gt; c); default boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; Objects.requireNonNull(filter); boolean removed = false; final Iterator&lt;E&gt; each = iterator(); while (each.hasNext()) &#123; if (filter.test(each.next())) &#123; each.remove(); removed = true; &#125; &#125; return removed; &#125; boolean retainAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); @Override default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0); &#125; default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false); &#125; default Stream&lt;E&gt; parallelStream() &#123; return StreamSupport.stream(spliterator(), true); &#125; &#125; Collection子接口 List接口 List代表的元素是有序、可重复的集合，集合中的每个元素都有其对应的顺序索引 一个线性表接口，比如最为常用的基于数组的线性表ArrayList和基于链表的线性表LinkedList Set接口 Set代表的元素是无序、不可重复的集合 有与 Collection 完全一样的接口，只是行为上不同，Set 不保存重复的元素。 Queue接口 队列 Map 查看Map接口可以发现使用两个泛型（K）指定为键，（V）指定为值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221public interface Map&lt;K,V&gt; &#123; int size(); boolean isEmpty(); boolean containsKey(Object key); boolean containsValue(Object value); V get(Object key); V put(K key, V value); V remove(Object key); void putAll(Map&lt;? extends K, ? extends V&gt; m); void clear(); Set&lt;K&gt; keySet(); Collection&lt;V&gt; values(); Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); interface Entry&lt;K,V&gt; &#123; K getKey(); V getValue(); V setValue(V value); boolean equals(Object o); int hashCode(); public static &lt;K extends Comparable&lt;? super K&gt;, V&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByKey() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getKey().compareTo(c2.getKey()); &#125; public static &lt;K, V extends Comparable&lt;? super V&gt;&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByValue() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getValue().compareTo(c2.getValue()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByKey(Comparator&lt;? super K&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getKey(), c2.getKey()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByValue(Comparator&lt;? super V&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getValue(), c2.getValue()); &#125; &#125; boolean equals(Object o); int hashCode(); default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key)) ? v : defaultValue; &#125; default void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Objects.requireNonNull(action); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; action.accept(k, v); &#125; &#125; default void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Objects.requireNonNull(function); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; // ise thrown from function is not a cme. v = function.apply(k, v); try &#123; entry.setValue(v); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; &#125; &#125; default V putIfAbsent(K key, V value) &#123; V v = get(key); if (v == null) &#123; v = put(key, value); &#125; return v; &#125; default boolean remove(Object key, Object value) &#123; Object curValue = get(key); if (!Objects.equals(curValue, value) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; remove(key); return true; &#125; default boolean replace(K key, V oldValue, V newValue) &#123; Object curValue = get(key); if (!Objects.equals(curValue, oldValue) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; put(key, newValue); return true; &#125; default V replace(K key, V value) &#123; V curValue; if (((curValue = get(key)) != null) || containsKey(key)) &#123; curValue = put(key, value); &#125; return curValue; &#125; default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) &#123; V newValue; if ((newValue = mappingFunction.apply(key)) != null) &#123; put(key, newValue); return newValue; &#125; &#125; return v; &#125; default V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue; if ((oldValue = get(key)) != null) &#123; V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) &#123; put(key, newValue); return newValue; &#125; else &#123; remove(key); return null; &#125; &#125; else &#123; return null; &#125; &#125; default V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue = get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue == null) &#123; // delete mapping if (oldValue != null || containsKey(key)) &#123; // something to remove remove(key); return null; &#125; else &#123; // nothing to do. Leave things as they were. return null; &#125; &#125; else &#123; // add or replace old mapping put(key, newValue); return newValue; &#125; &#125; default V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) &#123; remove(key); &#125; else &#123; put(key, newValue); &#125; return newValue; &#125;&#125; Iterator 所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，Iterator接口则是在集合类内部实现，并对外提供实现该接口的对象，用于迭代地遍历Collection中的元素，也称为迭代器 123456789101112131415161718public interface Iterator&lt;E&gt; &#123; // 是否还有下一个元素 boolean hasNext(); // 返回下一个元素 E next(); // 删除当前元素，JDK1.8新增的模拟方法，如果实现类没有实现该接口的这个方法，则调用此方法会抛异常 default void remove() &#123; throw new UnsupportedOperationException(\"remove\"); &#125; default void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (hasNext()) action.accept(next()); &#125;&#125; 其他 集合类存放的都是对象的引用，而非对象本身，出于表达上的便利，我们称集合中的对象就是指集合中对象的引用(reference)。 集合类作为容器类可以存储任何类型的数据，当然也可以结合泛型存储指定的类型（不过泛型仅仅在编译期有效，运行时是会被擦除的） 总结 Java 集合框架主要包括两种类型的容器 Collection集合，采用线性列表的存储方式，长度可动态改变，存储一个元素的集合，Collection 接口又有 3 种子类型 List Set Queue Map图，采用键/值对的存储方式，长度可动态改变 Java的集合框架提供了一下优点： 减少编程的工作量：通过提供有用的数据结构和算法，集合框架能让你更专注的实现程序的核心功能，而不是去做一个底层的管道工。Java框架通过促进无关API的互操作性，使得你不用自己去实现不同API的适配 提高程序的速度与质量：集合框架提供了一些有用数据结构和算法的高性能、高质量的实现。每个接口的不同的实现也是可以互换的，所以程序可以通过切换集合来做一些调整。正因为你从实现数据结构的那些苦差事中脱离出来，你才可以有更多的实现去改善你自己程序的性能和质量 参考 https://www.runoob.com/java/java-collections.html https://www.cnblogs.com/paddix/p/5539326.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java集合-集合使用笔记整理","slug":"backend/java/collection/Java集合-集合使用笔记整理","date":"2018-10-18T16:00:00.000Z","updated":"2019-11-27T14:40:00.789Z","comments":true,"path":"2018/10/19/backend/java/collection/Java集合-集合使用笔记整理/","link":"","permalink":"http://www.songshuiyang.com/2018/10/19/backend/java/collection/Java集合-集合使用笔记整理/","excerpt":"","text":"整理迭代器(Iterator)相关快速失败（fail-fast）和安全失败（fail-safe）的区别是什么 差别在于 ConcurrentModification 异常： 快速失败：当你在迭代一个集合的时候，如果有另一个线程正在修改你正在访问的那个集合时，就会抛出一个 ConcurrentModification 异常。 在 java.util 包下的都是快速失败。 安全失败：你在迭代的时候会去底层集合做一个拷贝，所以你在修改上层集合的时候是不会受影响的，不会抛出 ConcurrentModification 异常。在 java.util.concurrent 包下的全是安全失败的。 为何 Iterator 接口没有具体的实现？ Iterator 接口，定义了遍历集合的方法，但它的实现则是集合实现类的责任。每个能够返回用于遍历的 Iterator 的集合类都有它自己的 Iterator 实现内部类。 这就允许集合类去选择迭代器是fail-fast 还是 fail-safe 的。比如，ArrayList 迭代器是 fail-fast 的，而 CopyOnWriteArrayList 迭代器是 fail-safe 的。 参考","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java集合","slug":"Java集合","permalink":"http://www.songshuiyang.com/tags/Java集合/"}]},{"title":"Java基础-类的实例化顺序","slug":"backend/java/basicKnowledge/Java基础-类的实例化顺序","date":"2018-10-09T16:00:00.000Z","updated":"2020-03-16T11:43:55.423Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-类的实例化顺序/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-类的实例化顺序/","excerpt":"","text":"初始化顺序如下： 父类静态变量 父类静态代码块 子类静态变量、 子类静态代码块 父类非静态变量（父类实例成员变量） 父类构造函数 子类非静态变量（子类实例成员变量） 子类构造函数","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-笔记","slug":"backend/java/basicKnowledge/Java基础-笔记","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-10T02:08:41.974Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-笔记/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-笔记/","excerpt":"","text":"用引用操纵对象 在Java的世界里，一切都被视为对象，尽管一切都看成是对象，但操纵的标识符实际上是对象的一个引用,可将这一情形想象成用遥控板（句柄）操纵电视机（对象）。只要握住这个遥控板，就相当于掌握了与电视机连接的通道。但一旦需要“换频道”或者“关小声音”，我们实际操纵的是遥控板（句柄），再由遥控板自己操纵电视机（对象）。如果要在房间里四处走走，并想保持对电视机的控制，那么手上拿着的是遥控板，而非电视机。12遥控器 --&gt; 电视引用 --&gt; 对象 高精度数字类型 BigInteger 支持任意精度的整数。也就是说，我们可精确表示任意大小的整数值，同时在运算过程中不会丢失任何信息。 BigDecimal 支持任意精度的定点数字。例如，可用它进行精确的币值计算。 对应于我们针对主类型执行的操作。也就是说，能对 int 或 float 做的事情，对 BigInteger 和 BigDecimal 一样可以做。只是必须使用方法调用，不能使用运算符。此外，由于牵涉更多，所以运算速度会慢一些。我们牺牲了速度，但换来了精度。 类文件的限制 每个文件只能有一个public类, 也可以没有public，如果有的话必须与文件名相同 全局变量和static修饰的局部变量 默认初始化为 0 。因为全局变量和static静态局部变量存储在静态数据区。在静态数据区，内存中所有的字节默认值都是 0x00。 Java中的switch-case语句 switch接受的参数类型有10种，分别是基本类型的byte,short,int,char，以及引用类型的String(只有JavaSE 7 和以后的版本 可以接受String类型参数),enum和byte,short,int,char的封装类Byte,Short,Integer,Charactercase 后紧跟常量表达式，不能是变量。 Maps.newHashMap();123Map&lt;String, Object&gt; result = new HashMap&lt;String,Object&gt;();Map&lt;String, Object&gt; result = Maps.newHashMap(); 上面这种是Java原生API写法 下面这种是google的guava.jar提供的写法，目的是为了简化代码。唯一的区别就是简化代码 泛型 仅仅是Java的一颗语法糖，它不会影响Java虚拟机生成的汇编代码，在编译阶段，虚拟机就会把泛型的类型擦除，还原成没有泛型的代码，顶多编译速度稍微慢一些，执行速度是完全没有什么区别的。 重载的概念 方法名称相同，参数个数、次序、类型不同 因此重载对返回值没有要求，可以相同，也可以不同 但是如果参数的个数、类型、次序都相同，方法名也相同，仅返回值不同，则无法构成重载 null != a 与 a != null 区别场景 在其他人的项目中经常会看到 null ! = a 这种写法, 但平常使用的是都是 a != null 这种写法 原因：功能上是没有区别的，企业里大多是时候是推荐第一种的，是因为能够防止程序员书写遗漏等号导致错误。比如：null != a 这样少了！也会报错。而a != null少了!就不会报错了。程序员有时候容易把 == 误写为 = ，如果把常量放前面 5 = i ，会编译错误，而写成i = 5就不会报错了，所以这样写能发现这种笔误bug。 总结 所以在实际项目中，细节很重要，一个小小的问题有可能导致一系列的问题。 多阅读其他人的代码，借鉴其他人的思想及技巧。 枚举类enum 枚举是用来构建常量数据结构的模板，这个模板可扩展。枚举的使用增强了程序的健壮性 使用场景 1. 常量12345public enum Color &#123; RED, GREEN, BLANK, YELLOW &#125; 2. switch1234567891011121314151617181920212223public class B &#123; public static void main(String[] args) &#123; showColor( Color.RED ); &#125; static void showColor(Color color)&#123; switch ( color ) &#123; case BLANK: System.out.println( color ); break; case RED : System.out.println( color ); break; default: System.out.println( color ); break; &#125; &#125;&#125; 3. 自定义函数public enum Color { RED(&quot;红色&quot;, 1), GREEN(&quot;绿色&quot;, 2), BLANK(&quot;白色&quot;, 3), YELLO(&quot;黄色&quot;, 4); private String name ; private int index ; private Color( String name , int index ){ this.name = name ; this.index = index ; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getIndex() { return index; } public void setIndex(int index) { this.index = index; }","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-强引用-软引用-弱引用-虚引用","slug":"backend/java/basicKnowledge/Java基础-强引用-软引用-弱引用-虚引用","date":"2018-10-09T16:00:00.000Z","updated":"2020-03-16T11:43:55.420Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-强引用-软引用-弱引用-虚引用/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-强引用-软引用-弱引用-虚引用/","excerpt":"","text":"概览 JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 介绍强引用 强引用，就是我们最常见的普通对象引用，我们 new 出来的对象就是强引用，只要尚且存在强引用指向某一个对象，那就能表明该对象还存活，GC 不能去回收这种对象。需要回收强引用指向的对象，可以等待超出引用区域，或者是显式设置对象为 null，就可以通知让 GC 回收，当然实际的回收时间要看 GC 策略。 如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 12345678910111213public class Main &#123; public static void main(String[] args) &#123; // 创建一个对象，new出来的对象都是分配在java堆中的 Sample sample = new Sample(); // sample这个引用就是强引用 sample = null; // 将这个引用指向空指针, // 那么上面那个刚new来的对象就没用任何其它有效的引用指向它了 // 也就说该对象对于垃圾收集器是符合条件的 // 因此在接下来某个时间点 GC进行收集动作的时候, 该对象将会被销毁，内存被释放 &#125;&#125;class Sample &#123;&#125; 也可以画个简单的图理解一下： 软引用 当内存资源充足的时候，垃圾回收器不会回收软引用对应的对象的内存空间；但当内存资源紧张时，软引用所对应的对象就会被垃圾回收器回收。 软引用可用来实现内存敏感的高速缓存,比如网页缓存、图片缓存等。使用软引用能防止内存泄露，增强程序的健壮性。 SoftReference的特点是它的一个实例保存对一个Java对象的软引用， 该软引用的存在不妨碍垃圾收集线程对该Java对象的回收。 也就是说，一旦SoftReference保存了对一个Java对象的软引用后，在垃圾线程对 这个Java对象回收前，SoftReference类所提供的get()方法返回Java对象的强引用。另外，一旦垃圾线程回收该Java对象之 后，get()方法将返回null。 12345678910111213141516171819public class Main &#123; public static void main(String[] args) &#123; // 创建一个对象，new出来的对象都是分配在java堆中的 Sample sample = new Sample(); //sample这个引用就是强引用 // 创建一个软引用指向这个对象 那么此时就有两个引用指向Sample对象 SoftReference&lt;Sample&gt; softRef = new SoftReference&lt;Sample&gt;(sample); // 将强引用指向空指针 那么此时只有一个软引用指向Sample对象 // 注意：softRef这个引用也是强引用，它是指向SoftReference这个对象的 // 那么这个软引用在哪呢？ 可以跟一下java.lang.Reference的源码 // private T referent; 这个才是软引用， 只被jvm使用 sample = null; // 可以重新获得Sample对象，并用一个强引用指向它 sample = softRef.get(); &#125;&#125;class Sample &#123;&#125; 利用软引用解决OOM问题 下面举个例子，假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。 示例代码123456789101112131415161718192021222324private Map&lt;String, SoftReference&lt;Bitmap&gt;&gt; imageCache = new HashMap&lt;String, SoftReference&lt;Bitmap&gt;&gt;();public void addBitmapToCache(String path) &#123; // 强引用的Bitmap对象 Bitmap bitmap = BitmapFactory.decodeFile(path); // 软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = new SoftReference&lt;Bitmap&gt;(bitmap); // 添加该对象到Map中使其缓存 imageCache.put(path, softBitmap);&#125;public Bitmap getBitmapByPath(String path) &#123; // 从缓存中取软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = imageCache.get(path); // 判断是否存在软引用 if (softBitmap == null) &#123; return null; &#125; // 取出Bitmap对象，如果由于内存不足Bitmap被回收，将取得空 Bitmap bitmap = softBitmap.get(); return bitmap;&#125; 弱引用 弱引用会被Jvm忽略，也就说在GC进行垃圾收集的时候，如果一个对象只有弱引用指向它，那么和没有引用指向它是一样的效果，jvm都会对它就行果断的销毁，释放内存。 那么，ThreadLocalMap中的key使用弱引用的原因也是如此。当一条线程中的ThreadLocal对象使用完毕，没有强引用指向它的时候，垃圾收集器就会自动回收这个Key，从而达到节约内存的目的。 1WeakReference&lt;Person&gt; wr = new WeakReference&lt;Person&gt;(new Person()); 虚引用 “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动，为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用 当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收 程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动 在 JDK1.2 之后，用 PhantomReference 类来表示，通过查看这个类的源码，发现它只有一个构造函数和一个 get() 方法，而且它的 get() 方法仅仅是返回一个null，也就是说将永远无法通过虚引用来获取对象，虚引用必须要和 ReferenceQueue 引用队列一起使用。 总结 JDK设计这些引用是能让开发来控制其新建对象的生命周期，这样可以提高运行效率，减少资源消耗 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 参考转载 https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-常用类-String","slug":"backend/java/basicKnowledge/Java基础-常用类-String","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-10T02:08:41.967Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-常用类-String/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-常用类-String/","excerpt":"","text":"前言 String类代表字符串。 Java程序中的所有字符串文字（例如abc ）都被实现为此类的实例。 解析类成员变量12345678910111213141516171819202122public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = -6849794470754667710L; /** * Class String is special cased within the Serialization Stream Protocol. * * A String instance is written into an ObjectOutputStream according to * &lt;a href=\"&#123;@docRoot&#125;/../platform/serialization/spec/output.html\"&gt; * Object Serialization Specification, Section 6.2, \"Stream Elements\"&lt;/a&gt; */ private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; ...&#125; 上面是String类的成员变量 可以看到String底层使用一个char value[]字符数组来存储数据的 int hash是String的哈希值 因为String是不可变的，所以哈希值是固定的，这里做了下缓存处理 第一次调用hashCode()会初始化这个值，之后都是返回的hash对象123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; 构造 创建字符串对象两种方式的区别 1、直接赋值方式创建对象 代码示例 12345678910String string1 = \"abcd\";String string2 = \"abcd\";/** * ==: * 基本数据类型：比较的是基本数据类型的值是否相同 * 引用数据类型：比较的是引用数据类型的地址值是否相同 * 所以在这里的话：String类对象==比较，比较的是地址，而不是内容 */System.out.println(string1 == string2);// true 直接赋值方式创建的对象是在字符串常量池中，字符串池是方法区中的一部分特殊存储，当一个字符串被被创建的时候，首先会去这个字符串池中查找，如果找到，直接返回对该字符串的引用，如下图所示 2、通过构造方法创建字符串对象 代码示例 123String s1 = new String(\"Hollis\");String s2 = new String(\"Hollis\");System.out.println(s1 == s2); // false 通过构造方法创建字符串对象在运行时会涉及两个对象，一个是字符串字面量Hollis所对应的、驻留（intern）在一个全局共享的字符串常量池中的实例，另一个是通过new String(String)在堆里创建并初始化的、内容与Hollis相同的实例 我们可以知道的是，在编译期，符号引用s和字面量Hollis会被加入到Class文件的常量池中，然后在类加载阶段这两个常量会进入常量池。 若常量池中已经存在Hollis，则直接引用，也就是此时只会创建一个对象，如果常量池中不存在Hollis，则先创建Hollis之后再根据new String()创建堆上的数据 在不同版本的JDK中，Java堆和字符串常量池之间的关系是不一样的，上面这张图只是为了方便表述，就画成两个独立的物理区域了，具体情况请参考Java虚拟机规范。 上面两种实例化方式的比较1234567891011121314public class TestString &#123; public static void main(String[] args) &#123; String str1 = \"Lance\"; String str2 = new String(\"Lance\"); String str3 = str2; // 引用传递，str3直接指向st2的堆内存地址 String str4 = \"Lance\"; System.out.println(str1==str2); // false System.out.println(str1==str3); // false System.out.println(str3==str2); // true System.out.println(str1==str4); // true &#125;&#125; String的不变性前言 一旦一个string对象在内存(堆)中被创建出来，他就无法被修改。特别要注意的是，String类的所有方法都没有改变字符串本身的值，都是返回了一个新的对象。 如果你需要一个可修改的字符串，应该使用StringBuffer 或者 StringBuilder。否则会有大量时间浪费在垃圾回收上，因为每次试图修改都有新的string对象被创建出来。 解析 String的不变性可以从三个方面来解析 1、类是被final修饰了 我们知道被final修饰了的类是不能被继承，也就是说方法不能被重写，这就避免了因为继承引起的安全隐患 下面这张图讲解的很形象 2、类成员变量存放数据的字符数组被final修饰 private final char value[];可以看到是被final修饰了，也就是说第一次被创建了将不能被修改 3、字符串常量池 字符串池是方法区中的一部分特殊存储。当一个字符串被被创建的时候，首先会去这个字符串池中查找，如果找到，直接返回对该字符串的引用 总结 String的不变性主要是为了安全性和效率的缘故 其他 理解String的intern方法 当一个String实例str调用intern()方法时，Java查找常量池中是否有相同Unicode的字符串常量，如果有，则返回其的引用，如果没有，则在常量池中增加一个Unicode等于str的字符串并返回它的引用；1234567public class TestString &#123; public static void main(String args[])&#123; String str =new String(\"Lance\").intern();// 对匿名对象\"hello\"进行手工入池操作 String str1=\"Lance\"; System.out.println(str==str1);//true &#125;&#125; 总结参考 https://my.oschina.net/90888/blog/842605 https://www.cnblogs.com/zhangyinhua/p/7689974.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-基本数据类型及包装类","slug":"backend/java/basicKnowledge/Java基础-基本数据类型及包装类","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-27T15:11:32.563Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-基本数据类型及包装类/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-基本数据类型及包装类/","excerpt":"","text":"前言 我们知道Java有两大类型 8大基本数据类型 整数类型 byte 占1个字节，范围为-128(-2^7)到127(2^7-1)，在变量初始化的时候，byte类型的默认值为0 short 占2个字节，范围为-32,768 (-2^15)到32,767 (2^15-1)，在变量初始化的时候，short类型的默认值为0 int 占4个字节，范围为-2,147,483,648 (-2^31)到2,147,483,647 (2^31-1)，在变量初始化的时候，int类型的默认值为0 long 占8个字节，范围为-9,223,372,036,854,775,808(-2^63)到9,223,372,036, 854,775,807 (2^63-1)，在变量初始化的时候，long类型的默认值为0L或0l 浮点类型 flout 占4个字节，单精度浮点数 根据IEEE754-1985标准，默认值为0.0f double 占8个字节，双精度浮点数 根据IEEE754-1985标准，默认值为0.0d 布尔类型 boolean 默认值为false 字符类型 char 占2个字节，默认值为\\u0000 引用数据类型 数字超出范围怎么办？ 上面说过了，整型中，每个类型都有一定的表示范围，但是，在程序中有些计算会导致超出表示范围，即溢出。如以下代码： 1234567int i = Integer.MAX_VALUE;int j = Integer.MAX_VALUE;int k = i + j;System.out.println(\"i (\" + i + \") + j (\" + j + \") = k (\" + k + \")\"); // 输出结果：i (2147483647) + j (2147483647) = k (-2) 这就是发生了溢出，溢出的时候并不会抛异常，也没有任何提示。所以，在程序中，使用同类型的数据进行运算的时候，一定要注意数据溢出的问题。 为什么要分基本数据类型和引用数据类型？ 我们都知道在Java语言中，new一个对象是存储在堆里的，我们通过栈中的引用来使用这些对象，所以，对象本身来说是比较消耗资源的。 对于经常用到的类型，如int等，如果我们每次使用这种变量的时候都需要new一个Java对象的话，就会比较笨重。所以，和C++一样，Java提供了基本数据类型，这种数据的变量不需要使用new创建，他们不会在堆上创建，而是直接在栈内存中存储，因此会更加高效。 有了基本数据类型之外为什么还要包装类型呢？ Java语言是一个面向对象的语言，但是Java中的基本数据类型却是不面向对象的，这在实际使用时存在很多的不便 为了解决这个不足，在设计类时为每个基本数据类型设计了一个对应的类进行代表，这样八个和基本数据类型对应的类统称为包装类(Wrapper Class)。 为了让基本类型也具有对象的特征，就出现了包装类型，它相当于将基本类型“包装起来”，使得它具有了对象的性质，并且为其添加了属性和方法，丰富了基本类型的操作。 解析 包装类均位于java.lang包，包装类和基本数据类型的对应关系如下表所示: 基本数据类型 包装类 byte Byte short Boolean int Short long Long flout Float double Double boolean Boolean char Character 自动拆箱与自动装箱 在Java SE5中，为了减少开发人员的工作，Java提供了自动拆箱与自动装箱功能。 自动装箱: 就是将基本数据类型自动转换成对应的包装类。 自动拆箱：就是将包装类自动转换成对应的基本数据类型。 示例 12Integer i =10; // 自动装箱int b= i; // 自动拆箱 实现原理 自动拆装箱的代码： 1234public static void main(String[]args)&#123; Integer integer=1; //装箱 int i=integer; //拆箱&#125; 对以上代码进行反编译后可以得到以下代码： 1234public static void main(String[]args)&#123; Integer integer=Integer.valueOf(1); int i=integer.intValue(); &#125; 从上面反编译后的代码可以看出，int的自动装箱都是通过Integer.valueOf()方法来实现的，Integer的自动拆箱都是通过integer.intValue来实现的 将八种类型都反编译一遍 ，你会发现以下规律：自动装箱都是通过包装类的valueOf()方法来实现的.自动拆箱都是通过包装类对象的xxxValue()来实现的。 由于自动拆箱，如果包装类对象为null，那么自动拆箱时就有可能抛出NPE 如果一个for循环中有大量拆装箱操作，会浪费很多资源。 基本数据类型及包装类大小比较 Integer 用 ==比较的时候往往非常容易出错，先看题 1234567891011121314package com.lizi.basic;public class IntegerDemo &#123; public static void main(String[] args) &#123; Integer a = new Integer(3); Integer b = 3; int c = 3; System.out.println(a == b); System.out.println(a == c); &#125;&#125; 分析思路 基本数据类类型存的是数值本身，基本类型通过 == 比较的是他们的值大小 引用类型变量在内存放的是数据的引用，引用类型比较的是他们的引用地址 分析 a == b结果分析 Integer b = 3; 这里自动拆箱操作调用Integer.valueOf(3) 返回一个Integer的对象， 这个对象存放到cache中的 而 Integer a = new Integer(3);这里创建了一个新的对象Integer 所以 a == b 返回的是false a == c结果分析 一个Integer 与 int比较，先将Integer转换成int类型，再做值比较，所以返回的是true 结果 12falsetrue Integer缓存123Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;System.out.println(f1 == f2);System.out.println(f3 == f4); 上面涉及到自动装箱，实际上的操作是 12345// 当我们给一个Integer赋予一个int类型的时候会调用Integer的静态方法valueOf。Integer f1 = Integer.valueOf(100); Integer f2 = Integer.valueOf(100); Integer f3 = Integer.valueOf(150); Integer f4 = Integer.valueOf(150); 思考：那么Integer.valueOf()返回的Integer是不是是重新new Integer(num)来创建的呢？ 如果是这样的话，那么== 比较返回都是false，因为他们引用的堆地址不一样 具体来看看Integer.valueOf()的源码，可以看到下面这里并不是重新new Integer(num)来创建，而是做了一个判断，如果当前数值是在缓存数据之内，则返回的缓存的构造的数据 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; IntegerCache类解析 下面可以看到，在IntegerCache中cache数组初始化如下，存入了-128 - 127的值，最小值为-128，最大值可以通过属性来配置，如果没有配置则默认为1271234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 private static class IntegerCache &#123; // 最小值-128 static final int low = -128; // 最大值默认为127，可以通过属性来配置 static final int high; // 缓存值 static final Integer cache[]; static &#123; // 最大值可以通过属性来配置 // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; // for循环构造 for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // 最大值必须大于或等于127 // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125; &#125;* 从上面我们可以知道给`Integer` 赋予的int数值在`-128 - 127`的时候，直接从`cache`中获取，这些`cache`引用对`Integer`对象地址是不变的，但是不在这个范围内的数字，则`new Integer(i) `这个地址是新的地址，不可能一样的* 注意这里是个坑* 结果```javatruefalse 补充为什么byte取值-128~127 计算机系统中是用补码来存储的，首位为0表示正数，首位为1表示负数，所以有以下结论： 最大的补码用二进制表示为：01111111 = 127 最小的补码用二进制表示为：10000000 = -128 总结参考 https://my.oschina.net/90888/blog/861131","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-hashcode和equals的区别","slug":"backend/java/basicKnowledge/Java基础-hashcode和equals的区别","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-10T02:08:41.959Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-hashcode和equals的区别/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-hashcode和equals的区别/","excerpt":"","text":"前言： 首先，我们要介绍hashCode()和equals()方法的作用是是什么，然后才说他的区别，说了区别之后再说使用的时候需要注意到的地方，这样的回答思路基本是OK的，如果你在了解一些其他人不知道的那就更好了！下边我们就开始介绍： 分析： 一、hashCode()和equals()是什么？ hashCode()方法和equals()方法的作用其实一样，在Java里都是用来对比两个对象是否相等一致。 二、hashCode()和equals()的区别 下边从两个角度介绍了他们的区别：一个是性能，一个是可靠性。他们之间的主要区别也基本体现在这里。 1、equals()既然已经能实现对比的功能了，为什么还要hashCode()呢？ 因为重写的equals（）里一般比较的比较全面比较复杂，这样效率就比较低，而利用hashCode()进行对比，则只要生成一个hash值进行比较就可以了，效率很高。 2、hashCode()既然效率这么高为什么还要equals()呢？ 因为hashCode()并不是完全可靠，有时候不同的对象他们生成的hashcode也会一样（生成hash值得公式可能存在的问题），所以hashCode()只能说是大部分时候可靠，并不是绝对可靠，所以我们可以得出 equals()相等的两个对象他们的hashCode()肯定相等，也就是用equals()对比是绝对可靠的。 hashCode()相等的两个对象他们的equals()不一定相等，也就是hashCode()不是绝对可靠的。 三、hashCode()和equals()使用的注意事项 1、对于需要大量并且快速的对比的话如果都用equals()去做显然效率太低，所以解决方式是，每当需要对比的时候，首先用hashCode()去对比，如果hashCode()不一样，则表示这两个对象肯定不相等（也就是不必再用equals()去再对比了）,如果hashCode()相同，此时再对比他们的equals()，如果equals()也相同，则表示这两个对象是真的相同了，这样既能大大提高了效率也保证了对比的绝对正确性！ 2、这种大量的并且快速的对象对比一般使用的hash容器中，比如HashSet,HashMap,HashTable等等，比如HashSet里要求对象不能重复，则他内部必然要对添加进去的每个对象进行对比，而他的对比规则就是像上面说的那样，先hashCode()，如果hashCode()相同，再用equals()验证，如果hashCode()都不同，则肯定不同，这样对比的效率就很高了。 3、然而hashCode()和equals()一样都是基本类Object里的方法，而和equals()一样，Object里hashCode()里面只是返回当前对象的地址，如果是这样的话，那么我们相同的一个类，new两个对象，由于他们在内存里的地址不同，则他们的hashCode（）不同，所以这显然不是我们想要的，所以我们必须重写我们类的hashCode()方法，即一个类，在hashCode()里面返回唯一的一个hash值，比如下面： 示例public class Apple { private String color; public Apple(String color) { this.color = color; } public boolean equals(Object obj) { if(obj==null) return false; if (!(obj instanceof Apple)) return false; if (obj == this) return true; return this.color.equals(((Apple) obj).color); } public static void main(String[] args) { Apple a1 = new Apple(\"green\"); Apple a2 = new Apple(\"red\"); // hashMap stores apple type and its quantity HashMap&lt;Apple, Integer&gt; m = new HashMap&lt;Apple, Integer&gt;(); m.put(a1, 10); m.put(a2, 20); // System.out.println(\"hashCode:\" + new Apple(\"green\").hashCode()); System.out.println(\"hashCode:\" + new Apple(\"green\").hashCode()); System.out.println(m.get(new Apple(\"green\"))); } } // 结果 hashCode:1836019240 hashCode:325040804 null 上面这个例子重写了equals()方法但没有重写hashCode()方法，导致在HashMap里找不到数据，因为如果没有重写hashCode()方法，hashcode()方法的默认实现会为每个对象返回一个不同的int类型的值，所以会导致计算哈希桶位置索引的结果都不一样 总结： 1、阿里巴巴开发规范明确规定 只要重写 equals，就必须重写 hashCode； 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须重写这两个方法； 如果自定义对象做为 Map 的键，那么必须重写 hashCode 和 equals； String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象作为 key 来使用； 2、什么时候需要重写？ 一般的地方不需要重载hashCode，只有当类需要放在HashTable、HashMap、HashSet等等hash结构的集合时才会重载hashCode。 3、为什么equals()相等，hashCode就一定要相等，而hashCode相等，却不要求equals相等? 因为是按照hashCode来访问小内存块，所以hashCode必须相等。 HashMap获取一个对象是比较key的hashCode相等和equals为true。 之所以hashCode相等，却可以equals不等，就比如ObjectA和ObjectB他们都有属性name，那么hashCode都以name计算，所以hashCode一样，但是两个对象属于不同类型，所以equals为false。 4、为什么需要hashCode? 通过hashCode可以很快的查到小内存块。 通过hashCode比较比equals方法快，当get时先比较hashCode，如果hashCode不同，直接返回false。 参考： https://www.liangzl.com/get-article-detail-97291.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-Serializable序列化","slug":"backend/java/basicKnowledge/Java基础-Serializable序列化","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-27T15:11:32.559Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-Serializable序列化/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-Serializable序列化/","excerpt":"","text":"概念什么是序列化 我们的对象并不只是存在内存中，还需要通过网络传输到另一个地方，或者在硬盘保存起来，下次再加载出来用，所以需要Java序列化技术。 Java序列化技术正是将对象转变成一串由二进制字节组成的数组，可以通过将二进制数据保存到磁盘或者传输网络，磁盘或者网络接收者可以在对象的属类的模板上来反序列化类的对象，达到对象持久化的目的。 序列化/反序列化工具类 可以借助commons-lang3工具包里面的org.apache.commons.lang3.SerializationUtils类实现对象的序列化及反序列化，你没有必要自己写。 总结序列化注意事项 序列化对象必须实现序列化接口。 序列化对象里面的属性是对象的话也要实现序列化接口。 类的对象序列化后，类的序列化ID不能轻易修改，不然反序列化会失败。 类的对象序列化后，类的属性有增加或者删除不会影响序列化，只是值会丢失。 如果父类序列化了，子类会继承父类的序列化，子类无需添加序列化接口。 如果父类没有序列化，子类序列化了，子类中的属性能正常序列化，但父类的属性会丢失，不能序列化。 用Java序列化的二进制字节数据只能由Java反序列化，不能被其他语言反序列化。如果要进行前后端或者不同语言之间的交互一般需要将对象转变成Json/Xml通用格式的数据，再恢复原来的对象。 如果某个字段不想序列化，在该字段前加上transient关键字即可。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-Java位运算","slug":"backend/java/basicKnowledge/Java基础-Java位运算","date":"2018-10-09T16:00:00.000Z","updated":"2020-01-04T12:21:52.241Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-Java位运算/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-Java位运算/","excerpt":"","text":"前言 查看Java源码可以发现很多地方使用了位运算符，所以整理下 整理1、&amp;（按位与） ‘ &amp; ’ 符号的作用是对运算符的两侧以二进制表达的操作符按位进行‘与’运算。 只有两个操作数对应位同为1时，结果为1，其余全为0. （或者是只要有一个操作数为0，结果就为0）。 我们可以认为‘1’代表‘true’，‘0’代表‘false’。那么就可以理解为只有都为‘true’的时候才为‘true’，否则就是‘false’。 举例 1234567891011125 &amp; 10 = ?10 的二进制为：10105 的二进制为：0101则 5 &amp; 10 的二进制为 0000，完整的运算为 5 &amp; 10 = 0int i = 12; i &amp;= 7; i = ?‘ &amp;= ’ 的逻辑跟 ‘ += ’ 的处理逻辑是一样的i &amp;= 7 可以看成 i = i &amp; 7所以i = 4 2、|（按位或） ‘ | ’ 符号的作用是对运算符两侧以二进制表达的操作符按位分别进行’或’运算。 只有两个操作数对应位同为1时，结果为1，其余全为0. （或者是只要有一个操作数为1，结果就为1）。 我们可以认为‘1’代表‘true’，‘0’代表‘false’。那么就可以理解为只要有一个为‘true’的时候就为‘true’，否则就是‘false’。 举例 12345675 | 10 = ?10 的二进制为：10105 的二进制为：0101则 5 | 10 的二进制为 1111，完整的运算为 5 | 10 = 15 3、^（按位异或） ‘ ^ ’ 符号的作用是对运算符两侧以二进制表达的操作数按位分别进行’异或’运算。 我们可以认为‘1’代表‘true’，‘0’代表‘false’。那么就可以理解为值不相等的时候为‘true’，值相等的时候为‘false’。 12345675 ^ 10 = ?10 的二进制为：10105 的二进制为：0101则 5 ^ 10 的二进制为 1111，完整的运算为 5 ^ 10 = 15 4、~（按位非） ‘ ~ ’ 符号的作用是将各位数组取反。全部的0变为1，1变为0。 我们可以认为‘1’代表‘true’，‘0’代表‘false’。那么就可以理解为将‘true’变成‘false’，而‘false’变为‘true’。 1234567~ 10 = ?10 的二进制为：1010取反后为：1111 1111 1111 0101则 1111 1111 1111 0101 的十进制为 -11，完整的运算为 ~ 10 = -11 12345678910很多人对负数的二进制的转换很迷惑，在这里为大家讲解下：因为电脑的世界中只有 ‘ 1 ’ 和 ‘ 0 ’ ，所以在表示正负数的时候是从最高位看的，最高位如果为 ‘ 1 ’ 则为负数，如果是 ‘ 0 ’ 则是正数。但是如果负数单纯是把最高位变为1的话，在运算中会出现不是我们想要的值。所以引入了：‘原码’，‘反码’，‘补码’。正数的‘原码’，‘反码’，‘补码’都一样。负数的‘反码’是对除了符号位（最高位）的‘原码’取反，而‘补码’是对‘反码’ + 1，而计算机所采用的就是‘补码’的方式。示例：-11的‘原码’是 ： 1000 0000 0000 1011求出对应的反码 ： 1111 1111 1111 0100求出对应的补码 ： 1111 1111 1111 0101所以在计算机中 ‘ -11 ’ 对应的二进制为 ‘ 1111 1111 1111 0101 ’ 5、&lt;&lt;（左位移运算符） ‘ &lt;&lt; ’ 符号的作用是将一个运算对象的各二进制位全部左移若干位。 左边的二进制位丢弃，右边补0，左移可以看成是乘以2的多少次方。3 &lt;&lt; 3就代表3乘以2的3次方。 123456710 &lt;&lt; 3 = ?10 的二进制为：0000 0000 0000 1010移位后为：0000 0000 0101 0000 （80）则 10 &lt;&lt; 3 = 80 6、&gt;&gt;（右位移运算符） ‘ &gt;&gt; ’ 符号的作用是将一个运算对象的各二进制位全部右移若干位。 正数左补0，负数左补1，右边丢弃。 正数右移可以看成是跟2的多少次方取模，10 &gt;&gt; 3就代表10跟8取模得1。而负数则需要对应的转换，因为负数进行了补码的操作，所以跟正数的逻辑不同 123456710 &gt;&gt; 3 = ?10 的二进制为：0000 0000 0000 1010移位后为：0000 0000 0000 0001则 10 &gt;&gt; 3 = 1 7、&gt;&gt;&gt;（无符号右位移运算符） ‘ &gt;&gt;&gt; ’ 符号的作用是将一个运算对象的各二进制位全部右移若干位。 右移后左边空出的位用零来填充。移出右边的位被丢弃。无符号的意思是将符号位当作数字位看待。 正数的无符号右移可以看成是跟2的多少次方取模，10 &gt;&gt;&gt; 3就代表10跟8取模得1。而负数的无符号右移是不同的，就不需要再进行转换的操作，-1 &gt;&gt;&gt; 1 = 2147483647 123456710 &gt;&gt;&gt; 3 = ?10 的二进制为：0000 0000 0000 1010移位后为：0000 0000 0000 0001则 10 &gt;&gt;&gt; 3 = 1 补充&amp;和&amp;&amp;： 共同点：两者都可做逻辑运算符。它们都表示运算符的两边都是 true 时，结果为 true； 不同点: &amp;也是位运算符。&amp; 表示在运算时两边都会计算，然后再判断；&amp;&amp;表示先运算符号左边的东西，然后判断是否为 true，是 true 就继续运算右边的然后判断并输出，是 false 就停下来直接输出不会再运行后面的东西。 总结 Java位运算是针对于整型（byte、char、short、int、long）数据类型的二进制进行的移位操作。 我为什么要它？位运算的运算效率比直接对数字进行加减乘除高很多，代码需要考虑性能的时候 参考 https://www.cnblogs.com/yuanhailiang/p/9479105.html https://blog.csdn.net/qq_36423017/article/details/82222859","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-JDK各个版本特性","slug":"backend/java/basicKnowledge/Java基础-JDK各个版本特性","date":"2018-10-09T16:00:00.000Z","updated":"2020-03-16T11:43:55.416Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-JDK各个版本特性/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-JDK各个版本特性/","excerpt":"","text":"前言Oracle JDK 和 OpenJDK 的对比 对于Java 7，没什么关键的地方。OpenJDK项目主要基于Sun捐赠的HotSpot源代码。此外，OpenJDK被选为Java 7的参考实现，由Oracle工程师维护。关于JVM，JDK，JRE和OpenJDK之间的区别，Oracle博客帖子在2012年有一个更详细的答案： 问：OpenJDK存储库中的源代码与用于构建Oracle JDK的代码之间有什么区别？ 答：非常接近 - 我们的Oracle JDK版本构建过程基于OpenJDK 7构建，只添加了几个部分，例如部署代码，其中包括Oracle的Java插件和Java WebStart的实现，以及一些封闭的源代码派对组件，如图形光栅化器，一些开源的第三方组件，如Rhino，以及一些零碎的东西，如附加文档或第三方字体。展望未来，我们的目的是开源Oracle JDK的所有部分，除了我们考虑商业功能的部分。 总结： Oracle JDK大概每6个月发一次主要版本，而OpenJDK版本大概每三个月发布一次。但这不是固定的，我觉得了解这个没啥用处。详情参见：https://blogs.oracle.com/java-platform-group/update-and-faq-on-the-java-se-release-cadence。 OpenJDK 是一个参考模型并且是完全开源的，而Oracle JDK是OpenJDK的一个实现，并不是完全开源的； Oracle JDK 比 OpenJDK 更稳定。OpenJDK和Oracle JDK的代码几乎相同，但Oracle JDK有更多的类和一些错误修复。因此，如果您想开发企业/商业软件，我建议您选择Oracle JDK，因为它经过了彻底的测试和稳定。某些情况下，有些人提到在使用OpenJDK 可能会遇到了许多应用程序崩溃的问题，但是，只需切换到Oracle JDK就可以解决问题； 在响应性和JVM性能方面，Oracle JDK与OpenJDK相比提供了更好的性能； Oracle JDK不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本； Oracle JDK根据二进制代码许可协议获得许可，而OpenJDK根据GPL v2许可获得许可。 JDK1.5新特性 1、自动装箱与拆箱： 2、枚举 3、静态导入，如：import staticjava.lang.System.out 4、可变参数（Varargs） 5、内省（Introspector），主要用于操作JavaBean中的属性，通过getXxx/setXxx。一般的做法是通过类Introspector来获取某个对象的BeanInfo信息，然后通过BeanInfo来获取属性的描述器（PropertyDescriptor），通过这个属性描述器就可以获取某个属性对应的getter/setter方法，然后我们就可以通过反射机制来调用这些方法。 6、泛型(Generic)（包括通配类型/边界类型等） 7、For-Each循环 8、注解 9、协变返回类型：实际返回类型可以是要求的返回类型的一个子类型 JDK1.6新特性 1、AWT新增加了两个类:Desktop和SystemTray，其中前者用来通过系统默认程序来执行一个操作，如使用默认浏览器浏览指定的URL,用默认邮件客户端给指定的邮箱发邮件,用默认应用程序打开或编辑文件(比如,用记事本打开以txt为后缀名的文件),用系统默认的打印机打印文档等。后者可以用来在系统托盘区创建一个托盘程序 2、使用JAXB2来实现对象与XML之间的映射，可以将一个Java对象转变成为XML格式，反之亦然 3、StAX，一种利用拉模式解析(pull-parsing)XML文档的API。类似于SAX，也基于事件驱动模型。之所以将StAX加入到JAXP家族，是因为JDK6中的JAXB2和JAX-WS 2.0中都会用StAX。 4、使用Compiler API，动态编译Java源文件，如JSP编译引擎就是动态的，所以修改后无需重启服务器。 5、轻量级Http Server API，据此可以构建自己的嵌入式HttpServer,它支持Http和Https协议。 6、插入式注解处理API(PluggableAnnotation Processing API) 7、提供了Console类用以开发控制台程序，位于java.io包中。据此可方便与Windows下的cmd或Linux下的Terminal等交互。 8、对脚本语言的支持如: ruby,groovy, javascript 9、Common Annotations，原是J2EE 5.0规范的一部分，现在把它的一部分放到了J2SE 6.0中 10、嵌入式数据库 Derby JDK1.7新特性 1、对Java集合（Collections）的增强支持，可直接采用[]、{}的形式存入对象，采用[]的形式按照索引、键值来获取集合中的对象。如： 代码示例123456789List&lt;String&gt;list=[“item1”,”item2”];//存Stringitem=list[0];//直接取Set&lt;String&gt;set=&#123;“item1”,”item2”,”item3”&#125;;//存Map&lt;String,Integer&gt; map=&#123;“key1”:1,”key2”:2&#125;;//存Intvalue=map[“key1”];//取 2、在Switch中可用String 3、数值可加下划线用作分隔符（编译时自动被忽略） 4、支持二进制数字，如：int binary= 0b1001_1001; 5、简化了可变参数方法的调用 6、调用泛型类的构造方法时，可以省去泛型参数，编译器会自动判断。 7、Boolean类型反转，空指针安全,参与位运算 8、char类型的equals方法: booleanCharacter.equalsIgnoreCase(char ch1, char ch2) 9、安全的加减乘除: Math.safeToInt(longv); Math.safeNegate(int v); Math.safeSubtract(long v1, int v2);Math.safeMultiply(int v1, int v2)…… 10 、Map集合支持并发请求，注HashTable是线程安全的，Map是非线程安全的。但此处更新使得其也支持并发。另外，Map对象可这样定义：Map map = {name:”xxx”,age:18}; JDK1.8新特性 1、接口的默认方法 简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法 代码：12345public interface Vehicle &#123; default void print()&#123; System.out.println(\"我是一辆车!\"); &#125;&#125; 2、Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性，Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）： 代码123456Collections.sort(names,(String a, String b) -&gt; &#123; returnb.compareTo(a); &#125;);// 对于函数体只有一行代码的，你可以去掉大括号&#123;&#125;以及return关键字。如：Collections.sort(names,(String a, String b) -&gt; b.compareTo(a));Collections.sort(names, (a, b) -&gt; b.compareTo(a)); 3、Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 4、Date Time API − 加强对日期与时间的处理。 5、函数式接口：是指仅仅只包含一个抽象方法的接口，要加@FunctionalInterface注解 6、方法引用： 使用 :: 关键字来传递方法或者构造函数引用 方法引用通过方法的名字来指向一个方法，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 下面，我们在 Car 类中定义了 4 个方法作为例子来区分 Java 中 4 种不同方法的引用。12345678910111213141516171819202122232425262728293031323334353637package com.runoob.main; @FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; class Car &#123; //Supplier是jdk1.8的接口，这里和lamda一起使用了 public static Car create(final Supplier&lt;Car&gt; supplier) &#123; return supplier.get(); &#125; public static void collide(final Car car) &#123; System.out.println(\"Collided \" + car.toString()); &#125; public void follow(final Car another) &#123; System.out.println(\"Following the \" + another.toString()); &#125; public void repair() &#123; System.out.println(\"Repaired \" + this.toString()); &#125;&#125;public static void main(String[] args) &#123; // 1、构造器引用它的语法是Class::new，或者更一般的Class&lt; T &gt;::new实例如下 final Car car = Car.create( Car::new ); final List&lt; Car &gt; cars = Arrays.asList( car ); // 2、静态方法引用：它的语法是Class::static_method，实例如下： cars.forEach( Car::collide ); // 3、特定类的任意对象的方法引用：它的语法是Class::method实例如下： cars.forEach( Car::repair ); // 4、特定对象的方法引用：它的语法是instance::method实例如下： final Car police = Car.create( Car::new ); cars.forEach( police::follow );&#125; 7、多重注解 8、还增加了很多与函数式接口类似的接口以及与Map相关的API等…… 9、新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 10、Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 11、Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。 JDK1.9新特性 1、Java 平台级模块系统 当启动一个模块化应用时， JVM 会验证是否所有的模块都能使用，这基于 requires 语句——比脆弱的类路径迈进了一大步。模块允许你更好地强制结构化封装你的应用并明确依赖。 2、Linking 当你使用具有显式依赖关系的模块和模块化的 JDK 时，新的可能性出现了。你的应用程序模块现在将声明其对其他应用程序模块的依赖以及对其所使用的 JDK 模块的依赖。为什么不使用这些信息创建一个最小的运行时环境，其中只包含运行应用程序所需的那些模块呢？ 这可以通过 Java 9 中的新的 jlink 工具实现。你可以创建针对应用程序进行优化的最小运行时映像而不需要使用完全加载 JDK 安装版本。 3、JShell : 交互式 Java REPL 许多语言已经具有交互式编程环境，Java 现在加入了这个俱乐部。您可以从控制台启动 jshell ，并直接启动输入和执行 Java 代码。 jshell 的即时反馈使它成为探索 API 和尝试语言特性的好工具。 4、改进的 Javadoc Javadoc 现在支持在 API 文档中的进行搜索。另外，Javadoc 的输出现在符合兼容 HTML5 标准。此外，你会注意到，每个 Javadoc 页面都包含有关 JDK 模块类或接口来源的信息。 5、集合工厂方法 通常，您希望在代码中创建一个集合（例如，List 或 Set ），并直接用一些元素填充它。 实例化集合，几个 “add” 调用，使得代码重复。 Java 9，添加了几种集合工厂方法：12Set&lt;Integer&gt; ints = Set.of(1,2,3);List&lt;String&gt; strings = List.of(\"first\",\"second\"); 6、改进的 Stream API 长期以来，Stream API 都是 Java 标准库最好的改进之一。通过这套 API 可以在集合上建立用于转换的申明管道。在 Java 9 中它会变得更好。Stream 接口中添加了 4 个新的方法：dropWhile, takeWhile, ofNullable。还有个 iterate 方法的新重载方法，可以让你提供一个 Predicate (判断条件)来指定什么时候结束迭代： 代码：1IntStream.iterate(1, i -&gt; i &lt; 100, i -&gt; i + 1).forEach(System.out::println); 7、私有接口方法 如果您使用默认方法开发 API ，那么私有接口方法可能有助于构建其实现。 使用 Java 9，您可以向接口添加私有辅助方法：12345678public interface MyInterface &#123; void normal InterfaceMethod(); default void interface MethodWithDefault() &#123; init(); &#125; default void anotherDefaultMethod() &#123; init(); &#125; private void init() &#123; System.out.println(\"Initializing\"); &#125;&#125; 8、HTTP/2 Java 9 中有新的方式来处理 HTTP 调用。这个迟到的特性用于代替老旧的 HttpURLConnection API，并提供对 WebSocket 和 HTTP/2 的支持。注意：新的 HttpClient API 在 Java 9 中以所谓的孵化器模块交付。也就是说，这套 API 不能保证 100% 完成。不过你可以在 Java 9 中开始使用这套 API： 1234567HttpClient client = HttpClient.newHttpClient();HttpRequest req = HttpRequest.newBuilder(URI.create(\"http://www.google.com\")) .header(\"User-Agent\",\"Java\") .GET() .build();HttpResponse&lt;String&gt; resp = client.send(req, HttpResponse.BodyHandler.asString());HttpResponse&lt;String&gt; resp = client.send(req, HttpResponse.BodyHandler.asString()); 除了这个简单的请求/响应模型之外，HttpClient 还提供了新的 API 来处理 HTTP/2 的特性，比如流和服务端推送。 9、多版本兼容 JAR JDK10新特性 JEP 286: 局部变量的类型推导。该特性在社区讨论了很久并做了调查，可查看 JEP 286 调查结果。 JEP 296: 将 JDK 的多个代码仓库合并到一个储存库中。 JEP 304: 垃圾收集器接口。通过引入一个干净的垃圾收集器（GC）接口，改善不同垃圾收集器的源码隔离性。 JEP 307: 向 G1 引入并行 Full GC。 JEP 310: 应用类数据共享。为改善启动和占用空间，在现有的类数据共享（“CDS”）功能上再次拓展，以允许应用类放置在共享存档中。 JEP 312: 线程局部管控。允许停止单个线程，而不是只能启用或停止所有线程。 JEP 313: 移除 Native-Header Generation Tool (javah) JEP 314: 额外的 Unicode 语言标签扩展。包括：cu (货币类型)、fw (每周第一天为星期几)、rg (区域覆盖)、tz (时区) 等。 JEP 316: 在备用内存设备上分配堆内存。允许 HotSpot 虚拟机在备用内存设备上分配 Java 对象堆。 JEP 317: 基于 Java 的 JIT 编译器（试验版本）。 JEP 319: 根证书。开源 Java SE Root CA 程序中的根证书。 JEP 322: 基于时间的版本发布模式。“Feature releases” 版本将包含新特性，“Update releases” 版本仅修复 Bug 。 参考 https://www.jianshu.com/p/37b52f1ebd4a https://www.runoob.com/ https://snailclimb.gitee.io/javaguide/#/docs/java/Java基础知识","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-Java8-Stream","slug":"backend/java/basicKnowledge/Java基础-Java8-Stream","date":"2018-10-09T16:00:00.000Z","updated":"2020-03-16T11:43:55.419Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-Java8-Stream/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-Java8-Stream/","excerpt":"","text":"前言 Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。 Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。 Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。 这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。 元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。 示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Testpublic void test1 () &#123; // 在 Java 8 中, 集合接口有两个方法来生成流：1、stream() − 为集合创建串行流。 2、parallelStream() − 为集合创建并行流。 List&lt;String&gt; strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\"); List&lt;String&gt; filtered1 = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList()); System.out.println(filtered1);&#125;@Testpublic void test2() &#123; // forEach Stream 提供了新的方法 'forEach' 来迭代流中的每个数据。以下代码片段使用 forEach 输出了10个随机数： Random random = new Random(); random.ints().limit(10).forEach(System.out::println);&#125;@Testpublic void test3() &#123; // map 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数： List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); // 获取对应的平方数 List&lt;Integer&gt; squaresList = numbers.stream().map( i -&gt; i*i).distinct().collect(Collectors.toList());&#125;@Testpublic void test4() &#123; // filter 方法用于通过设置的条件过滤出元素。以下代码片段使用 filter 方法过滤出空字符串： List&lt;String&gt;strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\"); // 获取空字符串的数量 long count = strings.stream().filter(string -&gt; string.isEmpty()).count();&#125;@Testpublic void test5() &#123; // limit 方法用于获取指定数量的流。 以下代码片段使用 limit 方法打印出 10 条数据： Random random = new Random(); random.ints().limit(10).forEach(System.out::println);&#125;@Testpublic void test6() &#123; // sorted sorted 方法用于对流进行排序。以下代码片段使用 sorted 方法对输出的 10 个随机数进行排序： Random random = new Random(); random.ints().limit(10).sorted().forEach(System.out::println);&#125;@Testpublic void test7() &#123; // 并行（parallel）程序 parallelStream 是流并行处理程序的代替方法。以下实例我们使用 parallelStream 来输出空字符串的数量： List&lt;String&gt; strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\"); // 获取空字符串的数量 long count = strings.parallelStream().filter(string -&gt; string.isEmpty()).count(); System.out.println(count);&#125;@Testpublic void test8 () &#123; // Collectors 类实现了很多归约操作，例如将流转换成集合和聚合元素。Collectors 可用于返回列表或字符串： List&lt;String&gt;strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\"); List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList()); System.out.println(\"筛选列表: \" + filtered); String mergedString = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.joining(\", \")); System.out.println(\"合并字符串: \" + mergedString);&#125;@Testpublic void test9 () &#123; // 另外，一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上，它们可以用来产生类似如下的统计结果。 List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); IntSummaryStatistics stats = numbers.stream().mapToInt((x) -&gt; x).summaryStatistics(); System.out.println(\"列表中最大的数 : \" + stats.getMax()); System.out.println(\"列表中最小的数 : \" + stats.getMin()); System.out.println(\"所有数之和 : \" + stats.getSum()); System.out.println(\"平均数 : \" + stats.getAverage());&#125; 参考 https://www.runoob.com/java/java8-streams.html","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-ASCII 160 空格","slug":"backend/java/basicKnowledge/Java基础-ASCII 160 空格","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-10T02:08:41.928Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-ASCII 160 空格/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-ASCII 160 空格/","excerpt":"","text":"场景 获取从http传输过来的字符串的时候，碰到解析字符串不能分割字符串的情况 12String str = doc.get(0); // str = \"江西省 赣州市\"String [] area = str.spilt(\"\\\\s+\"); 运行上面的代码的时候发现不能截取字符串, 初步怀疑是编码问题，然而经过验证发现并不是,然后就通过字符串截取成 char 字符发现，该char字符ASCII是160, 马上查找资料发现是空格分两种编码格式: 1: 普通的空格,ASCII码为32 2:第二种是 网页上的 &amp;nbsp 空格,ASCII为160, 才发现空格也是有多种情况 解决方法:12// 需要将ASCII为160的空格转成普通的空格str = str.replaceAll(\"[\\\\s\\\\u00A0]+\", \" \");","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"Java基础-Exception与RuntimeException","slug":"backend/java/basicKnowledge/Java基础-Exception与RuntimeException","date":"2018-10-09T16:00:00.000Z","updated":"2019-11-27T15:11:32.511Z","comments":true,"path":"2018/10/10/backend/java/basicKnowledge/Java基础-Exception与RuntimeException/","link":"","permalink":"http://www.songshuiyang.com/2018/10/10/backend/java/basicKnowledge/Java基础-Exception与RuntimeException/","excerpt":"","text":"概述 Java 的异常体系，基于共同的祖先 java.lang.Throwable 类。如下图所示： Java异常体系分为 Error错误，表示系统级的错误和程序不必处理的异常，是 Java 运行环境中的内部错误或者硬件问题。 例如：内存资源不足等。 对于这种错误，程序基本无能为力，除了退出运行外别无选择，它是由 Java 虚拟机抛出的。 Exception异常 Exception: （检查型异常）在程序中必须使用 异常处理块 可以恢复的情况使用检查型异常 RuntimeException ：(运行时异常)可以不使用 异常处理块，如果有异常产生，将由 JVM 进行处理。 对编程错误使用运行时异常 常见的RuntimeException: ClassCastException NullPointerException ArrayIndexOutOfBoundsException IllegalArgumentException NumberFormatException","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://www.songshuiyang.com/tags/Java基础/"}]},{"title":"spring-data-jpa","slug":"backend/framework/spring/spring-data/spring-data-jpa","date":"2018-09-10T11:01:44.000Z","updated":"2018-10-15T12:32:16.771Z","comments":true,"path":"2018/09/10/backend/framework/spring/spring-data/spring-data-jpa/","link":"","permalink":"http://www.songshuiyang.com/2018/09/10/backend/framework/spring/spring-data/spring-data-jpa/","excerpt":"","text":"logo logo logo","categories":[{"name":"服务器","slug":"服务器","permalink":"http://www.songshuiyang.com/categories/服务器/"}],"tags":[{"name":"jpa","slug":"jpa","permalink":"http://www.songshuiyang.com/tags/jpa/"}]},{"title":"工具类-BigDecimal","slug":"backend/java/utils/工具类-BigDecimal","date":"2018-09-05T01:24:12.000Z","updated":"2020-03-16T11:43:55.524Z","comments":true,"path":"2018/09/05/backend/java/utils/工具类-BigDecimal/","link":"","permalink":"http://www.songshuiyang.com/2018/09/05/backend/java/utils/工具类-BigDecimal/","excerpt":"","text":"构造函数 参数类型为double的构造方法的结果有一定的不可预知性。有人可能认为在Java中写入newBigDecimal(0.1)所创建的BigDecimal正好等于 0.1（非标度值 1，其标度为 1），但是它实际上等于0.1000000000000000055511151231257827021181583404541015625。这是因为0.1无法准确地表示为 double（或者说对于该情况，不能表示为任何有限长度的二进制小数）。这样，传入到构造方法的值不会正好等于 0.1（虽然表面上等于该值）。 另一方面，String 构造方法是完全可预知的：写入 newBigDecimal(“0.1”) 将创建一个 BigDecimal，它正好等于预期的 0.1。因此，比较而言，通常建议优先使用String构造方法。 当double必须用作BigDecimal的源时，请注意，此构造方法提供了一个准确转换；它不提供与以下操作相同的结果：先使用Double.toString(double)方法，然后使用BigDecimal(String)构造方法，将double转换为String。要获取该结果，请使用static valueOf(double)方法。 运算 减乘除其实最终都返回的是一个新的BigDecimal对象，因为BigInteger与BigDecimal都是不可变的（immutable）的，在进行每一步运算时，都会产生一个新的对象，所以a.add(b);虽然做了加法操作，但是a并没有保存加操作后的值，正确的用法应该是a=a.add(b); 精度1234567891011121314151617BigDecimal.setScale() 方法用于格式化小数点setScale(1) 表示保留一位小数，默认用四舍五入方式setScale(1,BigDecimal.ROUND_DOWN) 直接删除多余的小数位，2.31变成2.3、2.35会变成2.3setScale(1,BigDecimal.ROUND_UP) 进位处理，2.31变成2.4 2.35变成2.4 setScale(1,BigDecimal.ROUND_CEILING) 如果为正数，则舍入行为与 ROUND_UP 相同，反之舍入行为与 ROUND_DOWN 相同setScale(1,BigDecimal.ROUND_FLOOR) 如果为正数，则舍入行为与 ROUND_DOWN 相同，反之舍入行为与 ROUND_UP 相同setScale(1,BigDecimal.ROUND_HALF_UP) 四舍五入，2.35变成2.4setScale(1,BigDecimal.ROUND_HALF_DOWN) 四舍五入，2.35变成2.3(如果是5则向下舍)，2.36变成2.4setScale(1,BigDecimal.ROUND_HALF_EVEN) 银行家舍入法 如果舍弃部分左边的数字为奇数，则舍入行为与 ROUND_HALF_UP 相同 如果为偶数，则舍入行为与 ROUND_HALF_DOWN 相同。如 1.15&gt;1.2 1.25&gt;1.2 异常处理foo.divide(bar)); 报异常1java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result。 原因： 1234567891011121314151617原来JAVA中如果用BigDecimal做除法的时候一定要在divide方法中传递第二个参数，定义精确到小数点后几位，否则在不整除的情况下，结果是无限循环小数时，就会抛出以上异常。解决方法：foo.divide(bar, 2, BigDecimal.ROUND_HALF_UP);注意这个divide方法有两个重载的方法，一个是传两个参数的，一个是传三个参数的：两个参数的方法：@param divisor value by which this &#123;@code BigDecimal&#125; is to be divided. 传入除数@param roundingMode rounding mode to apply. 传入round的模式三个参数的方法：@param divisor value by which this &#123;@code BigDecimal&#125; is to be divided. 传入除数@param scale scale of the &#123;@code BigDecimal&#125; quotient to be returned. 传入精度@param roundingMode rounding mode to apply. 传入round的模式","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"工具类-guava工具包","slug":"backend/java/utils/工具类-guava工具包","date":"2018-09-01T07:11:12.000Z","updated":"2020-03-16T11:43:55.528Z","comments":true,"path":"2018/09/01/backend/java/utils/工具类-guava工具包/","link":"","permalink":"http://www.songshuiyang.com/2018/09/01/backend/java/utils/工具类-guava工具包/","excerpt":"","text":"驼峰字符和下划线字符相互转换工具类导入Maven12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;21.0&lt;/version&gt;&lt;/dependency&gt; 示例：12345678910111213141516import org.junit.Test;import com.google.common.base.CaseFormat;public class GuavaTester &#123; @Test public void test() &#123; System.out.println(CaseFormat.LOWER_HYPHEN.to(CaseFormat.LOWER_CAMEL, \"test-data\"));//testData System.out.println(CaseFormat.LOWER_UNDERSCORE.to(CaseFormat.LOWER_CAMEL, \"test_data\"));//testData System.out.println(CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL, \"test_data\"));//TestData System.out.println(CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, \"testdata\"));//testdata System.out.println(CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, \"TestData\"));//test_data System.out.println(CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_HYPHEN, \"testData\"));//test-data &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"高可用","slug":"backend/server/JavaEE服务器/高可用","date":"2018-07-31T16:24:12.000Z","updated":"2020-03-16T11:43:55.561Z","comments":true,"path":"2018/08/01/backend/server/JavaEE服务器/高可用/","link":"","permalink":"http://www.songshuiyang.com/2018/08/01/backend/server/JavaEE服务器/高可用/","excerpt":"","text":"一、什么是高可用 高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。 假设系统一直能够提供服务，我们说系统的可用性是100%。 如果系统每运行100个时间单位，会有1个时间单位无法提供服务，我们说系统的可用性是99%。 很多公司的高可用目标是4个9，也就是99.99%，这就意味着，系统的年停机时间为8.76个小时。 百度的搜索首页，是业内公认高可用保障非常出色的系统，甚至人们会通过www.baidu.com 能不能访问来判断“网络的连通性”，百度高可用的服务让人留下啦“网络通畅，百度就能访问”，“百度打不开，应该是网络连不上”的印象，这其实是对百度最高的褒奖。 如何保障系统的高可用我们都知道，单点是系统高可用的大敌，单点往往是系统高可用最大的风险和敌人，应该尽量在系统设计的过程中避免单点。方法论上，高可用保证的原则是“集群化”，或者叫“冗余”：只有一个单点，挂了服务会受影响；如果有冗余备份，挂了还有其他backup能够顶上。 保证系统高可用，架构设计的核心准则是：冗余。 有了冗余之后，还不够，每次出现故障需要人工介入恢复势必会增加系统的不可服务实践。所以，又往往是通过“自动故障转移”来实现系统的高可用。 接下来我们看下典型互联网架构中，如何通过冗余+自动故障转移来保证系统的高可用特性。 分层高可用架构实践下面的图是常见的互联网分层架构 logo 【客户端层】到【反向代理层】的高可用， 是通过反向代理层的冗余来实现的。以nginx为例：有两台nginx，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是keepalived存活探测，相同virtual IP提供服务。 自动故障转移：当nginx挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-nginx，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的。 【反向代理层-&gt;站点层】的高可用 【反向代理层】到【站点层】的高可用，是通过站点层的冗余来实现的。假设反向代理层是nginx，nginx.conf里能够配置多个web后端，并且nginx能够探测到多个后端的存活性。 自动故障转移：当web-server挂了的时候，nginx能够探测到，会自动的进行故障转移，将流量自动迁移到其他的web-server，整个过程由nginx自动完成，对调用方是透明的。 【站点层-&gt;服务层】的高可用 【站点层】到【服务层】的高可用，是通过服务层的冗余来实现的。“服务连接池”会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。 自动故障转移：当service挂了的时候，service-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的service，整个过程由连接池自动完成，对调用方是透明的（所以说RPC-client中的服务连接池是很重要的基础组件）。 【服务层&gt;数据库层】的高可用 大部分互联网技术，数据库层都用了“主从同步，读写分离”架构，所以数据库层的高可用，又分为“读库高可用”与“写库高可用”两类。 参考： https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651959728&amp;idx=1&amp;sn=933227840ec8cdc35d3a33ae3fe97ec5&amp;chksm=bd2d046c8a5a8d7a13551124af36bedf68f7a6e31f6f32828678d2adb108b86b7e08c678f22f&amp;scene=21#wechat_redirect","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"基于 CentOS 搭建 Jenkins 自动化部署服务","slug":"backend/server/centos/基于 CentOS 搭建 Jenkins服务","date":"2018-07-20T12:48:12.000Z","updated":"2019-11-10T02:08:42.088Z","comments":true,"path":"2018/07/20/backend/server/centos/基于 CentOS 搭建 Jenkins服务/","link":"","permalink":"http://www.songshuiyang.com/2018/07/20/backend/server/centos/基于 CentOS 搭建 Jenkins服务/","excerpt":"","text":"需求： 使用 Jenkins 完成 git + Maven项目 + Tomcat 自动化部署 一： 环境准备1. Jenkins环境准备1.1 安装 jenkins-2.7.3123wget http://pkg.jenkins-ci.org/redhat-stable/jenkins-2.7.3-1.1.noarch.rpmrpm -ivh jenkins-2.7.3-1.1.noarch.rpm 1.2 配置启动12345678910111213141516171819202122232425262728291. 修改配置文件，默认端口为8080，如果不冲突则不需要修改 vim /etc/sysconfig/jenkins JENKINS_PORT=\"9080\"2. 配置JDK,启动服务如果报Java路径错误, 需要到vim /etc/profile 查看java路径 修改Jenkins启动配置文件，指定java安装路径。 /usr/local/jdk1.8.0_181/bin/java vim /etc/init.d/jenkins 在candidates中第一行添加java路径，如下： candidates=\" /usr/local/jdk1.8.0_181/bin/java /etc/alternatives/java /usr/lib/jvm/java-1.6.0/bin/java /usr/lib/jvm/jre-1.6.0/bin/java /usr/lib/jvm/java-1.7.0/bin/java /usr/lib/jvm/jre-1.7.0/bin/java /usr/lib/jvm/java-1.8.0/bin/java /usr/lib/jvm/jre-1.8.0/bin/java /usr/bin/java \" 3. 修改jenkins用户 为\"root\"用户4. 启动jenkins服务service jenkins restart5. 启动完成之后即可通过ip 端口进行访问 logo 2. Git 环境准备1234567安装git[root@iZwz9fjhnq78zfjphj8hi4Z bin]# yum –y install git查看是否安装成功[root@iZwz9fjhnq78zfjphj8hi4Z bin]# git --versiongit version 1.8.3.1 3. Maven 环境准备3.1 安装1234567cd /usr/localwget http://mirror.bit.edu.cn/apache/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gztar zxf apache-maven-3.5.4-bin.tar.gzmv apache-maven-3.5.4 /usr/local/maven-3.5.4 3.2 配置环境变量1234567891011vi /etc/profile然后还需要 配置环境变量。#在适当的位置添加export M2_HOME=/usr/local/maven-3.5.4export PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin保存退出后运行下面的命令使配置生效，或者重启服务器生效。source /etc/profile验证版本mvn -v 3.3 更换库源 阿里maven库123456789101112（1）找到 apache-maven-3.5.2\\conf 目录中的 settings.xml 文件（2）修改maven 本地仓库地址, 首先在D:\\Program Files创建文件夹MavenRepository ； 找到settings.xml 文件中 &lt;localRepository&gt; &lt;/localRepository&gt;打开注释修改如下： &lt;localRepository&gt;D:\\Program Files\\MavenRepository&lt;/localRepository&gt;（3）添加阿里源 ，找到 &lt;mirrors&gt; &lt;/ mirrors&gt;标签，在标签内部 添加内容如下： &lt;mirror&gt; &lt;id&gt;AliMaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; 4. 使用Jenkins4.1 配置工具环境配置上面的环境都准备好了之后，先配置一下 参数(系统管理-&gt; 全局工具配置) git不用配置使用默认 logo logo logo 4.2 创建一个任务1.点击创建任务，如果在创建项目时候，没有“创建一个Maven 项目”的选项。你需要安装Maven项目插件：Maven Integration plugin 。 logo 2.配置源码管理，jenkins会自动拉取代码放到/var/lib/jenkins/workspace/任务名 路径下 logo 3.配置Maven构建，构建完后会自动打包 logo 4.编写shell脚本，maven构建完成之后就是把打好的包放在tomcat下了并启动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#!/bin/bash#引入了系统环境变量，这样系统环境变量里面没有export声明的也可以用source /etc/profiletomcat_home=/usr/local/tomcat-8.0.48SHUTDOWN=$tomcat_home/bin/shutdown.shSTARTTOMCAT=$tomcat_home/bin/startup.shecho \"停止tomcat服务 /usr/local/tomcat8.0.48/bin/shutdown.sh\"#/usr/local/tomcat8.0.48/bin/shutdown.shecho \"关闭$tomcat_home\"$SHUTDOWNpidlist=`ps -ef |grep tomcat |grep -v \"grep\"|awk '&#123;print $2&#125;'`kill -9 $pidlistecho \"开始删除文件夹 usr/local/tomcat8.0.48/webapps/blogsys-parent\"rm -rf $tomcat_home/webapps/blogsys-parentecho \"开始删除文件 /usr/local/tomcat8.0.48/webapps/blogsys-parent.war\"rm -rf $tomcat_home/webapps/blogsys-parent.warecho \"开始拷贝文件 blogsys-parent.war 拷贝文件目录：/var/lib/jenkins/workspace/blogsys-parent/blogsys-admin/target &gt;&gt; /usr/local/tomcat8.0.48/webapps\"cp -ar /var/lib/jenkins/workspace/blogsys-parent/blogsys-admin/target/blogsys-parent.war $tomcat_home/webapps/blogsys-parent.warecho \"查找文件\"find $tomcat_home/webapps/ -name blogsys-parent.warecho \"启动$tomcat_home\"$STARTTOMCATecho \"延时5秒\"sleep 5echo \"关闭$tomcat_home\"$SHUTDOWNpidlist=`ps -ef |grep tomcat |grep -v \"grep\"|awk '&#123;print $2&#125;'`kill -9 $pidlistecho \"延时5秒重新启动\"sleep 5# 脚本中功能是复制替换某两个配置文件，然后关闭tomcat，重启Tomcat。但是，Tomcat只是启动了一下，就关闭了，并没有启动Tomcat的进程。在网上查了资料，需要在执行脚本之前加入：export BUILD_ID=XXXXXXexport BUILD_ID=dontKillMeecho \"启动$tomcat_home\"$STARTTOMCATecho \"延时10秒\"sleep 10echo \"打印日志开始-》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》\"tail -2000 $&#123;tomcat_home&#125;/logs/catalina.out``` ##### 启动任务可以看到日志输出```bashStarted by user songshuiyangBuilding in workspace /var/lib/jenkins/workspace/blogsys-parent &gt; git rev-parse --is-inside-work-tree # timeout=10Fetching changes from the remote Git repository &gt; git config remote.origin.url https://gitee.com/songshuiyang/blogsys-parent.git # timeout=10Fetching upstream changes from https://gitee.com/songshuiyang/blogsys-parent.git &gt; git --version # timeout=10using GIT_ASKPASS to set credentials 码云账号 &gt; git fetch --tags --progress https://gitee.com/songshuiyang/blogsys-parent.git +refs/heads/*:refs/remotes/origin/* &gt; git rev-parse refs/remotes/origin/master^&#123;commit&#125; # timeout=10 &gt; git rev-parse refs/remotes/origin/origin/master^&#123;commit&#125; # timeout=10Checking out Revision 926c54ff215417d928b32201b50e2c2cb40b6ba8 (refs/remotes/origin/master) &gt; git config core.sparsecheckout # timeout=10 &gt; git checkout -f 926c54ff215417d928b32201b50e2c2cb40b6ba8Commit message: \"优化 修复pom问题\" &gt; git rev-list --no-walk 926c54ff215417d928b32201b50e2c2cb40b6ba8 # timeout=10Parsing POMsEstablished TCP socket on 40447[blogsys-parent] $ /usr/local/jdk1.8.0_181/bin/java -cp /var/lib/jenkins/plugins/maven-plugin/WEB-INF/lib/maven35-agent-1.12-alpha-1.jar:/usr/local/maven-3.5.4/boot/plexus-classworlds-2.5.2.jar:/usr/local/maven-3.5.4/conf/logging jenkins.maven3.agent.Maven35Main /usr/local/maven-3.5.4 /var/cache/jenkins/war/WEB-INF/lib/remoting-3.23.jar /var/lib/jenkins/plugins/maven-plugin/WEB-INF/lib/maven35-interceptor-1.12-alpha-1.jar /var/lib/jenkins/plugins/maven-plugin/WEB-INF/lib/maven3-interceptor-commons-1.12-alpha-1.jar 40447&lt;===[JENKINS REMOTING CAPACITY]===&gt;channel startedExecuting Maven: -B -f /var/lib/jenkins/workspace/blogsys-parent/pom.xml clean install -Dmaven.test.skip=true[INFO] Scanning for projects...[WARNING] [WARNING] Some problems were encountered while building the effective model for com.ecut:blogsys-admin:war:0.0.1-SNAPSHOT[WARNING] 'dependencies.dependency.systemPath' for json:json:jar should not point at files within the project directory, $&#123;project.basedir&#125;/src/main/webapp/WEB-INF/lib/json.jar will be unresolvable by dependent projects @ line 25, column 19[WARNING] 'dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: com.fasterxml.jackson.core:jackson-databind:jar -&gt; version $&#123;jackson-databind.version&#125; vs 2.7.4 @ com.ecut:blogsys-parent:0.0.1-SNAPSHOT, /var/lib/jenkins/workspace/blogsys-parent/pom.xml, line 244, column 21[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-surefire-plugin is missing. @ com.ecut:blogsys-parent:0.0.1-SNAPSHOT, /var/lib/jenkins/workspace/blogsys-parent/pom.xml, line 383, column 21[WARNING] 'build.plugins.plugin.version' for org.springframework.boot:spring-boot-maven-plugin is missing. @ com.ecut:blogsys-parent:0.0.1-SNAPSHOT, /var/lib/jenkins/workspace/blogsys-parent/pom.xml, line 407, column 21[WARNING] [WARNING] Some problems were encountered while building the effective model for com.ecut:blogsys-core:jar:0.0.1-SNAPSHOT[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-surefire-plugin is missing. @ com.ecut:blogsys-parent:0.0.1-SNAPSHOT, /var/lib/jenkins/workspace/blogsys-parent/pom.xml, line 383, column 21[WARNING] 'build.plugins.plugin.version' for org.springframework.boot:spring-boot-maven-plugin is missing. @ com.ecut:blogsys-parent:0.0.1-SNAPSHOT, /var/lib/jenkins/workspace/blogsys-parent/pom.xml, line 407, column 21[WARNING] [WARNING] Some problems were encountered while building the effective model for com.ecut:blogsys-parent:pom:0.0.1-SNAPSHOT[WARNING] 'dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: com.fasterxml.jackson.core:jackson-databind:jar -&gt; version $&#123;jackson-databind.version&#125; vs 2.7.4 @ line 244, column 21[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-surefire-plugin is missing. @ line 383, column 21[WARNING] 'build.plugins.plugin.version' for org.springframework.boot:spring-boot-maven-plugin is missing. @ line 407, column 21[WARNING] [WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.[WARNING] [WARNING] For this reason, future Maven versions might no longer support building such malformed projects.[WARNING] [INFO] ------------------------------------------------------------------------[INFO] Reactor Build Order:[INFO] [INFO] blogsys-parent [pom][INFO] blogsys-admin [war][INFO] blogsys-core [jar][INFO] [INFO] ----------------------&lt; com.ecut:blogsys-parent &gt;-----------------------[INFO] Building blogsys-parent 0.0.1-SNAPSHOT [1/3][INFO] --------------------------------[ pom ]---------------------------------[INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ blogsys-parent ---[INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ blogsys-parent ---[INFO] Installing /var/lib/jenkins/workspace/blogsys-parent/pom.xml to /root/.m2/repository/com/ecut/blogsys-parent/0.0.1-SNAPSHOT/blogsys-parent-0.0.1-SNAPSHOT.pom[WARNING] Attempt to (de-)serialize anonymous class hudson.maven.reporters.MavenArtifactArchiver$2; see: https://jenkins.io/redirect/serialization-of-anonymous-classes/[WARNING] Attempt to (de-)serialize anonymous class hudson.maven.reporters.MavenFingerprinter$1; see: https://jenkins.io/redirect/serialization-of-anonymous-classes/[INFO] [INFO] -----------------------&lt; com.ecut:blogsys-admin &gt;-----------------------[INFO] Building blogsys-admin 0.0.1-SNAPSHOT [2/3][INFO] --------------------------------[ war ]---------------------------------[INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ blogsys-admin ---[INFO] Deleting /var/lib/jenkins/workspace/blogsys-parent/blogsys-admin/target[INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ blogsys-admin ---[INFO] Using 'UTF-8' encoding to copy filtered resources.[INFO] Copying 32 resources[INFO] [INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ blogsys-admin ---[INFO] Compiling 164 source files to /var/lib/jenkins/workspace/blogsys-parent/blogsys-admin/target/classes[WARNING] /var/lib/jenkins/workspace/blogsys-parent/blogsys-admin/src/main/java/com/ecut/core/shiro/SecurityUtils.java:[8,15] BASE64Encoder is internal proprietary API and may be removed in a future release[WARNING] /var/lib/jenkins/workspace/blogsys-parent/blogsys-admin/src/main/java/com/ecut/core/utils/elven/encryption/DesEncryptUtils.java:[8,15] BASE64Decoder is internal proprietary API and may be removed in a future release.....","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"},{"name":"Jenkins","slug":"Jenkins","permalink":"http://www.songshuiyang.com/tags/Jenkins/"}]},{"title":"Nginx 笔记","slug":"backend/server/centos/Nginx 笔记","date":"2018-06-05T13:48:12.000Z","updated":"2020-03-16T11:43:55.588Z","comments":true,"path":"2018/06/05/backend/server/centos/Nginx 笔记/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/server/centos/Nginx 笔记/","excerpt":"","text":"一. 为什么使用NginxNginx 是一个高性能的 Web 和反向代理服务器, 它具有有很多非常优越的特性: 作为 Web 服务器：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx 尤其受到虚拟主机提供商的欢迎。能够支持高达 50,000 个并发连接数的响应，感谢 Nginx 为我们选择了 epoll and kqueue 作为开发模型. 作为负载均衡服务器：Nginx 既可以在内部直接支持 Rails 和 PHP，也可以支持作为 HTTP代理服务器 对外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比 Perlbal 要好的多。 作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。 Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器: Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。基础功能 二. 基础功能 处理静态文件，索引文件以及自动索引； 反向代理加速(无缓存)，简单的负载均衡和容错； FastCGI，简单的负载均衡和容错； 模块化的结构。过滤器包括gzipping, byte ranges, chunked responses, 以及 SSI-filter 。在SSI过滤器中，到同一个 proxy 或者 FastCGI 的多个子请求并发处理；SSL 和 TLS SNI 支持；","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.songshuiyang.com/tags/Nginx/"},{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"基于 CentOS 搭建 Nginx 服务","slug":"backend/server/centos/基于 CentOS 搭建 Nginx服务","date":"2018-06-05T13:48:12.000Z","updated":"2019-11-10T02:08:42.094Z","comments":true,"path":"2018/06/05/backend/server/centos/基于 CentOS 搭建 Nginx服务/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/server/centos/基于 CentOS 搭建 Nginx服务/","excerpt":"1.安装使用Nginx1.1 yum安装1yum install nginx 1.2 提供目录权限12345678提供目录权限: 我需要访问的目录是 /var/ftp, 用户是root, 所以修改如下配置:[root@S205 conf.d]# cat /etc/nginx/nginx.conf |grep useruser root;否则会出现这样的错误:[root@S205 conf.d]# tail /var/log/nginx/error.log 2017/10/13 16:51:09 [error] 13383#0: *1 open() \"/home/data\" failed (13: Permission denied), client: 192.168.50.20, server: _, request: \"GET /data HTTP/1.1\", host: \"192.168.10.205:8080\"","text":"1.安装使用Nginx1.1 yum安装1yum install nginx 1.2 提供目录权限12345678提供目录权限: 我需要访问的目录是 /var/ftp, 用户是root, 所以修改如下配置:[root@S205 conf.d]# cat /etc/nginx/nginx.conf |grep useruser root;否则会出现这样的错误:[root@S205 conf.d]# tail /var/log/nginx/error.log 2017/10/13 16:51:09 [error] 13383#0: *1 open() \"/home/data\" failed (13: Permission denied), client: 192.168.50.20, server: _, request: \"GET /data HTTP/1.1\", host: \"192.168.10.205:8080\" 2.Nginx 命令2.1 启动重启123456[root@S205 conf.d]# systemctl enable nginx[root@S205 conf.d]# systemctl restart nginx[root@S205 conf.d]# vi /etc/nginx/nginx.conf 2.23.Nginx 启用对文件目录的http访问解决以ftp路径形式的图片，在谷歌浏览器上不能正常访问的问题，所以使用http的形式访问文件 3.1 配置如下：采用： http://ip/uploadfile/文件路径的形式访问 或者 直接 http://ip/文件路径的形式访问12345678910111213141516171819202122232425262728server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /var/ftp/pub; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; autoindex on; autoindex_localtime on; &#125; location /uploadfile &#123; alias /var/ftp/pub; autoindex on; autoindex_localtime on; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 3.2 autoindex 和 autoindex_localtime 生成目录索引1234autoindex on; #自动显示目录autoindex_exact_size off; #改为off后，显示出文件的大概大小，单位是kB或者MB或者GB；即人性化方式显示文件大小否则以byte显示autoindex_localtime on; #显示的文件时间为文件的服务器时间；即按服务器时间显示limit_rate_after 10m; #10m之后下载速度为10k 参考:http://blog.licess.com/nginx-autoindex/ 3.2 解决目录列表文件名乱码问题12345678910111213141516171819202122232425262728vi /etc/nginx/nginx.conf 加上 charset utf-8,gbk即可解决;user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; autoindex on; autoindex_exact_size off; autoindex_localtime on; charset utf-8,gbk;&#125; 4.Nginx 配置反向代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#user nobody;worker_processes 1;#error_log logs/error.log;error_log logs/error.log notice;#error_log logs/error.log info;#error_log /usr/local/etcinx/logs/error.log warn;#pid logsinx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; #tcp_nopush on; #keepalive_timeout 0; sendfile on; keepalive_timeout 65; gzip on; gzip_min_length 1k; gzip_comp_level 3; gzip_buffers 4 16k; gzip_vary on; server &#123; listen 80; server_name localhost 192.168.0.252 songshuiyang.com; location / &#123; proxy_pass http://127.0.0.1:4080; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 100m; &#125; location /uploadfile &#123; alias /var/ftp/pub ; &#125; location /webapp &#123; proxy_pass http://127.0.0.1:8068; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; location /admin-webapp &#123; alias html/test-admin-webapp; &#125; location = /favicon.ico &#123; alias /var/ftp/pub/favicon.ico; &#125; &#125;&#125;# include servers/*; 5.Nginx 简单的负载均衡的示例12345678910111213141516http &#123; upstream myproject &#123; server 127.0.0.1:8000 weight=3; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003;&#125;server &#123; listen 80; server_name www.domain.com; location / &#123; proxy_pass http://myproject; &#125; &#125;&#125; 本文参考： http://www.bubuko.com/infodetail-2349571.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.songshuiyang.com/tags/Nginx/"},{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"基于 CentOS 搭建 FTP 文件服务","slug":"backend/server/centos/基于 CentOS 搭建 FTP 文件服务","date":"2018-06-05T12:48:12.000Z","updated":"2019-11-10T02:08:42.084Z","comments":true,"path":"2018/06/05/backend/server/centos/基于 CentOS 搭建 FTP 文件服务/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/server/centos/基于 CentOS 搭建 FTP 文件服务/","excerpt":"1.安装并启动 FTP 服务1.1 使用 yum 安装 vsftpd12# yum默认都是安装最新版的软件yum install -y vsftpd 1.2 启动 vsftpd1234567安装完成后，启动 FTP 服务：service vsftpd start启动后，可以看到系统已经监听了 21 端口：netstat -nltp | grep 21此时，访问 ftp://主机ip 可浏览机器上的 /var/ftp目录了。","text":"1.安装并启动 FTP 服务1.1 使用 yum 安装 vsftpd12# yum默认都是安装最新版的软件yum install -y vsftpd 1.2 启动 vsftpd1234567安装完成后，启动 FTP 服务：service vsftpd start启动后，可以看到系统已经监听了 21 端口：netstat -nltp | grep 21此时，访问 ftp://主机ip 可浏览机器上的 /var/ftp目录了。 2.配置 FTP 权限2.1 了解 VSFTP 配置12345vsftpd 的配置目录为 /etc/vsftpd，包含下列的配置文件：vsftpd.conf 为主要配置文件ftpusers 配置禁止访问 FTP 服务器的用户列表user_list 配置用户访问控制 2.1 创建 FTP 用户1234创建一个用户 ftpuseruseradd ftpuser为用户 ftpuser 设置密码echo \"password\" | passwd ftpuser --stdin 2.2 限制该用户仅能通过 FTP 访问12限制用户 ftpuser只能通过 FTP 访问服务器，而不能直接登录服务器：usermod -s /sbin/nologin ftpuser 命令笔记:123456789101112用于修改用户的基本信息。usermod命令不允许你改变正在线上的使用者帐号名称。当usermod命令用来改变user id，必须确认这名user没在电脑上执行任何程序。你需手动更改使用者的crontab档。也需手动更改使用者的at工作档。采用NIS server须在server上更动相关的NIS设定。-c&lt;备注&gt;：修改用户帐号的备注文字；-d&lt;登入目录&gt;：修改用户登入时的目录；-e&lt;有效期限&gt;：修改帐号的有效期限；-f&lt;缓冲天数&gt;：修改在密码过期后多少天即关闭该帐号；-g&lt;群组&gt;：修改用户所属的群组；-G&lt;群组&gt;；修改用户所属的附加群组；-l&lt;帐号名称&gt;：修改用户帐号名称；-L：锁定用户密码，使密码无效；-s&lt;shell&gt;：修改用户登入后所使用的shell；-u&lt;uid&gt;：修改用户ID；-U:解除密码锁定。 2.3 创建登录欢迎文件1echo \"Welcome to use FTP service.\" &gt; /var/ftp/welcome.txt 2.4 配置权限12345设置访问权限chmod a-w /var/ftp &amp;&amp; chmod 777 -R /var/ftp/pub设置为用户的主目录：usermod -d /var/ftp ftpuser 命令笔记:123456789101112131415161718192021222324252627282930313233343536权限范围的表示法如下：u User，即文件或目录的拥有者；g Group，即文件或目录的所属群组；o Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；a All，即全部的用户，包含拥有者，所属群组以及其他用户；r 读取权限，数字代号为“4”;w 写入权限，数字代号为“2”；x 执行或切换权限，数字代号为“1”；- 不具任何权限，数字代号为“0”；s 特殊功能说明：变更文件或目录的权限。-c或——changes：效果类似“-v”参数，但仅回报更改的部分；-f或--quiet或——silent：不显示错误信息；-R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理；-v或——verbose：显示指令执行过程；--reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同；&lt;权限范围&gt;+&lt;权限设置&gt;：开启权限范围的文件或目录的该选项权限设置；&lt;权限范围&gt;-&lt;权限设置&gt;：关闭权限范围的文件或目录的该选项权限设置；&lt;权限范围&gt;=&lt;权限设置&gt;：指定权限范围的文件或目录的该选项权限设置；Linux用 户分为：拥有者、组群(Group)、其他（other），Linux系统中，预设的情況下，系统中所有的帐号与一般身份使用者，以及root的相关信 息， 都是记录在/etc/passwd文件中。每个人的密码则是记录在/etc/shadow文件下。 此外，所有的组群名称记录在/etc/group內！例：rwx rw- r--r=读取属性 //值＝4w=写入属性 //值＝2x=执行属性 //值＝1chmod u+x,g+w f01 //为文件f01设置自己可以执行，组员可以写入的权限chmod u=rwx,g=rw,o=r f01chmod 764 f01chmod a+x f01 //对文件f01的u,g,o都设置可执行属性文件的属主和属组属性设置chown user:market f01 //把文件f01给uesr，添加到market组ll -d f1 查看目录f1的属性 2.5 备注一： 以上配置是匿名用户可以通过ftp://主机ip 即可访问文件，但不能上传文件，所以需要添加一个ftpuser用户ftp上传操作，这样做有俩个好处 访问文件可以通过一个ftp绝对路径访问(也可以通过nginx代理通过http的形式访问)，不需要输入用户名及密码 上传修改文件只能通过该(ftpuser)用户才能进行操作，保证了其安全性 二： 阻止匿名访问和切换根目录1234567891011匿名访问和切换根目录都会给服务器带来安全风险，我们把这两个功能关闭。编辑 /etc/vsftpd/vsftpd.conf，找到下面两处配置并修改：vi /etc/vsftpd/vsftpd.conf # 禁用匿名用户 12 YES 改为NOanonymous_enable=NO# 禁止切换根目录 101 行 删除#chroot_local_user=YES编辑完成后保存配置，重新启动 FTP 服务service vsftpd restart 本文参考： https://www.baidu.com/link?url=3FcSvP44zFbo33EoJBucNlE1ZKKkncTuckfxuvNFJhCPvQuZmlebtZRzRAW3-W0SH8Ep8dShtJ8NSjWlozkrPa&amp;wd=&amp;eqid=edc2684700001d70000000065b17479b","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"},{"name":"Ftp","slug":"Ftp","permalink":"http://www.songshuiyang.com/tags/Ftp/"}]},{"title":"Shiro记事","slug":"backend/framework/shiro/Shiro记事","date":"2018-06-05T12:48:12.000Z","updated":"2020-03-16T11:43:55.399Z","comments":true,"path":"2018/06/05/backend/framework/shiro/Shiro记事/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/framework/shiro/Shiro记事/","excerpt":"","text":"Shiro内置了默认的拦截器配置Shiro使得多个角色可以访问同一URL在Shiro配置中，如果对某一URL作如下配置： /a.jsp = roles[&quot;role1, role2&quot;] 其效果等效于hasAllRoles，即要求所有角色都满足才可访问。 但在实际中，可能只需满足任一角色即可访问。在这种情况下，需要自己重载RolesAuthorizationFilter的isAccessAllowed，实现或的关系。具体实现如下：123456789101112131415161718192021222324252627import org.apache.shiro.subject.Subject;import org.apache.shiro.web.filter.authz.RolesAuthorizationFilter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;public class AnyOfRolesAuthorizationFilter extends RolesAuthorizationFilter &#123; @Override public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws IOException &#123; final Subject subject = getSubject(request, response); final String[] rolesArray = (String[]) mappedValue; if (rolesArray == null || rolesArray.length == 0) &#123; //no roles specified, so nothing to check - allow access. return true; &#125; for (String roleName : rolesArray) &#123; if (subject.hasRole(roleName)) &#123; return true; &#125; &#125; return false; &#125;&#125; 相应地，在INI文件中作如下配置：123456[main]...anyofroles = com.your.package.AnyOfRolesAuthorizationFilter[urls].../path/to/some/url = anyofroles[\"role1,role2\"]","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"shiro","slug":"shiro","permalink":"http://www.songshuiyang.com/tags/shiro/"}]},{"title":"Nginx-如何实现高并发","slug":"backend/network/Nginx-如何实现高并发","date":"2018-06-04T16:00:03.000Z","updated":"2020-03-16T11:43:55.531Z","comments":true,"path":"2018/06/05/backend/network/Nginx-如何实现高并发/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/network/Nginx-如何实现高并发/","excerpt":"","text":"Nginx 是如何实现高并发的？ 如果一个 server 采用一个进程(或者线程)负责一个request的方式，那么进程数就是并发数。那么显而易见的，就是会有很多进程在等待中。等什么？最多的应该是等待网络传输。其缺点胖友应该也感觉到了，此处不述。 思考下，Java 的 NIO 和 BIO 的对比哟。 而 Nginx 的异步非阻塞工作方式正是利用了这点等待的时间。在需要等待的时候，这些进程就空闲出来待命了。因此表现为少数几个进程就解决了大量的并发问题。 Nginx是如何利用的呢，简单来说：同样的 4 个进程，如果采用一个进程负责一个 request 的方式，那么，同时进来 4 个 request 之后，每个进程就负责其中一个，直至会话关闭。期间，如果有第 5 个request进来了。就无法及时反应了，因为 4 个进程都没干完活呢，因此，一般有个调度进程，每当新进来了一个 request ，就新开个进程来处理。 Nginx 的进程模型 Nginx 服务器，正常运行过程中是多进程的： 一个 Master 进程 Master 进程：管理 Worker 进程。对外接口：接收外部的操作（信号）；对内转发：根据外部的操作的不同，通过信号管理 Worker；监控：监控 Worker 进程的运行状态，Worker 进程异常终止后，自动重启 Worker 进程。 多个 Worker 进程。 Worker 进程：所有 Worker 进程都是平等的。实际处理：网络请求，由 Worker 进程处理。Worker 进程数量：在 nginx.conf 中配置，一般设置为核心数，充分利用 CPU 资源，同时，避免进程数量过多，避免进程竞争 CPU 资源，增加上下文切换的损耗。 回想下，BIO 是不是存在酱紫的问题？嘻嘻。 Nginx 不这样，每进来一个 request ，会有一个 worker 进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发 request ，并等待请求返回。那么，这个处理的 worker 不会这么傻等着，他会在发送完请求后，注册一个事件：“如果 upstream 返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有 request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker 才会来接手，这个 request 才会接着往下走。 这就是为什么说，Nginx 基于事件模型。 由于 web server 的工作性质决定了每个 request 的大部份生命都是在网络传输中，实际上花费在 server 机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即： webserver 刚好属于网络 IO 密集型应用，不算是计算密集型。 异步，非阻塞，使用 epoll ，和大量细节处的优化。也正是 Nginx 之所以然的技术基石。 Nginx 如何处理 HTTP 请求 首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 IP 地址，然后在 Nginx 的 Master 进程里面先初始化好这个监控的Socket(创建 S ocket，设置 addr、reuse 等选项，绑定到指定的 ip 地址端口，再 listen 监听)。 然后，再 fork(一个现有进程可以调用 fork 函数创建一个新进程。由 fork 创建的新进程被称为子进程 )出多个子进程出来。 之后，子进程会竞争 accept 新的连接。此时，客户端就可以向 nginx 发起连接了。当客户端与nginx进行三次握手，与 nginx 建立好一个连接后。此时，某一个子进程会 accept 成功，得到这个建立好的连接的 Socket ，然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体。 接着，设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。 为什么 Nginx 不使用多线程？ Apache: 创建多个进程或线程，而每个进程或线程都会为其分配 cpu 和内存（线程要比进程小的多，所以 worker 支持比 perfork 高的并发），并发过大会榨干服务器资源。 Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置 Nginx 主进程的工作进程的数量）(epoll)，不会为每个请求分配 cpu 和内存资源，节省了大量资源，同时也减少了大量的 CPU 的上下文切换。所以才使得 Nginx 支持更高的并发。 Netty、Redis 基本采用相同思路。 总结 Nginx采用多进程+异步非阻塞方式（IO 多路复用 Epoll）来保证拥有高性能并且能够支撑高并发 参考 芋道源码 http://www.iocoder.cn https://mp.weixin.qq.com/s/ni2qEWET-p6hzrdZWBPi3g","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.songshuiyang.com/tags/Nginx/"},{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"Nginx-常用配置","slug":"backend/network/Nginx-常用配置","date":"2018-06-04T16:00:02.000Z","updated":"2019-11-17T02:06:49.904Z","comments":true,"path":"2018/06/05/backend/network/Nginx-常用配置/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/network/Nginx-常用配置/","excerpt":"","text":"配置参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8;#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info;#进程文件pid /var/run/nginx.pid;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） worker_connections 65535;&#125;#设定http服务器http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型 #charset utf-8; #默认编码 server_names_hash_bucket_size 128; #服务器名字的hash表大小 client_header_buffer_size 32k; #上传文件大小限制 large_client_header_buffers 4 64k; #设定请求缓 client_max_body_size 8m; #设定请求缓 sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。 tcp_nopush on; #防止网络阻塞 tcp_nodelay on; #防止网络阻塞 keepalive_timeout 120; #长连接超时时间，单位是秒 #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用 upstream blog.ha97.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.ha97.com ha97.com; index index.html index.htm index.php; root /data/www/ha97; location ~ .*\\.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*\\.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /var/log/nginx/ha97access.log access; #对 \"/\" 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数， proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic \"NginxStatus\"; auth_basic_user_file conf/htpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125; &#125;&#125; 参考 http://www.ha97.com/5194.html","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.songshuiyang.com/tags/Nginx/"},{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"Nginx-FastCGI介绍","slug":"backend/network/Nginx-FastCGI介绍","date":"2018-06-04T16:00:01.000Z","updated":"2019-11-17T02:06:49.898Z","comments":true,"path":"2018/06/05/backend/network/Nginx-FastCGI介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/network/Nginx-FastCGI介绍/","excerpt":"","text":"FastCGI介绍 FastCGI是从CGI发展改进而来的。传统CGI接口方式的主要缺点是性能很差，因为每次HTTP服务器遇到动态程序时都需要重新启动脚本解析器来执行解析，然后结果被返回给HTTP服务器。这在处理高并发访问时，几乎是不可用的。另外传统的CGI接口方式安全性也很差，现在已经很少被使用了。 FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 Nginx不支持对外部程序的直接调用或者解析，所有的外部程序（包括PHP）必须通过FastCGI接口来调用，FastCGI接口在Linux下是socket（这个socket可以是文件socket，也可以是ip socket）。为了调用CGI程序，还需要一个FastCGI的wrapper（wrapper可以理解为用于启动另一个程序的程序），这个wrapper绑定在某个固定socket上，如端口或者文件socket。 当Nginx将CGI请求发送给这个socket的时候，通过FastCGI接口，wrapper接收到请求，然后派生出一个新的线程，这个线程调用解释器或者外部程序处理脚本并读取返回数据； 接着，wrapper再将返回的数据通过FastCGI接口，沿着固定的socket传递给Nginx；最后，Nginx将返回的数据发送给客户端。这就是Nginx+FastCGI的整个运作过程，如图所示。 快速通用网关接口（Fast Common Gateway Interface／FastCGI）是通用网关接口（CGI）的改进，描述了客户端和服务器程序之间传输数据的一种标准。FastCGI致力于减少Web服务器与CGI程式之间互动的开销，从而使服务器可以同时处理更多的Web请求。与为每个请求创建一个新的进程不同，FastCGI使用持续的进程来处理一连串的请求。这些进程由FastCGI进程管理器管理，而不是web服务器。 当进来一个请求时，Web 服务器把环境变量和这个页面请求通过一个unix domain socket(都位于同一物理服务器）或者一个IP Socket（FastCGI部署在其它物理服务器）传递给FastCGI进程。 由于 FastCGI 程序并不需要不断的产生新进程，可以大大降低服务器的压力并且产生较高的应用效率。它的速度效率最少要比CGI 技术提高 5 倍以上。它还支持分布式的部署， 即 FastCGI 程序可以在web 服务器以外的主机上执行。 CGI 就是所谓的短生存期应用程序，FastCGI 就是所谓的长生存期应用程序。FastCGI像是一个常驻(long-live)型的CGI，它可以一直执行着，不会每次都要花费时间去fork一次(这是CGI最为人诟病的fork-and-execute 模式)。 其他fastcgi 与 cgi 的区别？ 1）cgi web 服务器会根据请求的内容，然后会 fork 一个新进程来运行外部 c 程序（或 perl 脚本…）， 这个进程会把处理完的数据返回给 web 服务器，最后 web 服务器把内容发送给用户，刚才 fork 的进程也随之退出。 如果下次用户还请求改动态脚本，那么 web 服务器又再次 fork 一个新进程，周而复始的进行。 2）fastcgi web 服务器收到一个请求时，他不会重新 fork 一个进程（因为这个进程在 web 服务器启动时就开启了，而且不会退出），web 服务器直接把内容传递给这个进程（进程间通信，但 fastcgi 使用了别的方式，tcp 方式通信），这个进程收到请求后进行处理，把结果返回给 web 服务器，最后自己接着等待下一个请求的到来，而不是退出。 🚀 综上，差别在于是否重复 fork 进程，处理请求。 参考 芋道源码 http://www.iocoder.cn https://www.cnblogs.com/xiewenming/p/8109292.html","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.songshuiyang.com/tags/Nginx/"},{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"Nginx-概要介绍","slug":"backend/network/Nginx-概要介绍","date":"2018-06-04T16:00:00.000Z","updated":"2019-11-17T02:06:49.907Z","comments":true,"path":"2018/06/05/backend/network/Nginx-概要介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/06/05/backend/network/Nginx-概要介绍/","excerpt":"","text":"为什么使用NginxNginx 是一个高性能的 Web 和反向代理服务器, 它具有有很多非常优越的特性: 作为 Web 服务器：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx 尤其受到虚拟主机提供商的欢迎。能够支持高达 50,000 个并发连接数的响应，感谢 Nginx 为我们选择了 epoll and kqueue 作为开发模型. 作为负载均衡服务器：Nginx 既可以在内部直接支持 Rails 和 PHP，也可以支持作为 HTTP代理服务器 对外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比 Perlbal 要好的多。 作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。 Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器: Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。基础功能 基础功能 作为 http server ，处理静态文件，索引文件以及自动索引； 反向代理加速(无缓存)，简单的负载均衡和容错； FastCGI，简单的负载均衡和容错； 模块化的结构。过滤器包括gzipping, byte ranges, chunked responses, 以及 SSI-filter 。在SSI过滤器中，到同一个 proxy 或者 FastCGI 的多个子请求并发处理；SSL 和 TLS SNI 支持； 有哪些优点？ 跨平台、配置简单。 非阻塞、高并发连接：处理 2-3 万并发连接数，官方监测能支持 5 万并发。 内存消耗小：开启 10 个 Nginx 才占 150M 内存。 成本低廉，且开源。 稳定性高，宕机的概率非常小。 正向代理及反向代理 什么是正向代理？ 一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。 客户端才能使用正向代理。 正向代理总结就一句话：代理端代理的是客户端。例如说：😈 我们使用的翻墙软件，OpenVPN 等等。 什么是反向代理？ 反向代理（Reverse Proxy）方式，是指以代理服务器来接受 Internet上的连接请求，然后将请求，发给内部网络上的服务器并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 反向代理总结就一句话：代理端代理的是服务端。 Nginx 和 Apache 对比 轻量级，同样起 web 服务，Nginx 比 Apache 占用更少的内存及资源。 抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的，在高并发下 Nginx 能保持低资源低消耗高性能。 最核心的区别在于 Apache 是同步多进程模型，一个连接对应一个进程；Nginx 是异步的，多个连接（万级别）可以对应一个进程。 Nginx 高度模块化的设计，编写模块相对简单。 Nginx 负载均衡策略 负载均衡，即是代理服务器将接收的请求均衡的分发到各服务器中。 Nginx 默认提供了 3 种负载均衡策略： 1、轮询（默认）round_robin 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 2、IP 哈希 ip_hash 每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。 当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。 3、最少连接 least_conn 下一个请求将被分派到活动连接数量最少的服务器 通过 Nginx 插件，我们还可以引入 fair、url_hash 等负载均衡策略。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.songshuiyang.com/tags/Nginx/"},{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"使用微软提供的Office Online实现Office文档的在线查看,编辑等功能","slug":"backend/other/使用微软提供的Office Online实现Office文档的在线查看,编辑等功能","date":"2018-05-08T12:54:12.000Z","updated":"2020-03-16T11:43:55.537Z","comments":true,"path":"2018/05/08/backend/other/使用微软提供的Office Online实现Office文档的在线查看,编辑等功能/","link":"","permalink":"http://www.songshuiyang.com/2018/05/08/backend/other/使用微软提供的Office Online实现Office文档的在线查看,编辑等功能/","excerpt":"","text":"使用微软提供的Office Online实现Office文档的在线查看,编辑使用微软提供的Office Online平台只需要一个网址即可在线查看Xls,doc,PPT等文档 在线预览http://view.officeapps.live.com/op/view.aspx?src=要查看的文档地址 在线编辑在线编辑需要登录https://www.office.com并从onedrive中打开或新建文档也可以来自在线模板(下面的Excel来自Excel Online模板，编辑后的文件会保存到你的onedrive中)在线编辑Xls文档(部分功能不支持,但已经够用)","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"freemarker模板框架","slug":"backend/framework/freemarker/freemaker模板框架","date":"2018-04-14T15:35:12.000Z","updated":"2020-03-16T11:43:55.383Z","comments":true,"path":"2018/04/14/backend/framework/freemarker/freemaker模板框架/","link":"","permalink":"http://www.songshuiyang.com/2018/04/14/backend/framework/freemarker/freemaker模板框架/","excerpt":"","text":"freemaker 语法笔记 if 条件 1234567&lt;#if entity.columnName == 'id' &gt; &lt;#elseif entity.columnName == 'id' &gt; &lt;#else&gt; &lt;/#if&gt; list 遍历元素 12345678910111213141516171819202122232425262728293031323334353637383940414243441. 遍历要想在Freemarker中遍历list,必须通过使用list指令,即&lt;#list sequence as item&gt;…&lt;/#list&gt;sequence是集合(collection)的表达式，item是循环变量的名字，不能是表达式。&lt;#list userList as user&gt; …&lt;/#list&gt;List指令还隐含了两个循环变量： item_index:当前迭代项在所有迭代项中的位置，是数字值。 item_has_next:用于判断当前迭代项是否是所有迭代项中的最后一项。 注意：在使用上述两个循环变量时，一定要将item换成你自己定义的循环变量名,item其实就是前缀罢了。 &lt;#--Freemarker遍历list并应用list隐含变量item_index--&gt; item_index使用： &lt;#list userList as user&gt; 第$&#123;user_index+1&#125;个用户 用户名：$&#123;user.userName&#125; 密 码：$&#123;user.userPassword&#125; 年 龄: $&#123;user.age&#125; &lt;/#list&gt; &lt;#--Freemarker遍历list并应用list隐含变量item_has_next--&gt; item_has_next,size使用： &lt;#list userList as user&gt; 用户名：$&#123;user.userName&#125; 密 码：$&#123;user.userPassword&#125; 年 龄: $&#123;user.age&#125; &lt;#if !user_has_next&gt; 共有$&#123;userList?size&#125;最后一个用户是:$&#123;user.userName&#125; &lt;/#if&gt; &lt;/#list&gt;2. 排序sort升序排序函数 sort对序列(sequence)进行排序，要求序列中的变量必须是：字符串（按首字母排序）,数字，日期值。 &lt;#list list?sort as l&gt;…&lt;/#list&gt;sort_by函数 sort_by有一个参数,该参数用于指定想要排序的子变量，排序是按照变量对应的值进行排序,如： &lt;#list userList?sort_by(“age”) as user&gt;…&lt;/#list&gt; age是User对象的属性，排序是按age的值进行的。reverse降序排序函数 &lt;#list list? reverse as l&gt;…&lt;/#list&gt;。reverse使用同sort相同。reverse还可以同sort_by一起使用 如：想让用户按年龄降序排序，那么可以这个样写&lt;#list userList?sort_by(“age”)?reverse as user&gt;…&lt;/#list&gt;","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"freemarker","slug":"freemarker","permalink":"http://www.songshuiyang.com/tags/freemarker/"}]},{"title":"Spring 集成Redis","slug":"backend/framework/cache/Redis","date":"2018-04-08T14:02:12.000Z","updated":"2020-03-16T11:43:55.380Z","comments":true,"path":"2018/04/08/backend/framework/cache/Redis/","link":"","permalink":"http://www.songshuiyang.com/2018/04/08/backend/framework/cache/Redis/","excerpt":"一：Redis1. 什么是RedisRedis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。 官网: https://redis.io/ 中文教程网: http://www.redis.net.cn/tutorial/3501.html 2. 基本介绍Redis 简介 Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？ Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。","text":"一：Redis1. 什么是RedisRedis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。 官网: https://redis.io/ 中文教程网: http://www.redis.net.cn/tutorial/3501.html 2. 基本介绍Redis 简介 Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？ Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 3. 安装3.1 windows环境下载地址: https://github.com/MicrosoftArchive/redis/releases 3.1.1 修改配置文件12345redis.windows.conf 文件 配置密码 # requirepass foobaredrequirepass shuiyang 3.1.2 常用命令1234567redis服务安装成windows服务: redis-server --service-install redis.windows.conf开启服务：redis-server --service-start停止服务：redis-server --service-stop卸载服务：redis-server --service-uninstall 3.1.3 Redis可视化管理工具 RedisStudio，百度云连接：http://pan.baidu.com/s/1gfIbLar 密码：mpne Redis Desktop Manager https://redisdesktop.com/download 3.2 Linux环境下载地址：http://www.redis.net.cn/download/，下载最新文档版本。 3.2.1 安装1234$ wget http://download.redis.io/releases/redis-2.8.17.tar.gz$ tar xzf redis-2.8.17.tar.gz$ cd redis-2.8.17$ make make完后 redis-2.8.17目录下会出现编译后的redis服务程序redis-server,还有用于测试的客户端程序redis-cli 3.2.1 启动服务下面启动redis服务. 1$ ./redis-server 注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。 1./redis-server redis.conf redis.conf是一个默认的配置文件。我们可以根据需要使用自己的配置文件。 3.2.1 测试客户端程序启动redis服务进程后，就可以使用测试客户端程序redis-cli和redis服务交互了。 比如： 12345$ ./redis-cliredis&gt; set foo barOKredis&gt; get foo\"bar\" 4. 与Spring 集成4.1 导入maven1234567891011&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.6.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 4.2 新建 redis-config.properties1234567891011121314# Redis settingsredis.host=127.0.0.1redis.port=6379redis.pass=shuiyangredis.dbIndex=0redis.expiration=3000#最大空闲数redis.maxIdle=300#连接池的最大数据库连接数。设为0表示无限制,如果是jedis 2.4以后用redis.maxTotalredis.maxActive=600#最大建立连接等待时间。如果超过此时间将接到异常。设为-1表示无限制。redis.maxWait=1000#是否在从池中取出连接前进行检验,如果检验失败,则从池中去除连接并尝试取出另一个redis.testOnBorrow=true 4.3 新建 applicationContext-redis.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:cache=\"http://www.springframework.org/schema/cache\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/cache http://www.springframework.org/schema/cache/spring-cache.xsd\"&gt; &lt;!-- 启用缓存注解开关 --&gt; &lt;cache:annotation-driven cache-manager=\"cacheManager\"/&gt; &lt;!-- 配置JedisPoolConfig实例 --&gt; &lt;bean id=\"poolConfig\" class=\"redis.clients.jedis.JedisPoolConfig\"&gt; &lt;property name=\"maxIdle\" value=\"$&#123;redis.maxIdle&#125;\" /&gt; &lt;property name=\"maxTotal\" value=\"$&#123;redis.maxActive&#125;\" /&gt; &lt;property name=\"maxWaitMillis\" value=\"$&#123;redis.maxWait&#125;\" /&gt; &lt;property name=\"testOnBorrow\" value=\"$&#123;redis.testOnBorrow&#125;\" /&gt; &lt;/bean&gt; &lt;!-- 配置JedisConnectionFactory --&gt; &lt;bean id=\"jedisConnectionFactory\" class=\"org.springframework.data.redis.connection.jedis.JedisConnectionFactory\"&gt; &lt;property name=\"hostName\" value=\"$&#123;redis.host&#125;\" /&gt; &lt;property name=\"port\" value=\"$&#123;redis.port&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;redis.pass&#125;\" /&gt; &lt;property name=\"database\" value=\"$&#123;redis.dbIndex&#125;\" /&gt; &lt;property name=\"poolConfig\" ref=\"poolConfig\" /&gt; &lt;/bean&gt; &lt;!-- 配置RedisTemplate --&gt; &lt;bean id=\"redisTemplate\" class=\"org.springframework.data.redis.core.RedisTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"jedisConnectionFactory\" /&gt; &lt;/bean&gt; &lt;!-- 配置RedisCacheManager --&gt; &lt;bean id=\"cacheManager\" class=\"org.springframework.data.redis.cache.RedisCacheManager\"&gt; &lt;constructor-arg name=\"redisOperations\" ref=\"redisTemplate\" /&gt; &lt;property name=\"defaultExpiration\" value=\"$&#123;redis.expiration&#125;\" /&gt; &lt;/bean&gt; &lt;!-- 配置RedisCacheManager --&gt; &lt;bean id=\"cacheManager\" class=\"org.springframework.cache.support.SimpleCacheManager\"&gt; &lt;property name=\"caches\"&gt; &lt;set&gt; &lt;!-- 这里可以配置多个redis --&gt; &lt;bean class=\"com.ecut.core.config.RedisCache\"&gt; &lt;property name=\"redisTemplate\" ref=\"redisTemplate\" /&gt; &lt;property name=\"name\" value=\"articlesDetail\"/&gt; &lt;/bean&gt; &lt;bean class=\"com.ecut.core.config.RedisCache\"&gt; &lt;property name=\"redisTemplate\" ref=\"redisTemplate\" /&gt; &lt;property name=\"name\" value=\"getHotArticlesInCache\"/&gt; &lt;/bean&gt; &lt;bean class=\"com.ecut.core.config.RedisCache\"&gt; &lt;property name=\"redisTemplate\" ref=\"redisTemplate\" /&gt; &lt;property name=\"name\" value=\"articlesList\"/&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 4.4 引入 applicationContext-redis.xml redis-config.properties1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd\"&gt; &lt;!--使标注Spring注解的类生效--&gt; &lt;context:component-scan base-package=\"com.ecut\"/&gt; &lt;!-- 将多个配置文件读取到容器中，交给Spring管理 --&gt; &lt;bean id=\"propertyConfigurer\" class=\"com.ecut.core.spring.PropertyPlaceholderConfigurerFilter\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;!-- 这里支持多种寻址方式：classpath和file --&gt; &lt;value&gt;classpath:project.properties&lt;/value&gt; &lt;!-- 推荐使用file的方式引入，这样可以将配置和代码分离 --&gt; &lt;value&gt;classpath:jdbc.properties&lt;/value&gt; &lt;value&gt;classpath:redis-config.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;import resource=\"applicationContext-dao.xml\"/&gt; &lt;import resource=\"applicationContext-shiro.xml\"/&gt; &lt;!--encache redis选择一种缓存--&gt; &lt;!--&lt;import resource=\"applicationContext-encache.xml\"/&gt;--&gt; &lt;import resource=\"applicationContext-redis.xml\"/&gt;&lt;/beans&gt; 4.5 新建 RedisCache.java Cache接口实现类 Spring对于缓存只是提供了抽象的接口，并且通过接口来调用功能，没有具体的实现类，所以需要我们自己实现具体的操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136package com.ecut.core.config;import java.io.Serializable;import org.apache.commons.lang3.SerializationUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cache.Cache;import org.springframework.cache.support.SimpleValueWrapper;import org.springframework.dao.DataAccessException;import org.springframework.data.redis.connection.RedisConnection;import org.springframework.data.redis.core.RedisCallback;import org.springframework.data.redis.core.RedisTemplate;import java.io.Serializable;/** * Cache接口实现类 * * Spring对于缓存只是提供了抽象的接口，并且通过接口来调用功能，没有具体的实现类，所以需要我们自己实现具体的操作。 在上面配置中可知，每个实现类都会注入一个redisTemplate实例，我们就可以通过redisTemplate来操作redis * @author songshuiyang * @date 2018/4/9 20:38 */public class RedisCache implements Cache &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); private RedisTemplate&lt;String, Object&gt; redisTemplate; private String name; @Override public void clear() &#123; logger.info(\"----------------------------RedisCache 緩存清理-------------------------\"); redisTemplate.execute(new RedisCallback&lt;String&gt;() &#123; @Override public String doInRedis(RedisConnection connection) throws DataAccessException &#123; connection.flushDb(); return \"ok\"; &#125; &#125;); &#125; @Override public void evict(Object key) &#123; logger.info(\"----------------------------RedisCache 緩存刪除-------------------------\"); final String keyf=key.toString(); redisTemplate.execute(new RedisCallback&lt;Long&gt;() &#123; @Override public Long doInRedis(RedisConnection connection) throws DataAccessException &#123; return connection.del(keyf.getBytes()); &#125; &#125;); &#125; @Override public ValueWrapper get(Object key) &#123; logger.info(\"----------------------------RedisCache 缓存获取-------------------------\"); final String keyf = key.toString(); Object object = null; object = redisTemplate.execute(new RedisCallback&lt;Object&gt;() &#123; @Override public Object doInRedis(RedisConnection connection) throws DataAccessException &#123; byte[] key = keyf.getBytes(); byte[] value = connection.get(key); if (value == null) &#123; logger.info(\"----------------------------RedisCache 缓存不存在-------------------------\"); return null; &#125; return SerializationUtils.deserialize(value); &#125; &#125;); ValueWrapper obj=(object != null ? new SimpleValueWrapper(object) : null); logger.info(\"----------------------------RedisCache 获取到内容-------------------------\"); return obj; &#125; @Override public void put(Object key, Object value) &#123; System.out.println(\"-------加入缓存------\"); System.out.println(\"key----:\"+key); System.out.println(\"key----:\"+value); final String keyString = key.toString(); final Object valuef = value; final long liveTime = 86400; redisTemplate.execute(new RedisCallback&lt;Long&gt;() &#123; @Override public Long doInRedis(RedisConnection connection) throws DataAccessException &#123; byte[] keyb = keyString.getBytes(); byte[] valueb = SerializationUtils.serialize((Serializable) valuef); connection.set(keyb, valueb); if (liveTime &gt; 0) &#123; connection.expire(keyb, liveTime); &#125; return 1L; &#125; &#125;); &#125; @Override public &lt;T&gt; T get(Object arg0, Class&lt;T&gt; arg1) &#123; // TODO Auto-generated method stub return null; &#125; @Override public String getName() &#123; return this.name; &#125; @Override public Object getNativeCache() &#123; return this.redisTemplate; &#125; @Override public ValueWrapper putIfAbsent(Object arg0, Object arg1) &#123; // TODO Auto-generated method stub return null; &#125; public RedisTemplate&lt;String, Object&gt; getRedisTemplate() &#123; return redisTemplate; &#125; public void setRedisTemplate(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 4.6 完成以上的配置之后就可以使用 Spring Cache注解来使用缓存了首先使用注解标记方法，相当于定义了切点，然后使用Aop技术在这个方法的调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。 @Cacheable 12345678910111213141516171819202122232425262728表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。 这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。 可以使用key属性来指定key的生成规则。@Cacheable 支持如下几个参数： value：缓存位置名称，不能为空，如果使用EHCache，就是ehcache.xml中声明的cache的name, 指明将值缓存到哪个Cache中 key：缓存的key，默认为空，既表示使用方法的参数类型及参数值作为key，支持SpEL，如果要引用参数值使用井号加参数名，如：#userId， 一般来说，我们的更新操作只需要刷新缓存中某一个值，所以定义缓存的key值的方式就很重要，最好是能够唯一，因为这样可以准确的清除掉特定的缓存，而不会影响到其它缓存值 ， 本例子中使用实体加冒号再加ID组合成键的名称，如”user:1”、”order:223123”等 condition：触发条件，只有满足条件的情况才会加入缓存，默认为空，既表示全部都加入缓存，支持SpEL // 将缓存保存到名称为UserCache中，键为\"user:\"字符串加上userId值，如 'user:1' @Cacheable(value=\"UserCache\", key=\"'user:' + #userId\") public User findById(String userId) &#123; return (User) new User(\"1\", \"mengdee\"); &#125; // 将缓存保存进UserCache中，并当参数userId的长度小于12时才保存进缓存，默认使用参数值及类型作为缓存的key // 保存缓存需要指定key，value， value的数据类型，不指定key默认和参数名一样如：\"1\" @Cacheable(value=\"UserCache\", condition=\"#userId.length() &lt; 12\") public boolean isReserved(String userId) &#123; System.out.println(\"UserCache:\"+userId); return false; &#125; @CachePut 1与@Cacheable不同，@CachePut不仅会缓存方法的结果，还会执行方法的代码段。它支持的属性和用法都与@Cacheable一致。 @CacheEvict 1234567891011121314151617181920与@Cacheable功能相反，@CacheEvict表明所修饰的方法是用来删除失效或无用的缓存数据。@CacheEvict 支持如下几个参数： value：缓存位置名称，不能为空，同上 key：缓存的key，默认为空，同上 condition：触发条件，只有满足条件的情况才会清除缓存，默认为空，支持SpEL allEntries：true表示清除value中的全部缓存，默认为false //清除掉UserCache中某个指定key的缓存 @CacheEvict(value=\"UserCache\",key=\"'user:' + #userId\") public void removeUser(User user) &#123; System.out.println(\"UserCache\"+user.getUserId()); &#125; //清除掉UserCache中全部的缓存 @CacheEvict(value=\"UserCache\", allEntries=true) public final void setReservedUsers(String[] reservedUsers) &#123; System.out.println(\"UserCache deleteall\"); &#125; @Caching 1234如果需要使用同一个缓存注解（@Cacheable、@CacheEvict或@CachePut）多次修饰一个方法，就需要用到@Caching。@Caching(evict = &#123; @CacheEvict(\"primary\"), @CacheEvict(cacheNames=\"secondary\", key=\"#p0\") &#125;)public Book importBooks(String deposit, Date date) @CacheConfig 12345678与前面的缓存注解不同，这是一个类级别的注解。 如果类的所有操作都是缓存操作，你可以使用@CacheConfig来指定类，省去一些配置。@CacheConfig(\"books\")public class BookRepositoryImpl implements BookRepository &#123; @Cacheable public Book findBook(ISBN isbn) &#123;...&#125;&#125; 遇到的问题： spring+redis报错org.springframework.core.serializer.support.DeserializingConverter.(Ljava/lang/ClassLoader;)V 123456789101112这个问题的原因大概就是spring-data-redis.jar包版本不对 ，下面版本可以正常启动 &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.6.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; Spring Cache 注解问题，使用redis缓存会出现类型转化的问题 ,还未解决 参考：https://www.cnblogs.com/panter/p/6801210.htmlhttp://www.redis.net.cn/tutorial/3503.htmlhttps://www.cnblogs.com/hello-daocaoren/p/7891907.html","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"redis","slug":"redis","permalink":"http://www.songshuiyang.com/tags/redis/"}]},{"title":"微信公众号实现输入兑换码自动发红包功能","slug":"backend/business/payment/微信公众号开通发红包功能","date":"2018-04-03T14:15:12.000Z","updated":"2020-03-16T11:43:55.328Z","comments":true,"path":"2018/04/03/backend/business/payment/微信公众号开通发红包功能/","link":"","permalink":"http://www.songshuiyang.com/2018/04/03/backend/business/payment/微信公众号开通发红包功能/","excerpt":"前言 公司积分抽奖活动有红包奖项(虽然基本上都是这个奖)，但是用户兑奖的过程十分麻烦: 需要先联系公司客服，然后加客服微信，加完之后客服发一个微信红包作为兑换。所以决定简化这个兑奖过程，能不能将这个兑奖的过程改为由用户自己兑换，不用联系公司客服也能兑奖。 初步想法 公司有微信公众号，可以通过微信公众号进行发红包操作，一方面可以实现发送红包的功能，另一方面也可以推广公司的微信公众号。初步想法是用户在微信公众号里输入一个兑换码，然后微信自动发送一个红包给用户，用户只要点一下红包，红包就进用户自己口袋了 业务流程如果用户抽奖中了红包奖励，系统弹出一个提示框，里面有公司的微信公众号二维码图片（微信公众平台可以获取），及兑奖的兑换码，提示用户关注微信公众号，在公众号里面输入兑换码就可以获取红包","text":"前言 公司积分抽奖活动有红包奖项(虽然基本上都是这个奖)，但是用户兑奖的过程十分麻烦: 需要先联系公司客服，然后加客服微信，加完之后客服发一个微信红包作为兑换。所以决定简化这个兑奖过程，能不能将这个兑奖的过程改为由用户自己兑换，不用联系公司客服也能兑奖。 初步想法 公司有微信公众号，可以通过微信公众号进行发红包操作，一方面可以实现发送红包的功能，另一方面也可以推广公司的微信公众号。初步想法是用户在微信公众号里输入一个兑换码，然后微信自动发送一个红包给用户，用户只要点一下红包，红包就进用户自己口袋了 业务流程如果用户抽奖中了红包奖励，系统弹出一个提示框，里面有公司的微信公众号二维码图片（微信公众平台可以获取），及兑奖的兑换码，提示用户关注微信公众号，在公众号里面输入兑换码就可以获取红包 准备1、先介绍几个平台 I.微信公众平台:是微信公众账号申请入口和管理后台。商户可以在公众平台提交基本资料、业务资料、财务资料申请开通微信支付功能。 平台入口：http://mp.weixin.qq.com。 II.微信商户平台:微信商户平台是微信支付相关的商户功能集合，包括参数配置、支付数据查询与统计、在线退款、代金券或立减优惠运营等功能。 平台入口：http://pay.weixin.qq.com III. 红包接口地址： https://pay.weixin.qq.com/wiki/doc/api/tools/cash_coupon.php?chapter=13_4&amp;index=3 2、 在微信公众平台获取公众号二维码图片（提供了多种尺寸大小），该二维码是提供给用户扫描， 及公众账号appid 3、 在微信商户平台上下载证书（账户中心 - 账户设置 - API安全 - API证书（下载zip压缩包格式即可，无须解压），获取 商户号（账户中心 - 账户设置 - 商户信息 - 基本账户信息 - 微信支付商户号），API密钥（账户中心 - 账户设置 - API安全 - API密钥 - 设置密钥（密钥为32位，需要自行重新设置，记录并保存好，实在没记住也可以更改） 这些参数 4、 开通红包功能，以及充值红包金额，红包金额与充值交易金额是区分开来的，所以需要单独充值，发放现金红包将扣除商户的可用余额，请注意，可用余额并不是微信支付交易额，需要预先充值，确保可用余额充足。查看可用余额、充值、提现请登录微信支付商户平台，进入“资金管理”菜单，进行操作 5、 介绍1234567891011121314151617181920现金红包简介微信红包，2014年春节一经推出即受到广大用户好评，引发全民抢红包热潮。现将微信红包打造成“现金红包”，成为一款定向资金发放的营销工具，供商户使用。申请红包条件1、T+0 结算商户需满足两个条件：1、入驻满90天，2、截止今日往回推30天内连续正常交易。2、其余结算周期的商户无限制，可立即前往【商户平台】-&gt;【产品中心】申请开通。发放方式介绍商户发放现金红包有3种发放方式：1）接口发放商户根据文档”【商户平台】现金红包API文档V2“进行开发，一次调用可以给一个指定用户发送一个指定金额的红包，满足多元化的运营需求；2）通过上传openid文件发放收集要发送红包对象的openid，将openid编辑成txt文件，登录微信支付商户平台，使用上传文件功能发放。一份文件对应一个红包模板，便于管理；为了防止商户手误重复操作发送红包，创建的同一个文件只能上传一次。若需要重复发放则需要修改文件名称或重新创建。3）配置营销规则“满额送”发放配置的规则不可使用红包模版进行发放，商户须在【产品中心】-【现金红包】-【前往功能】中创建红包后配置自助规则：用户使用微信支付发生交易满足一定条件，立送现金红包。税务和发票问题商户给用户发红包，微信支付按照商户指定红包金额扣除完全对等的充值资金，资金最终进入用户零钱。微信支付并未从中收取资金作为营收，所以不予开具发票。发放现金红包请商户遵照国家法律依法纳税，在商户充值之前，我们默认商户已经合法上税，商户使用本功能的行为若涉及纳税或代扣代缴税款的义务，由商户自行承担该义务，我们不会替商户缴纳税款 。 程序实现1、用户抽奖中了红包奖励, 生成一笔抽奖记录，同时生成一笔红包记录，所以需要新建一个红包记录表(表结构如下图)，一开始生成的记录中红包状态是 0-未发放的状态，同时生成兑换码。 兑换码规则： 10位大写字母：3位固定字母开头 + 7位随机字母（大写字母是为了防止【数字0 与字母o O】【 1与字母l】混淆导致用户兑换不了奖， 3位固定字母是为了防止恶意用户无限次输入兑换码导致老是触发红包处理程序，如果不是以这个三个字母开头的文字，统一回复欢迎关注本微信公众号） 1234567891011121314151617181920DROP TABLE IF EXISTS `ge_lottery_redpack_record`;CREATE TABLE `ge_lottery_redpack_record` ( `id` varchar(32) NOT NULL, `created_by` varchar(32) NOT NULL, `created_date` datetime NOT NULL, `last_modified_by` varchar(32) NOT NULL, `last_modified_date` datetime NOT NULL, `remarks` varchar(255) DEFAULT NULL, `version` int(11) DEFAULT NULL, `locked` bit(1) DEFAULT b'0', `enable` bit(1) DEFAULT b'0', `fd_lottery_record_id` varchar(32) DEFAULT NULL COMMENT '中奖纪录id 作为外键', `fd_status` int(11) DEFAULT NULL COMMENT '红包状态 0:未发放 1：已发放待领取 2：发放失败 3：已领取 4：未领取已退款', `fd_redpack_send_date` datetime DEFAULT NULL COMMENT '红包发送时间(非微信)', `fd_redpack_order_id` varchar(32) DEFAULT NULL COMMENT '微信红包订单单号', `fd_redpack_openid` varchar(32) DEFAULT NULL COMMENT '微信红包订单用户在wxappid下的openid', `fd_redeem_code` varchar(32) DEFAULT NULL COMMENT '兑换码', `fd_redpack_price` decimal(19,4) DEFAULT NULL COMMENT '红包金额', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='抽奖红包纪录表'; 2、用户得到兑换码之后，就是在微信公众号里输入兑换码，当用户输入兑换码之后，用户信息会发到我们自己服务器后台中, 这里用户触发的是文本事件，我们需要的是三个参数 (1) 用户微信OpenID（用户在本微信公众号的唯一标识） (2) 用户发的兑换码 (3) HttpServletRequest（用于获取用户ip，发红包接口入参需要） 1234567891011// 文本事件if (WechatBindUtil.MESSAGE_TEXT.equals(msgType)) &#123; String content = map.get(\"Content\").trim(); // 如果输入的文本是是以RED开头的, 执行发红包操作 if (content.startsWith(\"RED\")) &#123; String resultContent = lotteryRedpackRecordService.sendRedpackByRedeemCode(fromUserName,content,req); message = WechatBindUtil.initText(toUserName, fromUserName, resultContent); &#125; else &#123; message = WechatBindUtil.initText(toUserName, fromUserName, \"欢迎关注本微信公众号\"); &#125;&#125; 3、如果输入的文本是是以RED开头的, 执行发红包操作, 首先是查询红包记录表有没有该兑换码且红包状态为未发放，如果有的话调用微信发红包接口，同时更改红包状态，记录红包发送时间，微信红包订单单号，微信红包订单用户在wxappid下的openid，没有的话给出提示，实现如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * 根据兑换码发送微信红包 * @param openid * @param redeemCode * @return */public String sendRedpackByRedeemCode (String openid, String redeemCode, HttpServletRequest request) &#123; Page&lt;LotteryRedpackRecord&gt; page = new Page&lt;&gt;(0); page.setParams(\"fdRedeemCode\",redeemCode); List&lt;LotteryRedpackRecord&gt; redpackRecords = findAutoByPage(page); if (redpackRecords.size() != 0) &#123; LotteryRedpackRecord oldRecord = redpackRecords.get(0); // 调用微信红包查询接口, 先更新红包纪录状态 updateRedpackState(oldRecord.getId()); // 更新完成之后获取新的红包纪录 LotteryRedpackRecord record = findById(oldRecord.getId()); Integer fdStatus = record.getFdStatus(); if (fdStatus.equals(R.LotteryRedpackRecord.FdStatus.未发放.getIndex())) &#123; RedpackDTO redpackDTO = new RedpackDTO(); // 以红包纪录id作为 微信红包接口请求的商品订单号 截取28位 String mchBillNo = record.getId(); mchBillNo= mchBillNo.substring(0,28); redpackDTO.setMchBillNo(mchBillNo); // 指定哪一个微信用户 redpackDTO.setReOpenid(openid); // 红包价格 redpackDTO.setTotalAmount(record.getFdRedpackPrice()); // 调用接口的机器Ip地址 String clientIp = WxUtils.getRemoteIp(request); redpackDTO.setClientIp(clientIp); Map&lt;String,String&gt; sendredpackResult = weixinPayService.sendredpack(redpackDTO); // 更新红包纪录表 LotteryRedpackRecord lotteryRedpackRecord = findById(record.getId()); lotteryRedpackRecord.setFdRedpackOpenid(openid); if (sendredpackResult.get(\"status\").equals(\"success\")) &#123; lotteryRedpackRecord.setFdStatus(R.LotteryRedpackRecord.FdStatus.已发放待领取.getIndex()); // 红包订单的微信单号-微信服务器上红包纪录的唯一标识 String redpackOrderId = sendredpackResult.get(\"sendListid\"); lotteryRedpackRecord.setFdRedpackOrderId(redpackOrderId); lotteryRedpackRecord.setFdRedpackSendDate(new Date()); // 更新抽奖纪录表, 变为已兑换 LotteryRecord lotteryRecord = lotteryRecordService.findById(record.getFdLotteryRecordId()); lotteryRecord.setFdStatus(R.LotteryRecordItem.FdStatus.已兑换.getIndex()); lotteryRecordService.saveSelective(lotteryRecord); saveSelective(lotteryRedpackRecord); &#125; else &#123; lotteryRedpackRecord.setFdStatus(R.LotteryRedpackRecord.FdStatus.发放失败.getIndex()); lotteryRedpackRecord.setRemarks(sendredpackResult.get(\"message\")); saveSelective(lotteryRedpackRecord); return \"红包发送失败, 请及时联系对应的客服!\"; &#125; &#125; else if (fdStatus.equals(R.LotteryRedpackRecord.FdStatus.已发放待领取.getIndex())) &#123; return \"该兑换码对应的红包已发送! 请注意查收\"; &#125; else if (fdStatus.equals(R.LotteryRedpackRecord.FdStatus.发放失败.getIndex())) &#123; return \"红包发送失败, 请及时联系对应的客服!\"; &#125; else if (fdStatus.equals(R.LotteryRedpackRecord.FdStatus.已领取.getIndex())) &#123; return \"该兑换码对应的红包已领取\"; &#125; else &#123; return \"该兑换码对应的红包已过时, 请及时联系对应的客服\"; &#125; &#125; else &#123; return \"该兑换码无效, 请输入正确的兑换码!\"; &#125; return \"红包已发送请注意查收! 注: 24小时后未领取该红包失效\";&#125; 4、调用微信红包接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 微信公众号发红包接口 * @param redpackDTO * @return */public Map&lt;String,String&gt; sendredpack(RedpackDTO redpackDTO) &#123; Map&lt;String,String&gt; resultMap = Maps.newHashMap(); Map&lt;String,String&gt; wxResultMap = Maps.newHashMap(); // 请求参数 Map&lt;String, String&gt; reqData = Maps.newHashMap(); logger.info(\"---------------------&gt;&gt;&gt; 开始发送红包start\", redpackDTO); try &#123; // 随机字符串 reqData.put(\"nonce_str\", WXPayUtil.generateNonceStr()); // 商户订单号 reqData.put(\"mch_billno\",redpackDTO.getMchBillNo()); // 商户号 reqData.put(\"mch_id\", WxPcPayConfigImpl.MCH_ID); // 公众账号appid reqData.put(\"wxappid\", WxPcPayConfigImpl.SENDREDPACK_WX_APPID); // 商户名称 reqData.put(\"send_name\", WxPcPayConfigImpl.SENDREDPACK_SEND_NAME); // 用户openid reqData.put(\"re_openid\",redpackDTO.getReOpenid()); // 付款金额 reqData.put(\"total_amount\", AmountUtils.transAmountToCent(redpackDTO.getTotalAmount())); // 红包发放总人数 reqData.put(\"total_num\", WxPcPayConfigImpl.SENDREDPACK_TOTAL_NUM); // 红包祝福语 reqData.put(\"wishing\", WxPcPayConfigImpl.SENDREDPACK_WISHING); // Ip地址 reqData.put(\"client_ip\", redpackDTO.getClientIp()); // 活动名称 reqData.put(\"act_name\", WxPcPayConfigImpl.SENDREDPACK_ACT_NAME); //备注 reqData.put(\"remark\", WxPcPayConfigImpl.SENDREDPACK_REMARK); // 生成签名 reqData.put(\"sign\", WXPayUtil.generateSignature(reqData, WxPcPayConfigImpl.API_KEY, WXPayConstants.SignType.MD5 )); String respXml = wxpay.requestWithCert(WxPcPayConfigImpl.SENDREDPACK_URL,reqData , 10000, 10000); wxResultMap = WXPayUtil.xmlToMap(respXml); &#125; catch (Exception e) &#123; e.printStackTrace(); logger.info(\"---------------------&gt;&gt;&gt; 微信公众号发送红包异常\"); resultMap.put(\"message\", e.getMessage()); resultMap.put(\"status\", \"failed\"); &#125; // 通信标识结果 String returnCode = wxResultMap.get(\"return_code\"); if (\"SUCCESS\".equals(returnCode)) &#123; String resultCode = wxResultMap.get(\"result_code\"); // 业务处理结果 if (\"SUCCESS\".equals(resultCode)) &#123; logger.info(\"---------------------&gt;&gt;&gt; 微信公众号发送红包成功\"); // 红包订单的微信单号 String sendListid = wxResultMap.get(\"send_listid\"); resultMap.put(\"sendListid\",sendListid); resultMap.put(\"message\",\"操作成功\"); resultMap.put(\"status\", \"success\"); &#125; else &#123; logger.info(\"---------------------&gt;&gt;&gt; 微信公众号发送红包失败, 原因: \" + wxResultMap.get(\"err_code_des\")); String errCodeDes = wxResultMap.get(\"err_code_des\"); resultMap.put(\"message\",errCodeDes); resultMap.put(\"status\", \"failed\"); return resultMap; &#125; &#125; else &#123; String returnMsg = wxResultMap.get(\"return_msg\"); logger.info(\"---------------------&gt;&gt;&gt; 微信公众号发送红包失败, 原因: \" + returnMsg); resultMap.put(\"message\", returnMsg); resultMap.put(\"status\", \"failed\"); return resultMap; &#125; return resultMap;&#125; 总结及注意事项1.红包是以分为单位，必须大于100分，小于20000分之间，这个很重要,不要一不小心把公司的钱都转出去了 2.需要对请求参数进行加签操作，wxpay里面封装了方法 3.现金红包接口请求是需要证书的，因为是出账，不像充值是属于进账不用证书， 需要调用requestWithCert 这个请求接口 1234567891011/** * 需要证书的请求 * @param strUrl String * @param reqData 向wxpay post的请求数据 Map * @param connectTimeoutMs 超时时间，单位是毫秒 * @param readTimeoutMs 超时时间，单位是毫秒 * @return API返回数据 * @throws Exception */public String requestWithCert(String strUrl, Map&lt;String, String&gt; reqData, int connectTimeoutMs, int readTimeoutMs) throws Exception &#123; 4.由于红包发出去了不知道用户有没有领取，所以可以用一个定时任务或者一个按钮调用微信红包状态查询接口，以更新红包的最新状态 5.可以借助第三方平台，如摇摇啦应用平台，借助这些平台可以不用开发接口，只要配置好参数就可以使用了，但唯一的缺点是要钱","categories":[{"name":"业务","slug":"业务","permalink":"http://www.songshuiyang.com/categories/业务/"}],"tags":[{"name":"支付","slug":"支付","permalink":"http://www.songshuiyang.com/tags/支付/"}]},{"title":"Docelver接口管理平台","slug":"backend/testwork/Docelver接口管理平台","date":"2018-04-03T12:07:12.000Z","updated":"2020-03-16T11:43:55.592Z","comments":true,"path":"2018/04/03/backend/testwork/Docelver接口管理平台/","link":"","permalink":"http://www.songshuiyang.com/2018/04/03/backend/testwork/Docelver接口管理平台/","excerpt":"","text":"前言在项目开发过程中，开发一个功能模块，需要前后端开发进行接口定义并形成文档，如果使用doc这些文档去维护接口，多会出现纰漏，特别是在多人开发的项目中，缺点尤为明显，所以需要一个像代码版本控制（git svn）类型的平台去维护这些文档，方便开发人员进行接口维护，前后端开发人员联调接口，测试人员编写测试用例 市场上常用的接口管理平台1. Rap 阿里出品官网地址： http://rapapi.org/org/index.do 官网介绍： RAP是一个可视化接口管理工具 通过分析接口结构，动态生成模拟数据，校验真实接口正确性， 围绕接口定义，通过一系列自动化工具提升我们的协作效率。我们的口号：提高效率，回家吃晚饭！ 使用体验： RAP的应用范围非常明确，是一个面向开发人员自测和联调的工具性平台，它更适合以开发为核心对接口进行维护 2. DOClever官网地址： http://www.doclever.cn/controller/index/index.html 可以对接口信息进行编辑管理，支持get,post,put,delete,patch 五种方法，支持 https 和 https 协议，并且支持 query，body，json，raw，rest，formdata 的参数可视化编辑。同时对 json 可以进行无限层次可视化编辑。并且，状态码，代码注入，markdown 文档等附加功能应有尽有。 接口调试运行，可以对参数进行加密，从md5 到 aes 一应俱全，返回参数与模型实时分析对比，给出不一致的地方，找出接口可能出现的问题。如果你不想手写文档，那么试试接口的数据生成功能，可以对接口运行的数据一键生成文档信息。 mock 的无缝整合，DOClever 自己就是一个 mock 服务器，当你把接口的开发状态设置成已完成，本地 mock 便会自动请求真实接口数据，否则返回事先定义好的 mock 数据。 支持 postman，rap，swagger 的导入，方便你做无缝迁移，同时也支持 html 文件的导出，方便你离线浏览！ 项目版本和接口快照功能并行，你可以为一个项目定义 1.0，1.1，1.2 版本，并且可以自由的在不同版本间切换回滚，再也不怕接口信息的遗失，同时接口也有快照功能，当你接口开发到一半或者接口需求变更的时候，可以随时查看之前编辑的接口信息。 自动化测试功能，目前市面上类似平台的接口自动化测试大部分都是伪自动化，对于一个复杂的场景，比如获取验证码，登陆，获取订单列表，获取某个特定订单详情这样一个上下文关联的一系列操作无能为力。而 DOClever 独创的自动化测试功能，只需要你编写极少量的 javascript 代码便可以在网页里完成这样一系列操作，同时，DOClever 还提供了后台定时批量执行测试用例并把结果发送到团队成员邮箱的功能，你可以及时获取接口的运行状态。 团队协作功能，很多类似的平台这样的功能是收费的，但是 DOClever 觉得好东西需要共享出来，你可以新建一个团队，并且把团队内的成员都拉进来，给他们分组，给他们分配相关的项目以及权限，发布团队公告等等。 DOClever 开源免费，支持内网部署，很多公司考虑到数据的安全性，不愿意把接口放到公网上，没有关系，DOClever 给出一个方便快捷的解决方案，你可以把平台放到自己的内网上，完全不需要连接外网，同时功能一样也不少，即便是对于产品的升级，DOClever 也提供了很便捷的升级方案！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"测试","slug":"测试","permalink":"http://www.songshuiyang.com/tags/测试/"}]},{"title":"高并发","slug":"backend/server/JavaEE服务器/高并发","date":"2018-04-01T12:50:44.000Z","updated":"2020-03-16T11:43:55.584Z","comments":true,"path":"2018/04/01/backend/server/JavaEE服务器/高并发/","link":"","permalink":"http://www.songshuiyang.com/2018/04/01/backend/server/JavaEE服务器/高并发/","excerpt":"","text":"一、什么是高并发 通常指通过设计保证系统能够同时并行处理很多请求。 高并发相关常用的一些指标 参数 定义 响应时间 系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。 吞吐量 单位时间内处理的请求数量。 QPS 每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。 并发用户数 同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。 二、如何提升系统的并发能力 互联网分布式架构设计，提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。 垂直扩展提升单机处理能力。垂直扩展的方式又有两种： 增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G，带宽； 提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间； 水平扩展下面的图是常见的互联网分层架构 logo 常见互联网分布式架构（1）客户端层：典型调用方是浏览器browser或者手机应用APP （2）反向代理层：系统入口，反向代理 （3）站点应用层：实现核心应用逻辑，返回html或者json （4）服务层：如果实现了服务化，就有这一层 （5）数据-缓存层：缓存加速访问存储 （6）数据-数据库层：数据库固化数据存储 各分层水平扩展架构实践 反向代理层的水平扩展: 配置多个服务器数量 反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。 当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。 站点层的水平扩展: 配置多个web服务 站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf，可以设置多个web后端。 当web后端成为瓶颈的时候，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。 服务层的水平扩展 1.服务层的水平扩展，是通过“服务连接池”实现的。 站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。 2.动静分离，页面静态化，CDN加速 3.不要频繁的new对象,对于在整个应用中只需要存在一个实例的类使用单例模式 数据层的水平扩展：缓存，数据库 在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。 三、如何处理高并发线程安全问题Java进程加锁乐观锁与悲观锁乐观锁乐观锁是相对悲观锁来说的，它认为数据一般情况下不会造成冲突，所以在访问记录前不会加排他锁，而是在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，具体说根据update返回的行数让用户决定如何去做。乐观锁并不会使用数据库提供的锁机制，一般在表添加version字段或者使用业务状态来做。 悲观锁悲观锁，指数据被外界修改持保守态度(悲观),在整个数据处理过程中，将数据处于锁定状态。 悲观锁的实现，往往依靠数据库提供的锁机制 。数据库中实现是对数据记录进行操作前，先给记录加排它锁，如果获取锁失败，则说明数据正在被其他线程修改，则等待或者抛出异常。如果加锁成功，则获取记录，对其修改，然后事务提交后释放排它锁。 一个例子：select * from 表 where .. for update; 悲观锁是先加锁再访问策略，处理加锁会让数据库产生额外的开销，还有增加产生死锁的机会，另外在多个线程只读情况下不会产生数据不一致行问题，没必要使用锁，只会增加系统负载，降低并发性，因为当一个事务锁定了该条记录，其他读该记录的事务只能等待。 乐观锁直到提交的时候才去锁定，所以不会产生任何锁和死锁。 参考: https://blog.csdn.net/DreamWeaver_zhou/article/details/78587580","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"算法(一)Java经典算法","slug":"backend/java/algorithm/算法(一)Java经典算法","date":"2018-03-31T16:24:12.000Z","updated":"2020-03-16T11:43:55.412Z","comments":true,"path":"2018/04/01/backend/java/algorithm/算法(一)Java经典算法/","link":"","permalink":"http://www.songshuiyang.com/2018/04/01/backend/java/algorithm/算法(一)Java经典算法/","excerpt":"","text":"排序算法冒泡排序123456789101112public void bubbleSort(int []a)&#123; int len=a.length; for(int i=0;i&lt;len;i++)&#123; for(int j=0;j&lt;len-i-1;j++)&#123;//注意第二重循环的条件 if(a[j]&gt;a[j+1])&#123; int temp=a[j]; a[j]=a[j+1]; a[j+1]=temp; &#125; &#125; &#125;&#125; 选择排序123456789101112131415public void selectSort(int[]a)&#123; int len=a.length; for(int i=0;i&lt;len;i++)&#123;//循环次数 int value=a[i]; int position=i; for(int j=i+1;j&lt;len;j++)&#123;//找到最小的值和位置 if(a[j]&lt;value)&#123; value=a[j]; position=j; &#125; &#125; a[position]=a[i];//进行交换 a[i]=value; &#125;&#125; 查找算法二分查找1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.Scanner;/* * 二分查找 */public class BinarySearch &#123; public static void main(String[] args) &#123; int[] arr=&#123;5,3,6,1,9,8,2,4,7&#125;; //先打印输出原始数组数据 System.out.println(\"原始数组数据如下：\"); for (int n : arr) &#123; System.out.print(n+\" \"); &#125; System.out.println(); //首先对数组进行排序，这里用冒泡排序 for(int i=0;i&lt;arr.length-1;i++)&#123; for(int j=0;j&lt;arr.length-1-i;j++)&#123; if(arr[j]&gt;arr[j+1])&#123; int temp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=temp; &#125; &#125; &#125; //遍历输出排序好的数组 System.out.println(\"经过冒泡排序后的数组：\"); for(int n:arr)&#123; System.out.print(n+\" \"); &#125; System.out.println();//换行 Scanner input=new Scanner(System.in); System.out.println(\"请输入你要查找的数：\"); int num=input.nextInt(); int result=binarySearch(arr, num); if(result==-1)&#123; System.out.println(\"你要查找的数不存在……\"); &#125; else&#123; System.out.println(\"你要查找的数存在，在数组中的位置是：\"+result); &#125; &#125; //二分查找算法 public static int binarySearch(int[] arr,int num)&#123; int low=0; int upper=arr.length-1; while(low&lt;=upper)&#123; int mid=(upper+low)/2; if(arr[mid]&lt;num)&#123; low=mid+1; &#125; else if(arr[mid]&gt;num)&#123; upper=mid-1; &#125; else return mid; &#125; return -1; &#125;&#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://www.songshuiyang.com/categories/数据结构/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"Windows批处理(cmd/bat)常用命令","slug":"backend/windows bat","date":"2018-03-24T07:54:12.000Z","updated":"2020-03-16T11:43:55.599Z","comments":true,"path":"2018/03/24/backend/windows bat/","link":"","permalink":"http://www.songshuiyang.com/2018/03/24/backend/windows bat/","excerpt":"需求在使用hexo写博客的时候, hexo d 老是不能把代码push上去，网上找了好多方法都不能解决, 只能自己手动把public文件下生成的文件自己敲git命令push上传, 每次写博客的时候都要执行这种操作, 次数多了会感觉厌烦, 所有想windows不是有批处理脚本吗, 所以自己查阅了一些资料, 写了一个草鸡简单的脚本 auto.bat1234567891011121314151617181920# 文件上传commitgit add -Agit commit -m \"auto commit\"git pushecho copy filexcopy D:\\workspace\\hexo-log-bak\\hexo-log-bak\\public\\*.* D:\\workspace\\hexo-log-upload\\songshuiyang.github.io /s /yecho 提交songshuiyang.github.io 文件cd ../../hexo-log-upload\\songshuiyang.github.iogit add -Agit commit -m \"auto commit\"git pushcd ../../hexo-log-bak/hexo-log-bak","text":"需求在使用hexo写博客的时候, hexo d 老是不能把代码push上去，网上找了好多方法都不能解决, 只能自己手动把public文件下生成的文件自己敲git命令push上传, 每次写博客的时候都要执行这种操作, 次数多了会感觉厌烦, 所有想windows不是有批处理脚本吗, 所以自己查阅了一些资料, 写了一个草鸡简单的脚本 auto.bat1234567891011121314151617181920# 文件上传commitgit add -Agit commit -m \"auto commit\"git pushecho copy filexcopy D:\\workspace\\hexo-log-bak\\hexo-log-bak\\public\\*.* D:\\workspace\\hexo-log-upload\\songshuiyang.github.io /s /yecho 提交songshuiyang.github.io 文件cd ../../hexo-log-upload\\songshuiyang.github.iogit add -Agit commit -m \"auto commit\"git pushcd ../../hexo-log-bak/hexo-log-bak 批处理文件批处理文件（batch file）包含一系列 DOS命令，通常用于自动执行重复性任务。用户只需双击批处理文件便可执行任务，而无需重复输入相同指令。编写批处理文件非常简单，但难点在于确保一切按顺序执行。编写严谨的批处理文件可以极大程度地节省时间，在应对重复性工作时尤其有效。 在Windows中善用批处理可以简化很多重复工作 常用DOS命令123456789101112131415161718192021222324252627282930313233343536373839404142文件夹管理 cd 显示当前目录名或改变当前目录。 md 创建目录。 rd 删除一个目录。 dir 显示目录中的文件和子目录列表。 tree 以图形显示驱动器或路径的文件夹结构。 path 为可执行文件显示或设置一个搜索路径。 xcopy 复制文件和目录树。文件管理 type 显示文本文件的内容。 copy 将一份或多份文件复制到另一个位置。 del 删除一个或数个文件。 move 移动文件并重命名文件和目录。(Windows XP Home Edition中没有) ren 重命名文件。 replace 替换文件。 attrib 显示或更改文件属性。 find 搜索字符串。 fc 比较两个文件或两个文件集并显示它们之间的不同网络命令 ping 进行网络连接测试、名称解析 ftp 文件传输 net 网络命令集及用户管理 telnet 远程登陆 ipconfig显示、修改TCP/IP设置 msg 给用户发送消息 arp 显示、修改局域网的IP地址-物理地址映射列表 系统管理 at 安排在特定日期和时间运行命令和程序 shutdown立即或定时关机或重启 tskill 结束进程 taskkill结束进程(比tskill高级，但WinXPHome版中无该命令) tasklist显示进程列表(Windows XP Home Edition中没有) sc 系统服务设置与控制 reg 注册表控制台工具 powercfg控制系统上的电源设置 例子","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.songshuiyang.com/tags/java/"}]},{"title":"Spring 集成Encache","slug":"backend/framework/cache/Encache","date":"2018-03-24T03:41:12.000Z","updated":"2020-03-16T11:43:55.377Z","comments":true,"path":"2018/03/24/backend/framework/cache/Encache/","link":"","permalink":"http://www.songshuiyang.com/2018/03/24/backend/framework/cache/Encache/","excerpt":"一：Encache1. 什么是EncacheEhCache 是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider。 官网: http://www.ehcache.org/ 2. 基本介绍Ehcache是一种广泛使用的开源Java分布式缓存。主要面向通用缓存,Java EE和轻量级容器。它具有内存和磁盘存储，缓存加载器,缓存扩展,缓存异常处理程序,一个gzip缓存servlet过滤器,支持REST和SOAP api等特点。 Ehcache最初是由Greg Luck于2003年开始开发。2009年,该项目被Terracotta购买。软件仍然是开源,但一些新的主要功能(例如，快速可重启性之间的一致性的)只能在商业产品中使用，例如Enterprise EHCache and BigMemory。维基媒体Foundationannounced目前使用的就是Ehcache技术。","text":"一：Encache1. 什么是EncacheEhCache 是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider。 官网: http://www.ehcache.org/ 2. 基本介绍Ehcache是一种广泛使用的开源Java分布式缓存。主要面向通用缓存,Java EE和轻量级容器。它具有内存和磁盘存储，缓存加载器,缓存扩展,缓存异常处理程序,一个gzip缓存servlet过滤器,支持REST和SOAP api等特点。 Ehcache最初是由Greg Luck于2003年开始开发。2009年,该项目被Terracotta购买。软件仍然是开源,但一些新的主要功能(例如，快速可重启性之间的一致性的)只能在商业产品中使用，例如Enterprise EHCache and BigMemory。维基媒体Foundationannounced目前使用的就是Ehcache技术。 3. 特点主要的特性有： 快速 简单 多种缓存策略 缓存数据有两级：内存和磁盘，因此无需担心容量问题 缓存数据会在虚拟机重启的过程中写入磁盘 可以通过RMI、可插入API等方式进行分布式缓存 具有缓存和缓存管理器的侦听接口 支持多缓存管理器实例，以及一个实例的多个缓存区域 提供Hibernate的缓存实现 ehcache与redis的区别1.redis的数据结构比较丰富，有key-value、hash、set等；ehcache比较简单，只有key-value 2.ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。redis是通过socket访问到缓存服务，效率ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。如果是单个应用或者对缓存访问要求很高的应用，用ehcache。如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。 二: Encache与Spring 集成1. 前言Spring自身并没有实现缓存解决方案，但是对缓存管理功能提供了声明式的支持，能够与多种流行的缓存实现进行集成。 Spring Cache是作用在方法上的（不能理解为只注解在方法上），其核心思想是：当我们在调用一个缓存方法时会把该方法参数和返回结果作为一个键值存放在缓存中，等到下次利用同样的参数调用该方法时将不再执行该方法，而是直接从缓存中获取结果进行返回。所以在使用Spring Cache的时候我们要保证我们的缓存的方法对于相同的方法参数要有相同的返回结果。 2. 开始集成 导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt;&lt;/dependency&gt; 编写ehcache.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://ehcache.org/ehcache.xsd\"&gt; &lt;!-- 磁盘缓存位置 在Windows的缓存目录为：C:\\Users\\登录用户~1\\AppData\\Local\\Temp\\ Linux：/tmp --&gt; &lt;diskStore path=\"java.io.tmpdir/ehcache\"/&gt; &lt;!--name：缓存名称。--&gt; &lt;!--maxElementsInMemory：缓存最大个数。--&gt; &lt;!--eternal：缓存中对象是否为永久的，如果是，超时设置将被忽略，对象从不过期。--&gt; &lt;!--timeToIdleSeconds：置对象在失效前的允许闲置时间（单位：秒）。仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大。--&gt; &lt;!--timeToLiveSeconds：缓存数据的生存时间（TTL），也就是一个元素从构建到消亡的最大时间间隔值，这只能在元素不是永久驻留时有效，如果该值是0就意味着元素可以停顿无穷长的时间。--&gt; &lt;!--maxEntriesLocalDisk：当内存中对象数量达到maxElementsInMemory时，Ehcache将会对象写到磁盘中。--&gt; &lt;!--overflowToDisk：内存不足时，是否启用磁盘缓存。--&gt; &lt;!--diskSpoolBufferSizeMB：这个参数设置DiskStore（磁盘缓存）的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区。--&gt; &lt;!--maxElementsOnDisk：硬盘最大缓存个数。--&gt; &lt;!--diskPersistent：是否在VM重启时存储硬盘的缓存数据。默认值是false。--&gt; &lt;!--diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是120秒。--&gt; &lt;!--memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。--&gt; &lt;!--clearOnFlush：内存数量最大时是否清除。--&gt; &lt;!--@Cacheable(value = \"users\", condition = \"#user.getId() &lt;= 2\")--&gt; &lt;!--@CachePut(value = \"users\", key = \"#user.getId()\")--&gt; &lt;!--@CacheEvict(value = \"users\", allEntries = true)--&gt; &lt;!-- 默认缓存 --&gt; &lt;defaultCache maxEntriesLocalHeap=\"10000\" eternal=\"false\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" maxEntriesLocalDisk=\"10000000\" diskExpiryThreadIntervalSeconds=\"120\" memoryStoreEvictionPolicy=\"LRU\"&gt; &lt;persistence strategy=\"localTempSwap\"/&gt; &lt;/defaultCache&gt; &lt;!-- 博客文章详情缓存 --&gt; &lt;cache name=\"articlesDetail\" maxElementsInMemory=\"1000\" eternal=\"false\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" overflowToDisk=\"false\" memoryStoreEvictionPolicy=\"LRU\"/&gt; &lt;!-- hotArticles缓存 --&gt; &lt;cache name=\"articlesDetail\" maxElementsInMemory=\"1000\" eternal=\"true\" overflowToDisk=\"false\" memoryStoreEvictionPolicy=\"LRU\"/&gt;&lt;/ehcache&gt; 在需要缓存的地方加上缓存注解 12345678910111213141516171819202122/** * 第一次执行会缓存文章,以id作为key, 第二次会直接取缓存的数据(需要在缓存有效期,过期会重新查询数据库) * @param id * @return */@Override@Cacheable(value = \"articlesDetail\", key = \"#id\")public BlogArticles selectByPrimaryKey(Integer id) &#123; return getMappser().selectByPrimaryKey(id);&#125;/** * 保存文章，同时删除record.getId()该已存的缓存数据 * @param record * @return */@Override@CacheEvict(value = \"articlesDetail\", key = \"#record.getId()\")public int updateByPrimaryKeySelective(BlogArticles record) &#123; setCurrentOperator(record); return getMappser().updateByPrimaryKeySelective(record);&#125; 3. 注解讲解首先使用注解标记方法，相当于定义了切点，然后使用Aop技术在这个方法的调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。 @Cacheable 12345678910111213141516171819202122232425262728表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。 这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。 可以使用key属性来指定key的生成规则。@Cacheable 支持如下几个参数： value：缓存位置名称，不能为空，如果使用EHCache，就是ehcache.xml中声明的cache的name, 指明将值缓存到哪个Cache中 key：缓存的key，默认为空，既表示使用方法的参数类型及参数值作为key，支持SpEL，如果要引用参数值使用井号加参数名，如：#userId， 一般来说，我们的更新操作只需要刷新缓存中某一个值，所以定义缓存的key值的方式就很重要，最好是能够唯一，因为这样可以准确的清除掉特定的缓存，而不会影响到其它缓存值 ， 本例子中使用实体加冒号再加ID组合成键的名称，如”user:1”、”order:223123”等 condition：触发条件，只有满足条件的情况才会加入缓存，默认为空，既表示全部都加入缓存，支持SpEL // 将缓存保存到名称为UserCache中，键为\"user:\"字符串加上userId值，如 'user:1' @Cacheable(value=\"UserCache\", key=\"'user:' + #userId\") public User findById(String userId) &#123; return (User) new User(\"1\", \"mengdee\"); &#125; // 将缓存保存进UserCache中，并当参数userId的长度小于12时才保存进缓存，默认使用参数值及类型作为缓存的key // 保存缓存需要指定key，value， value的数据类型，不指定key默认和参数名一样如：\"1\" @Cacheable(value=\"UserCache\", condition=\"#userId.length() &lt; 12\") public boolean isReserved(String userId) &#123; System.out.println(\"UserCache:\"+userId); return false; &#125; @CachePut 1与@Cacheable不同，@CachePut不仅会缓存方法的结果，还会执行方法的代码段。它支持的属性和用法都与@Cacheable一致。 @CacheEvict 1234567891011121314151617181920与@Cacheable功能相反，@CacheEvict表明所修饰的方法是用来删除失效或无用的缓存数据。@CacheEvict 支持如下几个参数： value：缓存位置名称，不能为空，同上 key：缓存的key，默认为空，同上 condition：触发条件，只有满足条件的情况才会清除缓存，默认为空，支持SpEL allEntries：true表示清除value中的全部缓存，默认为false //清除掉UserCache中某个指定key的缓存 @CacheEvict(value=\"UserCache\",key=\"'user:' + #userId\") public void removeUser(User user) &#123; System.out.println(\"UserCache\"+user.getUserId()); &#125; //清除掉UserCache中全部的缓存 @CacheEvict(value=\"UserCache\", allEntries=true) public final void setReservedUsers(String[] reservedUsers) &#123; System.out.println(\"UserCache deleteall\"); &#125; @Caching 1234如果需要使用同一个缓存注解（@Cacheable、@CacheEvict或@CachePut）多次修饰一个方法，就需要用到@Caching。@Caching(evict = &#123; @CacheEvict(\"primary\"), @CacheEvict(cacheNames=\"secondary\", key=\"#p0\") &#125;)public Book importBooks(String deposit, Date date) @CacheConfig 12345678与前面的缓存注解不同，这是一个类级别的注解。 如果类的所有操作都是缓存操作，你可以使用@CacheConfig来指定类，省去一些配置。@CacheConfig(\"books\")public class BookRepositoryImpl implements BookRepository &#123; @Cacheable public Book findBook(ISBN isbn) &#123;...&#125;&#125; 4. 创建Cache工具类, 方便对cache进行管理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.ecut.core.utils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cache.Cache;import org.springframework.cache.CacheManager;/** * 缓存工具类 * @author songshuiyang * @date 2018/3/24 12:16 */public class CacheUtils &#123; private final static Logger logger = LoggerFactory.getLogger(CacheUtils.class); private static CacheManager cacheManager = (CacheManager) SpringContextUtils.getBean(\"cacheManager\"); /** * 获取缓存 * @param cacheName 缓存名 * @param key 键 * @return Object */ public static Object get(String cacheName, Object key) &#123; Cache cache = cacheManager.getCache(cacheName); if (cache != null) &#123; //这里需要判断是否null if(cache.get(key) != null)&#123; return cache.get(key).get(); &#125; &#125; return null; &#125; /** * 添加缓存 * 存在则更新 * @param cacheName 缓存名 * @param key 键 * @param value 值 */ public static void put(String cacheName, Object key, Object value) &#123; Cache cache = cacheManager.getCache(cacheName); if(cache != null)&#123; cache.put(key, value); &#125; &#125; /** * 清除缓存 * @param cacheName 缓存名 * @param key 键 */ public static void remove(String cacheName, Object key) &#123; Cache cache = cacheManager.getCache(cacheName); if (cache != null) &#123; cache.evict(key); &#125;else&#123; logger.warn(\"this key is not in Cache\"); &#125; &#125;&#125;&#125; 参考：https://blog.csdn.net/vbirdbest/article/details/72763048http://www.cnblogs.com/jingmoxukong/p/5975994.html","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"}]},{"title":"hover.css","slug":"frontend/hover","date":"2018-03-20T12:52:12.000Z","updated":"2019-09-16T13:11:07.276Z","comments":true,"path":"2018/03/20/frontend/hover/","link":"","permalink":"http://www.songshuiyang.com/2018/03/20/frontend/hover/","excerpt":"","text":"Hover.cssA collection of CSS3 powered hover effects to be applied to links, buttons, logos, SVG, featured images and so on. Easily apply to your own elements, modify or just use for inspiration. Available in CSS, Sass, and LESS. 官网地址: http://ianlunn.github.io/Hover/ 演示地址: http://wow.techbrood.com/fiddle/852","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"css","slug":"css","permalink":"http://www.songshuiyang.com/tags/css/"}]},{"title":"Linux 命令笔记","slug":"backend/server/Linux/linux笔记","date":"2018-03-08T09:30:44.000Z","updated":"2019-11-10T02:08:42.073Z","comments":true,"path":"2018/03/08/backend/server/Linux/linux笔记/","link":"","permalink":"http://www.songshuiyang.com/2018/03/08/backend/server/Linux/linux笔记/","excerpt":"","text":"出现问题 bash: service: command not found, 解决方法：1yum install initscripts 查看端口12345678910111213141516# 查看80端口占用情况lsof -i tcp:80# 列出所有端口netstat -ntlp# 查看端口状态netstat -lnp|grep 88 #88请换为你的apache需要的端口，如：80# SSH执行以上命令，可以查看到88端口正在被哪个进程使用。如下图，进程号为 1777 。# 查看进程的详细信息ps 1777# 杀掉进程kill -9 1777 #杀掉编号为1777的进程（请根据实际情况输入）","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"Docker笔记","slug":"backend/server/Linux/Docker笔记","date":"2018-03-08T06:30:44.000Z","updated":"2019-11-10T02:08:42.070Z","comments":true,"path":"2018/03/08/backend/server/Linux/Docker笔记/","link":"","permalink":"http://www.songshuiyang.com/2018/03/08/backend/server/Linux/Docker笔记/","excerpt":"什么是DockerDocker 是一种“轻量级”容器技术，它几乎动摇了传统虚拟化技术的地位，现在国内外已经有越来越多的公司开始逐步使用 Docker 来替换现有的虚拟化平台了。作为一名 Java 程序员，我们是时候一起把 Docker 学起来了！ 1.传统虚拟化技术的体系架构： mechine.png 可见，我们在宿主机的操作系统上，可安装了多个虚拟机，而在每个虚拟机中，通过虚拟化技术，实现了一个虚拟操作系统，随后，就可以在该虚拟操作系统上，安装自己所需的应用程序了。这一切看似非常简单，但其中的技术细节是相当高深莫测的，大神级人物都不一定说得清楚。","text":"什么是DockerDocker 是一种“轻量级”容器技术，它几乎动摇了传统虚拟化技术的地位，现在国内外已经有越来越多的公司开始逐步使用 Docker 来替换现有的虚拟化平台了。作为一名 Java 程序员，我们是时候一起把 Docker 学起来了！ 1.传统虚拟化技术的体系架构： mechine.png 可见，我们在宿主机的操作系统上，可安装了多个虚拟机，而在每个虚拟机中，通过虚拟化技术，实现了一个虚拟操作系统，随后，就可以在该虚拟操作系统上，安装自己所需的应用程序了。这一切看似非常简单，但其中的技术细节是相当高深莫测的，大神级人物都不一定说得清楚。 凡是使用过虚拟机的同学，应该都知道，启动虚拟机就像启动一台计算机，初始化过程是相当慢的，我们需要等很久，才能看到登录界面。一旦虚拟机启动以后，就可以与宿主机建立网络连接，确保虚拟机与宿主机之间是互联互通的。不同的虚拟机之间却是相互隔离的，也就是说，彼此并不知道对方的存在，但每个虚拟机占用的都是宿主机的硬件与网络资源。 2.Docker 技术的体系架构 mechine.png 可见，在宿主机的操作系统上，有一个 Docker 服务在运行（或者称为“Docker 引擎”），在此服务上，我们可开启多个 Docker 容器，而每个 Docker 容器中可运行自己所需的应用程序，Docker 容器之间也是相互隔离的，同样地，都是占用的宿主机的硬件与网络资源。、 Docker 容器相对于虚拟机而言，除了在技术实现上完全不一样以外，启动速度较虚拟机而言有本质的飞跃，启动一个容器只在眨眼瞬间。不管是虚拟机还是 Docker 容器，它们都是为了隔离应用程序的运行环境，节省我们的硬件资源，为我们开发人员提供福利。 3.Docker 的 Logo: logo.png 很明显，这是一只鲸鱼，它托着许多集装箱。我们可以把宿主机可当做这只鲸鱼，把相互隔离的容器可看成集装箱，每个集装箱中都包含自己的应用程序。这 Logo 简直的太形象了！ 4.Docker的应用场景123451. Web 应用的自动化打包和发布。2. 自动化测试和持续集成、发布。3. 在服务型环境中部署和调整数据库或其他的后台应用。 5.Docker 的优点123456781、简化程序：Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管理。方便快捷已经是 Docker的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成。2、避免选择恐惧症：如果你有选择恐惧症，还是资深患者。Docker 帮你 打包你的纠结！比如 Docker 镜像；Docker 镜像中包含了运行环境和配置，所以 Docker 可以简化部署多种应用实例工作。比如 Web 应用、后台应用、数据库应用、大数据应用比如 Hadoop 集群、消息队列等等都可以打包成一个镜像部署。3、节省开支：一方面，云计算时代到来，使开发者不必为了追求效果而配置高额的硬件，Docker 改变了高性能必然高价格的思维定势。Docker 与云的结合，让云空间得到更充分的利用。不仅解决了硬件管理的问题，也改变了虚拟化的方式。 Docker 术语 术语 说明 Docker 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板。 Docker 容器(Container) 容器是独立运行的一个或一组应用。 Docker 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker API (https://docs.docker.com/reference/api/docker_remote_api) 与 Docker 的守护进程通信。 Docker 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 Docker 仓库(Registry) Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。 Docker Machine Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。 使用Docker前先配置 Docker国内镜像或者使用registry-mirrors配置加速由于国内访问直接访问Docker hub网速比较慢，拉取镜像的时间就会比较长。一般我们会使用镜像加速或者直接从国内的一些平台镜像仓库上拉取。 123456789101112131415161718192021222324方法一： 网易镜像中心：https://c.163.com/hub#/m/home/ 拉取镜像的命令是： docker pull 镜像名字 所以我们可以按照给出的镜像名字或者命令直接拉取。eg: docker pull hub.c.163.com/library/tomcat:latest方法二： daocloud镜像市场：https://hub.daocloud.io/如果说还是想从dockerhub上拉取，那么使用加速器修改docker的registry-mirrors。这里使用的是DaoCloud的加速器。 首先在http://www.daocloud.io/进行注册登录。然后点击加速器，得到如下脚本 curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://24524c4f.m.daocloud.io Copy 该脚本可以将 --registry-mirror 加入到你的 Docker 配置文件 /etc/docker/daemon.json 中。适用于 Ubuntu14.04、Debian、CentOS6 、CentOS7、Fedora、Arch Linux、openSUSE Leap 42.1，其他版本可能有细微不同。更多详情请访问文档。 也可以自己手动修改 /etc/docker/daemon.json&#123; \"registry-mirrors\": [\"http://ef017c13.m.daocloud.io\"], \"live-restore\": true&#125;最后重启docker service docker restart 安装 Docker1.前提条件1234使用 yum 安装（CentOS 7下）Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。通过 uname -r 命令查看你当前的内核版本 2.安装1yum -y install docker 3.启动服务1service docker start 4.测试运行 hello-world1docker run hello-world Docker中使用CentOS7镜像1.启动容器服务1systemctl start docker.service 2.下载CentOS7 镜像12345678910111213141516[root@JD docker]# docker pull centos:7.3.1611Trying to pull repository docker.io/library/centos ... 7.3.1611: Pulling from docker.io/library/centos版本: https://hub.docker.com/_/centos/ 可以在这个网站上选择自己想要的版本 latest, centos7, 7 (docker/Dockerfile) centos6, 6 (docker/Dockerfile) centos7.4.1708, 7.4.1708 (docker/Dockerfile) centos7.3.1611, 7.3.1611 (docker/Dockerfile) centos7.2.1511, 7.2.1511 (docker/Dockerfile) centos7.1.1503, 7.1.1503 (docker/Dockerfile) centos7.0.1406, 7.0.1406 (docker/Dockerfile) centos6.9, 6.9 (docker/Dockerfile) centos6.8, 6.8 (docker/Dockerfile) centos6.7, 6.7 (docker/Dockerfile) centos6.6, 6.6 (docker/Dockerfile) 3.下载成功之后查看本地所有的镜像，得到centos的 IMAGE ID: 66ee80d59a6812345[root@JD ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/tomcat latest 108db0e7c85e 2 weeks ago 557.4 MBdocker.io/hello-world latest f2a91732366c 3 months ago 1.848 kBdocker.io/centos 7.3.1611 66ee80d59a68 4 months ago 191.8 MB 4.启动docker中的CentOS712345678910111213141516171819docker run -ti 66ee /bin/bash#6866 是 IMAGE ID 前四位数字-能区分出是哪个image即可root@b4ad1d1c87da /]# #登录成功，接下来就可以为所欲为啦。命令笔记 容器是在镜像的基础上来运行的，一旦容器启动了，我们就可以登录到容器中，安装自己所需的软件或应用程序。既然镜像已经下载到本地，那么如何才能启动容器呢 docker run -i -t -v /root/software/:/mnt/software/ 25c5298b1a36 /bin/bash docker run &lt;相关参数&gt; &lt;镜像 ID&gt; &lt;初始命令&gt; -i：表示以“交互模式”运行容器 -t：表示容器启动后会进入其命令行 -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt; 假设我们的所有安装程序都放在了宿主机的/root/software/目录下，现在需要将其挂载到容器的/mnt/software/目录下。 初始命令表示一旦容器启动，需要运行的命令，此时使用“/bin/bash”，表示什么也不做，只需进入命令行即可。 5.检查CentOS7系统1234root@b4ad1d1c87da /]# uname -aLinux b4ad1d1c87da 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux[root@b4ad1d1c87da /]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) 6.退出1234ctrl+d 退出容器且关闭, docker ps 查看无,ctrl+p+q 退出容器但不关闭, docker ps 7.再进入CentOS71234567[root@wxtest1607 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb4ad1d1c87da 6866 \"/bin/bash\" 12 seconds ago Up 9 seconds mad_swanson drunk_hypatia得到 CONTAINER ID [root@wxtest1607 ~]# docker exec -ti b4ad /bin/bash [root@b4ad1d1c87da /]# 8.安装tomcat123456781. yum -y install tomcat注： 在docker中通过systemctl 启动服务的时候总是报Failed to get D-Bus connection: Operation not permitted 这样的错误提示。 解决方法： 解决办法就是在docker run 的时候运行/usr/sbin/init 。比如： docker run -ti 66ee /usr/sbin/init2. 在Centos使用yum安装后，Tomcat相关的目录都已采用符号链接到/usr/share/tomcat6目录，包含webapps等，这很方便我们配置管理 转载：http://www.runoob.com/docker/docker-tutorial.html 转载：http://developer.51cto.com/art/201702/529956.htm 转载：http://www.jb51.net/article/112921.htm 转载：https://www.jianshu.com/p/0aa535e681f5","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"http://www.songshuiyang.com/tags/Docker/"}]},{"title":"Centos7安装Mysql5.7.md","slug":"backend/server/Linux/Centos7安装Mysql5.7","date":"2018-03-07T12:30:44.000Z","updated":"2019-11-10T02:08:42.059Z","comments":true,"path":"2018/03/07/backend/server/Linux/Centos7安装Mysql5.7/","link":"","permalink":"http://www.songshuiyang.com/2018/03/07/backend/server/Linux/Centos7安装Mysql5.7/","excerpt":"一：配置YUM源 官网地址 在MySQL官网中下载YUM源rpm安装包：http://dev.mysql.com/downloads/repo/yum/ 1.下载mysql源安装包1wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 命令笔记:12345678910111213141516171819202122232425262728wget:用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用-a&lt;日志文件&gt;：在指定的日志文件中记录资料的执行过程；-A&lt;后缀名&gt;：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；-b：进行后台的方式运行wget；-B&lt;连接地址&gt;：设置参考的连接地址的基地地址；-c：继续执行上次终端的任务；-C&lt;标志&gt;：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；-d：调试模式运行指令；-D&lt;域名列表&gt;：设置顺着的域名列表，域名之间用“，”分隔；-e&lt;指令&gt;：作为文件“.wgetrc”中的一部分执行指定的指令；-h：显示指令帮助信息；-i&lt;文件&gt;：从指定文件获取要下载的URL地址；-l&lt;目录列表&gt;：设置顺着的目录列表，多个目录用“，”分隔；-L：仅顺着关联的连接；-r：递归下载方式；-nc：文件存在时，下载文件不覆盖原有文件；-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；-q：不显示指令执行过程；-nh：不查询主机名称；-v：显示详细执行过程；-V：显示版本信息；--passive-ftp：使用被动模式PASV连接FTP服务器；--follow-ftp：从HTML文件中下载FTP连接文件下载并以不同的文件名保存:wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080","text":"一：配置YUM源 官网地址 在MySQL官网中下载YUM源rpm安装包：http://dev.mysql.com/downloads/repo/yum/ 1.下载mysql源安装包1wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 命令笔记:12345678910111213141516171819202122232425262728wget:用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用-a&lt;日志文件&gt;：在指定的日志文件中记录资料的执行过程；-A&lt;后缀名&gt;：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；-b：进行后台的方式运行wget；-B&lt;连接地址&gt;：设置参考的连接地址的基地地址；-c：继续执行上次终端的任务；-C&lt;标志&gt;：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；-d：调试模式运行指令；-D&lt;域名列表&gt;：设置顺着的域名列表，域名之间用“，”分隔；-e&lt;指令&gt;：作为文件“.wgetrc”中的一部分执行指定的指令；-h：显示指令帮助信息；-i&lt;文件&gt;：从指定文件获取要下载的URL地址；-l&lt;目录列表&gt;：设置顺着的目录列表，多个目录用“，”分隔；-L：仅顺着关联的连接；-r：递归下载方式；-nc：文件存在时，下载文件不覆盖原有文件；-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；-q：不显示指令执行过程；-nh：不查询主机名称；-v：显示详细执行过程；-V：显示版本信息；--passive-ftp：使用被动模式PASV连接FTP服务器；--follow-ftp：从HTML文件中下载FTP连接文件下载并以不同的文件名保存:wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080 2.安装mysql源1yum localinstall mysql57-community-release-el7-8.noarch.rpm 命令笔记:12345678910111213141516171819202122232425262728293031323334353637yum命令是在Fedora和RedHat以及SUSE中基于rpm的软件包管理器，它可以使系统管理人员交互和自动化地更细与管理RPM软件包，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。选项:-h：显示帮助信息；-y：对所有的提问都回答“yes”；-c：指定配置文件；-q：安静模式；-v：详细模式；-d：设置调试等级（0-10）；-e：设置错误等级（0-10）；-R：设置yum处理一个命令的最大等待时间；-C：完全从缓存中运行，而不去下载或者更新任何头文件。参数：install：安装rpm软件包；update：更新rpm软件包；check-update：检查是否有可用的更新rpm软件包；remove：删除指定的rpm软件包；list：显示软件包的信息；search：检查软件包的信息；info：显示指定的rpm软件包的描述信息和概要信息；clean：清理yum过期的缓存；shell：进入yum的shell提示符；resolvedep：显示rpm软件包的依赖关系；localinstall：安装本地的rpm软件包；localupdate：显示本地rpm软件包进行更新；deplist：显示rpm软件包的所有依赖关系。实例部分常用的命令包括：自动搜索最快镜像插件：yum install yum-fastestmirror安装yum图形窗口插件：yum install yumex查看可能批量安装的列表：yum grouplist 3.检查mysql源是否安装成功1yum repolist enabled | grep \"mysql.*-community.*\" logo 看到上图所示表示mysql源安装成功。 可以修改vim /etc/yum.repos.d/mysql-community.repo源，改变默认安装的mysql版本。比如要安装5.6版本，将5.7源的enabled=1改成enabled=0。然后再将5.6源的enabled=0改成enabled=1即可 二 安装MySQL1yum install mysql-community-server 命令笔记:123456789101112131415161718192021222324252627安装yum install #全部安装yum install package1 #安装指定的安装包package1yum groupinsall group1 #安装程序组group1更新和升级yum update #全部更新yum update package1 #更新指定程序包package1yum check-update #检查可更新的程序yum upgrade package1 #升级指定程序包package1yum groupupdate group1 #升级程序组group1查找和显示yum info package1 #显示安装包信息package1yum list #显示所有已经安装和可以安装的程序包yum list package1 #显示指定程序包安装情况package1yum groupinfo group1 #显示程序组group1信息yum search string 根据关键字string查找安装包删除程序yum remove &amp;#124; erase package1 #删除程序包package1yum groupremove group1 #删除程序组group1yum deplist package1 #查看程序package1依赖情况 三：启动MySQL服务1.启动1systemctl start mysqld 命令笔记：123456789101112systemctl是系统服务管理器指令，它实际上将 service 和 chkconfig 这两个命令组合到一起。任务 旧指令 新指令使某服务自动启动 chkconfig --level 3 httpd on systemctl enable httpd.service使某服务不自动启动 chkconfig --level 3 httpd off systemctl disable httpd.service检查服务状态 service httpd status systemctl status httpd.service （服务详细信息） systemctl is-active httpd.service （仅显示是否 Active)显示所有已启动的服务 chkconfig --list systemctl list-units --type=service启动某服务 service httpd start systemctl start httpd.service停止某服务 service httpd stop systemctl stop httpd.service重启某服务 service httpd restart systemctl restart httpd.service 2.查看状态1234567891011121314151617查看MySQL的启动状态systemctl status mysqld输出：● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2018-03-07 21:14:55 CST; 18min ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 17338 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 17320 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 17343 (mysqld) CGroup: /system.slice/mysqld.service └─17343 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pidMar 07 21:14:54 VM_0_8_centos systemd[1]: Starting MySQL Server...Mar 07 21:14:55 VM_0_8_centos systemd[1]: Started MySQL Server. 3.开机启动12systemctl enable mysqldsystemctl daemon-reload 4.修改root本地登录密码12345678910111213141516171819202122232425mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个默认密码。通过下面的方式找到root默认密码，然后登录mysql进行修改：1. 修改密码策略 mysql5.7默认安装了密码安全检查插件（validate_password），默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位。否则会提示ERROR 1819 (HY000): Your password does not satisfy the current policy requirements错误 步骤1：不需要密码策略，添加/etc/my.cnf件中添加如下配置禁用即可： validate_password = off 步骤2：重新启动mysql服务使配置生效： systemctl restart mysqld 2. 查看初始密码： grep 'temporary password' /var/log/mysqld.log 输出： 2018-03-07T13:01:08.963552Z 1 [Note] A temporary password is generated for root@localhost: zktt1wKFD.HN 得到临时密码: zktt1wKFD.HN3. 登录mysql: mysql -uroot -p 输入临时密码进入mysql命令行4. 修改密码 set password for 'root'@'localhost'=password('MyNewPass4!'); 5. 重启服务 systemctl restart mysqld 四：开启远程连接1234567891011121314151617181920登入mysql mysql -uroot -p 使用mysql数据库 use mysql; 开启远程连接（root 用户名，% 所有人都可以访问 ，password 密码） GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'password' WITH GRANT OPTION; 也可以添加一个新用户: GRANT ALL PRIVILEGES ON *.* TO 'shuiyang'@'%' IDENTIFIED BY 'password!' WITH GRANT OPTION; FLUSH PRIVILEGES; 重起mysql服务 service mysqld restart如果执行完以上步骤，还是不能远程连接，那么我们需要查看服务器的防火墙是否开启 service iptables status如果防火墙开启，请关闭 service iptables stop 五：配置默认编码为utf812345678910111213141516171819202122修改/etc/my.cnf配置文件，在[mysqld]下添加编码配置，如下所示：[mysqld]character_set_server=utf8init_connect='SET NAMES utf8'重新启动mysql服务，查看数据库默认编码如下所示：mysql&gt; show variables like '%character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 备注：12345默认配置文件路径： 配置文件：/etc/my.cnf 日志文件：/var/log//var/log/mysqld.log 服务启动脚本：/usr/lib/systemd/system/mysqld.service socket文件：/var/run/mysqld/mysqld.pid 转载：https://www.linuxidc.com/Linux/2016-09/135288.htm转载:http://blog.csdn.net/sun614345456/article/details/53672150","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"计算机网络-基础-HTTPS原理解析","slug":"backend/network/计算机网络-基础-HTTPS原理解析","date":"2018-03-05T16:01:01.000Z","updated":"2019-11-27T15:11:32.612Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础-HTTPS原理解析/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础-HTTPS原理解析/","excerpt":"","text":"前言 HTTPS（全称：HyperText Transfer Protocol over Secure Socket Layer），其实 HTTPS 并不是一个新鲜协议，Google 很早就开始启用了，初衷是为了保证数据安全。 近两年，Google、Baidu、Facebook 等这样的互联网巨头，不谋而合地开始大力推行 HTTPS， 国内外的大型互联网公司很多也都已经启用了全站 HTTPS，这也是未来互联网发展的趋势。 为鼓励全球网站的 HTTPS 实现，一些互联网公司都提出了自己的要求： 1）Google 已调整搜索引擎算法，让采用 HTTPS 的网站在搜索中排名更靠前； 2）从 2017 年开始，Chrome 浏览器已把采用 HTTP 协议的网站标记为不安全网站； 3）苹果要求 2017年 App Store 中的所有应用都必须使用 HTTPS 加密连接； 4）当前国内炒的很火热的微信小程序也要求必须使用 HTTPS 协议； 5）新一代的 HTTP/2 协议的支持需以 HTTPS为基础。 等等，因此想必在不久的将来，全网 HTTPS 势在必行。 基础概念 HTTPS ，实际就是在 TCP 层与 HTTP 层之间加入了 SSL/TLS 来为上层的安全保驾护航，主要用到对称加密、非对称加密、证书，等技术进行客户端与服务器的数据加密传输，最终达到保证整个通信的安全性。 一句话概括：HTTP + 加密 + 认证 + 完整性保护 = HTTPS 如上图所示 HTTPS 相比 HTTP 多了一层 SSL/TLS，这一层目的就是保证数据安全 SSL 是安全套接层(secure sockets layer) TLS 是 SSL 的进化体，叫传输层安全(transport layer security)。 对称加密和非对称加密 加密算法分 对称加密 和 非对称加密 对称加密算法的加密与解密密钥相同 常见的 对称加密 算法主要有 DES、3DES、AES 等 非对称加密算法的加密密钥与解密密钥不同 常见的 非对称算法 主要有 RSA、DSA 等 没有HTTPS会怎么样 没有使用HTTPS会怎么样，先看下HTTP 访问过程，抓包如下： 如上图所示，HTTP请求过程中，客户端与服务器之间没有任何身份确认的过程，数据全部明文传输，“裸奔”在互联网上，所以很容易遭到黑客的攻击，如下： 可以看到，客户端发出的请求很容易被黑客截获，如果此时黑客冒充服务器，则其可返回任意信息给客户端，而不被客户端察觉，所以我们经常会听到一词“劫持”，现象如下： 所以 HTTP 传输面临的风险有： （1） 窃听风险：黑客可以获知通信内容。 （2） 篡改风险：黑客可以修改通信内容。 （3） 冒充风险：黑客可以冒充他人身份参与通信。 HTTP 向 HTTPS 演化的过程1、使用对称秘钥加密 为了防止上述现象的发生，人们想到一个办法：对传输的信息加密（即使黑客截获，也无法破解） 如下图所示，此种方式属于对称加密，双方拥有相同的密钥，信息得到安全传输，但此种方式的缺点是： （1）不同的客户端、服务器数量庞大，所以双方都需要维护大量的密钥，维护成本很高 （2）因每个客户端、服务器的安全级别不同，密钥极易泄露 2、使用非对称加密 使用对称加密时双方都需要维护大量的密钥，维护成本很高，那有没有其他方法呢，那么非对称加密出现了 非对称加密算法的加密密钥与解密密钥不同，一般是私钥放在服务器端用于解密，公钥分发给客户端，大家都用这个进行加密，但是这样也存在缺点 （1）使用非对称RSA加密算法性能是非常低的，原因在于寻找大素数、大数计算、数据分割需要耗费很多的CPU周期，那这样的话每次连接都要消耗性能 （2）公钥是公开的（也就是黑客也会有公钥），所以第 ④ 步私钥加密的信息，如果被黑客截获，其可以使用公钥进行解密，获取其中的内容 （3）如何确认服务器是真实的而不是黑客 3、解决上面非对称加密的问题3.1 问题一：使用非对称RSA加密算法性能是非常低问题 上面提到使用非对称RSA加密算法性能是非常低的，哪有什么优化的呢，那可以将对称加密，非对称加密两者结合起来，取其精华、去其糟粕，发挥两者的各自的优势 如下图所示 （1）第 ③ 步时，客户端将（咱们后续回话采用对称加密吧，这是对称加密的算法和对称密钥）这段信息用公钥进行加密，然后传给服务器 （2）服务器收到信息后，用私钥解密，提取出对称加密算法和对称密钥后，服务器说：好的，使用这个对称密钥进行加密 （3）后续两者之间信息的传输就可以使用对称加密的方式了，这样就解决了加密算法性能问题 3.2 问题二：公钥是公开的，从哪里获取公钥呢 （1）获取公钥可以提供一个下载公钥的地址，回话前让客户端去下载 缺点：下载地址有可能是假的；客户端每次在回话前都先去下载公钥也很麻烦 （2）回话开始时，服务器把公钥发给客户端 缺点：黑客冒充服务器，发送给客户端假的公钥 3.3 问题三：如何确认服务器是真实的而不是黑客 这个怎么解决呢？ 4、最终体 针对上面三个问题，终极武器出现了：SSL 证书 如上图所示，在第 ② 步时服务器发送了一个SSL证书给客户端，SSL 证书中包含的具体内容有：证书的发布机构CA、证书的有效期、公钥、证书所有者、签名、 客户端在接受到服务端发来的SSL证书时，会对证书的真伪进行校验，以浏览器为例说明如下： （1）首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验 （2）浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发 （3）如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。 （4）如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密 （5）浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比 （6）对比结果一致，则证明服务器发来的证书合法，没有被冒充 （7）此时浏览器就可以读取证书中的公钥，用于后续加密了 如果证书合法，客户端会产生一段随机数，这个随机数就作为通信的密钥，我们称之为对称密钥，然后客户端将这个对称秘钥、对称加密算法用公钥加密，然后将这些信息发送到服务器，服务器用密钥解密获取到这些信息之后就知道客户端要怎么加密了，现在双方就可以使用对称密钥进行加密解密通信了 所以通过发送SSL证书的形式，既解决了公钥获取问题，又解决了黑客冒充问题，一箭双雕，HTTPS加密过程也就此形成，所以相比HTTP，HTTPS 传输更加安全 （1） 所有信息都是加密传播，黑客无法窃听。 （2） 具有校验机制，一旦被篡改，通信双方会立刻发现。 （3） 配备身份证书，防止身份被冒充。 补充HTTP 和 HTTPS 的区别 端口不同：HTTP 与 HTTPS 使用不同的连接方式，用的端口也不一样，前者是 80，后者是 443。 资源消耗：和 HTTP 通信相比，HTTPS 通信会由于加解密处理消耗更多的 CPU 和内存资源。 开销：HTTPS 通信需要证书，而证书一般需要向认证机构申请免费或者付费购买。 总结 综上所述，相比 HTTP 协议，HTTPS 协议增加了很多握手、加密解密等流程，虽然过程很复杂，但其可以保证数据传输的安全。所以在这个互联网膨胀的时代，其中隐藏着各种看不见的危机，为了保证数据的安全，维护网络稳定，建议大家多多推广HTTPS。 HTTPS 缺点： 1、SSL证书费用很高，以及其在服务器上的部署、更新维护非常繁琐 2、HTTPS 降低用户访问速度（多次握手） 3、网站改用HTTPS 以后，由HTTP 跳转到 HTTPS 的方式增加了用户访问耗时（多数网站采用302跳转） 4、HTTPS涉及到的安全算法会消耗 CPU 资源，需要增加大量机器（https访问过程需要加解密） 参考 https://blog.csdn.net/zhongzh86/article/details/69389967 https://www.cnblogs.com/smlp/p/9779206.html https://juejin.im/post/5b48b0d7e51d4519962ea383 https://blog.csdn.net/clh604/article/details/22179907","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"计算机网络-基础-TCP三次握手","slug":"backend/network/计算机网络-基础-TCP三次握手","date":"2018-03-05T16:01:01.000Z","updated":"2020-01-04T12:21:52.254Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础-TCP三次握手/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础-TCP三次握手/","excerpt":"","text":"什么是 TCP 3次握手？ 详细来说，步骤如下： 第一次握手：Client 将标志位 SYN=1 ，随机产生一个值 seq=J ，并将该数据包发送给 Server 。此时，Client 进入SYN_SENT 状态，等待 Server 确认。 第二次握手：Server 收到数据包后由标志位 SYN=1 知道Client请求建立连接，Server 将标志位 SYN 和 ACK 都置为 1 ，ack=J+1，随机产生一个值 seq=K ，并将该数据包发送给 Client 以确认连接请求，Server 进入 SYN_RCVD 状态。此时，Server 进入 SYC_RCVD 状态。 第三次握手：Client 收到确认后，检查 ack 是否为 J+1 ，ACK 是否为 1 。 如果正确，则将标志位 ACK 置为 1 ，ack=K+1 ，并将该数据包发送给 Server 。此时，Client 进入 ESTABLISHED 状态。 Server 检查 ack 是否为 K+1 ，ACK 是否为 1 ，如果正确则连接建立成功。此时 Server 进入 ESTABLISHED 状态，完成三次握手，随后 Client 与 Server 之间可以开始传输数据了。 仔细看来，Client 会发起两次数据包，分别是 SYNC 和 ACK ；Server 会发起一次数据包，包含 SYNC 和 ACK 。也就是说，三次握手的过程中，Client 和 Server 互相做了一次 SYNC 和 ACK 。 为什么需要3次握手 主要目的防止服务器端的一直等待而浪费资源: 在谢希仁著《计算机网络》第四版中讲“三次握手”的目的是“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”。在另一部经典的《计算机网络》一书中讲“三次握手”的目的是为了解决“网络中存在延迟的重复分组”的问题。这两种不用的表述其实阐明的是同一个问题。 谢希仁版《计算机网络》中的例子是这样的，“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。 本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。 采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”。 为什么不是2次 三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 12345第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常。第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 假想一下，如果我们去掉了第三次呢？ 因为我们不进行第三次握手，所以在S对C的请求进行回应(第二次握手)后，就会理所当然的认为连接已建立，而如果C并没有收到S的回应呢？此时，C仍认为连接未建立，S会对已建立的连接保存必要的资源，如果大量的这种情况，S会崩溃。 因此第三次握手是必要的。 补充： 既然没法确认第二次的握手，C是否可以收到，那么怎么确定第三次握手S就可以收到呢？ 不错，这根本没法确定，因为完全可靠的通信协议是根本不存在的，我们任何的通信协议都是在接受这样的现实情况之上进行的。 而三次握手后，C和S至少可以确认之前的通信情况，但无法确认之后的情况。 在这个道理上说，无论是四次还是五次或是更多次都是徒劳的。 什么是 TCP 4次分手？ 当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。 四次挥手，简单来说，就是： 发送方：我要和你断开连接！ 接收方：好的，断吧。 接收方：我也要和你断开连接！ 发送方：好的，断吧。 第一次挥手：Client 发送一个 FIN=M ，用来关闭 Client 到 Server 的数据传送。此时，Client 进入 FIN_WAIT_1 状态。 第二次挥手，Server 收到 FIN 后，发送一个 ACK 给 Client ，确认序号为 M+1（与 SYN 相同，一个 FIN 占用一个序号）。此时，Server 进入 CLOSE_WAIT 状态。注意，TCP 链接处于半关闭状态，即客户端已经没有要发送的数据了，但服务端若发送数据，则客户端仍要接收。 第三次挥手，Server 发送一个 FIN=N ，用来关闭 Server 到 Client 的数据传送。此时 Server 进入 LAST_ACK 状态。 第四次挥手，Client 收到 FIN 后，此时 Client 进入 TIME_WAIT 状态。接着，Client 发送一个 ACK 给 Server ，确认序号为 N+1 。Server 接收到后，此时 Server 进入 CLOSED 状态，完成四次挥手。 为什么需要4次分手 TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP 是全双工模式，这就意味着： 当主机 1 发出 FIN 报文段时，只是表示主机 1 已经没有数据要发送了，主机 1 告诉主机 2 ，它的数据已经全部发送完毕了；但是，这个时候主机 1 还是可以接受来自主机 2 的数据；当主机 2 返回 ACK 报文段时，表示它已经知道主机 1 没有数据发送了，但是主机 2 还是可以发送数据到主机 1 的。 因为主机 2 此时可能还有数据想要发送给主机 1 ，所以挥手不能像握手只有三次，而是多了那么“一次”！ 当主机 2 也发送了 FIN 报文段时，这个时候就表示主机 2 也没有数据要发送了，就会告诉主机 1 ，我也没有数据要发送了，之后彼此就会愉快的中断这次 TCP 连接。 我们把四次挥手，理解成一次和平的挥手~ 如果要正确的理解四次的原理，就需要了解四次挥手过程中的状态变化。 参考 芋道源码 http://www.iocoder.cn https://www.cnblogs.com/smlp/p/9779206.html","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"计算机网络-基础-HTTP超文本传输协议","slug":"backend/network/计算机网络-基础-HTTP超文本传输协议","date":"2018-03-05T16:01:00.000Z","updated":"2019-11-27T15:11:32.614Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础-HTTP超文本传输协议/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础-HTTP超文本传输协议/","excerpt":"","text":"前言 HTTP 协议，是 Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 HTTP连接 HTTP协议即超文本传送协议(Hypertext Transfer Protocol )，是Web联网的基础，也是手机联网常用的协议之一，HTTP协议是建立在TCP协议之上的一种应用。 HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。 1）在HTTP 1.0中，客户端的每次请求都要求建立一次单独的连接，在处理完本次请求后，就自动释放连接。 2）在HTTP 1.1中则可以在一次连接中处理多个请求，并且多个请求可以重叠进行，不需要等待一个请求结束后再发送下一个请求。 由于HTTP在每次请求结束后都会主动释放连接，因此HTTP连接是一种“短连接”，要保持客户端程序的在线状态，需要不断地向服务器发起连接请求。通常 的做法是即时不需要获得任何数据，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道 客户端“在线”。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。 HTTP 协议包括哪些请求 GET: 对服务器资源的简单请求。 POST: 用于发送包含用户提交数据的请求。 HEAD：类似于 GET 请求，不过返回的响应中没有具体内容，用于获取报头。 PUT：传说中请求文档的一个版本。 DELETE：发出一个删除指定文档的请求。 TRACE：发送一个请求副本，以跟踪其处理进程。 OPTIONS：返回所有可用的方法，检查服务器支持哪些方法。 CONNECT：用于 SSL 隧道的基于代理的请求。 HTTP 状态码 1×× : 请求处理中，请求已被接受，正在处理 2×× : 请求成功，请求被成功处理 200 OK // 客户端请求成功 3×× : 重定向，要完成请求必须进行进一步处理 301 Moved Permanently // 永久重定向,使用域名跳转 302 Found // 临时重定向,未登陆的用户访问用户中心重定向到登录页面 4×× : 客户端错误，请求不合法 400 Bad Request // 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized // 请求未经授权，这个状态代码必须和 WWW-Authenticate 报头域一起使用 403 Forbidden // 服务器收到请求，但是拒绝提供服务 404 Not Found // 请求资源不存在，eg：输入了错误的 URL 5×× : 服务器端错误，服务器不能处理合法请求 500 Internal Server Error // 服务器发生不可预期的错误 503 Server Unavailable // 服务器当前不能处理客户端的请求，一段时间后可能恢复正常 HTTP1.0 和 HTTP1.1 支持长连接（最重要） HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接 HTTP 1.1在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟。在 HTTP1.1中 默认开启Connection：keep-alive ，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点。 节约带宽 HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。 这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。 另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础 缓存处理 在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准， HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 Host头处理 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。 但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。 HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。 HTTP 1.1 和 HTTP2.0 多路复用 HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。 当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。 TCP连接有一个预热和保护的过程，先检查数据是否传送成功，一旦成功过，则慢慢加大传输速度。因此对应瞬时并发的连接，服务器的响应就会变慢。所以最好能使用一个建立好的连接，并且这个连接可以支持瞬时并发的请求。 数据压缩 HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 补充GET产生一个TCP数据包；POST产生两个TCP数据包。 对于 GET 方式的请求，浏览器会把 HTTP header 和 data 一并发送出去，服务器响应 200（返回数据）。 而对于 POST，浏览器先发送 header ，服务器响应 100 continue ，浏览器再发送 data ，服务器响应 200 ok（返回数据）。 也就是说，GET 只需要汽车跑一趟就把货送到了，而 POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。 ps：不过要注意，POST 具体发几次，也和浏览器的实现有关系。例如：Firefox 只发一次。 ps2：据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的 TCP 在验证数据包完整性上，有非常大的优点。 HTTP、TCP、Socket 的关系 TCP/IP 代表传输控制协议/网际协议，指的是一系列协议族。 HTTP 本身就是一个协议，是从 Web 服务器传输超文本到本地浏览器的传送协议。 Socket 是 TCP/IP 网络的 API ，其实就是一个门面模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面。对用户来说，一组简单的接口就是全部，让 Socket 去组织数据，以符合指定的协议。 综上所述： TCP/IP、HTTP 都是协议，我们可以按照这个协议来传输数据，HTTP 是基于 TCP 来实现的 Socket可以理解为具体实施者，上面的协议都是规范，具体实现还是要Socket来去实现 一次完整的 HTTP 请求所经历的步骤 1、DNS 解析(通过访问的域名找出其 IP 地址，递归搜索)。 2、HTTP 请求，当输入一个请求时，建立一个 Socket 连接发起 TCP的 3 次握手。 如果是 HTTPS 请求，会略微有不同 3.1、客户端向服务器发送请求命令（一般是 GET 或 POST 请求）。 3.2、客户端发送请求头信息和数据。 4.1、服务器发送应答头信息。 4.2、服务器向客户端发送数据。 5、服务器关闭 TCP 连接（4次挥手）。 参考 芋道源码 http://www.iocoder.cn https://www.cnblogs.com/smlp/p/9779206.html","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"计算机网络-基础-RPC远程过程调用","slug":"backend/network/计算机网络-基础-RPC远程过程调用","date":"2018-03-05T16:00:03.000Z","updated":"2020-01-04T12:21:52.251Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础-RPC远程过程调用/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础-RPC远程过程调用/","excerpt":"","text":"摘抄链接 RPC 小闫笔记 一、RPC介绍什么是RPC 我们来看一下维基百科的释义，RPC(Remote Procedure Call的缩写)叫做远程过程调用，也叫做远程程序调用。它是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或者远程方法调用。 我们举个例子来理解一下，有两台计算机A和B，它们之间可以进行网络通讯，计算机A中的程序1如果可以调用计算机B中的程序2。这样一个调用过程我们就叫做远程过程调用。之所以叫做远程，是因为程序2和程序1不在同一计算机中，而是在不同计算机。 为什么需要RPC 如今的计算机应用中，单机性能上很难承受住产品的压力，需要不断扩充多台机器来提升整体的性能。同时为了充分利用这些集群里的计算机，需要对其从架构上进行划分，以提供不同的服务，服务间相互调用完成整个产品的功能。RPC就能帮助我们解决这些服务间的信息传递和调用。 RPC广义的概念 我们可以将所有通过网络来进行通讯调用的实现统称为RPC。看完这个概念，你也许会想，HTTP难道也是一种RPC实现咯？没错,可以这样理解。我们通过一个HTTP通讯过程探秘，看答案是否属实。 客户端将一些请求数据打包成一个HTTP协议报文，然后通过TCP传输给服务器。服务器接收到请求报文后，会进行过程调用。如果是静态服务器，会传递给客户端一个静态页面；如果是动态服务器，就会执行一段程序，将结果作为响应值通过TCP返回给客户端。客户端收到响应报文后，进行解析。解析之后再执行下面的过程。 这样一个过程是不是有些眼熟?对,和上面RPC的思想一样。 RPC 狭义的概念 看了广义的概念之后，你是不是觉得，有了HTTP，我们直接使用它不就好了，省得那么麻烦。我只能说，您想多了，我们是需要自己实现的。What？Why？How？震惊三联…… RPC的思想就是实现类似本地过程调用，当然要无限接近这个过程。那么就需要提高远程过程调用的执行速度，让其性能接近本地。这才是目的。HTTP的请求报文分为请求行，请求头和请求体，这里面会包含一些没有意义的数据，网络传输的数据量增大，减弱了传输性能，因此这种方式不可取。那么怎么办呢？我们可以自定义一种通讯数据的格式以及控制网络传输过程。这也是我们常用的方式。 我们常说的RPC是从狭义的概念上理解的，而狭义的RPC也剔除掉了HTTP通讯方式。统一采用自定义的流程控制，性能高的RPC。也就是自己定义数据格式,自己实现数据的接收等。 RPC 与 HTTP 相比与传统HTTP的实现而言，优点就是效率高；发起RPC调用的一方，在编写代码时可忽略RPC的具体实现，如同编写本地函数调用一样。 缺点就是通用性不怎么好。因为传输的数据不是HTTP协议格式，所以调用双方需要专门实现的通信库，对于不同的编程语言都要有相关实现。而HTTP作为一个标准协议，大部分的语言都已经有相关的实现，通用性要好的多。 HTTP更多的是面向用户和产品服务器的通讯，RPC更多的是面向产品内部服务器间的通讯。 实际情况下，RPC很少用到http协议来进行数据传输，毕竟我只是想传输一下数据而已，何必动用到一个文本传输的应用层协议呢，我为什么不直接使用二进制传输？比如直接用Java的Socket协议进行传输？ http1.1协议的 TCP 报文包含太多在传输过程中可能无用的信息 使用自定义 TCP 协议进行传输就会避免上面这个问题，极大地减轻了传输数据的开销 这也就是为什么通常会采用自定义 TCP 协议的 RPC 来进行进行服务调用的真正原因 实现 RPC 的可以传输协议可以直接建立在 TCP 之上，也可以建立在 HTTP 协议之上。大部分 RPC 框架都是使用的 TCP 连接（gRPC使用了HTTP2）。 二、RPC结构和调用流程RPC结构 RPC 的核心功能主要由 5 个模块组成，如果想要自己实现一个 RPC，最简单的方式要实现三个技术点，分别是： 服务寻址，我要知道是调那个服务吧 使用Zookeeper作为服务注册中心 数据流的序列化和反序列化 只有二进制数据才能在网络中传输，所以当二进制数据到了服务应用中需要将其解析为具体的类对象 将对象转换成二进制流的过程叫做序列化；将二进制流转换成对象的过程叫做反序列化 网络传输 远程调用往往用在网络上，客户端和服务端是通过网络连接的。 尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。 调用流程 首先我们看一下流程: 1.调用者(Caller,也叫客户端Client)以本地调用的方式发起调用。 2.Client stub(客户端存根,可理解为辅助助手)收到调用后,负责将被调用的方法名,参数等打包编码成特定格式的能进行网络传输的消息体。 3.Client stub将消息体通过网络发送给对端(服务端)。 4.Server stub(服务端存根,同样可理解为辅助助手)收到通过网络接收到消息后按照相应格式进行拆包解码,获取方法名和参数。 5.Server stub根据方法名和参数进行本地调用。 6.将被调用者(Callee,也叫Server)本地调用执行后将结果返回给server stub。 7.Server stub将返回值打包编码成消息,并通过网络发送给对端(客户端)。 8.Client stub收到消息后，进行拆包解码，返回给Client。 9.Client得到本次RPC调用的最终结果。 RPC的目标就是要将2~8这些步骤封装起来,让使用者对这些细节透明。 在了解了RPC的流程之后，为了实现RPC，还需要关注两点： 消息协议 客户端调用的参数和服务端的返回值这些在网络上传输的数据以何种方法打包编码和拆包解码 我们可以使用HTTP协议中关于报文格式的规定(如此一来,就变成了HTTP通讯),也可以自己定义某种格式,让客户端与服务端双方都遵循此种格式。传输控制 传输控制 在网络中数据的收发传输控制具体如何实现 三、补充RMI RMI是Java提供的一种访问远程对象的协议，是已经实现好了的，可以直接用了。 而RPC呢？人家只是一种编程模型，并没有规定你具体要怎样实现，你甚至都可以在你的RPC框架里面使用RMI来实现数据的传输，比如Dubbo：Dubbo - rmi协议 常见的 RPC 框架 RMI（JDK自带）： JDK自带的RPC，有很多局限性，不推荐使用。 Dubbo: Dubbo是 阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。目前 Dubbo 已经成为 Spring Cloud Alibaba 中的官方组件。 gRPC ： gRPC是可以在任何环境中运行的现代开源高性能RPC框架。它可以通过可插拔的支持来有效地连接数据中心内和跨数据中心的服务，以实现负载平衡，跟踪，运行状况检查和身份验证。它也适用于分布式计算的最后一英里，以将设备，移动应用程序和浏览器连接到后端服务。 Hessian： Hessian是一个轻量级的remotingonhttp工具，使用简单的方法提供了RMI的功能。 相比WebService，Hessian更简单、快捷。采用的是二进制RPC协议，因为采用的是二进制协议，所以它很适合于发送二进制数据。 Thrift： Apache Thrift是Facebook开源的跨语言的RPC通信框架，目前已经捐献给Apache基金会管理，由于其跨语言特性和出色的性能，在很多互联网公司得到应用，有能力的公司甚至会基于thrift研发一套分布式服务框架，增加诸如服务注册、服务发现等功能。 四、总结 要实现一个RPC不算难，难的是实现一个高性能高可靠的RPC框架。 比如，既然是分布式了，那么一个服务可能有多个实例，你在调用时，要如何获取这些实例的地址呢？ 这时候就需要一个服务注册中心，比如在Dubbo里头，就可以使用Zookeeper作为注册中心，在调用时，从Zookeeper获取服务的实例列表，再从中选择一个进行调用。 那么选哪个调用好呢？这时候就需要负载均衡了，于是你又得考虑如何实现复杂均衡，比如Dubbo就提供了好几种负载均衡策略。 这还没完，总不能每次调用时都去注册中心查询实例列表吧，这样效率多低呀，于是又有了缓存，有了缓存，就要考虑缓存的更新问题，blablabla…… 你以为就这样结束了，没呢，还有这些： 客户端总不能每次调用完都干等着服务端返回数据吧，于是就要支持异步调用； 服务端的接口修改了，老的接口还有人在用，怎么办？总不能让他们都改了吧？这就需要版本控制了； 服务端总不能每次接到请求都马上启动一个线程去处理吧？于是就需要线程池； 服务端关闭时，还没处理完的请求怎么办？是直接结束呢，还是等全部请求处理完再关闭呢？ …… 如此种种，都是一个优秀的RPC框架需要考虑的问题 RPC 解决了什么问题？ 从上面对 RPC 介绍的内容中，概括来讲RPC 主要解决了：让分布式或者微服务系统中不同服务之间的调用像本地调用一样简单。 参考 https://www.jianshu.com/p/2accc2840a1b https://blog.csdn.net/wangguohe/article/details/81536550 https://developer.51cto.com/art/201906/597963.htm https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/why-use-rpc","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"计算机网络-基础-UDP用户数据报协议","slug":"backend/network/计算机网络-基础-UDP用户数据报协议","date":"2018-03-05T16:00:02.000Z","updated":"2020-01-04T12:21:52.262Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础-UDP用户数据报协议/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础-UDP用户数据报协议/","excerpt":"","text":"前言UDP 是什么？ UDP（User Data Protocol，用户数据报协议），是与 TCP 相对应的协议。它是面向非连接的协议，它不与对方建立连接，而是直接就把数据包发送过去。 主要特点如下： UDP 是无连接的。 UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）。 UDP 是面向报文的。 UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低。对实时应用很有用，如 直播，实时视频会议等 UDP 支持一对一、一对多、多对一和多对多的交互通信。 UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短。 UDP 对应的应用层协议 DNS ：用于域名解析服务，将域名地址转换为 IP 地址。DNS 用的是 53 号端口。 SNMP ：简单网络管理协议，使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。 TFTP(Trivial File Transfer Protocol)：简单文件传输协议，该协议在熟知端口 69 上使用 UDP 服务。 TCP 与 UDP 的区别 TCP和 UDP协议属于传输层协议，它们之间的区别包括： TCP 是面向连接的；UDP 是无连接的。 TCP 是可靠的；UDP 是不可靠的。 TCP 只支持点对点通信；UDP 支持一对一、一对多、多对一、多对多的通信模式。 TCP 是面向字节流的；UDP 是面向报文的。 TCP 有拥塞控制机制；UDP 没有拥塞控制，适合媒体通信。 TCP 首部开销(20 个字节)，比 UDP 的首部开销(8 个字节)要大。 为什么 TCP 叫数据流模式？ UDP 叫数据报模式？ 所谓的“流模式”，是指TCP 发送端发送几次数据和接收端接收几次数据是没有必然联系的。 比如你通过 TCP 连接给另一端发送数据，你只调用了一次 write ，发送了 100 个字节，但是对方可以分 10 次收完，每次 10 个字节；你也可以调用 10 次 write ，每次 10 个字节，但是对方可以一次就收完。 原因：这是因为 TCP 是面向连接的，一个 Socket 中收到的数据都是由同一台主机发出，且有序地到达，所以每次读取多少数据都可以。 所谓的“数据报模式”，是指 UDP 发送端调用了几次 write ，接收端必须用相同次数的 read 读完。 UDP 是基于报文的，在接收的时候，每次最多只能读取一个报文，报文和报文是不会合并的，如果缓冲区小于报文长度，则多出的部分会被丢弃。 原因：这是因为 UDP 是无连接的，只要知道接收端的 IP 和端口，任何主机都可以向接收端发送数据。这时候，如果一次能读取超过一个报文的数据，则会乱套。 应用场景 虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"计算机网络-基础-TCP传输控制协议","slug":"backend/network/计算机网络-基础-TCP传输控制协议","date":"2018-03-05T16:00:01.000Z","updated":"2020-03-16T11:43:55.534Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础-TCP传输控制协议/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础-TCP传输控制协议/","excerpt":"","text":"前言TCP 是什么 TCP(Transmission Control Protocol)，传输控制协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议。主要特点如下： TCP 是面向连接的。 就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）。 TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达。 TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据。 面向字节流。 TCP 中的“流”（Stream），指的是流入进程或从进程流出的字节序列。 “面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 参考 芋道源码 http://www.iocoder.cn https://blog.csdn.net/xifeijian/article/details/12777187 https://blog.csdn.net/to_be_better/article/details/54885684","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"计算机网络-基础","slug":"backend/network/计算机网络-基础","date":"2018-03-05T16:00:00.000Z","updated":"2019-11-27T15:11:32.623Z","comments":true,"path":"2018/03/06/backend/network/计算机网络-基础/","link":"","permalink":"http://www.songshuiyang.com/2018/03/06/backend/network/计算机网络-基础/","excerpt":"","text":"OSI 七层体系结构 层级 （自上而下） 简介 实例 应用层（数据） 确定进程之间通信的性质以满足用户需要以及提供网络与用户应用 HTTP、TELNET、FTP、SMTP 表示层（数据） 主要解决用户信息的语法表示问题，如加密解密 会话层（数据） 提供包括访问验证和会话管理在内的建立和维护应用之间通信的机制，如服务器验证用户登录便是由会话层完成的 传输层（段） 实现网络不同主机上用户进程之间的数据通信，可靠与不可靠的传输，传输层的错误检测，流量控制等 TCP、UDP 网络层（包） 提供逻辑地址（IP）、选路，数据从源端到目的端的传输 IP、ICMP 数据链路层（帧） 将上层数据封装成帧，用MAC地址访问媒介，错误检测与修正 物理层（比特流） 设备之间比特流的传输，物理接口，电气特性等 区别 IPv4 和 IPv6 我们大多数人使用的是第二代互联网 IPv4 技术，它的最大问题是网络地址资源有限，从理论上讲能编址 1600 万个网络、链接 40 亿台主机。而根据相关数据，全球 IPv4 的 IP 地址已经即将用完。 而 IPv6 是作为 IETF 设计的用于替代现行版本 IP 协议(IPv4)的下一代 IP 协议，其 IPV6 地址长度为 12 8位，地址空间增大了 2^98 次方倍，几乎可以说是用之不竭的。所以随着 IPv4 不足，支持 IPv6 的网络势必会增长。 参考 芋道源码 http://www.iocoder.cn https://blog.csdn.net/xifeijian/article/details/12777187 https://blog.csdn.net/to_be_better/article/details/54885684 https://github.com/jawil/blog/issues/14","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://www.songshuiyang.com/tags/计算机网络/"}]},{"title":"百度富文本框编辑器Ueditor的使用","slug":"backend/other/百度富文本框编辑器Ueditor的使用","date":"2018-03-05T14:54:12.000Z","updated":"2020-03-16T11:43:55.554Z","comments":true,"path":"2018/03/05/backend/other/百度富文本框编辑器Ueditor的使用/","link":"","permalink":"http://www.songshuiyang.com/2018/03/05/backend/other/百度富文本框编辑器Ueditor的使用/","excerpt":"百度富文本框编辑器：官网： http://ueditor.baidu.com/website/ 官网演示地址：http://ueditor.baidu.com/website/onlinedemo.html UEditor是由百度web前端研发部开发所见即所得富文本web编辑器，具有轻量，可定制，注重用户体验等特点，开源基于MIT协议，允许自由使用和修改代码…","text":"百度富文本框编辑器：官网： http://ueditor.baidu.com/website/ 官网演示地址：http://ueditor.baidu.com/website/onlinedemo.html UEditor是由百度web前端研发部开发所见即所得富文本web编辑器，具有轻量，可定制，注重用户体验等特点，开源基于MIT协议，允许自由使用和修改代码… 开始使用：参考:http://fex.baidu.com/ueditor/ 1. 入门部署和体验1.1下载编辑器到官网下载 UEditor 最新版：[官网地址] 1.2创建demo文件解压下载的包，在解压后的目录创建 demo.html 文件，填入下面的html代码 123456789101112131415161718192021222324&lt;!DOCTYPE HTML&gt;&lt;html lang=\"en-US\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;ueditor demo&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- 加载编辑器的容器 --&gt; &lt;script id=\"container\" name=\"content\" type=\"text/plain\"&gt; 这里写你的初始化内容 &lt;/script&gt; &lt;!-- 配置文件 --&gt; &lt;script type=\"text/javascript\" src=\"ueditor.config.js\"&gt;&lt;/script&gt; &lt;!-- 编辑器源码文件 --&gt; &lt;script type=\"text/javascript\" src=\"ueditor.all.js\"&gt;&lt;/script&gt; &lt;!-- 实例化编辑器 --&gt; &lt;script type=\"text/javascript\"&gt; var ue = UE.getEditor('container'); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 1.3 在浏览器打开demo.html如果看到了编辑器，恭喜你，初次部署成功！ 2. 整合jsp后端配置2.1 下载 jsp 版本完整包下载地址: http://ueditor.baidu.com/website/download.html 选择 [1.4.3.3 Jsp 版本] 2.2 下载之后会得到如下文件按照官网上的做法是把文件copy到webapp跟目录下 , 但我们是集成ueditor, 肯定不是放在根目录下, 所以我们把文件都复制到 webapp/static/plugins/ueditor 下, 方便管理 logo 2.3 前台代码集成2.3.1 在需要集成ueditor的页面添加如下代码, 如果能看到编辑器则说明配置成功12345678910111213141516171819202122232425&lt;!DOCTYPE HTML&gt;&lt;html lang=\"en-US\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;ueditor demo&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"$&#123;ctx&#125;static/plugins/ueditor/lang/zh-cn/zh-cn.js\" media=\"all\" /&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- 加载编辑器的容器 --&gt; &lt;script id=\"container\" name=\"content\" type=\"text/plain\"&gt; 这里写你的初始化内容 &lt;/script&gt; &lt;!-- 配置文件 --&gt; &lt;script type=\"text/javascript\" src=\"$&#123;ctx&#125;static/plugins/ueditor/ueditor.config.js\"&gt;&lt;/script&gt; &lt;!-- 编辑器源码文件 --&gt; &lt;script type=\"text/javascript\" src=\"$&#123;ctx&#125;static/plugins/ueditor/ueditor.all.js\"&gt;&lt;/script&gt; &lt;!-- 实例化编辑器 --&gt; &lt;script type=\"text/javascript\"&gt; var ueditor = UE.getEditor('container'); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 获取编辑器内容123var ueditor = UE.getEditor('container');var content = ueditor.getContent(content); 设置编辑器内容12345// 等UEditor创建完成就使用UEditor的setContent函数var ueditor = UE.getEditor('container');ueditor.ready(function() &#123; ueditor.setContent(content);&#125;); 有了这些你可以处理一些普通文字, 但如果是要文件上传,图片上传,视频上传这些功能你就要进行一些后台代码的配置 2.4 后台代码集成后台环境： Spring + Spring Mvc + Mybatis + Maven 2.4.1 配置 ueditor.config.js原配置:1234567891011121314var URL = window.UEDITOR_HOME_URL || getUEBasePath();/** * 配置项主体。注意，此处所有涉及到路径的配置别遗漏URL变量。 */window.UEDITOR_CONFIG = &#123; //为编辑器实例添加一个路径，这个不能被注释 UEDITOR_HOME_URL: URL // 服务器统一请求接口路径 , serverUrl: URL + \"jsp/controller.jsp\" //工具栏上的所有的功能按钮和下拉框，可以在new编辑器的实例时选择自己需要的重新定义 修改后的配置：1234567891011121314window.UEDITOR_HOME_URL = \"/static/plugins/ueditor/\";var URL = window.UEDITOR_HOME_URL || getUEBasePath();/** * 配置项主体。注意，此处所有涉及到路径的配置别遗漏URL变量。 */window.UEDITOR_CONFIG = &#123; //为编辑器实例添加一个路径，这个不能被注释 UEDITOR_HOME_URL: URL // 服务器统一请求接口路径 , serverUrl: \"/ueditor/ueditorAction\" 主要是 window.UEDITOR_HOME_URL 这个参数赋值成自己的ueditor的文件路径 修改 服务器统一请求接口路径 /ueditor/ueditorAction , 这样Ueditor后台服务接口就会请求到这个接口中来 2.4.2 新增后台服务接口第一步： 导入jar包, 我是只添加了最后俩个包，其他的包可以通过maven的形式导入，copy 这俩个包放到WEBINF/lib目录下, 然后配置Maven依赖 logo 注：使用maven构建项目的时候需要进行如下配置, 这样maven构建的时候才不会报找不到lib目录下jar包的错误1234567&lt;dependency&gt; &lt;groupId&gt;json&lt;/groupId&gt; &lt;artifactId&gt;json&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/src/main/webapp/WEB-INF/lib/json.jar&lt;/systemPath&gt;&lt;/dependency&gt; 第二步：新建 后台统一服务接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/** * Ueditor 后台统一服务接口 * @author songshuiyang * @date 2018/3/4 18:11 */@Controller@RequestMapping(\"/ueditor\")public class UEditorController extends BaseController &#123; private HttpServletRequest request = null; private String actionType = null; private ConfigManager configManager = null; @RequestMapping(value = \"ueditorAction\", method = &#123;RequestMethod.GET,RequestMethod.POST&#125;) @ResponseBody public JSONObject exec (@RequestParam String action, HttpServletRequest request) &#123; String result; this.actionType = action; this.request = request; String rootPath = request.getSession().getServletContext().getRealPath(\"/\"); String contextPath = request.getContextPath(); this.configManager = ConfigManager.getInstance( rootPath, contextPath,\"/static/plugins/ueditor/jsp/controller.jsp\"); String callbackName = this.request.getParameter(\"callback\"); if ( callbackName != null ) &#123; result = !validCallbackName( callbackName ) ? new BaseState( false, AppInfo.ILLEGAL ).toJSONString() : callbackName+\"(\"+this.invoke()+\");\"; &#125; else &#123; result = this.invoke(); &#125; return JSONObject.fromObject(result); &#125; public String invoke() &#123; if ( actionType == null || !ActionMap.mapping.containsKey( actionType ) ) &#123; return new BaseState( false, AppInfo.INVALID_ACTION ).toJSONString(); &#125; if ( this.configManager == null || !this.configManager.valid() ) &#123; return new BaseState( false, AppInfo.CONFIG_ERROR ).toJSONString(); &#125; State state = null; int actionCode = ActionMap.getType( this.actionType ); Map&lt;String, Object&gt; conf; switch ( actionCode ) &#123; case ActionMap.CONFIG: return this.configManager.getAllConfig().toString(); case ActionMap.UPLOAD_IMAGE: case ActionMap.UPLOAD_SCRAWL: case ActionMap.UPLOAD_VIDEO: case ActionMap.UPLOAD_FILE: conf = this.configManager.getConfig( actionCode ); state = new Uploader( request, conf ).doExec(); break; case ActionMap.CATCH_IMAGE: conf = configManager.getConfig( actionCode ); String[] list = this.request.getParameterValues( (String)conf.get( \"fieldName\" ) ); state = new ImageHunter( conf ).capture( list ); break; case ActionMap.LIST_IMAGE: case ActionMap.LIST_FILE: conf = configManager.getConfig( actionCode ); int start = this.getStartIndex(); state = new FileManager( conf ).listFile( start ); break; &#125; assert state != null; return state.toJSONString(); &#125; private int getStartIndex () &#123; String start = this.request.getParameter( \"start\" ); try &#123; return Integer.parseInt( start ); &#125; catch ( Exception e ) &#123; return 0; &#125; &#125; /** * callback参数验证 * @param name 名字 * @return boolean */ private boolean validCallbackName ( String name ) &#123; return name.matches( \"^[a-zA-Z_]+[\\\\w0-9_]*$\" ); &#125;&#125; 一： 初始化ueditor的时候, ueditor会访问该接口, 此时action 参数是 config , 该接口会返回其/static/plugins/ueditor/jsp/config.json 配置的json参数，这些参数配置了上传功能的一些参数, 通过这些配置你可以DIY上传功能, ueditor获取到这些参数之后就可以使用上传功能了,否则你上传文件会提示： 后端配置项没有正常加载，上传插件不能正常使用！ 配置主要包括： 上传图片配置项 涂鸦图片上传配置项 截图工具上传 抓取远程图片配置 上传视频配置 上传文件配置 二： 如要上传图片, ueditor会访问该接口, 此时action 参数是 uploadimage ，则会执行上传图片操作, 上传成功后会返回123456&#123; \"state\": \"SUCCESS\", \"url\": \"upload/demo.jpg\", \"title\": \"demo.jpg\", \"original\": \"demo.jpg\"&#125; 三：由于系统文件上传使用的是阿里云的OSS所以需要将文件上传转到OSS处理上 前台配置：1234567891011121314151617&lt;script type=\"text/javascript\"&gt; // 当action是如下时，访问自己定义的服务接口 UE.Editor.prototype._bkGetActionUrl=UE.Editor.prototype.getActionUrl; UE.Editor.prototype.getActionUrl=function(action)&#123; // 上传图片, 文件, 视频 if (action == 'uploadimage' || action == 'uploadfile' || action == 'uploadvideo') &#123; return '/file/uploadLocal'; &#125; else if( action== 'uploadscrawl')&#123; // 上传涂鸦，涂鸦请求是Base64字符需要请求另外的接口 return '/file/uploadScrawl'; &#125; else if(action == 'listimage')&#123; return this._bkGetActionUrl.call(this, action); &#125; else&#123; return this._bkGetActionUrl.call(this, action); &#125; &#125; var ueditor = UE.getEditor('ueditorContainer');&lt;/script&gt; 后台接口：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.ecut.admin.controller;import com.aliyun.oss.ClientException;import com.aliyun.oss.OSSException;import com.ecut.admin.entity.OssFile;import com.ecut.admin.entity.UeditorState;import com.ecut.admin.service.impl.FileServiceImpl;import com.ecut.core.base.BaseController;import com.ecut.core.utils.Base64Utils;import com.ecut.core.utils.MessageUtils;import com.google.common.collect.Lists;import com.google.common.collect.Maps;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.MediaType;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.multipart.MultipartFile;import org.springframework.web.multipart.MultipartHttpServletRequest;import java.io.ByteArrayInputStream;import java.io.File;import java.io.IOException;import java.io.InputStream;import java.util.HashMap;import java.util.Iterator;import java.util.List;import java.util.Map;import static com.ecut.core.utils.MessageUtils.success;/** * 阿里云OSS文件上传控制器 * @author songshuiyang * @date 2018/2/11 20:22 */@Controller@RequestMapping(\"/file\")public class FileController extends BaseController &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired private FileServiceImpl fileServiceImpl; /** * 文件上传 * produces=\"application/json;charset=UTF-8 解决服务器返回406问题 * @param file * @return * @throws OSSException * @throws ClientException * @throws IOException */ @RequestMapping(value = \"/uploadLocal\", method = RequestMethod.POST, produces=\"application/json;charset=UTF-8\") @ResponseBody public UeditorState uploadLocalFile(@RequestParam(value = \"upfile\",required = false) MultipartFile file) throws OSSException, ClientException, IOException &#123; Map&lt;String, Object&gt; resultMap = new HashMap&lt;&gt;(); OssFile file1 = fileServiceImpl.uploadFileByMultipartFile(file); UeditorState ueditorState = new UeditorState(\"SUCCESS\",file1.getFileSrc(),file1.getFileName(),file1.getFileName()); return ueditorState; &#125; /** * 上传涂鸦照片 * @param upfile * @return * @throws Exception */ @RequestMapping(value = \"/uploadScrawl\", method = RequestMethod.POST, produces=\"application/json;charset=UTF-8\") @ResponseBody public UeditorState uploadscrawl(String upfile) throws Exception &#123; byte [] bytes= Base64Utils.decode(upfile); InputStream inputStream = new ByteArrayInputStream(bytes); String fileType = \"image/png\"; Long fileSize = new Long((long)bytes.length); String fileName = \"scrawl\" + System.currentTimeMillis() + \".png\"; String extensionName = \"png\"; OssFile file1 = fileServiceImpl.uploadFileByInputStream(inputStream, fileType,fileSize,fileName,extensionName); UeditorState ueditorState = new UeditorState(\"SUCCESS\",file1.getFileSrc(),file1.getFileName(),file1.getFileName()); return ueditorState; &#125;&#125; 2.4.3 问题集合解决百度ueditor富文本编辑器不能插入视频的问题/src掉链/src清空，不能显示视频转载：http://blog.csdn.net/qq_34787830/article/details/75092347 直接下载到的百度富文本编辑器当插入视频的时候会自动清掉src，不显示视频造成这样的原因是:百度富文本编辑器的过滤器xssFilter导致插入视频异常，编辑器在切换源码的过程中过滤掉img的_url属性（用来存储视频url） 解决办法: 1.在配置文件ueditor.config.js中，定位 //xss过滤白名单，即,whitList:{ }，对 img: 增加 “_url” 属性： 在下面的 video 标签后面新增3给标签，使Ueditor分别能支持embed标签和iframe标签：1234567source: ['src', 'type'],embed: ['type', 'class', 'pluginspage', 'src', 'width', 'height', 'align', 'style', 'wmode', 'play', + 'autoplay','loop', 'menu', 'allowscriptaccess', 'allowfullscreen', 'controls', 'preload'],iframe: ['src', 'class', 'height', 'width', 'max-width', 'max-height', 'align', 'frameborder', 'allowfullscreen']","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"分库分表-ShardingJdbc-使用","slug":"backend/database/sharding/分库分表-ShardingJdbc-使用","date":"2018-03-04T16:01:00.000Z","updated":"2019-11-10T02:08:41.826Z","comments":true,"path":"2018/03/05/backend/database/sharding/分库分表-ShardingJdbc-使用/","link":"","permalink":"http://www.songshuiyang.com/2018/03/05/backend/database/sharding/分库分表-ShardingJdbc-使用/","excerpt":"","text":"前言 ShardingSphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。 Sharding-JDBC 定位为轻量级Java框架，在Java的JDBC层提供的额外服务。 它使用客户端直连数据库，以jar包形式提供服务，无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。 适用于任何基于Java的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使用JDBC。 基于任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP等。 支持任意实现JDBC规范的数据库。目前支持MySQL，Oracle，SQLServer和PostgreSQL。 更多内容可通过官网来了解，上面文档也写的很清楚，官网链接 https://shardingsphere.apache.org/index_zh.html 使用实例Github完整代码链接 1、创建数据库和表 数据库及表： 123456ds0 ├── user_0 └── user_1 ds1 ├── user_0 └── user_1 执行sql 既然是分库分表 库结构与表结构一定是一致的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061-- 数据库1CREATE DATABASE IF NOT EXISTS `ds0` /*!40100 DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci */;USE `ds0`;SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for user_0-- ----------------------------DROP TABLE IF EXISTS `user_0`;CREATE TABLE `user_0` ( `id` int(11) NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;-- ------------------------------ Table structure for user_1-- ----------------------------DROP TABLE IF EXISTS `user_1`;CREATE TABLE `user_1` ( `id` int(11) NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;SET FOREIGN_KEY_CHECKS = 1;-- 数据库2CREATE DATABASE IF NOT EXISTS `ds1` /*!40100 DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci */;USE `ds1`;SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for user_0-- ----------------------------DROP TABLE IF EXISTS `user_0`;CREATE TABLE `user_0` ( `id` int(11) NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;-- ------------------------------ Table structure for user_1-- ----------------------------DROP TABLE IF EXISTS `user_1`;CREATE TABLE `user_1` ( `id` int(11) NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;SET FOREIGN_KEY_CHECKS = 1; 2、POM依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt;&lt;/dependency&gt; 3、代码 User 12345678910111213141516171819202122@Data@EqualsAndHashCode(callSuper = true)@Accessors(chain = true)@TableName(\"user\")public class User extends Model&lt;User&gt; &#123; /** * 主键Id */ private Integer id; /** * 名称 */ private String name; /** * 年龄 */ private Integer age;&#125; UserMapper 使用了mybatis plus 123456789101112public interface UserMapper extends BaseMapper&lt;User&gt; &#123; @Update(\"update user set name = #&#123;name&#125; where id = #&#123;id&#125;\") int updateUser(@Param(\"name\") String name, @Param(\"id\") int id); @Delete(\"delete from user where id = #&#123;id&#125;\") int deleteUser(int id); @Select(\"select id, name from user where id = #&#123;id&#125;\") User findUser(@Param(\"id\") int id);&#125; 4、配置分库 + 分表策略 行表达式分片策略 application.properties 123456789101112131415161718192021222324252627282930313233server.port=9000# 数据源 ds0,ds1sharding.jdbc.datasource.names=ds0,ds1# 第一个数据库sharding.jdbc.datasource.ds0.type=com.zaxxer.hikari.HikariDataSourcesharding.jdbc.datasource.ds0.driver-class-name=com.mysql.jdbc.Driversharding.jdbc.datasource.ds0.jdbc-url=jdbc:mysql://localhost:3306/ds0?characterEncoding=utf-8sharding.jdbc.datasource.ds0.username=rootsharding.jdbc.datasource.ds0.password=root# 第二个数据库sharding.jdbc.datasource.ds1.type=com.zaxxer.hikari.HikariDataSourcesharding.jdbc.datasource.ds1.driver-class-name=com.mysql.jdbc.Driversharding.jdbc.datasource.ds1.jdbc-url=jdbc:mysql://localhost:3306/ds1?characterEncoding=utf-8sharding.jdbc.datasource.ds1.username=rootsharding.jdbc.datasource.ds1.password=root# 分库策略 根据主键id取模拆分为2个库，分别是ds0到ds1sharding.jdbc.config.sharding.default-database-strategy.inline.sharding-column=idsharding.jdbc.config.sharding.default-database-strategy.inline.algorithm-expression=ds$-&gt;&#123;id % 2&#125;# 分表策略 用户数据根据age列取模拆分为2张表，分别是user_0到user_1，他们的逻辑表名为usersharding.jdbc.config.sharding.tables.user.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.user_$-&gt;&#123;0..1&#125;sharding.jdbc.config.sharding.tables.user.table-strategy.inline.sharding-column=age# 分片算法表达式sharding.jdbc.config.sharding.tables.user.table-strategy.inline.algorithm-expression=user_$-&gt;&#123;age % 2&#125;# 主键 UUID 18位数 如果是分布式还要进行一个设置 防止主键重复#sharding.jdbc.config.sharding.tables.user.key-generator-column-name=id# 打印执行的数据库以及语句sharding.jdbc.config.props..sql.show=truespring.main.allow-bean-definition-overriding=true 5、测试类新增数据 测试方法： 12345678910@Testpublic void test0 () &#123; for (int i= 0 ; i&lt; 20; i++) &#123; User user = new User(); user.setName(\"\"); user.setId(i); user.setAge(i + 10); userMapper.insert(user); &#125;&#125; 输出日志 可以看到ShardingJdbc对原始INSERT INTO user ( id, NAME, age ) VALUES ( ?, ?, ? )语句进行了Sql转化，实际是没有user这个表的，插入数据是插在user_0和user_1这两张表中的 那数据是怎么区分库和表的呢，ShardingJdbc是通过上面我们在application.properties配置分库 + 分表策略来进行划分的 划分库：根据主键id取模拆分为2个库，分别是ds0到ds1 划分表：用户数据根据age列取模拆分为2张表，分别是user_0到user_1，他们的逻辑表名为user 12345678910111213141516171819202122232425262728ShardingSphere-SQL : Rule Type: shardingShardingSphere-SQL : Logic SQL: INSERT INTO user ( id,name,age ) VALUES ( ?,?,? )ShardingSphere-SQL : SQLStatement: InsertStatement(super=DMLStatement(super=io.shardingsphere.core.parsing.parser.sql.dml.insert.InsertStatement@2e56b4d), columns=[Column(name=id, tableName=user), Column(name=name, tableName=user), Column(name=age, tableName=user)], generatedKeyConditions=[], insertValues=InsertValues(insertValues=[InsertValue(type=VALUES, expression=( ?,?,? ), parametersCount=3)]), columnsListLastPosition=34, generateKeyColumnIndex=-1, insertValuesListLastPosition=56)ShardingSphere-SQL : Actual SQL: ds0 ::: INSERT INTO user_0 ( id,name,age ) VALUES ( ?,?,? ) ::: [[0, , 10]]ShardingSphere-SQL : Rule Type: shardingShardingSphere-SQL : Logic SQL: INSERT INTO user ( id,name,age ) VALUES ( ?,?,? )ShardingSphere-SQL : SQLStatement: InsertStatement(super=DMLStatement(super=io.shardingsphere.core.parsing.parser.sql.dml.insert.InsertStatement@2e56b4d), columns=[Column(name=id, tableName=user), Column(name=name, tableName=user), Column(name=age, tableName=user)], generatedKeyConditions=[], insertValues=InsertValues(insertValues=[InsertValue(type=VALUES, expression=( ?,?,? ), parametersCount=3)]), columnsListLastPosition=34, generateKeyColumnIndex=-1, insertValuesListLastPosition=56)ShardingSphere-SQL : Actual SQL: ds1 ::: INSERT INTO user_1 ( id,name,age ) VALUES ( ?,?,? ) ::: [[1, , 11]] 数据库结果 删除数据 测试方法 1234@Testpublic void test1 () &#123; userMapper.deleteUser(1);&#125; 输出日志 12345ShardingSphere-SQL : Rule Type: shardingShardingSphere-SQL : Logic SQL: delete from user where id = ?ShardingSphere-SQL : SQLStatement: DMLStatement(super=io.shardingsphere.core.parsing.parser.sql.dml.DMLStatement@66d25ba9)ShardingSphere-SQL : Actual SQL: ds1 ::: delete from user_0 where id = ? ::: [[1]]ShardingSphere-SQL : Actual SQL: ds1 ::: delete from user_1 where id = ? ::: [[1]] 修改数据 测试方法 1234@Testpublic void test2 () &#123; userMapper.updateUser(\"20\", 2);&#125; 输出日志 12345ShardingSphere-SQL : Rule Type: shardingShardingSphere-SQL : Logic SQL: update user set name = ? where id = ?ShardingSphere-SQL : SQLStatement: DMLStatement(super=io.shardingsphere.core.parsing.parser.sql.dml.DMLStatement@38883a31)ShardingSphere-SQL : Actual SQL: ds0 ::: update user_0 set name = ? where id = ? ::: [[20, 2]]ShardingSphere-SQL : Actual SQL: ds0 ::: update user_1 set name = ? where id = ? ::: [[20, 2]] 查找数据 测试方法 1234@Testpublic void test3 () &#123; log.info(\"\" + userMapper.findUser(9));&#125; 输出日志 123456ShardingSphere-SQL : Rule Type: shardingShardingSphere-SQL : Logic SQL: select id, name from user where id = ?ShardingSphere-SQL : SQLStatement: SelectStatement(super=DQLStatement(super=io.shardingsphere.core.parsing.parser.sql.dql.select.SelectStatement@32e5af53), containStar=false, firstSelectItemStartPosition=7, selectListLastPosition=16, groupByLastPosition=0, items=[CommonSelectItem(expression=id, alias=Optional.absent()), CommonSelectItem(expression=name, alias=Optional.absent())], groupByItems=[], orderByItems=[], limit=null, subQueryStatement=null, subQueryStatements=[], subQueryConditions=[])ShardingSphere-SQL : Actual SQL: ds1 ::: select id, name from user_0 where id = ? ::: [[9]]ShardingSphere-SQL : Actual SQL: ds1 ::: select id, name from user_1 where id = ? ::: [[9]]c.s.s.sharding.test.UserMapperTest : User(id=9, name=, age=null) 总结 通过上面的例子可以看到Sharding-JDBC使用起来十分方便，业务层代码和平时单表操作是一样的，Sharding-JDBC自动给我们做了Sql转化，我们要做的就是配置分库 + 分表策略 参考 https://shardingsphere.apache.org/index_zh.html https://juejin.im/post/5cf0bff05188250640005e19","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"分库分表","slug":"分库分表","permalink":"http://www.songshuiyang.com/tags/分库分表/"}]},{"title":"分库分表-分库分表后如何部署上线","slug":"backend/database/sharding/分库分表-分库分表后如何部署上线","date":"2018-03-04T16:00:02.000Z","updated":"2019-11-10T02:08:41.835Z","comments":true,"path":"2018/03/05/backend/database/sharding/分库分表-分库分表后如何部署上线/","link":"","permalink":"http://www.songshuiyang.com/2018/03/05/backend/database/sharding/分库分表-分库分表后如何部署上线/","excerpt":"","text":"背景 分库分表对于新系统来说是十分容易的，因为不用考虑数据迁移，项目直接上线即可，但现实中大部分情况应该是针对于老系统进行分库分表，老系统嘛那就有老数据，那么分库分表后怎么把老数据迁移到新库新表呢？这是我们这一章节需要研究的 以下内容copy自这个帖子 ，这大兄弟写的太好了 分库分表后如何部署上线？1、停机部署法 大致思路就是，挂一个公告，半夜停机升级，然后半夜把服务停了，跑数据迁移程序，进行数据迁移。 步骤如下: (1)出一个公告，比如“今晚00:00～6:00进行停机维护，暂停服务” (2)写一个迁移程序，读 db-old数据库，通过中间件写入新库 db-new1 和 db-new2 ，具体如下图所示 (3)校验迁移前后一致性，没问题就切该部分业务到新库。 顺便科普一下，这个中间件。现在流行的分库分表的中间件有两种，一种是 proxy 形式的，例如 mycat，是需要额外部署一台服务器的。 还有一种是 client 形式的，例如当当出的 Sharding-JDBC ，就是一个jar包，使用起来十分轻便。我个人偏向Sharding-JDBC ，这种方式，无需额外部署，无其他依赖，DBA也无需改变原有的运维方式。 2、不停机迁移双写部署法 如果不想经常看凌晨的太阳，那么会想有没有其他的方案？ 1、系统中修改写数据库的代码，同时写单库和新库； 2、数据迁移工具获取到老库的数据，在新库中进行比较，如果新库中不存在，那么把数据保存到新库中；如果新库中存在数据，那么比较更新时间，如果老库的更新时间大于新库，那么修改新库的数据；如果老库的更新时间小于新库的，那么保持不变。 3、迁移完之后需要比较数据是否完全一样，在凌晨的时候，数据肯定会变为一致，因为很少数据进来。 4、最后凌晨，系统把写老库的代码删掉，都写新库。 整个迁移的过程就结束了，这个过程只有在删除写老库代码的时候，会停下服务（你使用了集群，其实对用户来说是无感知的）。 补充 上面的方法有一个硬伤，因为需要编写额外的代码，这么做是不是造成了严重的代码入侵。将非业务代码嵌入业务代码，这么做，后期删代码的时候特别累。 有没什么方法，可以避免这个问题的? 有的通过订阅 binlog 日志的形式 binlog会记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志，binlog不会记录SELECT和SHOW这类操作，因为这类操作对据本身并没有修改。 有了这些日志那就是可以通过这些日志来还原数据 参考 https://segmentfault.com/a/1190000016475827 http://www.chaiguanxin.com/articles/2018/11/11/1541923418699.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"分库分表","slug":"分库分表","permalink":"http://www.songshuiyang.com/tags/分库分表/"}]},{"title":"分库分表-分库分表中间件","slug":"backend/database/sharding/分库分表-分库分表中间件","date":"2018-03-04T16:00:01.000Z","updated":"2019-11-10T02:08:41.829Z","comments":true,"path":"2018/03/05/backend/database/sharding/分库分表-分库分表中间件/","link":"","permalink":"http://www.songshuiyang.com/2018/03/05/backend/database/sharding/分库分表-分库分表中间件/","excerpt":"","text":"背景 在将数据库进行分库分表之后，我们一般会引入分库分表的中间件，目标就是操作多库多表能像操作单库单表那样方便 分库分表中间件 🦅 目前，市面上提供的分库分表的中间件，主要有两种实现方式： Client 模式 Proxy 模式 1）Cobar 阿里 b2b团队开发和开源的，属于 Proxy 层方案。 早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。 2）MyCAT 基于 Cobar 改造的，属于 Proxy层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件 社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding Sphere 来说，年轻一些，经历的锤炼少一些。 3）Atlas 360 开源的，属于 Proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。 4）TDDL 淘宝团队开发的，属于 client 层方案。支持基本的crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond配置管理系统。 5）Sharding Sphere Sharding Sphere可能是目前最好的开源的分库分表解决方案，目前已经进入 Apache 孵化。 Sharding Sphere 提供三种模式： Sharding-JDBC Sharding-Proxy Sharding-Sidecar 计划开发中。 其中，Sharding-JDBC 属于 client 层方案，被大量互联网公司所采用。例如，当当、京东金融、中国移动等等。 如何选择？ 综上，现在其实建议考量的，就是 Sharding Sphere ，这个可以满足我们的诉求。 Sharding Sphere 的 Sharding-JDBC 方案，这种 Client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 sharding-jdbc 的依赖。 Sharding Sphere 的 Sharding-Proxy 方案，这种 Proxy 层方案，可以解决我们平时查询数据库的需求。我们只需要连接一个 Sharding-Proxy ，就可以查询分库分表中的数据。另外，如果我们有跨语言的需求，例如 PHP、GO 等，也可以使用它。 参考 http://www.iocoder.cn https://shardingsphere.apache.org/document/current/cn/features/sharding/","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"分库分表","slug":"分库分表","permalink":"http://www.songshuiyang.com/tags/分库分表/"}]},{"title":"分库分表-基础理论","slug":"backend/database/sharding/分库分表-基础理论","date":"2018-03-04T16:00:00.000Z","updated":"2019-11-10T02:08:41.839Z","comments":true,"path":"2018/03/05/backend/database/sharding/分库分表-基础理论/","link":"","permalink":"http://www.songshuiyang.com/2018/03/05/backend/database/sharding/分库分表-基础理论/","excerpt":"","text":"背景为什么要分库分表 传统的将数据集中存储至单一数据节点的解决方案，在性能、可用性和运维成本这三方面已经难于满足互联网的海量数据场景。 1、从性能方面来说 从性能方面来说，由于关系型数据库大多采用B+树类型的索引，在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的IO次数增加，进而导致查询性能的下降；同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈。 2、从可用性的方面来讲 从可用性的方面来讲，服务化的无状态型，能够达到较小成本的随意扩容，这必然导致系统的最终压力都落在数据库之上。而单一的数据节点，或者简单的主从架构，已经越来越难以承担。数据库的可用性，已成为整个系统的关键。 3、从运维成本方面考虑 从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，对于 DBA 的运维压力就会增大。数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。一般来讲，单一数据库实例的数据的阈值在 1TB 之内，是比较合理的范围。 那么为什么不选择 NoSQL 呢？ 传统的关系型数据库更适合处理一些业务场景 NoSQL 对 SQL 的不兼容性以及生态圈的不完善 什么是分库分表 数据分片，指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。数据分片的有效手段是对关系型数据库进行分库和分表。 分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈。除此之外，分库还能够用于有效的分散对数据库单点的访问量。 分表虽然无法缓解数据库压力，但却能够提供尽量将分布式事务转化为本地事务的可能，一旦涉及到跨库的更新操作，分布式事务往往会使问题变得复杂。 使用多主多从的分片方式，可以有效的避免数据单点，从而提升数据架构的可用性。 通过分库和分表进行数据的拆分来使得各个表的数据量保持在阈值以下，以及对流量进行疏导应对高访问量，是应对高并发和海量数据系统的有效手段。数据分片的拆分方式又分为垂直分片和水平分片。 垂直拆分 按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用。 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。 下图展示了根据业务需要，将用户表和订单表垂直分片到不同的数据库的方案。 垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。 垂直拆分的优点： 库表职责单一，复杂度降低，易于维护。 单库或单表压力降低。 相互之间的影响也会降低。 垂直拆分的缺点： 部分表关联无法在数据库级别完成，需要在程序中完成。 单表大数据量仍然存在性能瓶颈。 单表或单库高热点访问依旧对 DB 压力非常大。 事务处理相对更为复杂，需要分布式事务的介入。 拆分达到一定程度之后，扩展性会遇到限制。 水平拆分 水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。 例如：根据主键分片，偶数主键的记录放入0库（或表），奇数主键的记录放入1库（或表），如下图所示。 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。 水平拆分的优点： 解决单表单库大数据量和高热点访问性能遇到瓶颈的问题。 应用程序端整体架构改动相对较少。 事务处理相对简单。 只要切分规则能够定义好，基本上较难遇到扩展性限制。 水平拆分缺点： 拆分规则相对更复杂，很难抽象出一个能够满足整个数据库的切分规则。 后期数据的维护难度有所增加，人为手工定位数据更困难。 产品逻辑将变复杂。比如按年来进行历史数据归档拆分，这个时候在页面设计上就需要约束用户必须要先选择年，然后才能进行查询。 挑战 虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但分布式的架构在获得了收益的同时，也引入了新的问题。 面对如此散乱的分库分表之后的数据，应用开发工程师和数据库管理员对数据库的操作变得异常繁重就是其中的重要挑战之一。他们需要知道数据需要从哪个具体的数据库的分表中获取。 另一个挑战则是，能够正确的运行在单节点数据库中的SQL，在分片之后的数据库中并不一定能够正确运行。 例如：分表导致表名称的修改，或者分页、排序、聚合分组等操作的不正确处理。 例如：跨节点 join 的问题。 跨库事务也是分布式的数据库集群要面对的棘手事情。 合理采用分表，可以在降低单表数据量的情况下，尽量使用本地事务，善于使用同库不同表可有效避免分布式事务带来的麻烦。 要达到这个效果，需要尽量把同一组数据放到同一组 DB 服务器上。例如说，将同一个用户的订单主表，和订单明细表放到同一个库，那么在创建订单时，还是可以使用相同本地事务。 在不能避免跨库事务的场景，有些业务仍然需要保持事务的一致性。 而基于XA的分布式事务由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务。 分布式全局唯一 ID 。 在单库单表的情况下，直接使用数据库自增特性来生成主键ID，这样确实比较简单。 在分库分表的环境中，数据分布在不同的分表上，不能再借助数据库自增长特性。需要使用全局唯一 ID，例如 UUID、GUID等 。 参考 http://www.iocoder.cn https://shardingsphere.apache.org/document/current/cn/features/sharding/","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"分库分表","slug":"分库分表","permalink":"http://www.songshuiyang.com/tags/分库分表/"}]},{"title":"基于wordspress搭建个人博客系统","slug":"backend/other/基于wordspress搭建个人博客系统","date":"2018-03-04T12:54:12.000Z","updated":"2020-03-16T11:43:55.540Z","comments":true,"path":"2018/03/04/backend/other/基于wordspress搭建个人博客系统/","link":"","permalink":"http://www.songshuiyang.com/2018/03/04/backend/other/基于wordspress搭建个人博客系统/","excerpt":"什么是Wordspress：官网： https://cn.wordpress.org/ 提供了中英版 WordPress是使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可以把 WordPress当作一个内容管理系统（CMS）来使用。 WordPress是一款个人博客系统，并逐步演化成一款内容管理系统软件，它是使用PHP语言和MySQL数据库开发的。用户可以在支持 PHP 和 MySQL数据库的服务器上使用自己的博客。 WordPress有许多第三方开发的免费模板，安装方式简单易用。不过要做一个自己的模板，则需要你有一定的专业知识。比如你至少要懂的标准通用标记语言下的一个应用HTML代码、CSS、PHP等相关知识。 WordPress官方支持中文版，同时有爱好者开发的第三方中文语言包，如wopus中文语言包。WordPress拥有成千上万个各式插件和不计其数的主题模板样式。","text":"什么是Wordspress：官网： https://cn.wordpress.org/ 提供了中英版 WordPress是使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可以把 WordPress当作一个内容管理系统（CMS）来使用。 WordPress是一款个人博客系统，并逐步演化成一款内容管理系统软件，它是使用PHP语言和MySQL数据库开发的。用户可以在支持 PHP 和 MySQL数据库的服务器上使用自己的博客。 WordPress有许多第三方开发的免费模板，安装方式简单易用。不过要做一个自己的模板，则需要你有一定的专业知识。比如你至少要懂的标准通用标记语言下的一个应用HTML代码、CSS、PHP等相关知识。 WordPress官方支持中文版，同时有爱好者开发的第三方中文语言包，如wopus中文语言包。WordPress拥有成千上万个各式插件和不计其数的主题模板样式。 搭建教程：参考下面的帖子写的十分详细 https://www.jianshu.com/p/56750622cac9 LNMP一键安装包LNMP一键安装包是一个用Linux Shell编写的可以为CentOS/RHEL/Fedora/Aliyun/Amazon、Debian/Ubuntu/Raspbian/Deepin/Mint Linux VPS或独立主机安装LNMP(Nginx/MySQL/PHP)、LNMPA(Nginx/MySQL/PHP/Apache)、LAMP(Apache/MySQL/PHP)生产环境的Shell程序。https://lnmp.org/","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"Mysql-SQL语句在MySQL中如何执行的","slug":"backend/database/mysql/Mysql-SQL语句在MySQL中如何执行的","date":"2018-03-03T16:00:00.000Z","updated":"2020-01-04T12:21:52.025Z","comments":true,"path":"2018/03/04/backend/database/mysql/Mysql-SQL语句在MySQL中如何执行的/","link":"","permalink":"http://www.songshuiyang.com/2018/03/04/backend/database/mysql/Mysql-SQL语句在MySQL中如何执行的/","excerpt":"","text":"摘抄来自木木匠 ，写的很好 前言 本篇文章会分析下一个 sql 语句在 MySQL 中的执行流程，包括 sql 的查询在 MySQL 内部会怎么流转，sql 语句的更新是怎么完成的。 在分析之前我会先带着你看看 MySQL 的基础架构，知道了 MySQL 由那些组件组成已经这些组件的作用是什么，可以帮助我们理解和解决这些问题。 解析一、MySQL 基础架构分析1.1 MySQL 基本架构概览 下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。 先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在 1.2 节中会详细介绍到这些组件的作用。 连接器： 身份认证和权限相关(登录 MySQL 的时候)。 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。 分析器: 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。 优化器： 按照 MySQL 认为最优的方案去执行。 执行器: 执行语句，然后从存储引擎返回数据。 简单来说 MySQL 主要分为 Server 层和存储引擎层： Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。 存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。 1.2 Server 层基本组件介绍 连接器 连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。 主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。 查询缓存(MySQL 8.0 版本后移除) 查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。 连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。 MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。 所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。 MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。 分析器 MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步： 第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。 第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。 完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。 优化器 优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。 可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。 执行器 当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。 二、语句分析2.1 查询语句 说了以上这么多，那么究竟一条 sql 语句是如何执行的呢？其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下： 1select * from tb_student A where A.age='18' and A.name=' 张三 '; 结合上面的说明，我们分析下这个语句的执行流程： 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。 通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student,需要查询所有的列，查询条件是这个表的 id=’1’。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。 接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案： a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。 b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。 那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。 2.2 更新语句 以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下： 1update tb_student A set A.age='19' where A.name=' 张三 '; 我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块式binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块redo log（重做日志），我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下： 先查询到张三这一条数据，如果有缓存，也是会用到缓存。 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。 更新完成。 这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗? 这是因为最开始 MySQL 并没与 InnoDB 引擎( InnoDB 引擎是其他公司以插件形式插入 MySQL 的) ，MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。 并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？ 先写 redo log 直接提交，然后写 binlog，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 bingog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。 先写 binlog，然后写 redo log，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。 如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下： 判断 redo log 是否完整，如果判断是完整的，就立即提交。 如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。 这样就解决了数据一致性的问题。 总结 MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。 查询语句的执行流程如下：权限校验（如果命中缓存）—》查询缓存—》分析器—》优化器—》权限校验—》执行器—》引擎 更新语句执行流程如下：分析器—-》权限校验—-》执行器—》引擎—redo log(prepare 状态—》binlog—》redo log(commit状态) 参考 https://snailclimb.gitee.io/javaguide/#/docs/database/一条sql语句在mysql中如何执行的","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-高性能优化规范建议","slug":"backend/database/mysql/Mysql-高性能优化规范建议","date":"2018-03-03T16:00:00.000Z","updated":"2020-01-04T12:21:52.064Z","comments":true,"path":"2018/03/04/backend/database/mysql/Mysql-高性能优化规范建议/","link":"","permalink":"http://www.songshuiyang.com/2018/03/04/backend/database/mysql/Mysql-高性能优化规范建议/","excerpt":"","text":"前言一、数据库基本设计规范尽量控制单表数据量的大小,建议控制在 500 万以内。500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。 可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小 二、数据库字段设计规范优先选择符合存储需要的最小的数据类型 原因： 列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。 方法： a.将字符串转换成数字类型存储,如:将 IP 地址转换成整形数据 b.对于非负型的数据 (如自增 ID,整型 IP) 来说,要优先使用无符号整型来存储 无符号相对于有符号可以多出一倍的存储空间 12SIGNED INT -2147483648~2147483647UNSIGNED INT 0~4294967295 VARCHAR(N) 中的 N 代表的是字符数，而不是字节数，使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。过大的长度会消耗更多的内存 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据 a. 建议把 BLOB 或是 TEXT 列分离到单独的扩展表中 MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。 如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。 b. TEXT 或 BLOB 类型只能使用前缀索引 因为MySQL 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的 尽可能把所有列定义为 NOT NULL 原因： 索引 NULL 列需要额外的空间来保存，所以要占用更多的空间 进行比较和计算时要对 NULL 值做特别的处理 三、索引设计规范如何选择索引列的顺序 建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数） 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好） 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引） 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间） 重复索引示例：primary key(id)、index(id)、unique index(id) 冗余索引示例：index(a,b,c)、index(a,b)、index(a) 索引 SET 规范 尽量避免使用外键约束 不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引 外键可用于保证数据的参照完整性，但建议在业务端实现 外键会影响父表和子表的写操作从而降低性能 四、数据库 SQL 开发规范避免数据类型的隐式转换 隐式转换会导致索引失效如: select name,phone from customer where id = &#39;111&#39; 充分利用表上已经存在的索引 避免使用双%号的查询条件。如：a like ‘%123%’，（如果无前置%,只有后置%，是可以用到列上的索引的） 一个 SQL 只能利用到复合索引中的一列进行范围查询。如：有 a,b,c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b,c 列上的索引将不会被用到。 在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧，使用 left join 或 not exists 来优化 not in 操作，因为 not in 也通常会使用索引失效。 禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询 原因： 消耗更多的 CPU 和 IO 以网络带宽资源 无法使用覆盖索引 可减少表结构变更带来的影响 五、数据库操作行为规范超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作 大批量操作可能会造成严重的主从延迟 主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间， 而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况 binlog 日志为 row 格式时会产生大量的日志 大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因 避免产生大事务操作 大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。 特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批 其他总结参考 https://www.cnblogs.com/huchong/p/10219318.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"animate.css","slug":"frontend/animate","date":"2018-03-03T02:52:12.000Z","updated":"2019-09-16T13:11:07.269Z","comments":true,"path":"2018/03/03/frontend/animate/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/frontend/animate/","excerpt":"","text":"一 前言:背景：在看其他人的项目的时候发现其动画效果做的不错，通过看人家的代码发现用了这个animate.css这个css组件，使用起来也是特别的方便，所以就把他copy到项目中来了，顿时档次就上升了 简介:animate.css 是一个来自国外的 CSS3 动画库，它预设了抖动（shake）、闪烁（flash）、弹跳（bounce）、翻转（flip）、旋转（rotateIn/rotateOut）、淡入淡出（fadeIn/fadeOut）等多达 60 多种动画效果，几乎包含了所有常见的动画效果。而且使用起来也是特别方便 官网传送门: https://daneden.github.io/animate.css/ 在官网上有示例动画，主页也十分简洁，同时也提供了代码下载, 也可以看看这篇博客写的例子 https://www.cnblogs.com/xiaohuochai/p/7372665.html 二 如何使用：步骤： 在官网上下载 animate.css , 把他导入到项目中来, 也可以使用cdn https://unpkg.com/animate.css@3.5.2/animate.min.css 代码示例 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/animate.css@3.5.2/animate.min.css\"&gt; &lt;style&gt; .box&#123;height: 100px;width: 100px;background-color: lightblue&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=\"box animated flash\"&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 只要在元素中class 添加 animated 和相应的动画class名就可以实现动画效果, 当然也可以通过js动态设置class","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"css","slug":"css","permalink":"http://www.songshuiyang.com/tags/css/"}]},{"title":"Mysql-Sql-大表优化方案","slug":"backend/database/mysql/Mysql-Sql-大表优化方案","date":"2018-03-02T16:08:01.000Z","updated":"2020-03-30T12:55:19.259Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-Sql-大表优化方案/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-Sql-大表优化方案/","excerpt":"","text":"前言 当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化 解析一、单表优化 除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量： 字段优化 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME， 单表不要有太多字段，建议在20以内 避免使用NULL字段，很难查询优化且占用额外索引空间 索引优化 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描 值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段 不用外键，由程序保证约束 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引 查询SQL优化 可通过开启慢查询日志来找出较慢的SQL 不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边 sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库 不用SELECT * OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内 不用函数和触发器，在应用程序实现 避免%xxx式查询 少用JOIN 使用同类型进行比较，比如用’123’和’123’比，123和123比 尽量避免在WHERE子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大 存储引擎选择 MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 二、升级硬件 这个不多说了，根据MySQL是CPU密集型还是I/O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能 三、读写分离 也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离 四、表分区垂直拆分 按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用。 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。 下图展示了根据业务需要，将用户表和订单表垂直分片到不同的数据库的方案。 垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。 垂直拆分的优点： 库表职责单一，复杂度降低，易于维护。 单库或单表压力降低。 相互之间的影响也会降低。 垂直拆分的缺点： 部分表关联无法在数据库级别完成，需要在程序中完成。 单表大数据量仍然存在性能瓶颈。 单表或单库高热点访问依旧对 DB 压力非常大。 事务处理相对更为复杂，需要分布式事务的介入。 拆分达到一定程度之后，扩展性会遇到限制。 水平拆分 水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。 例如：根据主键分片，偶数主键的记录放入0库（或表），奇数主键的记录放入1库（或表），如下图所示。 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。 水平拆分的优点： 解决单表单库大数据量和高热点访问性能遇到瓶颈的问题。 应用程序端整体架构改动相对较少。 事务处理相对简单。 只要切分规则能够定义好，基本上较难遇到扩展性限制。 水平拆分缺点： 拆分规则相对更复杂，很难抽象出一个能够满足整个数据库的切分规则。 后期数据的维护难度有所增加，人为手工定位数据更困难。 产品逻辑将变复杂。比如按年来进行历史数据归档拆分，这个时候在页面设计上就需要约束用户必须要先选择年，然后才能进行查询。 其他总结参考 https://segmentfault.com/a/1190000006158186","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-Sql-EXPLAIN命令","slug":"backend/database/mysql/Mysql-Sql-EXPLAIN命令","date":"2018-03-02T16:08:01.000Z","updated":"2019-11-27T15:11:32.509Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-Sql-EXPLAIN命令/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-Sql-EXPLAIN命令/","excerpt":"","text":"简介 MySQL 提供了一个 EXPLAIN 命令, 它可以对 SELECT 语句进行分析, 并输出 SELECT 执行的详细信息, 以供开发人员针对性优化. EXPLAIN 命令用法十分简单, 在 SELECT 语句前加上 Explain 就可以了, 例如: 1EXPLAIN SELECT * from user_info WHERE id &lt; 300; 12345+----+-------------+---------+------+---------------+------+---------+------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+---------+------+---------------+------+---------+------+------+-------+| 1 | SIMPLE | servers | ALL | NULL | NULL | NULL | NULL | 1 | NULL |+----+-------------+---------+------+---------------+------+---------+------+------+-------+ 解析各列的含义如下: id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type： 表示了查询的类型, 它的常用取值有: SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. table： 表示查询涉及的表或衍生表 partitions: 匹配的分区 type: type 字段比较重要, 它提供了判断查询是否高效的重要依据依据，通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等. type 常用的取值有: ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免. index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中.当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL, 并且 key_len 字段是此次查询中使用到的索引的最长的那个. ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询. eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高 const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可 system: 表中只有一条数据. 这个类型是特殊的 const 类型. NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 通常来说, 不同的 type 类型的性能关系如下: ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system &lt; NULL ALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的. 而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快，后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了. possible_keys: 指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用 注意, 即使有些索引在 possible_keys 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 key 字段决定. key: 此字段是 MySQL 在当前查询时所真正使用到的索引. key_len： 表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到. 不损失精确性的情况下，长度越短越好 ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数. 这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好. filtered: 表示此查询条件所过滤的数据的百分比 extra: Explain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容: Using where:使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。注意：Extra列出现Using where表示 mysql服务器将在存储引擎检索行后再进行过滤。就是先读取整行数据，再按 where 条件进行检查，符合就留下，不符合就丢弃。 Using temporary：查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化. Using filesort: 当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行。 Using index：”覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using index condition：这是MySQL 5.6出来的新特性，叫做“索引条件推送”。简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。 Select tables optimized away：在没有GROUP BY子句的情况下，基于索引优化MIN/MAX操作，或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 distinct：优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作 Not exists：MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行， 就不再搜索了。 其他总结参考 https://segmentfault.com/a/1190000008131735","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-Sql-经典面试题","slug":"backend/database/mysql/Mysql-Sql-经典面试题","date":"2018-03-02T16:08:00.000Z","updated":"2019-11-10T02:08:41.611Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-Sql-经典面试题/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-Sql-经典面试题/","excerpt":"","text":"前言 很多查询都可以用经典的学生－课程－成绩案例来表示，下面是一些笔试或面试中遇到的经典题型 表结构 学生表student(id,name) 课程表course(id,name) 学生课程表student_course(sid,cid,score) 队伍表team(name)) sql 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for course-- ----------------------------DROP TABLE IF EXISTS `course`;CREATE TABLE `course` ( `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, `name` char(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of course-- ----------------------------INSERT INTO `course` VALUES (1, '语文');INSERT INTO `course` VALUES (2, '数学');-- ------------------------------ Table structure for student-- ----------------------------DROP TABLE IF EXISTS `student`;CREATE TABLE `student` ( `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, `name` char(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of student-- ----------------------------INSERT INTO `student` VALUES (1, '张三');INSERT INTO `student` VALUES (2, '李四');INSERT INTO `student` VALUES (3, '张三');INSERT INTO `student` VALUES (4, '王五');INSERT INTO `student` VALUES (5, '李好');-- ------------------------------ Table structure for student_course-- ----------------------------DROP TABLE IF EXISTS `student_course`;CREATE TABLE `student_course` ( `sid` int(10) UNSIGNED NOT NULL, `cid` int(10) UNSIGNED NOT NULL, `score` int(10) UNSIGNED NOT NULL, PRIMARY KEY (`sid`, `cid`) USING BTREE, INDEX `cid`(`cid`) USING BTREE, CONSTRAINT `student_course_ibfk_1` FOREIGN KEY (`sid`) REFERENCES `student` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT, CONSTRAINT `student_course_ibfk_2` FOREIGN KEY (`cid`) REFERENCES `course` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of student_course-- ----------------------------INSERT INTO `student_course` VALUES (1, 1, 80);INSERT INTO `student_course` VALUES (1, 2, 90);INSERT INTO `student_course` VALUES (2, 1, 90);INSERT INTO `student_course` VALUES (2, 2, 70);INSERT INTO `student_course` VALUES (3, 1, 50);INSERT INTO `student_course` VALUES (3, 2, 10);INSERT INTO `student_course` VALUES (4, 1, 66);INSERT INTO `student_course` VALUES (4, 2, 65);INSERT INTO `student_course` VALUES (5, 1, 23);INSERT INTO `student_course` VALUES (5, 2, 59);-- ------------------------------ Table structure for team-- ----------------------------DROP TABLE IF EXISTS `team`;CREATE TABLE `team` ( `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of team-- ----------------------------INSERT INTO `team` VALUES ('a');INSERT INTO `team` VALUES ('b');INSERT INTO `team` VALUES ('c');INSERT INTO `team` VALUES ('d');SET FOREIGN_KEY_CHECKS = 1; 问题 1、查询student表中重名的学生，结果包含id和name，按name,id升序 2、在student_course表中查询平均分不及格的学生，列出学生id和平均分 3、在student_course表中查询每门课成绩都不低于80的学生id 4、查询每个学生的总成绩，结果列出学生姓名和总成绩 5、总成绩最高的学生，结果列出学生id和总成绩 6、在student_course表查询课程1成绩第2高的学生，如果第2高的不止一个则列出所有的学生 7、在student_course表查询各科成绩最高的学生，结果列出学生id、课程id和对应的成绩 8、在student_course表中查询每门课的前2名，结果按课程id升序，同一课程按成绩降序 这个问题也就是取每组的前N条纪录 9、一个叫team的表，里面只有一个字段name,一共有4条纪录，分别是a,b,c,d,对应四个球队，两两进行比赛，用一条sql语句显示所有可能的比赛组合 10、题目：数据库中有一张如下所示的表 表名为sales 123456789年 季度 销售1991 1 111991 2 121991 3 131991 4 141992 1 211992 2 221992 3 231992 4 24 要求：写一个SQL语句查询出如下所示的结果 123年 一季度 二季度 三季度 四季度1991 11 12 13 141992 21 22 23 24 答案 1、查询student表中重名的学生，结果包含id和name，按name,id升序 我们经常需要查询某一列重复的行，一般通过group by(有重复的列)然后取count&gt;1的值12345678SELECT id, NAME FROM student WHERE NAME IN ( SELECT NAME FROM student GROUP BY NAME HAVING count( * ) &gt; 1 ) ORDER BY NAME; 2、在student_course表中查询平均分不及格的学生，列出学生id和平均分 group by和having是最常考的。 where子句中不能用聚集函数作为条件表达式，但是having短语可以 where和having的区别在于对用对象不同，where作用于记录，having作用于组12345678910 SELECT sid, avg( score ) AS avg_score FROM student_course GROUP BY sid HAVING avg_score &lt; 60 3、在student_course表中查询每门课成绩都不低于80的学生id 用到反向思想123456SELECT DISTINCT sid FROM student_course WHERE sid NOT IN ( SELECT sid FROM student_course WHERE score &lt; 80 ); 4、查询每个学生的总成绩，结果列出学生姓名和总成绩 如果使用下面的sql会过滤掉没有成绩的人 12345678910SELECT NAME , sum( score ) total FROM student, student_course WHERE student.id = student_course.sid GROUP BY sid; 更保险的做法应该是使用 左外连接 12345678SELECT NAME , sum( score ) FROM student LEFT JOIN student_course ON student.id = student_course.sid GROUP BY sid; 5、总成绩最高的学生，结果列出学生id和总成绩 sql12345678910SELECT sid, sum( score ) AS sum_score FROM student_course GROUP BY sid ORDER BY sum_score DESC LIMIT 1; 6、在student_course表查询课程1成绩第2高的学生，如果第2高的不止一个则列出所有的学生 这是个查询 第N大数 的问题。 我们先查出第2高的成绩： 1234567891011SELECT score FROM student_course WHERE cid = 1 GROUP BY score ORDER BY score DESC LIMIT 2; 使用这种方式是错的，因为作用的先后顺序是group by-&gt;min-&gt;order by-&gt;limit，mysql提供了limit offset,size这种方式来取第N大的值，因此正确的做法是： 12345678910SELECT score FROM student_course WHERE cid = 1 GROUP BY score ORDER BY score DESC LIMIT 1,1; 然后再取出该成绩对应的学生： 1234567SELECT * FROM student_course WHERE cid = 1 AND score = ( SELECT score FROM student_course WHERE cid = 1 GROUP BY score ORDER BY score DESC LIMIT 1, 1 ); 7、在student_course表查询各科成绩最高的学生，结果列出学生id、课程id和对应的成绩 嵌套查询12select * from student_course as x where score&gt;=(select max(score) from student_course as y where cid=x.cid); 8、在student_course表中查询每门课的前2名，结果按课程id升序，同一课程按成绩降序 这个问题也就是取每组的前N条纪录 * 123select * from student_course x where2&gt;(select count(distinct(score)) from student_course y where y.cid=x.cid and y.score&gt;x.score)order by cid,score desc; 9、一个叫team的表，里面只有一个字段name,一共有4条纪录，分别是a,b,c,d,对应四个球队，两两进行比赛，用一条sql语句显示所有可能的比赛组合 12345678SELECT a.NAME, b.NAME FROM team a, team b WHERE a.NAME &lt; b.NAME 10、题目：数据库中有一张如下所示的表 表名为sales 123456789年 季度 销售1991 1 111991 2 121991 3 131991 4 141992 1 211992 2 221992 3 231992 4 24 要求：写一个SQL语句查询出如下所示的结果 123年 一季度 二季度 三季度 四季度1991 11 12 13 141992 21 22 23 24 sql 123456select 年, sum(case when 季度=1 then 销售量 else 0 end) as 一季度, sum(case when 季度=2 then 销售量 else 0 end) as 二季度, sum(case when 季度=3 then 销售量 else 0 end) as 三季度, sum(case when 季度=4 then 销售量 else 0 end) as 四季度 from sales group by 年; 总结参考 http://www.iocoder.cn https://www.yanxurui.cc/posts/mysql/2016-11-10-10-sql-interview-questions/","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-锁-锁机制","slug":"backend/database/mysql/Mysql-锁-锁机制","date":"2018-03-02T16:07:00.000Z","updated":"2020-01-04T12:21:52.048Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-锁-锁机制/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-锁-锁机制/","excerpt":"","text":"前言 当多个查询同一时刻进行数据修改时，就会产生并发控制的问题，那么怎么处理这个问题呢，就要靠这个锁来处理，本章将介绍Mysql锁相关的一些知识点。 解析锁分类1、按照锁的粒度分类 表锁 Mysql中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 其锁定粒度最大，触发锁冲突的概率最高，并发度最低 MyISAM和 InnoDB引擎都支持表级锁。 行锁 Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 2、按照是否可写分类 表级锁和行级锁可以进一步划分为共享锁（s）和排他锁（X）。 共享锁（s） 共享锁（Share Locks，简记为S）又被称为读锁，其他用户可以并发读取数据，但任何事务都不能获取数据上的排他锁，直到已释放所有共享锁。 若事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 排他锁（X）： 排它锁（(Exclusive lock,简记为X锁)）又称为写锁，若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。 它防止任何其它事务获取资源上的锁，直到在事务的末尾将资源上的原始锁释放为止。在更新操作(INSERT、UPDATE 或 DELETE)过程中始终应用排它锁。 两者之间的区别： 共享锁：不堵塞，多个用户可以同时读一个资源，互不干扰。 排他锁：一个写锁会阻塞其他的读锁和写锁，这样可以只允许一个用户进行写入，防止其他用户读取正在写入的资源。 3、InnoDB行级锁 InnoDB的行级锁是针对索引加的锁，不针对数据记录，如果查询语句未命中任何索引，那么InnoDB会使用表级锁，因此即使访问不同行的记录，如果使用了相同的索引键仍然会出现锁冲突 InnoDB支持行级锁，包括如下几种： Record Lock（纪录索引锁）: 对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项； Gap Lock（间隙锁）: 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。 其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。 Next-key Lock（上面的两项的组合）： 锁定索引项本身和索引范围，即Record Lock和Gap Lock的结合。可解决幻读问题。 Innodb 的行锁是怎么实现的？ 例如：SELECT * FROM tab_with_index WHERE id = 1 FOR UPDATE FOR UPDATE 可以根据条件来完成行锁锁定，并且 id 是有索引键的列 如果 id 不是索引键那么 InnoDB将完成表锁，并发将无从谈起。 Innodb 的锁的策略为 next-key 锁，即record lock + gap lock，是通过在 index 上加 lock 实现的。 如果 index 为 unique index ，则降级为 record lock 行锁。 如果是普通 index ，则为 next-key lock 。 如果没有 index ，则直接锁住全表，即表锁。 什么是悲观锁？什么是乐观锁？ 1）悲观锁 它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。 艿艿：悲观锁，就是我们上面看到的共享锁和排他锁。 2）乐观锁 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。 而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 艿艿：乐观锁，实际就是通过版本号，从而实现 CAS 原子性更新。 什么是死锁 多数情况下，可以认为如果一个资源被锁定，它总会在以后某个时间被释放。而死锁发生在当多个进程访问同一数据库时，其中每个进程拥有的锁都是其他进程所需的，由此造成每个进程都无法继续下去。 简单的说，进程 A 等待进程 B 释放他的资源，B 又等待 A 释放他的资源，这样就互相等待就形成死锁。 其他总结 MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁 参考 http://www.iocoder.cn https://blog.csdn.net/qq_34337272/article/details/80611486","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-事务-事务隔离级别","slug":"backend/database/mysql/Mysql-事务-事务隔离级别","date":"2018-03-02T16:06:00.000Z","updated":"2020-01-04T12:21:52.037Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-事务-事务隔离级别/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-事务-事务隔离级别/","excerpt":"","text":"前言 事务就是对一系列的数据库操作（比如插入多条数据）进行统一的提交或回滚操作，如果插入成功，那么一起成功，如果中间有一条出现异常，那么回滚之前的所有操作。 这样可以防止出现脏数据，防止数据库数据出现问题。 解析事务的特性 ACID 原子性 Atomicity ：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 一致性 Consistency ：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。 隔离性 Isolation ：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括 读未提交（Read uncommitted） 读提交（read committed） 可重复读（repeatable read） 串行化（Serializable）。 持久性 Durability ：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 事务的并发问题MySQL 事务隔离级别会产生的并发问题 事务定义了四种事务隔离级别，不同数据库在实现时，产生的并发问题是不同的，不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差。 1、读未提交（Read uncommitted） 读未提交，顾名思义，就是一个事务可以读取另一个未提交事务的数据，事务中的修改，即使没有提交，对其他事务也都是可见的。 事例：老板要给程序员发工资，程序员的工资是3.6万/月。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。 分析：实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是脏读。 这样的话会导致脏读，那怎么解决脏读呢？Read committed！读提交，能解决脏读问题。 2、读提交（read committed） 读提交，顾名思义，就是一个事务要等另一个事务提交后才能读取数据，事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的… 分析：这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读 这个隔离级别会导致不可重复读，也可以叫做“不可重复读“，那怎么解决不可重复读问题？Repeatable read ！可重复读能解决 3、可重复读（repeatable read） 重复读就是在开始读取数据（事务开启）时，不再允许修改操作 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。 分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。 什么时候会出现幻读？ 事例：程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读。 那怎么解决幻读问题？Serializable！ 4、串行化（Serializable）。 Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 MySQL 默认的事务隔离级别为可重复读（repeatable-read） 实现结果如下表所示： 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 读已提交（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是（x） 串行化（serializable） 否 否 否 这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server) 是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEAaTABLE-READ（可重读） 并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。 MySQL InnoDB 采用 MVCC 来支持高并发 值得一提的是：大多数数据库默认的事务隔离级别是Read committed，比如Sql Server , Oracle。Mysql的默认隔离级别是Repeatable read。 总结 数据库事务的隔离级别有4种，由低到高分别为1、读未提交 2、读提交 3、可重复读 4、串行化，前三种级别因为事务并不是串行的，所以会带来如下三个问题： 1、脏读：事务 A 读取了事务 B 提交前更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。 2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。 3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 小结： 不可重复读的和幻读很容易混淆 不可重复读侧重于修改，解决不可重复读的问题只需锁住满足条件的行 幻读侧重于新增或删除，解决幻读需要锁表 参考 http://www.iocoder.cn https://snailclimb.gitee.io/javaguide/#/docs/database/MySQL https://www.cnblogs.com/ubuntu1/p/8999403.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-索引-索引失效的场景统计","slug":"backend/database/mysql/Mysql-索引-索引失效的场景统计","date":"2018-03-02T16:05:03.000Z","updated":"2020-03-30T12:55:19.262Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-索引-索引失效的场景统计/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-索引-索引失效的场景统计/","excerpt":"","text":"前言 通过上面章节我们知道通过索引可以很快速的找到我们想要的数据，但并不是说字段加了索引就能够发挥索引的好处，还跟索引的使用场景有关，但在有些场景下索引是不起作用的 统计 WHERE子句中对字段进行NULL值判断 在WHERE子句中使用!=或&lt;&gt;操作符 总结参考","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-索引-详细介绍","slug":"backend/database/mysql/Mysql-索引-详细介绍","date":"2018-03-02T16:05:02.000Z","updated":"2019-11-10T02:08:41.814Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-索引-详细介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-索引-详细介绍/","excerpt":"","text":"前言 MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，上一章节我们知道索引按照不同角度可以划分为不同的索引 解析一、从数据结构角度划分1、hash索引 只有memory（内存）存储引擎支持哈希索引，哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存放该值所在行数据的物理位置， 因为使用散列算法，计算一次就可以定位，不像B-Tree 索引需要从根节点到枝节点，因此访问速度非常快 但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能，Hash 索引仅仅能满足&quot;=&quot;,&quot;IN&quot;和&quot;&lt;=&gt;&quot;查询 2、FULLTEXT索引 在生成FULLTEXT索引时，会为文本生成一份单词的清单，在查找数据的时候会根据这个单词的清单来索引 现在MyISAM和InnoDB引擎都支持了 3、Spatial (R-Tree)（空间）索引 用于对GIS数据类型创建SPATIAL索引，只有MyISAM引擎支持，并且支持的不好。可以忽略。 4、BTree及B+Tree索引 B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，除了 Archive 存储引擎之外的其他所有的存储引擎都支持 B-Tree 索引。不仅仅在 MySQL 中是如此，实际上在其他的很多数据库管理系统中B-Tree 索引也同样是作为最主要的索引类型，这主要是因为B-Tree 索引的存储结构在数据库的数据检索中有非常优异的表现。 一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree ，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。 B+树是一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接。 在B+树上的常规检索，从根节点到叶子节点的搜索效率基本相当，不会出现大幅波动，而且基于索引的顺序扫描时，也可以利用双向指针快速左右移动，效率非常高。 二、从物理存储角度划分1、聚集索引（clustered index）2、非聚集索引（non-clustered index）解析索引的类型总结参考 http://www.iocoder.cn/ https://blog.csdn.net/tongdanping/article/details/79878302 https://blog.csdn.net/oChangWen/article/details/54024063 https://blog.csdn.net/endlu/article/details/51720299","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-索引-各种BTree类型","slug":"backend/database/mysql/Mysql-索引-各种BTree类型","date":"2018-03-02T16:05:01.000Z","updated":"2019-11-10T02:08:41.779Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-索引-各种BTree类型/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-索引-各种BTree类型/","excerpt":"","text":"前言 BTree是为了磁盘或其它存储设备而设计的一种数据结构，因为Mysql索引数据使用了此数据结构，BTree在网上搜索可以看到有各种类型，所以有必要对此进行归纳整理 目的 任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们需要这种数据结构能够做些什么？ 我们知道数据库的数据都是存放在电脑硬盘里面的，如果要提高查找速度，那么每次查找数据时把磁盘IO次数控制在一个很小的数量级，目的是在最少磁盘IO次数下能定位到数据 那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，BTree树应运而生。 总结一下目的就是在最少磁盘IO次数下能定位到数据，从而提高数据的查找定位速度 解析 BTree分为B-树、B+树、B*树几种类型，是不是开始晕了，下面将介绍这几种BTree 二叉树 介绍BTree之前先看下二叉树，BTree是在二叉树的演变下而诞生的 二叉树特性 (1)所有非叶子结点至多拥有两个儿子(Left和Right); (2)所有结点存储一个关键字 (3)非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树;(简单说，左边比自己小，右边比自己大) 从上图可以看到同样是二叉树，但结构不一样 左图是 平衡二叉树，平衡是指，它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树 右图是 普通二叉树 从二叉树的查找过程可以知道，如果要定位65这个数据的话，左图是 平衡二叉树 需要查找3次，右图是 普通二叉树 需要查找6次，所以最坏的情况下磁盘IO的次数由树的高度来决定。 从二叉树分析情况来看，减少磁盘IO的次数就必须要压缩树的高度，让瘦高的树尽量变成矮胖的树，所以B-Tree就在这样伟大的时代背景下诞生了。 数的高度计算如下图所示： B-树 （Balance Binary Tree)）多叉平衡树 –AVL树 上面的二叉树每个节点最多只能拥有2个子节点，而B-树的每个节点可以拥有2个以上的子节点 多叉是指B-树每个内结点有多个分支，即多叉，上图可以看到根节点有三个叉，P1指向小于17的数据，P2指向大于17小于35的数据，P3指向大于35的数据 特性： (1)根节点的左子树和右子树的深度最多相差1(确保了不会出现上图右边的极端现象) (2)根节点的左子树和右子树叶都是一棵平衡二叉树。 (3)所有结点都有存储关键字; 无论插入的序列是怎么样，我们都能通过调整构建一棵平衡二叉树，保证二叉树中的每个节点的平衡因子都不会大于1 多叉平衡树保证了树的深度达到最浅，从而比较的次数就会更少，时间复杂度就会降低 B+树 B+树的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中(B-树可以在非叶子结点命中) 特性： (1)所有关键字都出现在叶子结点的链表中(稠密索引)，且链表中的关键字恰好是有序的;(只有根节点存储关键字最后树的末梢才有值) (2)非叶子结点相当于是叶子结点的索引(稀疏索引)，叶子结点相当于是存储(关键字)数据的数据层。(非根节点，存储的其实是指向根节点的索引) (3) 因为前两点，所以不可能在非叶子结点存数据。(区别B-的第三条) (4)根节点横向也有链指针(方便快速顺藤摸瓜嘛，没这个指针，就算下一个取的值是挨着的邻居，也得跑个圈才能拿到) 注意，我们一般用到的索引结果，或者通常指的B-TREE结构，大部分就是在说B+结构啦~~ 如上图，是一颗b+树 浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示） 如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。 真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。 非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 来模拟下查找文件29的过程： (1) 根据根结点指针找到文件目录的根磁盘块1，将其中的信息导入内存。【磁盘IO操作1次】 (2) 此时内存中有两个文件名17，35和三个存储其他磁盘页面地址的数据。根据算法我们发现17&lt;29&lt;35，因此我们找到指针p2。 (3) 根据p2指针，我们定位到磁盘块3，并将其中的信息导入内存。【磁盘IO操作2次】 (4) 此时内存中有两个文件名26，30和三个存储其他磁盘页面地址的数据。根据算法我们发现26&lt;29&lt;30，因此我们找到指针p2。 (5) 根据p2指针，我们定位到磁盘块8，并将其中的信息导入内存。【磁盘IO操作3次】 (6) 此时内存中有两个文件名28，29。根据算法我们查找到文件29，并定位了该文件内存的磁盘地址。 上面我们知道使用b+树来查找文件29数据总计进行了三次IO，也就是说是大大减少了硬盘的工作量 3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的 如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高 通常在 B+Tree 上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对 B+Tree 进行两种查找运算： 一种是对于主键的范围查找和分页查找 另一种是从根节点开始，进行随机查找。 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 2~4 层。MySQL 的 InnoDB 存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要 1~3 次磁盘 I/O 操作。 ##### B*树 B*树 是B+树的变体， 特性 (1)B+树的非根和非叶子结点再增加指向兄弟的指针;(对比上边B+的第4条，在非根节点也添加横向链表) 总结 各种BTree树所有值（被索引的列）都是排过序的，为了查找更为方便快速，所以演化出了B-树、B+树、B*树 参考 https://blog.csdn.net/huxing998/article/details/77104731 http://www.iocoder.cn","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-索引-索引的使用","slug":"backend/database/mysql/Mysql-索引-索引的使用","date":"2018-03-02T16:05:00.000Z","updated":"2019-11-10T02:08:41.800Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-索引-索引的使用/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-索引-索引的使用/","excerpt":"","text":"前言使用索引的目的 索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？ 除了词典，生活中随处可见索引的例子，如坐火车的场景（比如你买了一张火车票，然后需要找到自己票的位置，那你是不是先看一下是在哪个车厢然后就是对号入座，这里的车厢就是索引，如果没有这个索引的话那你是不是要从头到尾在一节节车厢里找？）、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。 数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？ 我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。 但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。 但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。 解析索引的类型一、从逻辑角度划分 索引都是在存储引擎层实现的，主要有六种类型： 1、普通索引1create index index_name on tbl_name(index_col_name); 最基本的索引，没有任何约束。 2、唯一索引：1create unique index index_name on tbl_name(index_col_name,...); 唯一索引和单列索引类似，主要的区别在于，唯一索引限制列的值必须唯一，但允许有空值 对于多个字段，唯一索引规定列值的组合必须唯一。 与普通索引类似，但具有唯一性约束。 主键自动建立唯一索引 3、主键索引：1alter table tbl_name add primary key(index_col_name); 主键索引是一种特殊的唯一索引，不允许有空值 CREATE INDEX 不能创建主键索引，需要使用 ALTER TABLE 代替 特殊的唯一索引，不允许有空值。 4、复合索引：1create index index_name on tbl_name(index_col_name,...); 将多个列组合在一起创建索引，可以覆盖多个列。 复合索引遵守“最左前缀”原则，即在查询条件中使用了复合索引的第一个字段，索引才会被使用。因此，在复合索引中索引列的顺序至关重要。 5、外键索引： 只有InnoDB类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。 12 6、全文索引： 在一般情况下，模糊查询都是通过 like 的方式进行查询。但是，对于海量数据，这并不是一个好办法，在 like “value%” 可以使用索引，但是对于 like “%value%” 这样的方式，执行全表查询，这在数据量小的表，不存在性能问题，但是对于海量数据，全表扫描是非常可怕的事情,所以 like 进行模糊匹配性能很差。 这种情况下，需要考虑使用全文搜索的方式进行优化。全文搜索在 MySQL 中是一个 FULLTEXT 类型索引。 FULLTEXT 索引在 MySQL 5.6 版本之后支持 InnoDB，而之前的版本只支持 MyISAM 表。 示例 假设，有一张应用全文索引表。 12345CREATE TABLE IF NOT EXISTS `app_full_text` ( `app_id` bigint(20) NOT NULL, `app_name_full_text` text NOT NULL, `introduce_full_text` text NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8; 现在需要对应用的名称创建全文索引，可以这么设计。 1alter table `app_full_text` add fulltext key `app_name_intro` (`app_name_full_text`); 注意事项 全文索引只对英文有用，目前对中文还不支持。5.7版本之后通过使用ngram插件开始支持中文。 如果检索的字符串太短则无法检索得到预期的结果，检索的字符串长度至少为4字节 常用的全文索引引擎的解决方案有 Elasticsearch、Solr 等等。最为常用的是 Elasticsearch。 二、从数据结构角度划分1、B+树索引(O(log(n)))2、hash索引3、FULLTEXT索引（现在MyISAM和InnoDB引擎都支持了）4、R-Tree索引（用于对GIS数据类型创建SPATIAL索引）三、从物理存储角度划分1、聚集索引（clustered index）2、非聚集索引（non-clustered index）其他MySQL 索引的“使用”注意事项？ MySQL 索引通常是被用于提高 WHERE条件的数据行匹配时的搜索速度，在索引的使用过程中，存在一些使用细节和注意事项。 不要在列上使用函数和进行运算 不要在列上使用函数，这将导致索引失效而进行全表扫描。 示例：select * from news where year(publish_time) &lt; 2017 改造：select * from news where publish_time &lt; &#39;2017-01-01&#39; 不要在列上进行运算，这也将导致索引失效而进行全表扫描。 示例：select * from news where id / 100 = 1 改造：select * from news where id = 1 * 100 尽量避免使用 != 或 not in或 &lt;&gt; 等否定操作符 应该尽量避免在 where 子句中使用 != 或 not in 或 &lt;&gt; 操作符，因为这几个操作符都会导致索引失效而进行全表扫描。 尽量避免使用 or 来连接条件 应该尽量避免在 where 子句中使用 or来连接条件，因为这会导致索引失效而进行全表扫描。 示例：select * from news where id = 1 or id = 2 多个单列索引并不是最佳选择 MySQL 只能使用一个索引，会从多个索引中选择一个限制最为严格的索引，因此，为多个列创建单列索引，并不能提高 MySQL 的查询性能。 假设，有两个单列索引，分别为 news_year_idx(news_year) 和 news_month_idx(news_month)。现在，有一个场景需要针对资讯的年份和月份进行查询，那么，SQL 语句可以写成：select * from news where news_year = 2017 and news_month = 1 事实上，MySQL 只能使用一个单列索引。为了提高性能，可以使用复合索引 news_year_month_idx(news_year, news_month) 保证 news_year 和 news_month 两个列都被索引覆盖。 复合索引的最左前缀原则 复合索引遵守“最左前缀”原则，即在查询条件中使用了复合索引的第一个字段，索引才会被使用。因此，在复合索引中索引列的顺序至关重要。如果不是按照索引的最左列开始查找，则无法使用索引。 假设，有一个场景只需要针对资讯的月份进行查询，那么，SQL 语句可以写成：select * from news where news_month = 1 此时，无法使用 news_year_month_idx(news_year, news_month)索引，因为遵守“最左前缀”原则，在查询条件中没有使用复合索引的第一个字段，索引是不会被使用的。 什么是索引的最左匹配特性？ 当 B+Tree 的数据项是复合的数据结构，比如索引 (name, age, sex) 的时候，B+Tree 是按照从左到右的顺序来建立搜索树的。 比如当 (张三, 20, F)这样的数据来检索的时候，B+Tree 会优先比较name 来确定下一步的所搜方向，如果 name相同再依次比较 age 和 sex ，最后得到检索的数据。 但当 (20, F)这样的没有 name 的数据来的时候，B+Tree 就不知道下一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较因子，必须要先根据 name 来搜索才能知道下一步去哪里查询。 比如当 (张三, F) 这样的数据来检索时，B+Tree 可以用 name 来指定搜索方向，但下一个字段 age 的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是 F 的数据了。 这个是非常重要的性质，即索引的最左匹配特性。 覆盖索引的好处 范围查询对多列查询的影响 查询中的某个列有范围查询，则其右边所有列都无法使用索引优化查找。 举个例子，假设有一个场景需要查询本周发布的资讯文章，其中的条件是必须是启用状态，且发布时间在这周内 SQL 语句可以写成：select * from news where publish_time &gt;= &#39;2017-01-02&#39; and publish_time &lt;= &#39;2017-01-08&#39; and enable = 1 这种情况下，因为范围查询对多列查询的影响，将导致 news_publish_idx(publish_time, enable)索引中 publish_time 右边所有列都无法使用索引优化查找。换句话说，news_publish_idx(publish_time, enable)索引等价于 news_publish_idx(publish_time)。 索引不会包含有NULL值的列 只要列中包含有NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL值，那么这一列对于此复合索引就是无效的。 因此，在数据库设计时，除非有一个很特别的原因使用 NULL 值，不然尽量不要让字段的默认值为 NULL。 like 语句的索引失效问题 like 的方式进行查询，在 like “value%” 可以使用索引，但是对于 like “%value%” 这样的方式，执行全表查询，这在数据量小的表，不存在性能问题，但是对于海量数据，全表扫描是非常可怕的事情 根据业务需求，考虑使用 ElasticSearch或 Solr 是个不错的方案。 总结 索引（在MYSQL中也叫做键&lt;key&gt;），是存储引擎用于快速找到记录的一种数据结构。索引用来快速地寻找那些具有特定值的记录，所有MySQL索引都以B-树的形式保存。如果没有索引，执行查询时MySQL必须从第一个记录开始扫描整个表的所有记录，直至找到符合要求的记录。表里面的记录数量越多，这个操作的代价就越高。如果作为搜索条件的列上已经创建了索引，MySQL无需扫描任何记录即可迅速得到目标记录所在的位置。如果表有1000个记录，通过索引查找记录至少要比顺序扫描记录快100倍。 索引对查询的速度有着至关重要的影响，理解索引也是进行数据库性能调优的起点，很多时候，当你的应用程序进行SQL查询速度很慢时，应该想想是否可以建索引。 索引有什么好处 提高数据的检索速度，降低数据库IO成本 使用索引的意义就是通过缩小表中需要查询的记录的数目从而加快搜索的速度。 降低数据排序的成本，降低CPU消耗 索引之所以查的快，是因为先将数据排好序，若该字段正好需要排序，则正好降低了排序的成本。 索引有什么坏处 占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。 降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，从而减低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。 索引的使用场景 1、对非常小的表，大部分情况下全表扫描效率更高。 2、对中大型表，索引非常有效。 3、特大型的表，建立和使用索引的代价随着增长，可以使用分区技术来解决。 参考 https://tech.meituan.com/2014/06/30/mysql-index.html http://www.iocoder.cn/ http://blog.720ui.com/2017/mysql_core_03_how_use_index/ http://blog.720ui.com/2017/mysql_core_04_index_item/ https://www.cnblogs.com/duanxz/p/3799045.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-面试题","slug":"backend/database/mysql/Mysql-面试题","date":"2018-03-02T16:04:00.000Z","updated":"2019-11-10T02:08:41.820Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-面试题/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-面试题/","excerpt":"","text":"int(11) 中的 11 代表什么涵义？ int(11) 中的 11 ，不影响字段存储的范围，只影响展示效果 一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，再把 MySQL 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15？ 一般情况下，我们创建的表的类型是 InnoDB ，如果新增一条记录（不重启 MySQL 的情况下），这条记录的 ID 是18 ；但是如果重启 MySQL 的话，这条记录的 ID 是 15 。因为 InnoDB 表只把自增主键的最大 ID 记录到内存中，所以重启数据库或者对表 OPTIMIZE 操作，都会使最大 ID 丢失。 但是，如果我们使用表的类型是 MyISAM ，那么这条记录的 ID 就是 18 。因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里面，重启 MYSQL 后，自增主键的最大 ID 也不会丢失。最后，还可以跟面试官装个 x ，生产数据，不建议进行物理删除记录。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-主键id选用","slug":"backend/database/mysql/Mysql-主键id选用","date":"2018-03-02T16:04:00.000Z","updated":"2020-01-04T12:21:52.031Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-主键id选用/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-主键id选用/","excerpt":"","text":"前言 在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识，数据日渐增长，对数据分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求；特别一点的如订单、骑手、优惠券也都需要有唯一ID做标识。 此时一个能够生成全局唯一ID的系统是非常必要的。概括下来，那业务系统对ID号的要求有哪些呢？ 全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。 上述123对应三类不同的场景，3和4需求还是互斥的，无法使用同一个方案满足。 解析 查看资料发现有生成id 有下面这几种方式： 一、数据库自增id 数据库自增id分为两种形式 单表id字段设置整型，利用给字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用下列SQL读写MySQL得到ID号。 单独使用某张表来生成id，生成id的算法由程序生成，这样做成一个单独的id生成服务，实现高可用的话可以部署多台机器 优点： 非常简单，利用现有数据库系统的功能实现，成本小，有DBA专业维护。 ID号单调自增，可以实现一些对ID有特殊要求的业务。 缺点： 强依赖DB，当DB异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。 ID发号性能瓶颈限制在单台MySQL的读写性能。 二、UUID UUID是通用唯一识别码（Universally Unique Identifier)的缩写，开放软件基金会(OSF)规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素。利用这些元素来生成UUID。 标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，示例：550e8400-e29b-41d4-a716-446655440000，到目前为止业界一共有5种方式生成UUID，详情见IETF发布的UUID规范 优点： 性能非常高：本地生成，没有网络消耗。 缺点： 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用： MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求：All indexes other than the clustered index are known as secondary indexes. In InnoDB, each record in a secondary index contains the primary key columns for the row, as well as the columns specified for the secondary index. InnoDB uses this primary key value to search for the row in the clustered index.*** If the primary key is long, the secondary indexes use more space, so it is advantageous to have a short primary key 对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。 三、snowflake 雪花算法概述 这种方案大致来说是一种以划分命名空间（UUID也算，由于比较常见，所以单独分析）来生成ID的一种算法，这种方案把64-bit分别划分成多段，把时间戳，工作机器id，序列号信息组合成唯一，比如在snowflake中的64-bit分别表示如下图（图片来自网络）所示： 1bit:一般是符号位，不做处理 41bit:用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。 10bit:10bit用来记录机器ID，总共可以记录1024台机器，一般用前5位代表数据中心，后面5位是某个数据中心的机器ID 12bit:循环位，用来对同一个毫秒之内产生不同的ID，12位可以最多记录4095个，也就是在同一个机器同一毫秒最多记录4095个，多余的需要进行等待下毫秒。 优点： 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 整个分布式系统内不会产生重复id（因为有datacenterId和workerId来做区分） 可以根据自身业务特性分配bit位，非常灵活。 缺点： 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。 四、利用 redis 生成 id 熟悉Redis的同学，应该知道在Redis中有两个命令Incr，IncrBy,因为Redis是单线程的所以能保证原子性。 优点： 性能比较好，灵活方便，不依赖于数据库 缺点： 由于redis是内存的KV数据库，即使有AOF和RDB，但是依然会存在数据丢失，有可能会造成ID重复。 但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。 五、美团的Leaf分布式ID生成系统 Leaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件 这个方案是将数据库主键自增进行优化。官方介绍： https://tech.meituan.com/2019/03/07/open-source-project-leaf.html) https://github.com/Meituan-Dianping/Leaf/blob/master/README_CN.md Github 总结参考 https://tech.meituan.com/2017/04/21/mt-leaf.html https://juejin.im/post/5bb0217ef265da0ac2567b42","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-如何设置字段自动获取当前时间","slug":"backend/database/mysql/Mysql-如何设置字段自动获取当前时间","date":"2018-03-02T16:04:00.000Z","updated":"2019-11-10T02:08:41.672Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-如何设置字段自动获取当前时间/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-如何设置字段自动获取当前时间/","excerpt":"","text":"应用场景： 1231、在数据表中，要记录每条数据是什么时候创建的，不需要应用程序去特意记录，而由数据数据库获取当前时间自动记录创建时间；2、在数据库中，要记录每条数据是什么时候修改的，不需要应用程序去特意记录，而由数据数据库获取当前时间自动记录修改时间； 实现方式: 123456789--修改CreateTime 设置默认时间 CURRENT_TIMESTAMP ALTER TABLE `table_name`MODIFY COLUMN `created_date` datetime NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间' ;--修改 UpdateTime 设置 默认时间 CURRENT_TIMESTAMP 设置更新时间为 ON UPDATE CURRENT_TIMESTAMP ALTER TABLE `table_name`MODIFY COLUMN `last_modified_date` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间' ; 转自：https://www.cnblogs.com/lhj588/p/4245719.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-在SELECT的读取锁定主要分为两种方式","slug":"backend/database/mysql/Mysql-在SELECT的读取锁定主要分为两种方式","date":"2018-03-02T16:04:00.000Z","updated":"2019-11-10T02:08:41.638Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-在SELECT的读取锁定主要分为两种方式/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-在SELECT的读取锁定主要分为两种方式/","excerpt":"","text":"在SELECT 的读取锁定主要分为两种方式： SELECT … LOCK IN SHARE MODE SELECT … FOR UPDATE 这两种方式在事务(Transaction) 进行当中SELECT 到同一个数据表时，都必须等待其它事务数据被提交(Commit)后才会执行。 而主要的不同在于LOCK IN SHARE MODE 在有一方事务要Update 同一个表单时很容易造成死锁。 简单的说，如果SELECT 后面若要UPDATE 同一个表单，最好使用SELECT … UPDATE。 悲观锁介绍 悲观锁是对数据被的修改持悲观态度（认为数据在被修改的时候一定会存在并发问题），因此在整个数据处理过程中将数据锁定。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在应用层中实现了加锁机制，也无法保证外部系统不会修改数据）。 使用场景举例商品goods表中有一个字段status，status为1代表商品未被下单，status为2代表商品已经被下单，那么我们对某个商品下单时必须确保该商品status为1。假设商品的id为1。如果不采用锁，那么操作方法如下：123456//1.查询出商品信息select status from t_goods where id=1;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_goods set status=2; 上面这种场景在高并发访问的情况下很可能会出现问题。前面已经提到，只有当goods status为1时才能对该商品下单，上面第一步操作中，查询出来的商品status为1。但是当我们执行第三步Update操作的时候，有可能出现其他人先一步对商品下单把goods status修改为2了，但是我们并不知道数据已经被修改了，这样就可能造成同一个商品被下单2次，使得数据不一致。所以说这种方式是不安全的。 使用悲观锁来实现在上面的场景中，商品信息从查询出来到修改，中间有一个处理订单的过程，使用悲观锁的原理就是，当我们在查询出goods信息后就把当前的数据锁定，直到我们修改完毕后再解锁。那么在这个过程中，因为goods被锁定了，就不会出现有第三者来对其进行修改了。要使用悲观锁，我们必须关闭mysql数据库的自动提交属性。 123456789101112set autocommit=0; //设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：//0.开始事务begin;/begin work;/start transaction; (三者选一就可以)//1.查询出商品信息select status from t_goods where id=1 for update;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_goods set status=2;//4.提交事务commit;/commit work; 注：上面的begin/commit为事务的开始和结束，因为在前一步我们关闭了mysql的autocommit，所以需要手动控制事务的提交，在这里就不细表了。 上面的第一步我们执行了一次查询操作：select status from t_goods where id=1 for update;与普通查询不一样的是，我们使用了select…for update的方式，这样就通过数据库实现了悲观锁。此时在t_goods表中，id为1的那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。 注：需要注意的是，在事务中，只有SELECT … FOR UPDATE 或LOCK IN SHARE MODE 相同数据时会等待其它事务结束后才执行，一般SELECT … 则不受此影响。拿上面的实例来说，当我执行select status from t_goods where id=1 for update;后。我在另外的事务中如果再次执行select status from t_goods where id=1 for update;则第二个事务会一直等待第一个事务的提交，此时第二个查询处于阻塞的状态，但是如果我是在第二个事务中执行select status from t_goods where id=1;则能正常查询出数据，不会受第一个事务的影响。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-数据库三大范式","slug":"backend/database/mysql/Mysql-数据库三大范式","date":"2018-03-02T16:04:00.000Z","updated":"2019-11-10T02:08:41.773Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-数据库三大范式/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-数据库三大范式/","excerpt":"","text":"前言 数据库范式是为解决关系数据库中数据冗余、更新异常、插入异常、删除异常问题而引入的。简单的理解，数据库范式可以避免数据冗余，减少数据库的空间，并且减轻维护数据完整性的麻烦。 解析第一范式（1NF） 第一范式，强调属性的原子性约束，要求属性具有原子性，不可再分解。 举个例子，活动表（活动编码，活动名称，活动地址），假设这个场景中，活动地址可以细分为国家、省份、城市、市区、位置，那么就没有达到第一范式。 第二范式（2NF） 第二范式是指在满足第一范式的情况下，关系表R中的所有非主属性都完全依赖于R的每一个候选关键属性 这句话怎么理解呢，举个栗子： 假如有一个学生课程表student_course(学号, 姓名, 课程名称, 成绩, 学分)，关键字为组合关键字(学号, 课程名称)，因为只有这两个属性一起才能决定一条记录，即(学号, 课程名称) → (姓名, 成绩, 学分) ，这个关系表便不符合第二范式，因为”姓名”仅依赖于”学号”，”学分”仅依赖于”课程名”，因此，不满足第二范式条件。 那么，不满足第二范式会有什么问题呢？如下： 数据冗余 对于一门课程，如果有n名学生选修，则这门课程的全部信息将会重复存储n-1次，同理，一个学生选修了m门课程，则学生全部信息会重复存储m-1次，导致数据冗余存储。 更新问题 如果要更新某门课程的学分，那么所有关联这门课程的记录都将更新，否则会出现数据不一致问题。 插入问题 假如新增一门课程，但是尚未有学生选修，则该门课程的信息无法入库。 删除问题 假如某门课程对应的记录完全被删除，则将导致这门课程的信息完全丢失。 * 那我们可以按照第二范式来改造上述关系表，将表才分成student(学号，姓名)，cource(课程名称，学分)，student_cource(学号， 课程名称， 成绩)，这样便避免了上述问题。 第三范式（3NF） 第三范式是指，在满足第二范式的前提下，关系表R中的所有非主属性由主键直接决定，不存在间接依赖关系，简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。 这句话怎么理解呢，举个栗子： 如表emp(id，name，age，dept_id，dept_name，dept_detail)，这张表中的员工id能够决定所有非主属性，但我们发现dept_name，dept_detail这两个非主属性也可以由非主属性dept_id决定，而dept_id又依赖于id，因此存在间接传递依赖，不满足第三范式。 同时，可以看出，不满足第三范式的问题是存在大量的冗余数据，解决该问题的方式很简单，只需将原关系表拆分为emp(id，name，age， dept_id)， dept(dept_id，dept_name, dept_detail)，这样不管是对于表emp还是表dept，各自的非主属性都直接依赖于主键，满足第三范式，同时也解决了数据冗余的问题。 反模式总结 第二范式的侧重点是非主键列是否完全依赖于主键，还是依赖于主键的一部分。第三范式的侧重点是非主键列是直接依赖于主键，还是间接依赖主键，三大范式可以这么记 第一范式不可拆 第二范式非主键列完全依赖主键 第三范式非主键列直接依赖主键 三大范式只是一般设计数据库的基本理念，可以建立冗余较小、结构合理的数据库。如果有特殊情况，当然要特殊对待，数据库设计最重要的是看需求跟性能，需求&gt;性能&gt;表结构。所以不能一味的去追求范式建立数据库。 然而，通过数据库范式化设计，将导致数据库业务涉及的表变多，并且可能需要将涉及的业务表进行多表连接查询，这样将导致性能变差，且不利于分库分表。因此，出于性能优先的考量，可能在数据库的结构中需要使用反模式的设计，即空间换取时间，采取数据冗余的方式避免表之间的关联查询。至于数据一致性问题，因为难以满足数据强一致性，一般情况下，使存储数据尽可能达到用户一致，保证系统经过一段较短的时间的自我恢复和修正，数据最终达到一致。 参考 https://www.cnblogs.com/knowledgesea/p/3667395.html http://blog.720ui.com/2017/mysql_core_07_anti-pattern/","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-存储引擎","slug":"backend/database/mysql/Mysql-存储引擎","date":"2018-03-02T16:04:00.000Z","updated":"2019-11-10T02:08:41.755Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-存储引擎/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-存储引擎/","excerpt":"","text":"前言 数据库管理系统就是操作数据，包括增删改查，那么具体执行这些操作的是数据库的存储引擎，不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySQL的核心就是存储引擎。 解析存储引擎查看 MySQL给开发者提供了查询存储引擎的功能，执行SHOW ENGINES语句可以得到以下结果 Support列的值表示某种引擎是否能使用：YES表示可以使用、NO表示不能使用、DEFAULT表示该引擎为当前默认的存储引擎 在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。 四种存储引擎 下面来看一下其中几种常用的引擎。 InnoDB存储引擎 InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： 1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的 3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 5、InnoDB被用在众多需要高性能的大型数据库站点上 InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 MyISAM存储引擎 MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有： 1、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持 2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成 3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16 4、最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上 5、BLOB和TEXT列可以被索引 6、NULL被允许在索引的列中，这个值占每个键的0~1个字节 7、所有数字键值以高字节优先被存储以允许一个更高的索引压缩 8、每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快 9、可以把数据文件和索引文件放在不同目录 10、每个字符列可以有不同的字符集 11、有VARCHAR的表可以固定或动态记录长度 12、VARCHAR和CHAR列可以多达64KB 使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex） MEMORY存储引擎 MEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有： 1、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度 2、MEMORY存储引擎执行HASH和BTREE缩影 3、可以在一个MEMORY表中有非唯一键值 4、MEMORY表使用一个固定的记录长度格式 5、MEMORY不支持BLOB或TEXT列 6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引 7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表） 8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享 9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） Archive存储引擎 Archive存储引擎置只支持INSERT和SELECT操作，支持行锁，但本身并不是事务安全的存储引擎，其最大的优点是其具有较好的压缩比，压缩比一般可达到1:10，可以将同样的数据以更小的磁盘空间占用来存储。 Archive存储引擎非常适合存储归档数据，如历史数据、日志信息数据等等，这类数据往往数据量非常大，并且基本只有INSERT和SELECT操作，使用这个存储引擎可以非常节约磁盘空间。 存储引擎的选择 不同的存储引擎都有各自的特点，以适应不同的需求，如下表所示： 功 能 MYISAM Memory InnoDB Archive 存储限制 256TB RAM 64TB None 支持事物 No No Yes No 支持全文索引 Yes No No No 支持数索引 Yes Yes Yes No 支持哈希索引 No Yes No No 支持数据缓存 No N/A Yes No 支持外键 No No Yes No 其他 目前，MySQL 默认的存储引擎是 InnoDB ，并且也是最主流的选择，在 MySQL5.1 以及之前的版本，默认的存储引擎是 MyISAM ，但是目前已经不再更新 总结 使用哪一种引擎需要灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 InnoDB： 如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，是一个好的选择 优点： 支持事务管理，崩溃修复能力和并发控制，支持自动增长列，支持外键； 缺点： 读写效率较差，占用数据空间大； 应用场景：适合于对事务完整性要求高，要求并发控制，需要频繁更新，删除等操作的数据库； MyISAM 如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率 优点： 占用空间小，处理速度快； 缺点： 不支持事务的完整性和并发性； 应用场景：适用于表主要用于插入新纪录和读出记录，对应用完整性和并发性要求低； 在 MySQL5.1 以及之前的版本，默认的存储引擎是 MyISAM ，但是目前已经不再更新 Memory 使用Memory存储引擎的出发点是速度，为得到最快的响应时间，采用的逻辑存储介质是系统内存，虽然在内存中存储表数据确实会提供很高的性能，但当mysqld守护进程崩溃时，所有的Memory数据都会丢失 如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果 优点： 处理速度快； 缺点： 数据易丢失，生命周期短； 应用场景： 适用于读写速度快，对数据安全性要求低，使用相对较小的数据库表； Archive 如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。 应用场景：Archive非常适合存储归档数据，如记录日志信息可以使用Archive 参考: https://blog.csdn.net/jygqm/article/details/82903517","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-字符集和排序规则说明","slug":"backend/database/mysql/Mysql-字符集和排序规则说明","date":"2018-03-02T16:04:00.000Z","updated":"2020-01-04T12:21:52.042Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-字符集和排序规则说明/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-字符集和排序规则说明/","excerpt":"","text":"字符集utf8mb4 和 utf8 比较utf8是使用1~4个字节，一种变长的编码格式。（字符编码 ） mb4即 most bytes 4，使用4个字节来表示完整的UTF-8。而MySQL中的utf8是utfmb3，只有三个字节，节省空间但不能表达全部的UTF-8，只能支持“基本多文种平面”（Basic Multilingual Plane，BMP）。 那上面说了既然utf8能够存下大部分中文汉字,那为什么还要使用utf8mb4呢? 原来mysql支持的 utf8 编码最大字符长度为 3 字节，如果遇到 4 字节的宽字符就会插入异常了。三个字节的 UTF-8 最大能编码的 Unicode 字符是 0xffff，也就是 Unicode 中的基本多文种平面(BMP)。也就是说，任何不在基本多文本平面的 Unicode字符，都无法使用 Mysql 的 utf8 字符集存储。包括 Emoji 表情(Emoji 是一种特殊的 Unicode 编码，常见于 ios 和 android 手机上)，和很多不常用的汉字，以及任何新增的 Unicode 字符等等(utf8的缺点)。 推荐使用utf8mb4。 排序规则ci 是 case insensitive, 即 “大小写不敏感”, a 和 A 会在字符判断中会被当做一样的。 bin 是二进制, a 和 A 会别区别对待。 例如你运行如下sql, 那么在utf8_bin中你就找不到 txt = ‘A’ 的那一行, 而 utf8_general_ci 则可以。1SELECT * FROM table WHERE txt = 'a'; 常用排序规则 utf8_general_ci：不区分大小写，这个你在注册用户名和邮箱的时候就要使用。 utf8_general_cs：区分大小写，如果用户名和邮箱用这个 就会照成不良后果。 utf8_bin：字符串每个字符串用二进制数据编译存储。 区分大小写，而且可以存二进制的内容。 总结 utf8_unicode_ci和utf8_general_ci对中、英文来说没有实质的差别。 utf8_general_ci：校对速度快，但准确度稍差。 utf8_unicode_ci：准确度高，但校对速度稍慢。 如果你的应用有德语、法语或者俄语，请一定使用utf8_unicode_ci。一般用utf8_general_ci就够了，到现在也没发现问题。 参考:https://www.cnblogs.com/zwakeup/p/8267204.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-数据类型","slug":"backend/database/mysql/Mysql-数据类型","date":"2018-03-02T16:03:00.000Z","updated":"2019-11-10T02:08:41.775Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-数据类型/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-数据类型/","excerpt":"前言MySQL中定义数据字段的类型对你数据库的优化是非常重要的。 MySQL支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。","text":"前言MySQL中定义数据字段的类型对你数据库的优化是非常重要的。 MySQL支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。 数值类型MySQL支持所有标准SQL数值数据类型。 这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)，以及近似数值数据类型(FLOAT、REAL和DOUBLE PRECISION)。 关键字INT是INTEGER的同义词，关键字DEC是DECIMAL的同义词。 BIT数据类型保存位字段值，并且支持MyISAM、MEMORY、InnoDB和BDB表。 作为SQL标准的扩展，MySQL也支持整数类型TINYINT、MEDIUMINT和BIGINT。下面的表显示了需要的每个整数类型的存储和范围。 logo 备注:1.BIT[M] 位字段类型，M表示每个值的位数，范围从1到64，如果M被忽略，默认为1 2.TINYINT[(M)] [UNSIGNED] [ZEROFILL] M默认为4,占1个字节 很小的整数。带符号的范围是-128到127。无符号的范围是0到255。 BOOL，BOOLEAN 是TINYINT(1)的同义词。zero值被视为假。非zero值视为真。 4.SMALLINT[(M)] [UNSIGNED] [ZEROFILL] M默认为6,占2个字节 小的整数。带符号的范围是-32768到32767。无符号的范围是0到65535。 5.MEDIUMINT[(M)] [UNSIGNED] [ZEROFILL] M默认为9,占3个字节 中等大小的整数。带符号的范围是-8388608到8388607。无符号的范围是0到16777215。 INT[(M)] [UNSIGNED] [ZEROFILL] M默认为11,占4个字节 普通大小的整数。带符号的范围是-2147483648到2147483647。无符号的范围是0到4294967295。 7.BIGINT[(M)] [UNSIGNED] [ZEROFILL] M默认为20,占8个字节 大整数。带符号的范围是-9223372036854775808到9223372036854775807。无符号的范围是0到18446744073709551615。 注意：这里的M代表的并不是存储在数据库中的具体的长度，以前总是会误以为int(3)只能存储3个长度的数字，int(11)就会存储11个长度的数字，这是大错特错的。 tinyint(1) 和 tinyint(4) 中的1和4并不表示存储长度，只有字段指定zerofill是有用，如tinyint(4)，如果实际值是2，如果列指定了zerofill，查询结果就是0002，左边用0来填充。 日期和时间类型表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。 每个时间类型有一个有效值范围和一个”零”值，当指定不合法的MySQL不能表示的值时使用”零”值。 TIMESTAMP类型有专有的自动更新特性 logo 字符串类型字符串类型指CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM和SET。该节描述了这些类型如何工作以及如何在查询中使用这些类型 logo","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"Mysql-用户及权限管理","slug":"backend/database/mysql/Mysql-用户及权限管理","date":"2018-03-02T16:02:00.000Z","updated":"2019-11-10T02:08:41.777Z","comments":true,"path":"2018/03/03/backend/database/mysql/Mysql-用户及权限管理/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/mysql/Mysql-用户及权限管理/","excerpt":"权限控制授权语法：1234567891011121314151617181920GRANT privileges (columns) ON what TO user IDENTIFIED BY \"password\" WITH GRANT OPTION权限列表:ALTER: 修改表和索引。CREATE: 创建数据库和表。DELETE: 删除表中已有的记录。DROP: 抛弃(删除)数据库和表。INDEX: 创建或抛弃索引。INSERT: 向表中插入新行。REFERENCE: 未用。SELECT: 检索表中的记录。UPDATE: 修改现存表记录。FILE: 读或写服务器上的文件。PROCESS: 查看服务器中执行的线程信息或杀死线程。RELOAD: 重载授权表或清空日志、主机缓存或表缓存。SHUTDOWN: 关闭服务器。ALL: 所有权限，ALL PRIVILEGES同义词。USAGE: 特殊的 \"无权限\" 权限。用 户账户包括 \"username\" 和 \"host\" 两部分，后者表示该用户被允许从何地接入。tom@'%' 表示任何地址，默认可以省略。还可以是 \"tom@192.168.1.%\"、\"tom@%.abc.com\" 等。数据库格式为 db@table，可以是 \"test.*\" 或 \"*.*\"，前者表示 test 数据库的所有表，后者表示所有数据库的所有表。子句 \"WITH GRANT OPTION\" 表示该用户可以为其他用户分配权限。","text":"权限控制授权语法：1234567891011121314151617181920GRANT privileges (columns) ON what TO user IDENTIFIED BY \"password\" WITH GRANT OPTION权限列表:ALTER: 修改表和索引。CREATE: 创建数据库和表。DELETE: 删除表中已有的记录。DROP: 抛弃(删除)数据库和表。INDEX: 创建或抛弃索引。INSERT: 向表中插入新行。REFERENCE: 未用。SELECT: 检索表中的记录。UPDATE: 修改现存表记录。FILE: 读或写服务器上的文件。PROCESS: 查看服务器中执行的线程信息或杀死线程。RELOAD: 重载授权表或清空日志、主机缓存或表缓存。SHUTDOWN: 关闭服务器。ALL: 所有权限，ALL PRIVILEGES同义词。USAGE: 特殊的 \"无权限\" 权限。用 户账户包括 \"username\" 和 \"host\" 两部分，后者表示该用户被允许从何地接入。tom@'%' 表示任何地址，默认可以省略。还可以是 \"tom@192.168.1.%\"、\"tom@%.abc.com\" 等。数据库格式为 db@table，可以是 \"test.*\" 或 \"*.*\"，前者表示 test 数据库的所有表，后者表示所有数据库的所有表。子句 \"WITH GRANT OPTION\" 表示该用户可以为其他用户分配权限。 实例： 12345678910111213141516171819202122use mysql1. 新建用户, 并赋予所有数据库权限 GRANT ALL PRIVILEGES ON *.* TO 'username'@'host' IDENTIFIED BY 'password' WITH GRANT OPTION; 说明: 1. username - 你将创建的用户名, host - 指定该用户在哪个主机上可以登陆,如果是本地用户可用localhost, 如果想让该用户可以从任意远程主机登陆,可以使用通配符%. password - 该用户的登陆密码,密码可以为空,如果为空则该用户可以不需要密码登陆服务器. 2. 指定helloworld数据库: GRANT ALL PRIVILEGES ON helloword.* TO 'username'@'host' IDENTIFIED BY 'password' WITH GRANT OPTION;2. 指定该用户只能执行 select 和 update 命令 GRANT SELECT, UPDATE ON *.* TO 'username'@'%' IDENTIFIED BY 'password';3. 另外每当调整权限后，通常需要执行以下语句刷新权限： FLUSH PRIVILEGES;4. grant 普通数据用户，查询、插入、更新、删除 数据库中所有表数据的权利。 grant select on testdb.* to common_user@’%’ grant insert on testdb.* to common_user@’%’ grant update on testdb.* to common_user@’%’ grant delete on testdb.* to common_user@’%’ 或者，用一条 MySQL 命令来替代： grant select, insert, update, delete on testdb.* to common_user@’%’ 用户12345678910111213141516171819202122232425262728293031323334351. 删除刚才创建的用户： DROP USER username@localhost;2. 查看用户创建是否成功 select user,host from user ; +-----------+-----------+ | user | host | +-----------+-----------+ | root | % | | select | % | | server | % | | shuiyang | % | | user | % | | mysql.sys | localhost | +-----------+-----------+ 3. 查看select用户的授权 show grants for select; MySQL [mysql]&gt; show grants for `select`; +---------------------------------------------+ | Grants for select@% | +---------------------------------------------+ | GRANT SELECT, UPDATE ON *.* TO 'select'@'%' | +---------------------------------------------+ 1 row in set (0.00 sec) 4. 设置与更改用户密码SET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword')如果是当前登陆用户用SET PASSWORD = PASSWORD(\"newpassword\");","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/tags/数据库/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.songshuiyang.com/tags/Mysql/"}]},{"title":"分布式-Dubbo-概念介绍","slug":"backend/distributed/dobbo/分布式-Dubbo-概念介绍","date":"2018-03-02T16:00:03.000Z","updated":"2020-01-04T12:21:52.073Z","comments":true,"path":"2018/03/03/backend/distributed/dobbo/分布式-Dubbo-概念介绍/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/distributed/dobbo/分布式-Dubbo-概念介绍/","excerpt":"","text":"概念一、重要的概念1.1 什么是 Dubbo? Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。简单来说 Dubbo 是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。 Dubbo 目前已经有接近 23k 的 Star ，Dubbo的Github 地址：https://github.com/apache/incubator-dubbo 。 另外，在开源中国举行的2018年度最受欢迎中国开源软件这个活动的评选中，Dubbo 更是凭借其超高人气仅次于 vue.js 和 ECharts 获得第三名的好成绩。 Dubbo 是由阿里开源，后来加入了 Apache 。正式由于 Dubbo 的出现，才使得越来越多的公司开始使用以及接受分布式架构。 我们上面说了 Dubbo 实际上是 RPC 框架 总结参考 https://snailclimb.gitee.io/javaguide/#/docs/system-design/data-communication/dubbo","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"Druid Monitor","slug":"backend/database/Druid Monitor","date":"2018-03-02T16:00:00.000Z","updated":"2019-11-10T02:08:41.589Z","comments":true,"path":"2018/03/03/backend/database/Druid Monitor/","link":"","permalink":"http://www.songshuiyang.com/2018/03/03/backend/database/Druid Monitor/","excerpt":"","text":"Druid Monitor监控JavaSE和JavaWeb效果图: logo http://blog.csdn.net/binglovezi/article/details/50610269","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.songshuiyang.com/categories/数据库/"}],"tags":[{"name":"druid","slug":"druid","permalink":"http://www.songshuiyang.com/tags/druid/"}]},{"title":"分布式-Zookeeper-基本命令","slug":"backend/distributed/zookeeper/分布式-Zookeeper-基本命令","date":"2018-03-01T16:00:05.000Z","updated":"2020-01-04T12:21:52.089Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-基本命令/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-基本命令/","excerpt":"","text":"前言 连接 ZooKeeper 服务 可以看出控制台打印出了很多信息，包括我们的主机名称、JDK 版本、操作系统等等。如果你成功看到这些信息，说明你成功连接到 ZooKeeper 服务。 12345678910111213141516171819202122D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin&gt;zkCli.cmd -server 127.0.0.1:2181Connecting to 127.0.0.1:21812019-12-27 11:13:26,167 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT2019-12-27 11:13:26,170 [myid:] - INFO [main:Environment@100] - Client environment:host.name=DESKTOP-DT6DIHG2019-12-27 11:13:26,171 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_1812019-12-27 11:13:26,171 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation2019-12-27 11:13:26,171 [myid:] - INFO [main:Environment@100] - Client environment:java.home=C:\\Program Files\\Java\\jre1.8.0_1812019-12-27 11:13:26,171 [myid:] - INFO [main:Environment@100] - Client environment:java.class.path=D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\build\\classes;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\build\\lib\\*;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\zookeeper-3.4.5.jar;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\lib\\jline-0.9.94.jar;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\lib\\log4j-1.2.15.jar;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\lib\\netty-3.2.2.Final.jar;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\lib\\slf4j-api-1.6.1.jar;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\lib\\slf4j-log4j12-1.6.1.jar;D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin\\..\\conf2019-12-27 11:13:26,172 [myid:] - INFO [main:Environment@100] - Client environment:java.library.path=C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\WINDOWS\\Sun\\Java\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;\"C:\\Program Files\\Java\\jdk1.8.0_181\\bin;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\bin;\";C:\\Program Files\\Git\\cmd;C:\\Program Files\\MySQL\\MySQL Utilities 1.6\\;D:\\soft\\consul_1.2.2_windows_amd64;C:\\Program Files\\erl10.1\\bin;%RABBITMQ_HOME%\\sbin;C:\\Program Files\\010 Editor;C:\\Program Files\\nodejs\\;D:\\Downloads\\rocketmq-all-4.5.2-bin-release;C:\\Users\\songsy\\AppData\\Local\\Microsoft\\WindowsApps;;C:\\Users\\songsy\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\songsy\\AppData\\Roaming\\npm;.2019-12-27 11:13:26,172 [myid:] - INFO [main:Environment@100] - Client environment:java.io.tmpdir=C:\\Users\\songsy\\AppData\\Local\\Temp\\2019-12-27 11:13:26,173 [myid:] - INFO [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;2019-12-27 11:13:26,173 [myid:] - INFO [main:Environment@100] - Client environment:os.name=Windows 102019-12-27 11:13:26,174 [myid:] - INFO [main:Environment@100] - Client environment:os.arch=amd642019-12-27 11:13:26,174 [myid:] - INFO [main:Environment@100] - Client environment:os.version=10.02019-12-27 11:13:26,174 [myid:] - INFO [main:Environment@100] - Client environment:user.name=songsy2019-12-27 11:13:26,175 [myid:] - INFO [main:Environment@100] - Client environment:user.home=C:\\Users\\songsy2019-12-27 11:13:26,175 [myid:] - INFO [main:Environment@100] - Client environment:user.dir=D:\\Downloads\\Downloads\\zookeeper-3.4.5\\zookeeper-3.4.5\\bin2019-12-27 11:13:26,177 [myid:] - INFO [main:ZooKeeper@438] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@579bb367Welcome to ZooKeeper!2019-12-27 11:13:26,421 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@966] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)2019-12-27 11:13:26,425 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@849] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating sessionJLine support is enabled help 命令查看 zookeeper 常用命令 1234567891011121314151617181920212223[zk: 127.0.0.1:2181(CONNECTED) 31] helpZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port 创建节点(create 命令) 12[zk: 127.0.0.1:2181(CONNECTED) 37] create /name \"songsy\"Created /name 获取节点的数据(get 命令) get 命令可以获取指定节点的数据内容和节点的状态 12345678910111213[zk: 127.0.0.1:2181(CONNECTED) 38] get /name\"songsy\"cZxid = 0x10fctime = Fri Dec 27 14:38:20 CST 2019mZxid = 0x10fmtime = Fri Dec 27 14:38:20 CST 2019pZxid = 0x10fcversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 8numChildren = 0 更新节点数据内容(set 命令) 12345678910111213141516171819202122232425[zk: 127.0.0.1:2181(CONNECTED) 39] set /name \"songshuiyang\"cZxid = 0x10fctime = Fri Dec 27 14:38:20 CST 2019mZxid = 0x110mtime = Fri Dec 27 14:40:19 CST 2019pZxid = 0x10fcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 14numChildren = 0[zk: 127.0.0.1:2181(CONNECTED) 40] get /name\"songshuiyang\"cZxid = 0x10fctime = Fri Dec 27 14:38:20 CST 2019mZxid = 0x110mtime = Fri Dec 27 14:40:19 CST 2019pZxid = 0x10fcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 14numChildren = 0 查看某个目录下的子节点(ls 命令) zookeeper 中的 ls 命令和 linux 命令中的 ls 类似， 这个命令将列出绝对路径path下的所有子节点信息（列出1级，并不递归） 12[zk: 127.0.0.1:2181(CONNECTED) 42] ls /[name, dubbo, zookeeper, node1] 查看节点状态(stat 命令) 123456789101112[zk: 127.0.0.1:2181(CONNECTED) 43] stat /namecZxid = 0x10fctime = Fri Dec 27 14:38:20 CST 2019mZxid = 0x110mtime = Fri Dec 27 14:40:19 CST 2019pZxid = 0x10fcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 14numChildren = 0 删除节点(delete 命令) 这个命令很简单，但是需要注意的一点是如果你要删除某一个节点，那么这个节点必须无子节点才行。 1[zk: 127.0.0.1:2181(CONNECTED) 45] delete /name Zookeeper 的 Java 客户端都有哪些？ Zookeeper 自带的 zkclient Apache 开源的 Curator 参考 https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper数据模型和常见命令?id=查看常用命令help-命令","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-Zookeeper-Session会话","slug":"backend/distributed/zookeeper/分布式-Zookeeper-Session会话","date":"2018-03-01T16:00:05.000Z","updated":"2020-01-04T12:21:52.081Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-Session会话/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-Session会话/","excerpt":"","text":"前言 Zookeeper既然是服务提供者，那必然需要与客户端进行通信，那么Session 指的是 ZooKeeper 服务器与客户端会话 解析 在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。 客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。 通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。 在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。 总结参考","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-Zookeeper-工作原理","slug":"backend/distributed/zookeeper/分布式-Zookeeper-工作原理","date":"2018-03-01T16:00:04.000Z","updated":"2020-01-04T12:21:52.094Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-工作原理/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-工作原理/","excerpt":"","text":"前言底层实现 ZooKeeper 底层其实只提供了两个功能： ①管理（存储、读取）用户程序提交的数据； ②为用户程序提供数据节点监听通知服务。 所以Zookeeper的工作原理基本上是围绕这两块来实现的 高性能原理 ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。 ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） 集群工作原理 ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。 ZooKeeper 的核心是原子广播（上面章节提到的请求会同时发给其他 Zookeeper 机器并且达成一致后，请求才会返回成功），这个机制保证了各个 Server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分别是 恢复模式（选主） 广播模式（同步） 恢复模式（选主） 当整个 Zookeeper 集群刚刚启动，或者 Leader 服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader服务器保持正常通信时，所有进程（服务器）进入崩溃恢复模式。 首先，选举产生新的Leader服务器。 然后，集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。 当集群中超过半数机器与该Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式， 广播模式（同步） 状态同步保证了 Leader 和 Server 具有相同的系统状态，Leader 服务器开始接收客户端的事务请求，生成事务提案来进行事务请求处理。 参考 芋道源码 http://www.iocoder.cn https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper?id=_22-会话（session）","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-Zookeeper-Leader选举过程","slug":"backend/distributed/zookeeper/分布式-Zookeeper-Leader选举过程","date":"2018-03-01T16:00:03.000Z","updated":"2020-01-04T12:21:52.078Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-Leader选举过程/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-Leader选举过程/","excerpt":"","text":"前言 上一章节我们知道了 Zookeeper 集群中是一个由多个 Server 组成：一个 Leader，多个 Follower。Leader在集群中是一个非常重要的角色，负责了整个事务的处理和调度，保证分布式数据一致性的关键所在。 既然Leader在ZooKeeper集群中这么重要所以一定要保证集群在任何时候都有且仅有一个Leader存在，所以本章将介绍Leader选举过程 什么时候需要选举Leader呢？这个好比战场上带兵打仗，这里的Leader就是带兵的将军，那么就是下面这两种场景需要选举： 1、刚开始组建军队的时候需要选举（ZooKeeper服务启动） 2、将军站死了之后需要重新选举（ZooKeeper Leader 崩溃） 概念 Zookeeper Server有三种角色【Leader、Follower、Observer】组成，在Zookeeper中Observer是不参与Leader选举过程的投票的，所以Leader挂了之后是从Follower服务中选举产生Leader Zookeeper Server的状态 LOOKING：寻找Leader LEADING：Leader状态，对应的节点为Leader。 FOLLOWING：Follower状态，对应的节点为Follower。 OBSERVING：Observer状态，对应节点为Observer，该节点不参与Leader选举。 ZXID（zookeeper transaction id） 每个改变Zookeeper状态的操作都会形成一个对应的zxid，并记录到transaction log中。 这个值越大，表示更新越新 myid 服务器SID，一个数字,通过配置文件配置，唯一 SID 服务器的唯一标识 成为Leader的必要条件： Leader要具有最高的zxid 当集群的规模是n时，集群中大多数的机器（至少n/2+1）得到响应并follow选出的Leader 心跳机制 Leader与Follower利用PING来感知对方的是否存活，当Leader无法相应PING时，将重新发起Leader选举。 Zookeeper 的选举算法有两种： 一种是基于 basic paxos 实现的 另外一种是基于 fast paxos 算法实现的。系统默认的选举算法为 fast paxos 解析 下面我们来介绍在两种场景下Leader的选举过程 一、服务器启动时期的Leader选举1.每个服务器发送一个投票(SID,ZXID) 其中sid是自己的myid，初始阶段都将自己投为Leader。 2.接收来自其他服务器的投票。 集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。 3.处理投票 针对每个投票都按以下规则与自己的投票PK，PK后依据情况是否更新投票，再发送给其他机器。 a.优先检查ZXID，ZXID较大者优先为Leader b.如果ZXID相同，检查SID，SID较大者优先为Leader 4.统计投票 每次投票后，服务器统计所有投票，判断是否有过半的机器收到相同的投票，如果某个投票达到一半的要求，则认为该投票提出者可以成为Leader。 在统计投票时，有个过半的概念，大于集群机器数量的一半，即大于或等于(n/2+1)。那么我们来看看如下的统计： 集群数量 至少正常运行数量 允许挂掉的数量 2 2 的半数为 1，半数以上最少为 2 0 3 3 的半数为 1.5，半数以上最少为 2 1 4 4 的半数为 2，半数以上最少为 3 1 5 5 的半数为 2.5，半数以上最少为 3 2 6 6 的半数为 3，半数以上最少为 4 2 通过以上可以发现： 3 台服务器和 4 台服务器都最多允许 1 台服务器挂掉，5 台服务器和 6 台服务器都最多允许 2 台服务器挂掉，明显 4 台服务器成本高于 3 台服务器成本，6 台服务器成本高于 5 服务器成本。 这是由于半数以上投票通过决定的。所以，Zookeeper 集群推荐节点数是单数。 简单的来说Zookeeper 集群推荐节点数是单数目的是节省资源！ 另外，因为 Zookeeper 使用一致性协议，过多的节点，反倒会降低性能 5.改变服务器状态 一旦确定了Leader，每个服务器都更新自己的状态，Leader变更为Leading，Follower变更为Following 正常情况下一旦选出一个Leader则一直会保持，除非Leader服务器宕掉，则再进行重新选举。 二、服务器运行时期的Leader选举1.变更状态 当Leader宕机后，余下的所非Observer的服务器都会将自己的状态变更为Looking，然后开启新的Leader选举流程。 2.每个服务器发出一个投票。 生成(SID,ZXID)信息，注意运行期间的ZXID可能是不同的，但是在投票时都会将自己投为Leader，然后发送给其他的服务器。 3.接收来自各个服务器的投票 与启动时过程相同 4.处理投票 与启动时过程相同 5.统计投票 与启动时过程相同 6.改变服务器状态 与启动时过程相同 参考 芋道源码 http://www.iocoder.cn https://www.cnblogs.com/leesf456/p/6107600.html https://juejin.im/post/5d6f6bb3f265da03b31bed05","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-Zookeeper-集群部署方式","slug":"backend/distributed/zookeeper/分布式-Zookeeper-集群部署方式","date":"2018-03-01T16:00:02.000Z","updated":"2020-01-04T12:21:52.099Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-集群部署方式/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-集群部署方式/","excerpt":"","text":"前言Zookeeper 有两种部署方式 1、单机 2、集群 Zookeeper 集群 Zookeeper 集群，是一个由多个 Server 组成，一个 Leader，多个 Follower。 这个不同于我们常见的 Master/Slave 模式，这里的Leader 为客户端服务器提供读写服务，除了 Leader 外其他的机器只能提供读服务。 每个 Server 保存一份数据副本全数据一致，分布式读 Follower ，写由 Leader 实施更新请求转发，由 Leader 实施更新请求顺序进行，来自同一个 Client 的更新请求按其发送顺序依次执行数据更新原子性，一次数据更新要么成功，要么失败。 全局唯一数据视图，Client 无论连接到哪个 Server，数据视图都是一致的实时性，在一定事件范围内，Client 能读到最新数据。 一般来说，测试环境部署单机，而生产环境必须必须必须部署集群。 集群中的机器角色 1、Leader 事务请求的唯一调度和处理者，保证集群事务处理的顺序性。 集群内部各服务的调度者。 2、Follower 处理客户端的非事务请求，转发事务请求给 Leader 服务器。 参与事务请求 Proposal 的投票。 参与 Leader 选举投票。 3、Observer 3.3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力。 处理客户端的非事务请求，转发事务请求给 Leader 服务器 不参与任何形式的投票。 如果 ZooKeeper 集群的读取负载很高，或者客户端多到跨机房，可以设置一些 Observer 服务器，以提高读取的吞吐量。Observer 和 Follower 比较相似，只有一些小区别： 首先 Observer 不属于法定人数，即不参加选举也不响应提议，也不参与写操作的“过半写成功”策略； 其次是 Observer 不需要将事务持久化到磁盘，一旦 Observer 被重启，需要从 Leader 重新同步整个名字空间。 集群机器台数 在一个集群中，最少需要 3 台。或者保证 2N + 1 台，即奇数。为什么保证奇数？主要是为了选举算法。 集群如果有 3 台机器，挂掉 1 台集群还能工作吗？挂掉 2 台呢？记住一个原则：过半存活即可用。所以挂掉 1 台可以继续工作，挂掉 2 台不可以工作。 集群支持动态添加机器吗？ 在 3.5 版本开始，支持动态扩容。 而在 3.5 版本之前，Zookeeper 在这方面不太好。所以需要如下两种方式： 全部重启：关闭所有 Zookeeper 服务，修改配置之后启动。不影响之前客户端的会话。 逐个重启：顾名思义。这是比较常用的方式。 Server 工作状态服务器具有四种状态，分别是： LOOKING 寻找 Leader 状态 当服务器处于该状态时，它会认为当前集群中没有 Leader ，因此需要进入 Leader 选举状态。 FOLLOWING 跟随者状态 表明当前服务器角色是 Follower 。 LEADING 领导者状态 表明当前服务器角色是 Leader 。 OBSERVING 观察者状态 表明当前服务器角色是 Observer 。 总结 ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。 参考 芋道源码 http://www.iocoder.cn","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-Zookeeper-Eureka与Zookeeper","slug":"backend/distributed/zookeeper/分布式-Zookeeper-Eureka与Zookeeper","date":"2018-03-01T16:00:01.000Z","updated":"2019-11-19T12:31:03.251Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-Eureka与Zookeeper/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-Eureka与Zookeeper/","excerpt":"","text":"前言 由之前章节我们可以知道，CAP理论：一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。在此Zookeeper保证的是CP, 而Eureka则是AP。 Zookeeper保证CP、 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接受服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但是zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。 Eureka保证AP Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册或时如果发现连接失败，则会自动切换至其它节点，只要有一台Eureka还在，就能保证注册服务可用(保证可用性)，只不过查到的信息可能不是最新的(不保证强一致性)。除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务 Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用) 当网络稳定时，当前实例新的注册信息会被同步到其它节点中 因此， Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。 总结 Eureka作为单纯的服务注册中心来说要比zookeeper更加“专业”，因为注册服务更重要的是可用性，我们可以接受短期内达不到一致性的状况。不过Eureka目前1.X版本的实现是基于servlet的java web应用，它的极限性能肯定会受到影响。期待正在开发之中的2.X版本能够从servlet中独立出来成为单独可部署执行的服务。 参考 https://www.cnblogs.com/gzhlt/p/7807976.html","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-Zookeeper-分布式协调服务-简介","slug":"backend/distributed/zookeeper/分布式-Zookeeper-分布式协调服务-简介","date":"2018-03-01T16:00:00.000Z","updated":"2020-01-04T12:21:52.086Z","comments":true,"path":"2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-分布式协调服务-简介/","link":"","permalink":"http://www.songshuiyang.com/2018/03/02/backend/distributed/zookeeper/分布式-Zookeeper-分布式协调服务-简介/","excerpt":"","text":"前言Zookeeper 是什么？ ZooKeeper 是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 ZooKeeper 的由来 下面这段内容摘自《从Paxos到Zookeeper 》第四章第一节的某段内容，推荐大家阅读以下： Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。 关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家RaghuRamakrishnan开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好要用来进行分布式环境的协调一一于是，Zookeeper的名字也就由此诞生了。 官网：zookeeper.apache.org/ 分布式应用程序可以基于 Zookeeper 实现诸如功能： 数据发布/订阅 负载均衡 命名服务 分布式协调/通知 集群管理 Master 选举 分布式锁 分布式队列 特性 顺序一致性(有序性) 从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到 Zookeeper 中去。 有序性是 Zookeeper 中非常重要的一个特性。 所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid(Zookeeper Transaction Id)。 而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个 Zookeeper 最新的 zxid 。 原子性 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 单一视图 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 可靠性 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非有另一个事务对其进行了变更。 实时性 Zookeeper 保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。 Zookeeper 的设计目标 1、简单的数据结构，Zookeeper 使得分布式程序能够通过一个共享的树形结构的名字空间来进行相互协调，即 Zookeeper 服务器内存中的数据模型由一系列被称为 ZNode 的数据节点组成，Zookeeper 将全量的数据存储在内存中，以此来提高服务器吞吐、减少延迟的目的。 2、可以构建集群 Zookeeper 集群通常由一组机器构成，组成 Zookeeper 集群的而每台机器都会在内存中维护当前服务器状态，并且每台机器之间都相互通信。 3、顺序访问，对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序。 4、高性能，Zookeeper 和 Redis 一样全量数据存储在内存中，100%读请求压测 QPS 12-13W 。 应用场景 Zookeeper 的功能很强大，应用场景很多，结合我们实际工作中使用 Dubbo 框架的情况，Zookeeper 主要是做注册中心用。 基于 Dubbo 框架开发的提供者、消费者都向 Zookeeper 注册自己的 URL ，消费者还能拿到并订阅提供者的注册 URL ，以便在后续程序的执行中去调用提供者。 而提供者发生了变动，也会通过 Zookeeper 向订阅的消费者发送通知。 Zookeeper支持集群部署，所以可以实现注册中心的高可用 当然，Zookeeper 能提供的不仅仅如此，再例如： 统一命名服务。 命名服务是指通过指定的名字来获取资源或服务的地址，利用zk创建一个全局的路径，即时唯一的路径，这个路径就可以作为一个名字，指向集群中机器或者提供服务的地址，又或者一个远程的对象等。 分布式锁服务。 这个比较好理解，Zookeeper 实现的分布式锁的可靠性会比 Redis 实现的分布式锁高，当然相对来说，性能会低。 有了 ZooKeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分成两类，一个是保持独占，另一个是控制时序。 1、保持独占，我们把 znode 看作是一把锁，通过 createZnode 的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 /distribute_lock 节点就释放出锁。 2、控制时序，/distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和 Master 一样，编号最小的获得锁，用完删除，依次方便。 配置管理。 例如说，Spring Cloud Config Zookeeper ，就实现了基于 Zookeeper 的 Spring Cloud Config 的实现，提供配置中心的服务。 注册与发现。 是否有机器加入或退出 所有机器约定在父目录下创建临时目录节点，然后监听父目录节点下的子节点变化。一旦有机器挂掉，该机器与 ZooKeeper 的连接断开，其所创建的临时目录节点也被删除，所有其他机器都收到通知：某个节点被删除了。 Master 选举。 基于 Zookeeper 实现分布式协调，从而实现主从的选举。这个在 Kafka、Elastic-Job 等等中间件，都有所使用到。 队列管理 1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待。在约定的目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 2、队列按照 FIFO 方式进行入队和出队操作。和分布式锁服务中的控制时序的场景基本原理一致，入列有编号，出列按编号。创建 PERSISTENT_SEQUENTIAL 节点，创建成功时 Watcher 通知等待的队列，队列删除序列号最小的节点以消费。此场景下，znode 用于消息存储，znode 存储的数据就是消息队列中的消息内容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息丢失的问题。Zookeeper 对于读写请求有所不同： 客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的 Zookeeper 机器来处理。 对于写请求，这些请求会同时发给其他 Zookeeper 机器并且达成一致后，请求才会返回成功（保证一致性）。因此，随着 Zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。 Zookeeper 提供了什么 1、文件系统。 Zookeeper 提供一个多层级的节点命名空间(节点称为 znode)。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。 Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得 Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限为 1M 2、通知机制。 ZooKeeper 性能 ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。 ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） Zookeeper 节点类型 PERSISTENT 持久节点 创建之后一直存在，除非有删除操作，创建节点的客户端会话失效也不影响此节点。 PERSISTENT_SEQUENTIAL 持久顺序节点 跟持久一样，就是父节点在创建下一级子节点的时候，记录每个子节点创建的先后顺序，会给每个子节点名加上一个数字后缀。 EPHEMERAL 临时节点 创建客户端会话失效（注意是会话失效，不是连接断了），节点也就没了。不能建子节点。 EPHEMERAL_SEQUENTIAL 临时顺序节点 基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。 Zookeeper是如何保证事务的顺序一致性的 Zookeeper采用了递增的事务Id来标识，所有的proposal都在被提出的时候加上了zxid，zxid实际上是一个64位的数字，高32位是epoch用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，低32位用来递增计数。 当新产生proposal的时候，会依据数据库的两阶段过程，首先会向其他的server发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行 Zookeeper 的 Java 客户端都有哪些？ Zookeeper 自带的 zkclient Apache 开源的 Curator 客户端监控软件ZooInspector 下载地址 https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip 百度网盘地址：http://pan.baidu.com/s/1jH8MxRC 总结 Zookeeper这个动物园管理员我们可以简单的理解就是一个文件数据库仓库，大家可以在我这边存放数据，来取数据，同时提供了通知机制：提供者发生了变动， Zookeeper 会向订阅的消费者发送通知。 利用上面的特性，所以在分布式系统中，使用Zookeeper作为一个注册中心来是很方便有效的 Zookeeper集群使用CP来保证数据的一致性 参考 芋道源码 http://www.iocoder.cn https://snailclimb.gitee.io/javaguide/#/docs/system-design/framework/ZooKeeper","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://www.songshuiyang.com/tags/Zookeeper/"}]},{"title":"分布式-基于RocketMQ处理分布式事务","slug":"backend/distributed/transaction/分布式-基于RocketMQ处理分布式事务","date":"2018-02-28T16:01:04.000Z","updated":"2019-11-19T12:31:03.248Z","comments":true,"path":"2018/03/01/backend/distributed/transaction/分布式-基于RocketMQ处理分布式事务/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/transaction/分布式-基于RocketMQ处理分布式事务/","excerpt":"","text":"前言 RocketMQ的最新版本（4.3.0+）中已经实现了可靠消息服务的所有功能，并且在保证高并发、高可用、高性能方面做了更为优秀的架构实现。 工作流程 在应用场景中分布式服务通过MQ通信的过程中，发送消息的一方我们称之为Producer，接收消费消息的一方我们称之为Consumer。 如果Producer自身业务逻辑本地事务执行成功与否希望和消息的发送保持一个原子性（也就是说如果Producer本地事务执行成功，那么这笔消息就一定要被成功的发送到RocketMQ服务的指定Topic，并且Consumer一定要被消费成功； 反之，如果Producer本地事务执行失败，那么这笔消息就应该被RocketMQ服务器丢弃）的话，RocketMQ是怎么做的呢？ 执行流程 1、Producer选择使用RockerMQ提供的事务消息方法向RocketMQ服务发送事务消息(设置消息属性TRAN_MSG=TRUE)； 2、RocketMQ服务端在收到消息后会判断消息的属性是否为事务消息，如果是普通消息就直接Push给Consumer；如果是事务消息就会对该消息进行特殊处理设置事务ID，并暂时设置该消息对Consumer不可见，之后向Producer返回Pre消息发送状态(SEND_OK)。 3、之后Producer就会开始执行本地事务逻辑，并设置本地事务处理状态后向RocketMQ服务器发送该事务消息的确认/回滚消息(COMMIT_MESSAGE／ROLLBACK_MESSAGE。 4、RocketMQ服务器根据该笔事务消息的本地事务执行状态决定是否将消息Push给Consumer还是删除该消息。 5、之后Consumer就会消费该消息，执行Consumer的本地事务逻辑，如果执行成功则向RocketMQ返回CONSUME_SUCCESS；反之出现异常则需要返回RECONSUME_LATER，以便RocketMQ再次Push该消息，这一点在实际编程中需要控制好。 正常情况下以上就是RocketMQ事务消息的基本运行流程了，但是从异常情况考虑，理论上也是存在Producer迟迟不发送确认或回滚消息的情况，RocketMQ服务端也会设置后台线程去扫描消息状态，之后会调用Producer的本地checkLocalTransaction函数获取本地事务状态后继续进行第3步操作。 总结参考 https://mp.weixin.qq.com/s/PgUqRfoPmRK-pia-pUvQjg?","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-TX-LCN分布式事务框架","slug":"backend/distributed/transaction/分布式-TX-LCN分布式事务框架","date":"2018-02-28T16:01:03.000Z","updated":"2019-11-19T12:31:03.242Z","comments":true,"path":"2018/03/01/backend/distributed/transaction/分布式-TX-LCN分布式事务框架/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/transaction/分布式-TX-LCN分布式事务框架/","excerpt":"","text":"前言 官网传送门链接，下面的内容是从官网上copy的，建议把官网的内容都看下 框架定位 TX-LCN定位于一款事务协调性框架Github地址，框架其本身并不操作事务，而是基于对事务的协调从而达到事务一致性的效果。 解决方案 在一个分布式系统下存在多个模块协调来完成一次业务。那么就存在一次业务事务下可能横跨多种数据源节点的可能。TX-LCN将可以解决这样的问题。 例如存在服务模块A 、B、 C。A模块是mysql作为数据源的服务，B模块是基于redis作为数据源的服务，C模块是基于mongo作为数据源的服务。若需要解决他们的事务一致性就需要针对不同的节点采用不同的方案，并且统一协调完成分布式事务的处理。 解决方案：若采用TX-LCN分布式事务框架，则可以将A模块采用LCN模式、B/C采用TCC模式就能完美解决。 原理介绍 TX-LCN由两大模块组成, TxClient、TxManager，TxClient作为模块的依赖框架，提供TX-LCN的标准支持，TxManager作为分布式事务的控制放。事务发起方或者参与反都由TxClient端来控制。 原理图: 核心步骤 创建事务组：是指在事务发起方开始执行业务代码之前先调用TxManager创建事务组对象，然后拿到事务标示GroupId的过程。 加入事务组：添加事务组是指参与方在执行完业务方法以后，将该模块的事务信息通知给TxManager的操作。 通知事务组：是指在发起方执行完业务代码以后，将发起方执行结果状态通知给TxManager,TxManager将根据事务最终状态和事务组的信息来通知相应的参与模块提交或回滚事务，并返回结果给事务发起方。 LCN事务模式一、原理介绍: LCN模式是通过代理Connection的方式实现对本地事务的操作，然后在由TxManager统一协调控制事务。当本地事务提交回滚或者关闭连接时将会执行假操作，该代理的连接将由LCN连接池管理。 二、模式特点: 该模式对代码的嵌入性为低。 该模式仅限于本地存在连接对象且可通过连接对象控制事务的模块。 该模式下的事务提交与回滚是由本地事务方控制，对于数据一致性上有较高的保障。 该模式缺陷在于代理的连接需要随事务发起方一共释放连接，增加了连接占用的时间。 TCC事务模式一、原理介绍: TCC事务机制相对于传统事务机制（X/Open XA Two-Phase-Commit），其特征在于它不依赖资源管理器(RM)对XA的支持，而是通过对（由业务系统提供的）业务逻辑的调度来实现分布式事务。主要由三步操作， Try: 尝试执行业务、 Confirm:确认执行业务、 Cancel: 取消执行业务。 二、模式特点: 该模式对代码的嵌入性高，要求每个业务需要写三种步骤的操作。 该模式对有无本地事务控制都可以支持使用面广。 数据一致性控制几乎完全由开发者控制，对业务开发难度要求高。 TXC事务模式一、原理介绍： TXC模式命名来源于淘宝，实现原理是在执行SQL之前，先查询SQL的影响数据，然后保存执行的SQL快走信息和创建锁。当需要回滚的时候就采用这些记录数据回滚数据库，目前锁实现依赖redis分布式锁控制。 二、模式特点: 该模式同样对代码的嵌入性低。 该模式仅限于对支持SQL方式的模块支持。 该模式由于每次执行SQL之前需要先查询影响数据，因此相比LCN模式消耗资源与时间要多。 该模式不会占用数据库的连接资源 示例代码 TX-LCN提供了Dubbo示例和SpringCloud 示例代码，共三个模块如下： SpringServiceA (发起方 | LCN模式) 关键代码123456789101112131415161718192021222324@Overridepublic String execute(String value, String exFlag) &#123; // step1. 通过restTemplate调服务B String dResp = restTemplate.getForObject(\"http://127.0.0.1:12002/rpc?value=\" + value, String.class); // String dResp = serviceBClient.rpc(value); // step2. 通过feign调服务C String eResp = serviceCClient.rpc(value); // step3. 执行本地 Demo demo = new Demo(); demo.setGroupId(TracingContext.tracing().groupId()); demo.setDemoField(value); demo.setCreateTime(new Date()); demo.setAppName(Transactions.getApplicationId()); demoMapper.save(demo); // 置异常标志，DTX 回滚 if (Objects.nonNull(exFlag)) &#123; throw new IllegalStateException(\"by exFlag\"); &#125; return dResp + \" &gt; \" + eResp + \" &gt; \" + \"ok-service-a\";&#125; SpringServiceB (参与方 | TXC模式) 关键代码，加了个@TxcTransaction(propagation = DTXPropagation.SUPPORTS)注解1234567891011121314@Override@TxcTransaction(propagation = DTXPropagation.SUPPORTS)@Transactionalpublic String rpc(String value) &#123; Demo demo = new Demo(); demo.setGroupId(TracingContext.tracing().groupId()); demo.setDemoField(value); demo.setAppName(Transactions.getApplicationId()); demo.setCreateTime(new Date()); demoMapper.save(demo); return \"ok-service-b\";&#125; SpringServiceC (参与方 | TCC模式) 关键代码，加了个@TccTransaction(propagation = DTXPropagation.SUPPORTS)注解及confirmRpc、cancelRpc方法12345678910111213141516171819202122232425262728@Override@TccTransaction(propagation = DTXPropagation.SUPPORTS)@Transactionalpublic String rpc(String value) &#123; Demo demo = new Demo(); demo.setDemoField(value); demo.setCreateTime(new Date()); demo.setAppName(Transactions.getApplicationId()); demo.setGroupId(TracingContext.tracing().groupId()); demoMapper.save(demo); ids.putIfAbsent(TracingContext.tracing().groupId(), Sets.newHashSet(demo.getId())); ids.get(TracingContext.tracing().groupId()).add(demo.getId()); return \"ok-service-c\";&#125; public void confirmRpc(String value) &#123; ids.get(TracingContext.tracing().groupId()).forEach(id -&gt; &#123; log.info(\"tcc-confirm-&#123;&#125;-&#123;&#125;\" + TracingContext.tracing().groupId(), id); ids.get(TracingContext.tracing().groupId()).remove(id); &#125;);&#125; public void cancelRpc(String value) &#123; ids.get(TracingContext.tracing().groupId()).forEach(id -&gt; &#123; log.info(\"tcc-cancel-&#123;&#125;-&#123;&#125;\", TracingContext.tracing().groupId(), id); demoMapper.deleteByKId(id); &#125;);&#125; 代码地址:https://github.com/codingapi/txlcn-demo，代码`down`下来就能运行，很赞 总结 TX-LCN 使用起来十分方便，可以很好与Dubbo应用及SpringCloud 应用集成，有了例子再去理解分布式事务就很形象了 参考 https://txlcn.org","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-Atomikos处理多数据源事务","slug":"backend/distributed/transaction/分布式-Atomikos处理多数据源事务","date":"2018-02-28T16:01:02.000Z","updated":"2019-11-19T12:31:03.240Z","comments":true,"path":"2018/03/01/backend/distributed/transaction/分布式-Atomikos处理多数据源事务/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/transaction/分布式-Atomikos处理多数据源事务/","excerpt":"","text":"前言 在Java开发过程中使用一个数据库时，使用@Transactional注解可以很方便的支持事务，但一个项目中如果使用了两个以上数据库那么再使用这个注解就不支持事务了，所以在此背景下Atomikos应运而生，Atomikos目的是为了处理多数据源事务问题 XA规范 介绍Atomikos之前先介绍XA规范， XA规范是描述了全局的事务管理器与局部的资源管理器之间的接口。XA规范的目的是允许多个资源（如数据库，应用服务器，消息队列，等等）在同一事务中访问，这样可以使ACID属性跨越应用程序而保持有效。 XA 使用 两阶段提交（2PC）来保证所有资源同时提交或回滚任何特定的事务。 两阶段提交协议（The two-phase commit protocol，2PC）是 XA 用于在全局事务中协调多个资源的机制。 两阶段协议遵循 OSI（Open System Interconnection，开放系统互联）/DTP 标准，虽然它比标准本身早若干年出现。 两阶段提交协议包含了两个阶段： 第一阶段（也称准备阶段） 第二阶段（也称提交阶段） 一个描述两阶段提交很好的类比是典型的结婚仪式，每个参与者（结婚典礼中的新郎和新娘）都必须服从安排，在正式步入婚姻生活之前说“我愿意”。考虑有的杯具情形，“参与者”之一在做出承诺前的最后一刻反悔。两阶段提交之于此的结果也成立，虽然不具备那么大的破坏性。 大家想一个场景，在做单应用的时候，有的同学连过两个库吧？在一个事务中会同时向两个系统插入数据。但是对于普通事务来讲，是管不了的。 看下图（只是举例这种操作的套路，不局限于下面的业务）： 一个服务里面要去操作两个库，如何保证事务成功呢？ 下面有两个实例 实现普通应用实践 看下面代码Atomikos 自己实现了一个事务管理器，我们获取的连接都从它哪里拿。 第一步先开启事务，然后进行预提交，db1 和 db2都先进行预先执行，注意：这里没有提交事务。 第二步才是真正的提交事务，由Atomikos 来发起提交的，如果出现异常则发起回滚操作。 这个过程是不是就有两个角色了，一个 事务管理器，一个资源管理器（我们这里是 数据库，也可以是其他的组件，消息队列什么的）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.zhouq.jta;import com.atomikos.icatch.jta.UserTransactionImp;import com.atomikos.jdbc.AtomikosDataSourceBean;import javax.transaction.UserTransaction;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.Statement;import java.util.Properties;/** * Create by zhouq on 2019/4/4 */public class AtomikosJTATest &#123; private static AtomikosDataSourceBean createAtomikosDataSourceBean(String dbName) &#123; Properties p = new Properties(); p.setProperty(\"url\", \"jdbc:mysql://localhost:3306/\" + dbName); p.setProperty(\"user\", \"root\"); p.setProperty(\"password\", \"root\"); // 使用 AtomikosDataSourceBean 封装 com.mysql.jdbc.jdbc2.optional.MysqlXADataSource AtomikosDataSourceBean ds = new AtomikosDataSourceBean(); ds.setUniqueResourceName(dbName); ds.setXaDataSourceClassName(\"com.mysql.jdbc.jdbc2.optional.MysqlXADataSource\"); ds.setXaProperties(p); return ds; &#125; public static void main(String[] args) throws Exception &#123; //准备两个数据源 AtomikosDataSourceBean ds1 = createAtomikosDataSourceBean(\"db_user\"); AtomikosDataSourceBean ds2 = createAtomikosDataSourceBean(\"db_account\"); Connection connection1 = null; Connection collection2 = null; PreparedStatement ps1 = null; PreparedStatement ps2 = null; //用 Atomikos 实现的事物来构建 UserTransaction userTransaction = new UserTransactionImp(); try &#123; //开启事物 userTransaction.begin(); // 执行db1 上面的 sql connection1 = ds1.getConnection(); ps1 = connection1.prepareStatement(\"INSERT INTO USER(name) VALUE (?)\", Statement.RETURN_GENERATED_KEYS); ps1.setString(1, \"zhouq\"); ps1.executeUpdate(); //测试异常 System.out.println(1 / 0); //执行db2 上面的 sql collection2 = ds2.getConnection(); ps2 = collection2.prepareStatement(\"INSERT INTO account(account) VALUE (?)\"); ps2.setString(1, \"zhouq6b\"); ps2.executeUpdate(); // 两阶段提交 userTransaction.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); //回滚 userTransaction.rollback(); &#125; finally &#123; try &#123; ps1.close(); ps2.close(); connection1.close(); collection2.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Spring应用实践 下面我们在Spring Boot、Mybatis、Gradle环境下来集成Atomikos这个框架，具体实现代码见 GitHub代码链接 的feature-atomikos分支，代码已通过测试，下面将讲解主要配置项 首先导入atomikos的gradle依赖，哇，Spring Boot已经是提供了atomikos的Starter了，只要导这个依赖就可以了 1compile(\"org.springframework.boot:spring-boot-starter-jta-atomikos:1.5.5.RELEASE\") 在application.yml配置两个数据库 1234567891011121314151617181920212223242526# 主数据库master: datasource: use-jndi: false jndi-name: jdbc/datasource url: jdbc:mysql://127.0.0.1:3306/iframe?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false username: root password: root driver-class: com.mysql.jdbc.Driver initial-size: 0 min-idle: 10 max-active: 100 max-wait: 20000# 从数据库slave: datasource: use-jndi: false jndi-name: jdbc/datasource url: jdbc:mysql://127.0.0.1:3306/iframe1?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false username: root password: root driver-class: com.mysql.jdbc.Driver initial-size: 0 min-idle: 10 max-active: 100 max-wait: 20000 配置Atomikos数据源及事务管理器 AbstractAtomikosConfig.java抽象基类，这个类用于提取创建数据源的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586@Slf4jpublic abstract class AbstractAtomikosConfig &#123; @Autowired private Environment env; /** * 创建数据源 * * @param prefix * @return */ protected DruidXADataSource createXaDataSource(String prefix) &#123; // 是否使用数据源 boolean useJndi = env.getProperty(prefix + \".\" + \"datasource.use-jndi\", Boolean.class, false); // 数据源名称 String jndiName = env.getProperty(prefix + \".\" + \"datasource.jndi-name\", \"\"); // 数据库链接 String url = env.getProperty(prefix + \".\" + \"datasource.url\", \"\"); String username = env.getProperty(prefix + \".\" + \"datasource.username\", \"\"); String password = env.getProperty(prefix + \".\" + \"datasource.password\", \"\"); String driverClass = env.getProperty(prefix + \".\" + \"datasource.driver-class\", \"\"); // 数据源默认初始链接数 int initialSize = env.getProperty(prefix + \".\" + \"datasource.initial-size\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_INIT_SIZE); // 数据源最大连接数 int maxActive = env.getProperty(prefix + \".\" + \"datasource.max-active\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_MAX_ACTIVE); // 数据源最小连接数 int minIdle = env.getProperty(prefix + \".\" + \"datasource.min-idle\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_MIN_IDLE); // 配置获取连接等待超时的时间 int maxWait = env.getProperty(prefix + \".\" + \"datasource.max-wait\", Integer.class, DataSouceConstant.DEFAULT_DATASOURCE_MAX_WAIT); if (useJndi) &#123; try &#123; log.debug(\"get datasource from jndi - [&#123;&#125;].\", jndiName); Context context = new InitialContext(); DruidXADataSource dataSource = (DruidXADataSource) context.lookup(jndiName); return dataSource; &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); &#125; &#125; else &#123; log.debug(\"create druid datasource.\"); log.debug(\"url - &#123;&#125;.\", url); log.debug(\"username - &#123;&#125;.\", username); log.debug(\"password - &#123;&#125;.\", password); log.debug(\"driverClass - &#123;&#125;.\", driverClass); log.debug(\"initialSize - &#123;&#125;.\", initialSize); log.debug(\"maxActive - &#123;&#125;.\", maxActive); log.debug(\"minIdle - &#123;&#125;.\", minIdle); try &#123; DruidXADataSource datasource = new DruidXADataSource(); datasource.setUrl(url); datasource.setDriverClassName(driverClass); datasource.setUsername(username); datasource.setPassword(password); datasource.setInitialSize(initialSize); datasource.setMaxActive(maxActive); datasource.setMinIdle(minIdle); datasource.setMaxWait(maxWait); datasource.setFilters(\"stat,slf4j\"); datasource.setProxyFilters(getDruidFilters()); return datasource; &#125; catch (Exception e) &#123; &#125; &#125; return null; &#125; public List&lt;Filter&gt; getDruidFilters() &#123; Slf4jLogFilter slf4jLogFilter = new Slf4jLogFilter(); slf4jLogFilter.setDataSourceLogEnabled(false); slf4jLogFilter.setStatementLogEnabled(false); slf4jLogFilter.setStatementExecutableSqlLogEnable(true); slf4jLogFilter.setResultSetLogEnabled(false); slf4jLogFilter.setResultSetCloseAfterLogEnabled(false); slf4jLogFilter.setConnectionLogEnabled(false); List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); filters.add(new StatFilter()); filters.add(slf4jLogFilter); return filters; &#125;&#125; AtomikosMasterConfig.java用于创建主库数据源及注册事务管理器，绑定主库数据源的sqlSessionFactory，注意这里主库绑定的Mapper和从库绑定的Mapper是不一样的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Configuration@EnableTransactionManagement@MapperScan(value = \"com.songsy.iframe.mapper.master\", sqlSessionFactoryRef = \"masterSqlSessionFactory\")public class AtomikosMasterConfig extends AbstractAtomikosConfig &#123; /** * 使用这个来做总事务 后面的数据源就不用设置事务了 * * @return */ @Bean(name = \"transactionManager\") @Primary public JtaTransactionManager regTransactionManager() &#123; UserTransactionManager userTransactionManager = new UserTransactionManager(); UserTransaction userTransaction = new UserTransactionImp(); return new JtaTransactionManager(userTransaction, userTransactionManager); &#125; /** * 主库数据源 * * @return */ @Bean(name = \"masterDataSource\") @Primary public DataSource masterDataSource() &#123; AtomikosDataSourceBean atomikosDataSourceBean = new AtomikosDataSourceBean(); // DataSouceConstant.MASTER_DATA_SOURCE_PREFIX = master atomikosDataSourceBean.setXaDataSource(createXaDataSource(DataSouceConstant.MASTER_DATA_SOURCE_PREFIX)); atomikosDataSourceBean.setUniqueResourceName(DataSouceConstant.MASTER_DATA_SOURCE_PREFIX); atomikosDataSourceBean.setPoolSize(5); return atomikosDataSourceBean; &#125; /** * 主库数据源 绑定的SessionFactory * * @return */ @Bean(name = \"masterSqlSessionFactory\") @Primary public SqlSessionFactory masterSqlSessionFactory(@Qualifier(\"masterDataSource\") DataSource masterDataSource) throws Exception &#123; final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(masterDataSource); return sessionFactory.getObject(); &#125;&#125; AtomikosSlaveConfig.java用于创建从库数据源，绑定从库数据源的sqlSessionFactory 1234567891011121314151617181920212223242526272829303132@Configuration@MapperScan(value = \"com.songsy.iframe.mapper.slave\", sqlSessionFactoryRef = \"slaveSqlSessionFactory\")public class AtomikosSlaveConfig extends AbstractAtomikosConfig &#123; /** * 从库数据源 * * @return */ @Bean(name = \"slaveDataSource\") public DataSource masterDataSource() &#123; AtomikosDataSourceBean atomikosDataSourceBean = new AtomikosDataSourceBean(); // DataSouceConstant.SLAVE_DATA_SOURCE_PREFIX = slave atomikosDataSourceBean.setXaDataSource(createXaDataSource(DataSouceConstant.SLAVE_DATA_SOURCE_PREFIX)); atomikosDataSourceBean.setUniqueResourceName(DataSouceConstant.SLAVE_DATA_SOURCE_PREFIX); atomikosDataSourceBean.setPoolSize(5); return atomikosDataSourceBean; &#125; /** * 从库数据源 绑定的SessionFactory * * @return */ @Bean(name = \"slaveSqlSessionFactory\") public SqlSessionFactory masterSqlSessionFactory(@Qualifier(\"slaveDataSource\") DataSource masterDataSource) throws Exception &#123; final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(masterDataSource); return sessionFactory.getObject(); &#125;&#125; 具体业务代码结构图 从UserServiceImpl.java可以看到加了@Transactional注解，只要执行了updateAllUser方法第二行会抛出异常并触发事务回滚 12345678910111213141516171819@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserMasterDataService userMasterService; @Autowired private UserSlaveDataService userSlaveDataService; @Override @Transactional public void updateAllUser(User user) &#123; userMasterService.updateMasterDatabase(user); // 触发事务回滚 System.out.println(1/0); userSlaveDataService.updateSlaveDatabase(user); &#125;&#125; 测试类 12345678910111213141516/** * 测试 */@Testpublic void updateAllUserTest2() &#123; User user = new User(); user.setUsername(\"songsy\"); user.setAddress(\"广东深圳\"); user.setAge(88); user.setHeadPortrait(\"头像\"); user.setNickname(\"某某\"); user.setPassword(\"root\"); user.setSex(1); user.setVersion(new Long(9999)); userService.updateAllUser(user);&#125; 总结 对于同一个应用如果涉及多个数据库，那么可以使用Atomikos来处理多数据源事务的问题 参考 http://www.justdojava.com/2019/04/17/java-distributed-transaction/ https://blog.csdn.net/sinat_36596988/article/details/82149241","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-分布式事务解决方案","slug":"backend/distributed/transaction/分布式-分布式事务解决方案","date":"2018-02-28T16:01:00.000Z","updated":"2019-11-19T12:31:03.246Z","comments":true,"path":"2018/03/01/backend/distributed/transaction/分布式-分布式事务解决方案/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/transaction/分布式-分布式事务解决方案/","excerpt":"","text":"前言 建议可以先看分布式-分布式事务理论这一章节再来梳理这一章节，毕竟先有理论后有实践 分布式事务的实现主要有以下 6 种方案： XA 方案 TCC补偿性事务解决方案 可靠消息最终一致性方案 本地消息表 SAGA方案 分布式事务解决方案1、XA 方案 我们知道在单个数据库应用中一般就一个事务管理器及一个资源管理器(数据源)，这种情况下使用Spring的Transactional可以很方便的处理事务问题，因为单数据源的情况下开启事务只要保证业务操作是同一个数据库Connection及关闭自动提交功能就可以实现事务，但如果出现了多个数据源，这种情况下Spring的Transactional就处理不了这个问题了，因为涉及到多个数据源，有多个数据源就有多个连接，这种情况怎么处理呢？ 所以就有人这么想，设计一个全局的事务管理器来统一管理这些多个数据源的事务，事务提交、回滚都由它来控制，但是数据库有好多类型（SQLServer,MYSQL,ORACLE,DB2,Sybase），这样怎么来实现统一管理呢，所以就需要指定一个规范 那么分布式事务协议XA就这么出来了，XA 是 X/Open DTP 组织 1994 年定义的分布式事务协议 大家只要按照这个规范去设计实现就能实现多个资源（如数据库，应用服务器，消息队列，等等）在同一事务中访问 XA规范是描述了全局的事务管理器与局部的资源管理器之间的接口，XA规范的目的是允许多个资源（如数据库，应用服务器，消息队列，等等）在同一事务中访问，这样可以使ACID属性跨越应用程序而保持有效。 XA协议包括： 一阶段提交（1PC） 二阶段提交（2PC） （二阶段提交是 XA 的标准实现） 三阶段提交（3PC）两种实现 1.1 、1PC一阶段提交 下图是（1PC） 一阶段提交的工作流程图 （1PC） 一阶段提交通过去掉 XA 的Prepare 阶段，也称弱XA，以达到减少资源锁定范围而提升并发性能的效果，典型的实现为在一个业务线程中，遍历所有的数据库连接，依次做 commit 或者 rollback 。 （1PC） 一阶段提交同本地事务相比，性能损耗低，但在事务提交的执行过程中，若出现网络故障、数据库宕机等预期之外的异常，将会造成数据不一致，且无法进行回滚。 基于（1PC） 一阶段提交的事务无需额外的实现成本，相对容易。目前支持的有： 1、MyCAT 2、Sharding-Sphere默认支持 1.2 、2PC二阶段提交 下图是（2PC） 二阶段提交的工作流程图 2PC二阶段提交是 XA 的标准实现，也称强XA，2PC二阶段提交是几乎所有分布式事务算法的基础，后续的分布式事务算法几乎都由此改进而来。 2PC二阶段协议遵循 OSI（Open System Interconnection，开放系统互联）/DTP 标准，虽然它比标准本身早若干年出现。 2PC二阶段提交（two-phase commit protocol）,2PC是一个非常经典的强一致、中心化的原子提交协议。 这里所说的中心化是指协议中有两类节点： 一个中心化协调者节点（coordinator） N个参与者节点（partcipant）。 工作流程第一阶段：请求/表决阶段 既然称为二阶段提交，说明在这个过程中是大致存在两个阶段的处理流程。第一个阶段如👆图所示，这个阶段被称之为请求/表决阶段。是个什么意思呢？ 就是在分布式事务的发起方在向分布式事务协调者（Coordinator）发送请求时，Coordinator首先会分别向参与者（Partcipant）节点A、参与这节点（Partcipant）节点B分别发送事务预处理请求，称之为Prepare，有些资料也叫Vote Request。 说的直白点就是问一下这些参与节点这件事你们能不能处理成功了，此时这些参与者节点一般来说就会打开本地数据库事务，然后开始执行数据库本地事务，但在执行完成后并不会立马提交数据库本地事务，而是先向Coordinator报告说：我这边可以处理了/我这边不能处理。 如果所有的参与这节点都向协调者作了Vote Commit的反馈的话，那么此时流程就会进入第二个阶段了。 第二阶段：提交/执行阶段 正常流程 如果所有参与者节点都向协调者报告说我这边可以处理，那么此时协调者就会向所有参与者节点发送全局提交确认通知（global_commit），即你们都可以进行本地事务提交了 此时参与者节点就会完成自身本地数据库事务的提交，并最终将提交结果回复ack消息给Coordinator，然后Coordinator就会向调用方返回分布式事务处理完成的结果。 异常流程 相反，在第二阶段除了所有的参与者节点都反馈我这边可以处理了的情况外，也会有节点反馈说我这边不能处理的情况发生，此时参与者节点就会向协调者节点反馈Vote_Abort的消息。 此时分布式事务协调者节点就会向所有的参与者节点发起事务回滚的消息global_rollback，此时各个参与者节点就会回滚本地事务，释放资源，并且向协调者节点发送ack确认消息，协调者节点就会向调用方返回分布式事务处理失败的结果。 示例 一个描述二阶段提交很好的类比是典型的结婚仪式，每个参与者（结婚典礼中的新郎和新娘）都必须服从安排，在正式步入婚姻生活之前说“我愿意”。考虑有的杯具情形，“参与者”之一在做出承诺前的最后一刻反悔。二阶段提交之于此的结果也成立，虽然不具备那么大的破坏性。 大家想一个场景，在做单应用的时候，有的同学连过两个库吧？在一个事务中会同时向两个系统插入数据。但是对于普通事务来讲，是管不了的。 看下图（只是举例这种操作的套路，不局限于下面的业务）： 一个服务里面要去操作两个库，如何保证事务成功呢。 具体实现见 分布式-Atomikos处理多数据源事务 章节 存在的问题： 实际上分布式事务是一件非常复杂的事情，二阶段提交只是通过增加了事务协调者（Coordinator）的角色来通过2个阶段的处理流程来解决分布式系统中一个事务需要跨多个服务节点的数据一致性问题。但是从异常情况上考虑，这个流程也并不是那么的无懈可击。 以下几点是XA-二阶段提交协议中会遇到的一些问题： 性能问题 从流程上我们可以看得出，其最大缺点就在于它的执行过程中间，节点都处于阻塞状态。各个操作数据库的节点此时都占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知进行全局提交，参与者进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。 数据不一致 在第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就会导致节点间数据的不一致问题。 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 1.3 、3PC二阶段提交 三阶段提交又称3PC，其在二阶段提交的基础上增加了CanCommit阶段，并引入了超时机制(这个是重点)。一旦事务参与者迟迟没有收到协调者的Commit请求，就会自动进行本地commit，这样相对有效地解决了协调者单点故障的问题。 但是性能问题和不一致问题仍然没有根本解决。下面我们还是一起看下三阶段流程的是什么样的？ 工作流程第一阶段：CanCommit阶段 这个阶段类似于2PC中的第二个阶段中的Ready阶段，是一种事务询问操作，事务的协调者向所有参与者询问“你们是否可以完成本次事务？”，如果参与者节点认为自身可以完成事务就返回“YES”，否则“NO” 而在实际的场景中参与者节点会对自身逻辑进行事务尝试，其实说白了就是检查下自身状态的健康性，看有没有能力进行事务操作。 第二阶段：PreCommit阶段 在阶段一中，如果所有的参与者都返回Yes的话，那么就会进入PreCommit阶段进行事务预提交。此时分布式事务协调者会向所有的参与者节点发送PreCommit请求，参与者收到后开始执行事务操作，并将Undo和Redo信息记录到事务日志中。参与者执行完事务操作后（此时属于未提交事务的状态），就会向协调者反馈Ack表示我已经准备好提交了，并等待协调者的下一步指令。 否则，如果阶段一中有任何一个参与者节点返回的结果是No响应，或者协调者在等待参与者节点反馈的过程中超时（2PC中只有协调者可以超时，参与者没有超时机制）。整个分布式事务就会中断，协调者就会向所有的参与者发送abort请求。 第三阶段：DoCommit阶段 在阶段二中如果所有的参与者节点都可以进行PreCommit提交，那么协调者就会从“预提交状态”-》“提交状态”。然后向所有的参与者节点发送doCommit请求，参与者节点在收到提交请求后就会各自执行事务提交操作，并向协调者节点反馈“Ack”消息，协调者收到所有参与者的Ack消息后完成事务。 相反，如果有一个参与者节点未完成PreCommit的反馈或者反馈超时，那么协调者都会向所有的参与者节点发送abort请求，从而中断事务。 总结 看到这里，你是不是会疑惑”3PC相对于2PC而言到底优化了什么地方呢?” 相比较2PC而言，3PC对于协调者（Coordinator）和参与者（Partcipant）都设置了超时时间，而2PC只有协调者才拥有超时机制。这解决了一个什么问题呢？ 这个优化点，主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题， 因为参与者自身拥有超时机制会在超时后，自动进行本地commit从而进行释放资源。而这种机制也侧面降低了整个事务的阻塞时间和范围。 另外，通过CanCommit、PreCommit、DoCommit三个阶段的设计，相较于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。 以上就是3PC相对于2PC的一个提高（相对缓解了2PC中的前两个问题），但是3PC依然没有完全解决数据不一致的问题。 2、TCC补偿性事务解决方案 说起分布式事务的概念，不少人都会搞混淆，似乎好像分布式事务就是TCC。实际上TCC与2PC、3PC一样，只是分布式事务的一种实现方案而已。 TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留(比如冻结金额)，看一下数据库资源是否能工作 Confirm 阶段主要是对业务系统做确认提交，Try 阶段执行成功并开始执行 Confirm 阶段时，默认 Confirm 阶段是不会出错的。即：只要 Try 成功，Confirm 一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 注意这里也有一个全局的事务管理器，一般是有框架来实现 TCC事务的处理流程与2PC二阶段提交类似，不过2PC通常都是在跨库的DB层面，而TCC本质上就是一个应用层面的2PC，需要通过业务逻辑来实现。 TCC 方案让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。 当然 TCC 方案也有不足之处，集中表现在以下两个方面： 对应用的侵入性强。业务逻辑的每个分支都需要实现 try、confirm、cancel 三个操作，比如下面的代码，应用侵入性较强，改造成本高。 12345678910111213141516171819202122232425262728@Override@TccTransaction(propagation = DTXPropagation.SUPPORTS)@Transactionalpublic String rpc(String value) &#123; Demo demo = new Demo(); demo.setDemoField(value); demo.setCreateTime(new Date()); demo.setAppName(Transactions.getApplicationId()); demo.setGroupId(TracingContext.tracing().groupId()); demoMapper.save(demo); ids.putIfAbsent(TracingContext.tracing().groupId(), Sets.newHashSet(demo.getId())); ids.get(TracingContext.tracing().groupId()).add(demo.getId()); return \"ok-service-c\";&#125;public void confirmRpc(String value) &#123; ids.get(TracingContext.tracing().groupId()).forEach(id -&gt; &#123; log.info(\"tcc-confirm-&#123;&#125;-&#123;&#125;\" + TracingContext.tracing().groupId(), id); ids.get(TracingContext.tracing().groupId()).remove(id); &#125;);&#125;public void cancelRpc(String value) &#123; ids.get(TracingContext.tracing().groupId()).forEach(id -&gt; &#123; log.info(\"tcc-cancel-&#123;&#125;-&#123;&#125;\", TracingContext.tracing().groupId(), id); demoMapper.deleteByKId(id); &#125;);&#125; 实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm 和 cancel 接口必须实现幂等。 上述原因导致 TCC 方案大多被研发实力较强、有迫切需求的大公司所采用。微服务倡导服务的轻量化、易部署，而 TCC 方案中很多事务的处理逻辑需要应用自己编码实现，复杂且开发量大。 示例 在 分布式-TX-LCN分布式事务框架这一章节有例子TX-LCN框架的TCC补偿性事务解决方案 3、可靠消息最终一致性方案3.1、基于 RocketMQ 消息队列中间件 消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。 因此基于消息队列实现的事务是我们除了单机事务外最优先考虑使用的形态。 参考 分布式-基于RocketMQ处理分布式事务这一章节 其他分布式事务产品 目前国内主要的开源分布式事务框架包括： 框架名称 GitHub 地址 star 数量(截止到20191025) 阿里seata https://github.com/seata/seata 12243 tcc-transaction https://github.com/changmingxie/tcc-transaction 4194 tx-lcn https://github.com/codingapi/tx-lcn/ 2986 Hmily https://github.com/yu199195/hmily 2560 ByteTCC https://github.com/liuyangming/ByteTCC 2112 EasyTransaction https://github.com/QNJR-GROUP/EasyTransaction 1888 myth https://github.com/yu199195/myth 1381 总结 不论任何一种分布式事务解决方案都会增加你系统的复杂度，这样的成本实在是太高了，千万不要因为追求某些设计，而引入不必要的成本和复杂度，在条件允许的情况下，我们应该尽可能地使用单机事务，因为单机事务里，无需额外协调其他数据源，减少了网络交互时间消耗以及协调时所需的存储 IO 消耗，在修改等量业务数据的情况下，单机事务将会有更高的性能。 能不用分布式事务就不用，如果非得使用的话，结合自己的业务分析，看看自己的业务比较适合哪一种，是在乎强一致，还是最终一致即可。上面对解决方案只是一些简单介绍，如果真正的想要落地，其实每种方案需要思考的地方都非常多，复杂度都比较大。 通过分析我们可以发现，并不存在一种事务形态能解决所有的问题，我们需要根据特定的业务场景选择合适的事务形态。甚至于有时需要混合多种事务形态才能更好的完成目标。 具体到分布式事务的实现上，业界主要采用了 XA 协议的强一致规范以及柔性事务的最终一致规范，所以，市面上的分布式事务的解决方案，除了 XA 协议是强一致的，其他都是最终一致的。 选择对应的事务形态的优先次序：单机事务 &gt; 基于消息的事务 &gt; TCC 事务 4、本地消息表 本地消息表，其实是 国外的 Ebay 搞出来的这么一套思想，经调研并没有大规模使用 具体工作流程 1、A 系统在自己本地一个事务里操作同时，插入一条数据到消息表； 2、接着 A 系统将这个消息发送到 MQ 中去； 3、B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息； 4、B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态； 5、如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理； 6、这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。 这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的，会导致如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。 本地消息队列是 BASE 理论，是最终一致模型，适用于对一致性要求不高的。实现这个模型时需要注意重试的幂等。 5、Saga 方案 Saga 是 30 年前一篇数据库伦理提到的一个概念。其核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。 参考 https://juejin.im/post/5b5a0bf9f265da0f6523913b http://www.justdojava.com/2019/04/17/java-distributed-transaction/ https://www.infoq.cn/article/xa-transactions-handle https://cj466.top/plan/94.html https://blog.csdn.net/sinat_36596988/article/details/82149241 https://mp.weixin.qq.com/s?__biz=MzU3NDY4NzQwNQ==&amp;mid=2247484507&amp;idx=1&amp;sn=7d59417ee1a1ba47a54186edff8460b9&amp;chksm=fd2fd599ca585c8f498a996d26bde123e50adba2445629773be975a3c658e7139d2f8c21bd18&amp;scene=21 https://www.infoq.cn/article/2018/08/rocketmq-4.3-release","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-无状态服务","slug":"backend/distributed/分布式-无状态服务","date":"2018-02-28T16:00:02.000Z","updated":"2020-01-04T12:21:52.104Z","comments":true,"path":"2018/03/01/backend/distributed/分布式-无状态服务/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/分布式-无状态服务/","excerpt":"","text":"前言 对于无状态服务，首先说一下什么是状态： 如果一个数据需要被多个服务共享，才能完成一笔交易，那么这个数据被称为状态。进 而依赖这个“状态”数据的服务被称为有状态服务，反之称为无状态服务。 那么这个无状态服务原则并不是说在微服务架构里就不允许存在状态，表达的真实意思是要把有状态的业务服务改变为无状态的计算类服务，那么状态数据也就相应的迁移到对应的“有状态数据服务”中。 场景说明 例如我们以前在本地内存中建立的数据缓存、Session缓存，到现在的微服务架构中就应该把这些数据迁移到分布式缓存中存储，让业务服务变成一个无状态的计算节点。 迁移后，就可以做到按需动态伸缩，微服务应用在运行时动态增删节点，就不再需要考虑缓存数据如何同步的问题。 参考 https://www.cnblogs.com/stulzq/p/8573828.html","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-一致性hash算法","slug":"backend/distributed/分布式-一致性hash算法","date":"2018-02-28T16:00:02.000Z","updated":"2020-04-04T13:40:13.399Z","comments":true,"path":"2018/03/01/backend/distributed/分布式-一致性hash算法/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/分布式-一致性hash算法/","excerpt":"","text":"前言 首先来看一下百度百科的概念： 一致性哈希算法在1997年由麻省理工学院提出，是一种特殊的哈希算法，目的是解决分布式缓存的问题。 [1] 在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在分布式哈希表( Distributed Hash Table，DHT) 中存在的动态伸缩等问题 [2] 从上面可以知道这个算法是解决分布式缓存中服务器动态伸缩问题 分布式缓存 随着业务的扩展，流量的剧增，单体项目逐渐划分为分布式系统。对于经常使用的数据，我们可以使用Redis作为缓存机制，减少数据层的压力。因此，重构后的系统架构如下图所示： 由上图可以看到有三台redis来搭建分布式缓存架构，每次Redis请求会随机发送到其中一台，但是这种策略会引发如下两个问题： 同一份数据可能在多个Redis数据库，造成数据冗余 某一份数据在其中一台Redis数据库已存在，但是再次访问Redis数据库，并没有命中数据已存在的库。无法保证对相同的key的所有访问都发送到相同的Redis中 要解决上述的问题，我们需要稍稍改变一些key存入Redis的规则，使用hash算法： 例如，有三台Redis，对于每次的访问都可以通过计算hash来求得hash值。 如公式 h=hash(key)%3，我们把Redis编号设置成0,1,2来保存对应hash计算出来的值，h的值等于Redis对应的编号。 但是有个问题就是当服务器数量发生变更的时候上面的hash算法就要进行相应的调整： 场景： 有台服务器挂了 服务器宕机了，那么为了填补空缺，要将宕机的服务器从编号列表中移除，后面的服务器按顺序前移一位并将其编号值减一，此时每个key就要按h = Hash(key) % 2重新计算。 要新增服务器了 如果新增一台服务器，规则也同样需要重新计算，h = Hash(key) % 4 系统中如果有服务器更变，会直接影响到Hash值，大量的key会重定向到其他服务器中，造成缓存命中率降低，而这种情况在分布式系统中是十分糟糕的。 针对于上面这个问题，一致性hash算法出现了 一致性哈希算法 一致性Hash算法也是使用取模的方法，但是普通hash算法是通过服务器的数量进行取模，所以一旦服务器数量发送变更就会影响，和普通hash算法不同的是一致性Hash算法是对2^32取模 对2^32（为什么是2^32而不是其他数呢）取模的话那怎么定位到那台机器呢，这个范围那么大，所以设计了一个圆环来划分（为什么要设计一个圆环呢，是为了切蛋糕），如下图所示： 整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。 有了圆环之后我们需要将服务器放到圆环对应的点上，我们可以按照IP或主机名作为关键字进行哈希，这样就能确定其在哈希环的位置： 由上面我们知道了三个服务器的具体位置，假设有一个数据A过来，经过哈希计算的到定位，如下图所示： 得到数据A的位置之后我们怎么定位到那台服务器呢？ 我们从A位置沿顺时针滚动，遇到的第一台服务器就是其应该定位到的服务器： 数据A会被定位到RedisService1上 数据B会被定位到RedisService2上 数据C、D会被定位到RedisService3上 上面就是一致性哈希算法的具体工作流程，下面来看一下一致性哈希算法的容错性和扩展性如何呢？ 特点容错性 假如RedisService2宕机了，那么会怎样呢？由下图可以知道数据B会沿着圆环定位到RedisService3上 扩展性 假如增加一台服务器RedisService4，原本数据C是保存到RedisService3中，但由于增加了RedisService4，数据C被保存到RedisService4中。干扰的也只有RedisService3而已，其他数据不会受到影响。 虚拟节点 前面部分都是讲述到Redis节点较多和节点分布较为均衡的情况，如果节点较少就会出现节点分布不均衡造成数据倾斜问题。 例如，我们的的系统有两台Redis，分布的环位置如下图所示：这样数据都会被定位到RedisService1中 为了解决这种数据存储不平衡的问题，一致性哈希算法引入了虚拟节点机制，即对每个节点计算多个哈希值，每个计算结果位置都放置在对应节点中，这些节点称为虚拟节点。 具体做法可以在服务器IP或主机名的后面增加编号来实现，例如上面的情况，可以为每个服务节点增加三个虚拟节点，于是可以分为 RedisService1#1、 RedisService1#2、 RedisService1#3、 RedisService2#1、 RedisService2#2、 RedisService2#3，具体位置如下图所示： 对于数据定位的hash算法仍然不变，只是增加了虚拟节点到实际节点的映射。例如，数据C保存到虚拟节点Redis1#2，实际上数据保存到Redis1中。这样，就能解决服务节点少时数据不平均的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 总结参考 https://segmentfault.com/a/1190000017847097 https://blog.csdn.net/qq_40551994/article/details/100991581","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-微服务架构下的秒杀","slug":"backend/distributed/分布式-微服务架构下的秒杀","date":"2018-02-28T16:00:02.000Z","updated":"2020-03-16T11:43:55.373Z","comments":true,"path":"2018/03/01/backend/distributed/分布式-微服务架构下的秒杀/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/分布式-微服务架构下的秒杀/","excerpt":"","text":"前言 淘宝的双十一、各大平台的秒杀活动相信大家都有所体验，设计及实现一个好的秒杀系统是一个复杂且充满挑战的任务，下面通过各大网站博客收集过来的资料来汇总成一篇具体实现方案 秒杀系统的场景特点 秒杀时大量用户会在同一时间同时进行抢购，网站瞬时访问流量激增； 秒杀一般是访问请求量远远大于库存数量，只有少部分用户能够秒杀成功； 秒杀业务流程比较简单，一般就是下订单操作； 分析硬件设施及网络环境 系统做的再牛逼，没有好的运行环境是不可能发挥具体功效的，所以选择一套合适的硬件设施及秒杀网络的优化也是很重要的： 硬件设施优化 性能不够，硬件来凑 网络环境优化 IDC多线路（电信、联通、移动）的接入 带宽的升级 当一个活动的访问量级特别大的时候，可能从域名分发进来的nginx就算是做了高可用，但实际上最终还是单机在线，始终敌不过超大流量的压力时，我们可以考虑域名的多IP映射。也就是说同一个域名下面映射多个外网的IP，再映射到DMZ的多组高可用的nginx服务上，nginx再配置可用的应用服务集群来减缓压力； 前端设计思路 有了上面的良好的环境支持，那么用户就可以正常访问秒杀页面了，所以这个前端页面也需要做处理 这个前端页面设计可以采用下面几点来进行优化 使用前后端分离的系统设计模式 静态页面展示和业务数据分离，后台只负责接口传输，具体的显示效果通过前端项目来实现，这样相对于之前服务端渲染的系统来说性能更好 静态缓存 将一些静态资源缓存到浏览器中，减少交互次数及资源消耗 将静态数据缓存在 CDN，其擅长处理大并发的静态文件请求 后端设计思路服务架构 既然是秒杀场景，那就需要保证服务的高可用、高并发，所以后端系统架构可以采用SpringCloud、Dubbo分布式微服务框架架构，通过负载均衡来处理请求，一个服务撑不住那就两个，两个服务撑不住那就三个。。。 下图是服务架构图： 由上图可以看到除了接口服务拆分之外，可以看到还做了如下处理： Mysql集群、读写分离 Redis集群 ES集群 秒杀接口设计 1、秒杀相关的活动页面相关的接口，所有查询能加缓存的，全部添加redis的缓存； 2、活动相关真实库存、锁定库存、限购、下单处理状态等全放redis； 3、当有请求进来时，首先通过redis原子自增的方式记录当前请求数，当请求超过一定量，比如说库存的10倍之后，后面进入的请求则直接返回活动太火爆的响应；而能进入抢购的请求，则首先进入活动ID为粒度的分布式锁，第一步进行用户购买的重复性校验，满足条件进入下一步，否则返回已下单的提示； 4、第二步，判断当前可锁定的库存是否大于购买的数量，满足条件进入下一步，否则返回已售罄的提示； 5、第三步，锁定当前请求的购买库存，从锁定库存中减除，并将下单的请求放入kafka消息队列； 6、第四步，在redis中标记一个polling的key（用于轮询的请求接口判断用户是否下订单成功），在kafka消费端消费完成创建订单之后需要删除该key，并且维护一个活动id+用户id的key，防止重复购买； 7、第五步，消息队列消费，创建订单，创建订单成功则扣减redis中的真实库存，并且删除polling的key。如果下单过程出现异常，则删除限购的key，返还锁定库存，提示用户下单失败； 8、第六步，提供一个轮询接口，给前端在完成抢购动作后，检查最终下订单操作是否成功，主要判断依据是redis中的polling的key的状态； 9、整个流程会将所有到后端的请求拦截的在redis的缓存层面，除了最终能下订单的库存限制订单会与数据库存在交互外，基本上无其他的交互，将数据库I/O压力降到了最低； 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/** * 秒杀接口，先将请求放入队列模式 * @param jsonObject * @return */@ApiOperation(value=\"去秒杀--先队列模式\",nickname=\"Guoqing\")@RequestMapping(value=\"/goSeckillByQueue\", method=RequestMethod.POST)public BaseResponse goSeckillByQueue(@RequestBody JSONObject jsonObject) &#123; int stallActivityId = jsonObject.containsKey(\"stallActivityId\") ? jsonObject.getInteger(\"stallActivityId\") : -1; //活动Id AssertUtil.isTrue(stallActivityId != -1, \"非法參數\"); int purchaseNum = jsonObject.containsKey(\"purchaseNum\") ? jsonObject.getInteger(\"purchaseNum\") : 1; //购买数量 AssertUtil.isTrue(purchaseNum != -1, \"非法參數\"); String openId = jsonObject.containsKey(\"openId\") ? jsonObject.getString(\"openId\") : null; AssertUtil.isTrue(!StringUtil.isEmpty(openId), 1101, \"非法參數\"); String formId = jsonObject.containsKey(\"formId\") ? jsonObject.getString(\"formId\") : null; AssertUtil.isTrue(!StringUtil.isEmpty(formId), 1101, \"非法參數\"); long addressId = jsonObject.containsKey(\"addressId\") ? jsonObject.getLong(\"addressId\") : -1; AssertUtil.isTrue(addressId != -1, \"非法參數\"); //通过分享入口进来的参数 String shareCode = jsonObject.getString(\"shareCode\"); String shareSource = jsonObject.getString(\"shareSource\"); String userCode = jsonObject.getString(\"userId\"); JSONObject jsonStr = new JSONObject(); jsonStr.put(\"stallActivityId\", stallActivityId); jsonStr.put(\"purchaseNum\", purchaseNum); jsonStr.put(\"openId\", openId); jsonStr.put(\"addressId\", addressId); jsonStr.put(\"formId\", formId); jsonStr.put(\"shareCode\", shareCode); jsonStr.put(\"shareSource\", shareSource); jsonStr.put(\"userCode\", userCode); // 判断秒杀活动是否开始 if( !seckillService.checkStartSeckill(stallActivityId) ) &#123; return new BaseResponse(false, 6205, \"秒杀活动尚未开始，请稍等！\"); &#125; // 这里拒绝多余的请求，比如库存100，那么超过500或者1000的请求都可以拒绝掉，利用redis的原子自增操作 long count = redisRepository.incr(\"BM_MARKET_SECKILL_COUNT_\" + stallActivityId); if( count &gt; 500 ) &#123; return new BaseResponse(false, 6405, \"活动太火爆，已经售罄啦！\"); &#125; logger.info(\"第\" + count + \"个请求进入到了消息队列\"); // 做用户重复购买校验 if( redisRepository.exists(\"BM_MARKET_SECKILL_LIMIT_\" + stallActivityId + \"_\" + openId) ) &#123; return new BaseResponse(false, 6105, \"您正在参与该活动，不能重复购买！\"); &#125; // 放入kafka消息队列 kafkaSender.sendChannelMess(\"demo_seckill_queue\", jsonStr.toString()); return new BaseResponse();&#125;/** * 06.05-轮询请求当前用户是否秒杀下单成功 * &lt;p&gt;Title: seckillPolling&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @param jsonObject * @return */@ApiOperation(value=\"轮询接口--先分布式锁模式\",nickname=\"Guoqing\")@RequestMapping(value=\"/seckillPolling\", method=RequestMethod.POST)public SeckillInfoResponse seckillPolling(@RequestBody JSONObject jsonObject) &#123; int stallActivityId = jsonObject.containsKey(\"stallActivityId\") ? jsonObject.getInteger(\"stallActivityId\") : -1; //活动Id AssertUtil.isTrue(stallActivityId != -1, \"非法參數\"); String openId = jsonObject.containsKey(\"openId\") ? jsonObject.getString(\"openId\") : null; AssertUtil.isTrue(!StringUtil.isEmpty(openId), 1101, \"非法參數\"); SeckillInfoResponse response = new SeckillInfoResponse(); if( redisRepository.exists(\"BM_MARKET_LOCK_POLLING_\" + stallActivityId + \"_\" + openId) ) &#123; //如果缓存中存在锁定秒杀和用户ID的key，则证明该订单尚未处理完成，需要继续等待 response.setIsSuccess(true); response.setResponseCode(6103); response.setResponseMsg(\"排队中，请稍后\"); response.setRefreshTime(1000); &#125; else &#123; //如果缓存中该key已经不存在，则表明该订单已经下单成功，可以进入支付操作，并取出orderId返回 String redisOrderInfo = redisRepository.get(\"BM_MARKET_SECKILL_ORDERID_\" + stallActivityId + \"_\" + openId); if( redisOrderInfo == null ) &#123; response.setIsSuccess(false); response.setResponseCode(6106); response.setResponseMsg(\"秒杀失败，下单出现异常，请重试！\"); response.setOrderCode(null); response.setRefreshTime(0); &#125;else &#123; response.setIsSuccess(true); response.setResponseCode(6104); response.setResponseMsg(\"秒杀成功\"); response.setOrderCode(redisOrderInfo); response.setRefreshTime(0); &#125; &#125; return response;&#125;/** * 轮询请求 判断是否获得下单资格 * @param jsonObject * @return */@ApiOperation(value=\"轮询接口--先队列模式\",nickname=\"Guoqing\")@RequestMapping(value=\"/seckillPollingQueue\", method=RequestMethod.POST)public SeckillInfoResponse seckillPollingQueue(@RequestBody JSONObject jsonObject) &#123; int stallActivityId = jsonObject.containsKey(\"stallActivityId\") ? jsonObject.getInteger(\"stallActivityId\") : -1; //活动Id AssertUtil.isTrue(stallActivityId != -1, \"非法參數\"); String openId = jsonObject.containsKey(\"openId\") ? jsonObject.getString(\"openId\") : null; AssertUtil.isTrue(!StringUtil.isEmpty(openId), 1101, \"非法參數\"); SeckillInfoResponse response = new SeckillInfoResponse(); //是否存在下单资格码的key if( redisRepository.exists(\"BM_MARKET_SECKILL_QUEUE_\"+stallActivityId+\"_\"+openId) )&#123; String result = redisRepository.get(\"BM_MARKET_SECKILL_QUEUE_\"+stallActivityId+\"_\"+openId); response = JSONObject.parseObject(JSONObject.parseObject(result).getJSONObject(\"response\").toJSONString(), SeckillInfoResponse.class); &#125; else &#123; response.setIsSuccess(true); response.setResponseCode(0); response.setResponseMsg(\"活动太火爆，排队中...\"); response.setRefreshTime(0); &#125; return response;&#125; Github完整代码链接 总结 通过上面代码我们可以看到主要逻辑是请求进来之后，通过活动开始判断和重复秒杀判断之后，即进入到消息队列，然后在消息的消费端去做库存判断等操作，通过消息队列达到削峰的操作 秒杀架构设计理念 限流：鉴于只有少部分用户能够秒杀成功，所以要限制大部分流量，只允许少部分流量进入服务后端（暂未处理）； 削峰：对于秒杀系统瞬时的大量用户涌入，所以在抢购开始会有很高的瞬时峰值。实现削峰的常用方法有利用缓存或者消息中间件等技术； 异步处理：对于高并发系统，采用异步处理模式可以极大地提高系统并发量，异步处理就是削峰的一种实现方式； 内存缓存：秒杀系统最大的瓶颈最终都可能会是数据库的读写，主要体现在的磁盘的I/O，性能会很低，如果能把大部分的业务逻辑都搬到缓存来处理，效率会有极大的提升； 可拓展：如果需要支持更多的用户或者更大的并发，将系统设计为弹性可拓展的，如果流量来了，拓展机器就好； 参考 https://mp.weixin.qq.com/s/flSXbWKOdNtPzWJHb20K2g","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-分布式自增ID雪花算法","slug":"backend/distributed/分布式-分布式自增ID雪花算法","date":"2018-02-28T16:00:02.000Z","updated":"2020-01-04T12:21:52.101Z","comments":true,"path":"2018/03/01/backend/distributed/分布式-分布式自增ID雪花算法/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/分布式-分布式自增ID雪花算法/","excerpt":"","text":"前言 这种方案大致来说是一种以划分命名空间（UUID也算，由于比较常见，所以单独分析）来生成ID的一种算法，这种方案把64-bit分别划分成多段，把时间戳，工作机器id，序列号信息组合成唯一，比如在snowflake中的64-bit分别表示如下图（图片来自网络）所示： 解析 1bit:一般是符号位，不做处理 41bit:用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。 10bit:10bit用来记录机器ID，总共可以记录1024台机器，一般用前5位代表数据中心，后面5位是某个数据中心的机器ID 12bit:循环位，用来对同一个毫秒之内产生不同的ID，12位可以最多记录4095个，也就是在同一个机器同一毫秒最多记录4095个，多余的需要进行等待下毫秒。 源码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeIdWorker &#123; // ==============================Fields=========================================== /** 开始时间截 (2015-01-01) 用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。*/ private final long twepoch = 1420041600000L; /** 机器id所占的位数 */ private final long workerIdBits = 5L; /** 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** 序列在id中占的位数 */ private final long sequenceBits = 12L; /** 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** 工作机器ID(0~31) */ private long workerId; /** 数据中心ID(0~31) */ private long datacenterId; /** 毫秒内序列(0~4095) */ private long sequence = 0L; /** 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeIdWorker(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException( String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; //时间戳改变，毫秒内序列重置 else &#123; sequence = 0L; &#125; //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125; //==============================Test============================================= /** 测试 */ public static void main(String[] args) &#123; // 机器id 与序列id ，也可以不传 SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0); for (int i = 0; i &lt; 1000; i++) &#123; long id = idWorker.nextId(); //System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125; &#125;&#125; 优点： 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 整个分布式系统内不会产生重复id（因为有datacenterId和workerId来做区分） 可以根据自身业务特性分配bit位，非常灵活。 缺点： 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。 场景说明 Mongdb objectID ：可以算作是和snowflake类似方法，通过“时间+机器码+pid+inc”共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。 #### 参考 https://www.cnblogs.com/stulzq/p/8573828.html https://www.cnblogs.com/relucent/p/4955340.html","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-分布式系统的CAP理论","slug":"backend/distributed/分布式-分布式系统的CAP理论","date":"2018-02-28T16:00:01.000Z","updated":"2019-11-10T02:08:41.890Z","comments":true,"path":"2018/03/01/backend/distributed/分布式-分布式系统的CAP理论/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/分布式-分布式系统的CAP理论/","excerpt":"","text":"前言 当你开发或者设计一个分布式系统的时候，CAP理论是无论如何也绕不过去的。本文就来介绍一下到底什么是CAP理论，如何证明CAP理论，以及CAP的权衡问题。 CAP理论概述 CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 分析CAP的定义Consistency 一致性 一致性指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致 对于一致性，可以分为从客户端和服务端两个不同的视角。 从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。 从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。 一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。 从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。 三种一致性策略 1、对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。 2、如果能容忍后续的部分或者全部访问不到，则是弱一致性。 3、如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。 CAP中说，不可能同时满足的这个一致性指的是强一致性。 Availability 可用性 可用性指服务一直可用，而且是正常响应时间。 对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的。 可用性分类 可用水平（%） 可用水平（%） 容错可用性 99.9999 &lt;1 min 极高可用性 99.999 &lt;5 min 具有故障自动恢复能力的可用性 99.99 &lt;53 min 高可用性 99.9 &lt;8.8h 商品可用性 99 &lt;43.8 min 通常我们描述一个系统的可用性时，我们说淘宝的系统可用性可以达到5个9，意思就是说他的可用水平是99.999%，即全年停机时间不超过 (1-0.99999)36524*60 = 5.256 min，这是一个极高的要求。 好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。一个分布式系统，上下游设计很多系统如负载均衡、WEB服务器、应用代码、数据库服务器等，任何一个节点的不稳定都可以影响可用性。 Partition Tolerance分区容错性 分区容错性指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 分区容错性和扩展性紧密相关，在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。 比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。 简单点说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性。 CAP的证明 如上图，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。 在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。 如上图，是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。 这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用行；N1和N2之间的网络环境为分区容错性。这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？ 作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。 假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？ 有二种选择 第一，牺牲数据一致性，保证可用性。响应旧的数据V0给用户； 第二，牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。 这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。 CAP权衡 通过CAP理论及前面的证明，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ 我们分三种情况来阐述一下。 CA without P 这种情况在分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。 比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。 其实，在CAP理论中。C，A，P三者并不是平等的，CAP之父在《Spanner，真时，CAP理论》一文中写到： 如果说Spanner真有什么特别之处，那就是谷歌的广域网。Google通过建立私有网络以及强大的网络工程能力来保证P，在多年运营改进的基础上，在生产环境中可以最大程度的减少分区发生，从而实现高可用性。 从Google的经验中可以得到的结论是，无法通过降低CA来提升P。要想提升系统的分区容错性，需要通过提升基础设施的稳定性来保障。 所以，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。 CP without A 如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。 一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。 设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。 无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？ 在我的Zookeeper介绍（二）——Zookeeper概述一文中其实介绍过zk关于CAP的思考，这里再简单回顾一下： ZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。 AP wihtout C 要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。 这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。 你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的（但是可能实际已经没票了），你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。 但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 适合的才是最好的 上面介绍了如何CAP中权衡及取舍以及典型的案例。孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。 对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CP，舍弃A。比如前几年支付宝光缆被挖断的事件，在网络出现故障的时候，支付宝就在可用性和数据一致性之间选择了数据一致性，用户感受到的是支付宝系统长时间宕机，但是其实背后是无数的工程师在恢复数据，保证数数据的一致性。 对于其他场景，比较普遍的做法是选择可用性和分区容错性，舍弃强一致性，退而求其次使用最终一致性来保证数据的安全 其他CAP理论应用实例 MySQL 主从异步复制是 AP 系统。 MySQL 主从半同步复制是 CP 系统。 Zookeeper 是 CP 系统。 Redis 主从同步是 AP 系统。 Eureka 主从同步是 AP 系统。 BASE理论 BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性 Basically Available（基本可用） 分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 Soft state（软状态） 允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。 Eventually consistent（最终一致性） 最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。 BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 对于大部分的分布式应用而言，只要数据在规定的时间内达到最终一致性即可。 我们可以把符合传统的 ACID 叫做刚性事务，把满足 BASE 理论的最终一致性事务叫做柔性事务。 一味的追求强一致性，并非最佳方案。对于分布式应用来说，刚柔并济是更加合理的设计方案，即在本地服务中采用强一致事务， 在跨系统调用中采用最终一致性，如何权衡系统的性能与一致性，是十分考验架构师与开发者的设计功力的。 具体到分布式事务的实现上，业界主要采用了 XA 协议的强一致规范以及柔性事务的最终一致规范，所以，市面上的分布式事务的解决方案，除了 XA 协议是强一致的，其他都是最终一致的。 总结 首先CAP理论是在分布式系统环境下出现的，对于单节点，CA 必然是可以保证的，所以需要在多节点系统的基础上去理解它，一个分布式系统里面肯定是有多个节点的，节点组成的网络本来应该是连通的，然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域，数据就散布在了这些不连通的区域中，这就叫分区。 当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了，这时分区就是无法容忍的。 提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里，容忍性就提高了。 然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。 总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。 参考 https://www.hollischuang.com/archives/666 强烈推荐 http://www.ruanyifeng.com/blog/2018/07/cap.html https://www.zhihu.com/question/54105974/answer/139037688","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"分布式-分布式事务理论","slug":"backend/distributed/transaction/分布式-分布式事务理论","date":"2018-02-28T16:00:00.000Z","updated":"2019-11-19T12:31:03.244Z","comments":true,"path":"2018/03/01/backend/distributed/transaction/分布式-分布式事务理论/","link":"","permalink":"http://www.songshuiyang.com/2018/03/01/backend/distributed/transaction/分布式-分布式事务理论/","excerpt":"","text":"前言数据库事务的概念 在讲述分布式事务的概念之前，我们先来回顾下事务相关的一些概念。 事务的基本概念： 就是一个程序执行单元，里面的操作要么全部执行成功，要么全部执行失败，不允许只成功一半另外一半执行失败的事情发生。 例如一段事务代码做了两次数据库更新操作，那么这两次数据库操作要么全部执行成功，要么全部回滚。 事务的ACID基本特性： Atomicity（原子性）: 表示事务是一个不可分割的整体，所有操作要么全做，要么全不做 只要事务中有一个操作出错，回滚到事务开始前的状态的话，那么之前已经执行的所有操作都是无效的，都应该回滚到开始前的状态。 Consistency（一致性）： 表示事务执行前后，数据从一个状态到另一个状态必须是一致的 比如A向B转账（ A、B的总金额就是一个一致性状态），不可能出现A扣了钱，B却没收到的情况发生。 Isolation（隔离性）： 多个并发事务之间相互隔离，不能互相干扰。关于事务的隔离性，可能不是特别好理解，这里的并发事务是指两个事务操作了同一份数据的情况； 而对于并发事务操作同一份数据的隔离性问题，则是要求不能出现脏读、幻读的情况，即事务A不能读取事务B还没有提交的数据，或者在事务A读取数据进行更新操作时，不允许事务B率先更新掉这条数据。而为了解决这个问题，常用的手段就是加锁了，对于数据库来说就是通过数据库的相关锁机制来保证。 Durablity（持久性）： 事务完成后，对数据库的更改是永久保存的，不能回滚。 关系型数据库中，提供了强大的事务处理能力，可以满足 ACID（Atomicity，Consistency，Isolation，Durability）的特性，这种特性保证了数据操作的强一致性，这也是分布式环境中弱一致性以及最终一致性能够得以实现的基础。 分布式事务的基础 数据库的 ACID 满足了数据库本地事务的基础，但是它无法满足分布式事务，这个时候衍生了CAP 和 BASE 两个经典理论。 CAP理论 参考 分布式-分布式系统的CAP理论 这一章节 BASE 理论 BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性 Basically Available（基本可用） 分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 Soft state（软状态） 允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。 Eventually consistent（最终一致性） 最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。 BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 对于大部分的分布式应用而言，只要数据在规定的时间内达到最终一致性即可。 我们可以把符合传统的 ACID 叫做刚性事务，把满足 BASE 理论的最终一致性事务叫做柔性事务。 一味的追求强一致性，并非最佳方案。对于分布式应用来说，刚柔并济是更加合理的设计方案，即在本地服务中采用强一致事务， 在跨系统调用中采用最终一致性，如何权衡系统的性能与一致性，是十分考验架构师与开发者的设计功力的。 具体到分布式事务的实现上，业界主要采用了 XA 协议的强一致规范以及柔性事务的最终一致规范，所以，市面上的分布式事务的解决方案，除了 XA 协议是强一致的，其他都是最终一致的。 什么是分布式事务 上面的数据库事务的处理是在一个数据库里面进行的，分布式微服务的出现使得这些服务需要分别操作不同的数据库和表，服务之间通过网络调用，所以这里就变成了跨服务跨数据库来处理事务了，也是要遵循上面的ACID特性 分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上，本质上来说，分布式事务就是为了保证不同数据库的数据一致性。 情况一： 单体应用涉及多个数据源 情况二： 多服务应用共用一个数据源 情况三： 多服务应用涉及多个数据源 分布式事务简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败 总结 这一章节介绍了分布式事务的一些基础理论，下一章节将介绍具体的分布式事务的解决方案 参考 https://juejin.im/post/5b5a0bf9f265da0f6523913b http://www.justdojava.com/2019/04/17/java-distributed-transaction/ https://www.infoq.cn/article/xa-transactions-handle https://cj466.top/plan/94.html https://blog.csdn.net/sinat_36596988/article/details/82149241 https://mp.weixin.qq.com/s?__biz=MzU3NDY4NzQwNQ==&amp;mid=2247484507&amp;idx=1&amp;sn=7d59417ee1a1ba47a54186edff8460b9&amp;chksm=fd2fd599ca585c8f498a996d26bde123e50adba2445629773be975a3c658e7139d2f8c21bd18&amp;scene=21 https://www.infoq.cn/article/2018/08/rocketmq-4.3-release","categories":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://www.songshuiyang.com/tags/分布式/"}]},{"title":"阿里巴巴Java编程规范","slug":"backend/java/standard/阿里巴巴Java编程规范","date":"2018-02-13T01:54:12.000Z","updated":"2020-03-16T11:43:55.521Z","comments":true,"path":"2018/02/13/backend/java/standard/阿里巴巴Java编程规范/","link":"","permalink":"http://www.songshuiyang.com/2018/02/13/backend/java/standard/阿里巴巴Java编程规范/","excerpt":"前言：关于《阿里巴巴Java开发手册》 你是否曾因Java代码规范版本纷杂而无所适从？ 你是否想过代码规范能将系统故障率降低20%？ 你是否曾因团队代码风格迥异而协同困难？ 你是否正在review一些原本可以避免的故障？ 你是否无法确定自己的代码足够健壮？","text":"前言：关于《阿里巴巴Java开发手册》 你是否曾因Java代码规范版本纷杂而无所适从？ 你是否想过代码规范能将系统故障率降低20%？ 你是否曾因团队代码风格迥异而协同困难？ 你是否正在review一些原本可以避免的故障？ 你是否无法确定自己的代码足够健壮？ 码出高效，码出质量！相比C++代码规范业界已经达成共识，Java代码规范业界比较混乱，我们期待这次发布的Java代码规范能够给业界带来一个标准，促使整体行业代码规范水平得到提高，最终能够帮助企业和开发者提升代码质量和降低代码故障率。 阿里出品，质量保证！阿里Java技术团队一手打造出Dubbo、JStorm、Fastjson等诸多流行开源框架，部分已成为Apache基金会孵化项目； 阿里在Java后端领域支撑起全球访问量最大的服务器集群； Java代码构建的阿里双11业务系统订单处理能力达到17.5万笔/秒； 到目前已累计数亿行高并发、高稳定性的最佳Java代码实践； …… 此次公开的Java开发手册正是出自这样的团队，近万名阿里Java技术精英的经验总结，并经历了多次大规模一线实战检验及完善，铸就了这本高含金量的阿里Java开发手册。该手册以Java开发者为中心视角，划分为编程规约、异常日志规约、MYSQL规约、工程规约、安全规约五大块，再根据内容特征，细分成若干二级子目录。根据约束力强弱和故障敏感性，规约依次分为强制、推荐、参考三大类。此套规范不仅能让代码一目了然， 更有助于加强团队分工与合作、真正提升效率。 无规矩不成方圆 无规范不能协作众所周知，制订交通法规表面上是要限制行车权，实际上是保障公众的人身安全。试想如果没有限速，没有红绿灯，没有规定靠右行驶，谁还敢上路行驶。 同理，对软件来说，适当的规范和标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的方式一起做事，降低故障率，提升协作效率。开发手册详细列举如何开发更加高效，更加容错，更加有协作性，力求知其然，更知其不然，结合正反例，提高代码质量。比如，异常日志处理时的各种不规范行为；集合转换的各种坑；创建线程池出现的等待队列OOM等。 阿里技术资深大咖联袂推荐阿里高级研究员多隆：工程师对于代码，一定要“精益求精”，不论从性能，还是简洁优雅，都要具备“精益求精”的工匠精神，认真打磨自己的作品。 阿里研究员毕玄：一个优秀的工程师和一个普通工程师的区别，不是现在满天飞的架构图，他的功底就是体现在他写的每一行代码上。 阿里研究员玄难：代码是软件工程里面的产品设计、系统架构设计等工作的最后承载体，代码的质量决定了一切工作的成败。 阿里巴巴B2B事业群CTO李纯：好的软件产品离不开工程师高质量的代码及相互间顺畅的沟通与合作。简单，适用的代码规约背后所传递的是技术上的追求卓越、协同合作的精神，是每个技术团队不可缺失的重要利器。 阿里研究员、HipHop作者：赵海平（花名：福贝）：程序员是创造个性化作品的艺术家，但同时也是需要团队合作的工种。个性化应尽量表现在代码效率和算法方面，牺牲小我，成就大我。 拥抱规范，远离伤害！开发的同学们赶紧行动起来，遵守代码规范，你好，我好，大家好！ 传送门 原文: https://yq.aliyun.com/articles/69327?spm=5176.100239.blogcont69327.158.xUUgiz&amp;p=2#comments 「阿里巴巴编码规范」考试认证 : https://edu.aliyun.com/certification/cldt02 点击下载《阿里巴巴Java开发手册》(纪念版): https://yq.aliyun.com/attachment/download/?id=4942 IDE插件下载 : https://github.com/alibaba/p3c 以下记录以下自己需要注意的一些规范, 遵守代码规范，你好，我好，大家好！编程规约命名风格 【强制】 抽象类命名使用 Abstract 或 Base 开头； 异常类命名使用 Exception 结尾； 测试类命名以它要测试的类的名称开始，以 Test 结尾。 【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。 正例： MAX_STOCK_COUNT 反例： MAX_COUNT 【强制】 POJO 类中布尔类型的变量，都不要加 is，否则部分框架解析会引起序列化错误。 反例： 定义为基本数据类型 Boolean isDeleted； 的属性，它的方法也是 isDeleted()， RPC 框架在反向解析的时候， “以为”对应的属性名称是 deleted，导致属性获取不到，进而抛出异 常。 【强制】杜绝完全不规范的缩写， 避免望文不知义。 反例： AbstractClass“缩写” 命名成 AbsClass； condition“缩写” 命名成 condi，此类随意缩写严重降低了代码的可阅读性。 【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组合来表达其意。 正例： 从远程仓库拉取代码的类命名为 PullCodeFromRemoteRepository。 反例： 变量 int a; 的随意命名方式。 【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加） ，保持代码的简洁性，并加上有效的 Javadoc 注释。尽量不要在接口里定义变量，如果一定要定义变量，肯定是与接口方法相关，并且是整个应用的基础常量。 正例： 接口方法签名： void f(); 接口基础常量表示： String COMPANY = “alibaba”; 反例： 接口方法定义： public abstract void f(); 说明： JDK8 中接口允许有默认实现，那么这个 default 方法，是对所有实现类都有价值的默认实现。 【参考】枚举类名建议带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开。说明： 枚举其实就是特殊的常量类，且构造方法被默认强制是私有。 正例： 枚举名字为 ProcessStatusEnum 的成员名称： SUCCESS / UNKOWN_REASON。 【参考】各层命名规约： A) Service/DAO 层方法命名规约 1） 获取单个对象的方法用 get 做前缀。 2） 获取多个对象的方法用 list 做前缀。 3） 获取统计值的方法用 count 做前缀。 4） 插入的方法用 save/insert 做前缀。 5） 删除的方法用 remove/delete 做前缀。 6） 修改的方法用 update 做前缀。 B) 领域模型命名规约 1） 数据对象： xxxDO， xxx 即为数据表名。 2） 数据传输对象： xxxDTO， xxx 为业务领域相关的名称。 3） 展示对象： xxxVO， xxx 一般为网页名称。 4） POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。 常量定义 【强制】不允许任何魔法值（即未经定义的常量） 直接出现在代码中。 反例： String key = “Id#taobao_” + tradeId; cache.put(key, value); 【推荐】不要使用一个常量类维护所有常量， 按常量功能进行归类，分开维护。 说明： 大而全的常量类，非得使用查找功能才能定位到修改的常量，不利于理解和维护。 正例： 缓存相关常量放在类 CacheConsts 下； 系统配置相关常量放在类 ConfigConsts 下。 代码格式1.示例 123456789101112131415161718public static void main(String[] args) &#123; // 缩进 4 个空格 String say = \"hello\"; // 运算符的左右必须有一个空格 int flag = 0;阿里巴巴 Java 开发手册 // 关键词 if 与括号之间必须有一个空格，括号内的 f 与左括号， 0 与右括号不需要空格 if (flag == 0) &#123; System.out.println(say); &#125; // 左大括号前加空格且不换行；左大括号后换行 if (flag == 1) &#123; System.out.println(\"world\"); // 右大括号前换行，右大括号后有 else，不用换行 &#125; else &#123; System.out.println(\"ok\"); // 在右大括号后直接结束，则必须换行 &#125;&#125; 2.【强制】 注释的双斜线与注释内容之间有且仅有一个空格。 正例： // 注释内容， 注意在//和注释内容之间有一个空格。 3.【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则： 1） 第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。 2） 运算符与下文一起换行。 3） 方法调用的点符号与下文一起换行。 4） 方法调用时，多个参数， 需要换行时， 在逗号后进行。 5） 在括号前不要换行，见反例。 正例：123456StringBuffer sb = new StringBuffer();// 超过 120 个字符的情况下，换行缩进 4 个空格， 点号和方法名称一起换行sb.append(\"zi\").append(\"xin\")... .append(\"huang\")... .append(\"huang\")... .append(\"huang\"); 反例： 1234567StringBuffer sb = new StringBuffer();// 超过 120 个字符的情况下，不要在括号前换行sb.append(\"zi\").append(\"xin\")...append (\"huang\");// 参数很多的方法调用可能超过 120 个字符， 不要在逗号前换行method(args1, args2, args3, ... , argsX); 4.【强制】方法参数在定义和传入时，多个参数逗号后边必须加空格。 正例： 下例中实参的”a”,后边必须要有一个空格。 method(“a”, “b”, “c”);5.【推荐】方法体内的执行语句组、变量的定义语句组、不同的业务逻辑之间或者不同的语义 之间插入一个空行。相同业务逻辑和语义之间不需要插入空行。 说明： 没有必要插入多个空行进行隔开 注释规范 【强制】类、类属性、类方法的注释必须使用 Javadoc 规范，使用/*内容/格式，不得使用// xxx 方式。 说明： 在 IDE 编辑窗口中， Javadoc 方式会提示相关注释，生成 Javadoc 可以正确输出相应注释； 在 IDE 中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率 【强制】所有的抽象方法（包括接口中的方法） 必须要用 Javadoc 注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能。 说明： 对子类的实现要求，或者调用注意事项，请一并说明 【强制】所有的类都必须添加创建者和创建日期。 【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改 【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。1） 待办事宜（TODO） :（标记人，标记时间， [预计处理时间]）表示需要实现，但目前还未实现的功能。这实际上是一个 Javadoc 的标签，目前的 Javadoc还没有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个 Javadoc 标签） 。2） 错误，不能工作（FIXME） :（标记人，标记时间， [预计处理时间]）在注释中用 FIXME 标记某代码是错误的，而且不能工作，需要及时纠正的情况。 异常处理 【强制】有 try 块放到了事务代码中， catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。 【强制】有 try 块放到了事务代码中， catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。 MySQL 数据库 建表规约1.【强制】表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint（1 表示是， 0 表示否） 。 说明： 任何字段如果为非负数，必须是 unsigned。 正例： 表达逻辑删除的字段名 is_deleted， 1 表示删除， 0 表示未删除 2.【强制】 varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长 度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索 引效率。3.【强制】表必备三字段： id, gmt_create, gmt_modified。 说明： 其中 id 必为主键，类型为 unsigned bigint、单表时自增、步长为 1。 gmt_create,gmt_modified 的类型均为 datetime 类型，前者现在时表示主动创建，后者过去分词表示被 动更新4.【推荐】表的命名最好是加上“业务名称表的作用”。 正例： alipay_task / force_project / trade_config5.【强制】业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。 说明： 不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明 显的； 另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必 然有脏数据产生6.【强制】超过三个表禁止 join。需要 join 的字段，数据类型必须绝对一致； 多表关联查询时， 保证被关联的字段需要有索引。 说明： 即使双表 join 也要注意表索引、 SQL 性能 MySQL 数据库 SQL语句 【强制】不要使用 count(列名)或 count(常量)来替代 count()， count()是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。说明： count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"解决CSS和JS文件的客户端缓存问题","slug":"frontend/CSS和JS文件的客户端缓存问题","date":"2018-02-10T03:48:12.000Z","updated":"2019-09-16T13:11:07.249Z","comments":true,"path":"2018/02/10/frontend/CSS和JS文件的客户端缓存问题/","link":"","permalink":"http://www.songshuiyang.com/2018/02/10/frontend/CSS和JS文件的客户端缓存问题/","excerpt":"","text":"场景做项目的时候，发现自己修改了一个css文件但样式并没有应用，查看http请求(如下图)，注意这个参数Status Code:200 OK (from disk cache) , 说明文件是是之前浏览器缓存的文件，浏览器并没有请求我们新改的文件1234Request URL:http://localhost:8080/static/layui/build/css/app.cssRequest Method:GETStatus Code:200 OK (from disk cache)Remote Address:127.0.0.1:8080Referrer Policy:no-referrer-when-downgrade 解决方法 发现问题了，现在就是要解决如果是服务器js css等文件修改了，怎样让浏览器能够请求我们最新的文件, 通过查看其他人的解决方法，还有看了一下大厂百度, 淘宝 , 新浪 对这个问题的处理，总结了一下下面几种方法: 方法一: 在css文件上, js文件后面加上版本号?v=12453651&lt;link rel=\"stylesheet\" href=\"$&#123;ctx&#125;static/admin/css/main.css?v=1245365\" media=\"all\" /&gt; 如果是经常更新的css文件版本号可以取当前时间的时间戳 v=1518237859338 ,这样就可以每次都获取到最新的文件，但缺点就是每次刷新页面都会请求该文件，在项目开发过程中可以使用这种方式 如果是更新频率不高的的文件，可以取: v=20180210 , 这样的话刷新页面就不会每次请求这个文件了，可以减轻服务器的压力 如果是项目稳定了基本没有改动了，可以取一个固定值:v=0.0.1 方法二：一个版本一个文件夹 淘宝的做法: 用一个文件 6.2.31https://g.alicdn.com/kg/??component/6.2.3/extension/content-box/xtpl/view.xtpl-min.js","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"js","slug":"js","permalink":"http://www.songshuiyang.com/tags/js/"},{"name":"css","slug":"css","permalink":"http://www.songshuiyang.com/tags/css/"}]},{"title":"Redis-高可用集群","slug":"backend/cache/redis/Redis-高可用集群","date":"2018-02-03T16:00:06.000Z","updated":"2020-01-04T12:21:52.023Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-高可用集群/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-高可用集群/","excerpt":"","text":"前言Redis 集群方案 1、Redis Sentinel 2、Redis Cluster 3、Twemproxy 4、Codis 5、客户端分片 解析Redis 主从同步 Redis 主从同步，是很多 Redis 集群方案的基础，例如 Redis Sentinel、Redis Cluster 等等，所以我们先来了解Redis的主从同步功能 Redis的主从同步机制允许slave从master那里通过网络传输拷贝到完整的数据备份，从而达到主从机制。为了实现主从复制，我们准备三个redis服务，依次命名为master，slave1，slave2。 配置主服务器 为了测试效果，我们先修改master主服务器的配置文件redis.conf的端口信息 1port 6300 配置从服务器 先修改slave1从服务器的配置文件redis.conf的端口信息和从服务器配置 12port 6301slaveof 127.0.0.1 6300 再修改slave2从服务器的配置文件redis.conf的端口信息和从服务器配置 12port 6302slaveof 127.0.0.1 6300 值得注意的是，从redis2.6版本开始，slave支持只读模式，而且是默认的。可以通过配置项slave-read-only来进行配置。 此外，如果master通过requirepass配置项设置了密码，slave每次同步操作都需要验证密码，可以通过在slave的配置文件中添加以下配置项masterauth &lt;password&gt; Redis Sentinel 哨兵 官方中文文档 上面的主从机制方案中主服务器可能存在单点故障，万一主服务器宕机，这是个麻烦事情，所以Redis提供了Redis-Sentinel，以此来实现主从切换的功能，类似与zookeeper。 Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，当用Redis做master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换。 而Redis-Sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。 它的主要功能有以下几点 监控（Monitoring）：不断地检查redis的主服务器和从服务器是否运作正常。 提醒（Notification）：如果发现某个redis服务器运行出现状况，可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移（Automatic failover）：能够进行自动切换。当一个主服务器不能正常工作时，会将失效主服务器的其中一个从服务器升级为新的主服务器，并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 配置Sentinel Redis Sentinel 兼容 Redis 2.4.16 或以上版本， 推荐使用 Redis 2.8.0 或以上的版本。 必须指定一个sentinel的配置文件sentinel.conf，如果不指定将无法启动Sentinel。首先，我们先创建一个配置文件sentinel.conf 12port 26379sentinel monitor master 127.0.0.1 6300 2 官方典型的配置如下 123456789sentinel monitor mymaster 127.0.0.1 6379 2 # 这行配置指示 Sentinel 去监视一个名为 mymaster 的主服务器， 这个主服务器的 IP 地址为 127.0.0.1 ， 端口号为 6300， 而将这个主服务器判断为失效至少需要 2 个 Sentinel 同意，只要同意 Sentinel 的数量不达标，自动故障迁移就不会执行。sentinel down-after-milliseconds mymaster 60000 # 指定了 Sentinel 认为服务器已经断线所需的毫秒数。sentinel failover-timeout mymaster 180000 sentinel parallel-syncs mymaster 1 # 指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。 sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5 配置文件介绍 配置文件只需要配置master的信息就好啦，不用配置slave的信息，因为slave能够被自动检测到(master节点会有关于slave的消息)。 需要注意的是，配置文件在sentinel运行期间是会被动态修改的，例如当发生主备切换时候，配置文件中的master会被修改为另外一个slave。这样，之后sentinel如果重启时，就可以根据这个配置来恢复其之前所监控的redis集群的状态。 启动Sentinel 下面两种方式都必须指定一个sentinel的配置文件sentinel.conf， 如果不指定将无法启动sentinel，sentinel默认监听26379端口，所以运行前必须确定该端口没有被别的进程占用。 对于 redis-sentinel 程序， 你可以用redis-sentinel sentinel.conf命令来启动 Sentinel 系统 对于 redis-server 程序， 你可以用redis-server sentinel.conf --sentinel命令来启动一个运行在 Sentinel 模式下的 Redis 服务器 Redis Cluster设计原则和初衷 在官方文档Cluster Spec中，作者详细介绍了Redis集群为什么要设计成现在的样子 最核心的目标有三个： 性能：这是Redis赖以生存的看家本领，增加集群功能后当然不能对性能产生太大影响，所以Redis采取了P2P模式完全去中心化而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。 水平扩展：集群的最重要能力当然是扩展，文档中称可以线性扩展到1000结点。 可用性：在Cluster推出之前，可用性要靠Sentinel保证。有了集群之后也自动具有了Sentinel的监控和自动Failover能力。 它采用了P2P的模式，完全去中心化。支持多节点数据集自动分片，提供一定程度的分区可用性，部分节点挂掉或者无法连接其他节点后，服务可以正常运行。Redis 3.0集群采用Hash Slot方案，而不是一致性哈希。Redis把所有的Key分成了16384个slot，每个Redis实例负责其中一部分slot。集群中的所有信息（节点、端口、slot等），都通过节点之间定期的数据交换而更新。 Redis客户端在任意一个Redis实例发出请求，如果所需数据不在该实例中，通过重定向命令引导客户端访问所需的实例。 Redis 3.0集群，目前支持的cluster特性 节点自动发现 slave-&gt;master 选举,集群容错 Hot resharding:在线分片 集群管理:cluster xxx 基于配置(nodes-port.conf)的集群管理 ASK 转向/MOVED 转向机制 如上图所示，所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。节点的fail是通过集群中超过半数的节点检测失效时才生效。客户端与redis节点直连，不需要中间proxy层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。redis-cluster把所有的物理节点映射到[0-16383]slot上cluster负责维护node&lt;-&gt;slot&lt;-&gt;value。 选举过程是集群中所有master参与，如果半数以上master节点与master节点通信超时，认为当前master节点挂掉。 当集群不可用时，所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误。如果集群任意master挂掉，且当前master没有slave，集群进入fail状态，也可以理解成进群的slot映射[0-16383]不完成时进入fail状态。如果进群超过半数以上master挂掉，无论是否有slave集群进入fail状态。 Twemproxy Twemproxy是由Twitter开源的Redis代理， Redis客户端把请求发送到Twemproxy，Twemproxy根据路由规则发送到正确的Redis实例，最后Twemproxy把结果汇集返回给客户端。 Twemproxy通过引入一个代理层，将多个Redis实例进行统一管理，使Redis客户端只需要在Twemproxy上进行操作，而不需要关心后面有多少个Redis实例，从而实现了Redis集群。 Twemproxy本身也是单点，需要用Keepalived做高可用方案。 这么些年来，Twenproxy作为应用范围最广、稳定性最高、最久经考验的分布式中间件，在业界广泛使用。 但是Twemproxy存在诸多不方便之处，最主要的是，Twemproxy无法平滑地增加Redis实例，业务量突增，需增加Redis服务器；业务量萎缩，需要减少Redis服务器。但对Twemproxy而言，基本上都很难操作。其次，没有友好的监控管理后台界面，不利于运维监控。 Codis Codis解决了Twemproxy的这两大痛点，由豌豆荚于2014年11月开源，基于Go和C开发、现已广泛用于豌豆荚的各种Redis业务场景。 Codis引入了Group的概念，每个Group包括1个Redis Master及一个或多个Redis Slave，这是和Twemproxy的区别之一，实现了Redis集群的高可用。当1个Redis Master挂掉时，Codis不会自动把一个Slave提升为Master，这涉及数据的一致性问题，Redis本身的数据同步是采用主从异步复制，当数据在Maste写入成功时，Slave是否已读入这个数据是没法保证的，需要管理员在管理界面上手动把Slave提升为Master。 Codis使用，可以参考官方文档https://github.com/CodisLabs/codis/blob/release3.0/doc/tutorial_zh.md 参考 http://www.iocoder.cn http://blog.720ui.com/2016/redis_action_04_cluster/ https://blog.csdn.net/dc_726/article/details/48552531","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"Redis-数据淘汰策略","slug":"backend/cache/redis/Redis-数据淘汰策略","date":"2018-02-03T16:00:05.000Z","updated":"2020-01-04T12:21:52.012Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-数据淘汰策略/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-数据淘汰策略/","excerpt":"","text":"前言内存大小 我们知道Redis是基于内存的key-value数据库，因为系统的内存大小有限，所以我们在使用Redis的时候可以配置Redis能使用的最大的内存大小。 如果不设置最大内存大小或者设置最大内存大小为0，在64位操作系统下不限制内存大小，在32位操作系统下最多使用3GB内存 设置最大内存大小 1、获取设置的Redis能使用的最大内存大小 config get maxmemory 命令可以获取设置的Redis能使用的最大内存大小，Redis中默认是0，所以是不限制内存大小，依赖于硬件内存大小 2、通过配置文件配置 通过在Redis安装目录下面的redis.conf配置文件中添加以下配置设置内存大小 12// 设置Redis最大占用内存大小为100Mmaxmemory 100mb 3、通过命令修改 Redis支持运行时通过命令动态修改内存大小 1234// 设置Redis最大占用内存大小为100M127.0.0.1:6379&gt; config set maxmemory 100mb// 获取设置的Redis能使用的最大内存大小127.0.0.1:6379&gt; config get maxmemory 过期策略 Redis 的过期策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理 如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？ 定期删除：redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！ 惰性删除 ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！ 仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ redis 内存淘汰机制。 实际上Redis定义了几种策略用来处理这种情况： noe-viction(默认策略)：对于写请求不再提供服务，直接返回错误（DEL请求和部分特殊请求除外） allkeys-lru：从所有key中使用LRU算法进行淘汰 volatile-lru：从设置了过期时间的key中使用LRU算法进行淘汰 allkeys-random：从所有key中随机淘汰数据 volatile-random：从设置了过期时间的key中随机淘汰 其他总结参考 https://snailclimb.gitee.io/javaguide/#/docs/database/Redis/Redis http://www.iocoder.cn/Fight/Cannot-think-of-The-interviewer-asked-me-what-if-Redis-runs-out-of-memory/?self","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"Redis-线程模型","slug":"backend/cache/redis/Redis-线程模型","date":"2018-02-03T16:00:04.000Z","updated":"2020-03-16T13:05:29.698Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-线程模型/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-线程模型/","excerpt":"","text":"前言高性能服务器 一定是 多线程来实现的？ 以前一直有个误区，以为：高性能服务器 一定是 多线程来实现的，原因很简单：因为误区二导致的：多线程 一定比 单线程 效率高，其实不然 在说这个事前希望大家都能对 CPU 、 内存 、 硬盘的速度都有了解了，这样可能理解得更深刻一点 1.顺序访问：这种情况下，内存访问速度仅仅是硬盘访问速度的6~7倍（358.2M / 53.2M = 6.7） 2.随机访问：这种情况下，内存访问速度就要比硬盘访问速度快上10万倍以上 （36.7M / 316 = 113,924） redis 核心就是 如果我的数据全都在内存里，我单线程的去操作 就是效率最高的，为什么呢，因为多线程的本质就是 CPU 模拟出来多个线程的情况，这种模拟出来的情况就有一个代价，就是上下文的切换，对于一个内存的系统来说，它没有上下文的切换就是效率最高的。redis 用 单个CPU 绑定一块内存的数据，然后针对这块内存的数据进行多次读写的时候，都是在一个CPU上完成的，所以它是单线程处理这个事。在内存的情况下，这个方案就是最佳方案 —— 阿里 沈询 因为一次CPU上下文的切换大概在 1500ns 左右。 从内存中读取 1MB 的连续数据，耗时大约为 250us，假设1MB的数据由多个线程读取了1000次，那么就有1000次时间上下文的切换， 那么就有1500ns * 1000 = 1500us ，我单线程的读完1MB数据才250us ,你光时间上下文的切换就用了1500us了，我还不算你每次读一点数据 的时间， 那什么时候用多线程的方案呢？ 答案是：下层的存储等慢速的情况。比如磁盘 内存是一个 IOPS 非常高的系统，因为我想申请一块内存就申请一块内存，销毁一块内存我就销毁一块内存，内存的申请和销毁是很容易的。而且内存是可以动态的申请大小的。 磁盘的特性是：IPOS很低很低，但吞吐量很高。这就意味着，大量的读写操作都必须攒到一起，再提交到磁盘的时候，性能最高。为什么呢？ 如果我有一个事务组的操作（就是几个已经分开了的事务请求，比如写读写读写，这么五个操作在一起），在内存中，因为IOPS非常高，我可以一个一个的完成，但是如果在磁盘中也有这种请求方式的话， 我第一个写操作是这样完成的：我先在硬盘中寻址，大概花费10ms，然后我读一个数据可能花费1ms然后我再运算（忽略不计），再写回硬盘又是10ms ，总共21ms 第二个操作去读花了10ms, 第三个又是写花费了21ms ,然后我再读10ms, 写21ms ，五个请求总共花费83ms，这还是最理想的情况下，这如果在内存中，大概1ms不到。 所以对于磁盘来说，它吞吐量这么大，那最好的方案肯定是我将N个请求一起放在一个buff里，然后一起去提交。 方法就是用异步：将请求和处理的线程不绑定，请求的线程将请求放在一个buff里，然后等buff快满了，处理的线程再去处理这个buff。然后由这个buff 统一的去写入磁盘，或者读磁盘，这样效率就是最高。java里的 IO不就是这么干的么~ 对于慢速设备，这种处理方式就是最佳的，慢速设备有磁盘，网络 ，SSD 等等， 多线程 ，异步的方式处理这些问题非常常见，大名鼎鼎的netty 就是这么干的。 顺便再提一句：redis 的瓶颈在网络上 。。。。 解析 Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。 文件事件处理器的结构包含 4 个部分： 多个 Socket 。 IO 多路复用程序。 文件事件分派器。 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。 多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。 上图是客户端与 redis 的一次通信过程： 客户端 Socket01 向 Redis 的 Server Socket 请求建立连接，此时 Server Socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 Socket01，并将该 Socket01 的 AE_READABLE 事件与命令请求处理器关联。 假设此时客户端发送了一个 set key value 请求，此时 Redis 中的 Socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 Socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 Scket01 的 set key value 并在自己内存中完成 set key value 的设置。操作完成后，它会将 Scket01 的 AE_WRITABLE 事件与令回复处理器关联。 如果此时客户端准备好接收返回结果了，那么 Redis 中的 Socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 Socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。 总结 Redis 是非阻塞 IO ，多路复用。 为什么 Redis 效率这么高 1、C 语言实现：我们都知道，C 语言的执行速度非常快。 2、纯内存操作：Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征，如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。 3、基于非阻塞的 IO 多路复用机制。 4、单线程，避免了多线程的频繁上下文切换问题。 Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销。 单线程无需考虑并发的问题。 5、丰富的数据结构。 Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化。例如，压缩表，对短数据进行压缩存储 参考 http://www.iocoder.cn https://mp.weixin.qq.com/s/O1dY6sFjtN2SL3WcHRKlOA https://blog.csdn.net/pan_tian/article/details/10306003","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"Redis-持久化存储RBD-AOF","slug":"backend/cache/redis/Redis-持久化存储RBD-AOF","date":"2018-02-03T16:00:03.000Z","updated":"2020-03-16T12:57:40.786Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-持久化存储RBD-AOF/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-持久化存储RBD-AOF/","excerpt":"","text":"前言 Redis虽然是一种内存型数据库，一旦服务器进程退出，数据库的数据就会丢失，为了解决这个问题Redis提供了两种持久化的方案，将内存中的数据保存到磁盘中，避免数据的丢失。 1、【全量】RDB 持久化，是指在指定的时间间隔内将内存中的数据集快照写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 2、【增量】AOF持久化，以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 RDB持久化是redis默认的 解析【全量】RDB 持久化工作流程 【全量】RDB 持久化用来生成某一个时间点的数据快照，会生成一个经过压缩的二进制文件，服务器只会保存一个RDB文件 RDB 文件生成 每次进行RDB持久化时，redis都是将内存中完成的数据写到文件中，不是增量的持久化； 写RDB文件时，先把内存中数据写到临时文件，然后替换原来的RDB文件； RDB持久化可以手动执行，也可以按照服务器的配置定期自动执行。 1）save和bgsave命令：（手动用于生成RDB文件的命令） save：会阻塞redis服务器进程，直到创建RDB文件完毕为止；（在此期间进程不能处理任何请求） bgsave：fork一个子进程来创建RDB文件，父进程可以继续处理命令请求； 2）定期自动执行： redis服务器允许用户通过设置配置文件save选项，让服务器每隔一段时间自动执行一次bgsave命令 RDB 文件载入 redis并没有专门的命令去载入RDB文件，只有在服务器启动的时候检测到RDB文件存在就会自动执行载入。 如果redis启用了AOF持久化功能，那么服务器优先使用AOF文件还原数据。 当服务器载入RDB文件时，会一直处于阻塞状态，直到载入完毕为止。 载入时RDB文件时,系统会自动检查、如果是过期键不会加载到数据库中。 优点 可以灵活设置备份频率和周期。你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 非常适合冷备份，对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。推荐，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 OSS 分布式存储上。 性能最大化。对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。 恢复更快。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。 缺点 容易造成数据丢失 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 所以RDB 在实际场景下，需要和 AOF 一起使用。 会出现服务停止的情况 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。 所以，RDB 建议在业务低估，例如在半夜执行。 【增量】AOF持久化 有上面分析可知：RDB方式持久化的颗粒比较大，当服务器宕机时，到上次save或bgsave后的所有数据都会丢失。而AOF的持久化颗粒比较细，当服务器宕机后，只有宕机之前没来得AOF的操作数据会丢失。 工作流程 AOF持久化是通过保存redis服务器所执行的写命令来记录数据库状态的；被写入AOF文件的所有命令都是以Redis的命令请求协议格式保存的（Redis的请求协议是纯文本的）。服务器在启动时，通过载入AOF文件、并执行其中的命令来还原服务器状态。 AOF 添加记录 命令追加：服务器在执行玩一个写命令后，会以协议的格式把其追加到aof_buf缓冲区末尾； 文件写入：redis服务器进程就是一个事件循环，在每次事件循环结束，会根据配置文件中的appednfsync属性值决定是否将aof_buf中的数据写入到AOF文件中； 文件同步：将内存缓冲区的数据写到磁盘；（由于OS的特性导致） 优点 该机制可以带来更高的数据安全性，即数据持久性。Redis 中提供了 3 种同步策略，即每秒同步、每修改(执行一个命令)同步和不同步。 事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。 而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。 至于不同步，无需多言，我想大家都能正确的理解它。 缺点 对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。 以前 AOF 发生过 bug ，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。 其他Redis 4.0 对于持久化机制的优化 Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 总结 bgsave 做镜像全量持久化，AOF 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。 果突然机器掉电会怎样？取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。 实际上，极端情况下，是最多丢失 2 秒的数据。因为 AOF 线程，负责每秒执行一次 fsync 操作，操作完成后，记录最后同步时间。主线程，负责对比上次同步时间，如果超过 2 秒，阻塞等待成功。 bgsave 的原理是fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 不建议在主 Redis 节点开启 RDB 功能呢？因为会带来一定时间的阻塞，特别是数据量大的时候。 参考 http://www.iocoder.cn https://lanjingling.github.io/2015/11/16/redis-chijiuhua/","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"Redis-使用-队列操作","slug":"backend/cache/redis/Redis-使用-队列操作","date":"2018-02-03T16:00:01.000Z","updated":"2020-04-11T12:23:47.813Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-使用-队列操作/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-使用-队列操作/","excerpt":"","text":"12345678910111213141516171819public class Tests &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test1 () &#123; for (int i = 1; i &lt; 20; i ++) &#123; stringRedisTemplate.opsForList().rightPush(\"list_order\", String.valueOf(i)); &#125; for (int i = 1; i &lt; 20; i ++) &#123; log.info(stringRedisTemplate.opsForList().leftPop(\"list_order\")); &#125; &#125;&#125; 参考","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"Redis-常用命令","slug":"backend/cache/redis/Redis-常用命令","date":"2018-02-03T16:00:01.000Z","updated":"2019-11-10T02:08:41.532Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-常用命令/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-常用命令/","excerpt":"","text":"5种基本数据类型命令String(字符串)1234567891011121314151617181920212223242526本地:0&gt;SET name songsy\"OK\"本地:0&gt;GET name\"songsy\"// 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。本地:0&gt;GETSET name songshuiyang\"songsy\"// 将值 value 关联到 key ，并将 key 的过期时间设为 10 seconds (以秒为单位)。本地:0&gt;SETEX cache 10 value11 \"OK\"// 只有在 key 不存在时设置 key 的值。本地:0&gt;SETNX name lihao\"0\"// 将 key 中储存的数字值加减本地:0&gt;SET numberKey \"1\"\"OK\"本地:0&gt;INCR numberKey\"2\"本地:0&gt;DECR numberKey\"1\" Hash(字典)123456127.0.0.1:6379&gt; HMSET person1 name \"songsy\" age 3 adderss \"jiangxi\"OK127.0.0.1:6379&gt; HGET person1 name\"songsy\"127.0.0.1:6379&gt; HGET person1 age\"3\" List(列表)12345678910127.0.0.1:6379&gt; LPUSH queue person1(integer) 1127.0.0.1:6379&gt; LPUSH queue person2(integer) 2127.0.0.1:6379&gt; LPUSH queue person3(integer) 3127.0.0.1:6379&gt; LRANGE queue 0 101) \"person3\"2) \"person2\"3) \"person1\" Set(集合)123456789101112127.0.0.1:6379&gt; SADD setKey b1(integer) 1127.0.0.1:6379&gt; SADD setKey b2(integer) 1127.0.0.1:6379&gt; SADD setKey b3(integer) 1127.0.0.1:6379&gt; SADD setKey b2(integer) 0127.0.0.1:6379&gt; SMEMBERS setKey1) \"b3\"2) \"b2\"3) \"b1\" Zset Sorted Set(有序集合)12345678910111213127.0.0.1:6379&gt; ZADD zsetKey 2 name1(integer) 1127.0.0.1:6379&gt; ZADD zsetKey 5 name2(integer) 1127.0.0.1:6379&gt; ZADD zsetKey 1 name3(integer) 1127.0.0.1:6379&gt; ZADD zsetKey 7 name4(integer) 1127.0.0.1:6379&gt; ZRANGE zsetKey 0 101) \"name3\"2) \"name1\"3) \"name2\"4) \"name4\" Redis 发布订阅 Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 示例 先开个redis 客户端，执行创建订阅频道名为 redisChat的命令 123456redis 127.0.0.1:6379&gt; SUBSCRIBE redisChatReading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"redisChat\"3) (integer) 1 再开个 redis 客户端，然后在同一个频道 redisChat 发布两次消息，订阅者就能接收到消息 123456789101112131415redis 127.0.0.1:6379&gt; PUBLISH redisChat \"Redis is a great caching technique\"(integer) 1redis 127.0.0.1:6379&gt; PUBLISH redisChat \"Learn redis by runoob.com\"(integer) 1# 订阅者的客户端会显示如下消息1) \"message\"2) \"redisChat\"3) \"Redis is a great caching technique\"1) \"message\"2) \"redisChat\"3) \"Learn redis by runoob.com\" 参考 https://www.runoob.com/redis","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"Redis-基础概念","slug":"backend/cache/redis/Redis-基础概念","date":"2018-02-03T16:00:00.000Z","updated":"2019-11-10T02:08:41.516Z","comments":true,"path":"2018/02/04/backend/cache/redis/Redis-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/02/04/backend/cache/redis/Redis-基础概念/","excerpt":"","text":"前言什么是 Redis ？ Redis ，全称 Remote Dictionary Server ，是一个基于内存的高性能 Key-Value 数据库。 Redis 已经成为互联网公司在缓存组件选择的唯一。例如说，在各种公有云上，缓存服务都是提供的 Redis。再例如说，招聘简历要求上，都会要求掌握 Redis 。 解析Redis 数据类型 类型 简介 特性 场景 其他 String(字符串) redis最基本的类型，一个 key 对应一个 value 1、二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 2、最大能存储 512MB 最常使用 Hash(字典) hash 是一个键值(key=&gt;value)对集合 1、hash 特别适合用于存储对象，并且可以像数据库中update一个属性一样只修改某一项属性值 存储、读取、修改用户属性 List(列表) Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 增删快,提供了操作某一段元素的API 1、最新消息排行等功能(比如朋友圈的时间线) 2、消息队列 Set(集合) Set 是 string 类型的无序集合，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 Zset Sorted Set(有序集合) Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 数据插入集合时,已经进行天然排序 1、排行榜 2、带权重的消息队列 Redis 有什么优点 1、速度快 日常业务中，我们使用比较多的数据库是 MySQL ，缓存是 Redis 。一起来看看，阿里云提供的性能规格： Redis 性能规格，https://help.aliyun.com/document_detail/26350.html 。打底 8W QPS ，最高可达千万 QPS 。 MySQL 性能规格 https://help.aliyun.com/document_detail/53637.html 。打底 1.4K QPS ，最高 7W QPS 。 2、支持丰富数据类型 String(字符串) Hash(哈希) list(列表) sets(集合) sorted sets(有序集合) 3、丰富的特性 订阅发布 Pub / Sub 功能 Key 过期策略 事务 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作 中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 支持多个 DB Redis支持多个数据库，并且每个数据库的数据是隔离的不能共享，并且基于单机才有，如果是集群就没有数据库的概念。 客户端与Redis建立连接后会自动选择0号数据库，不过可以随时使用SELECT命令更换数据库，如要选择1号数据库：SELECT 1 4、持久化存储 Redis 提供 RDB 和 AOF两种数据的持久化存储方案，解决内存数据库最担心的万一 Redis 挂掉，数据会消失掉。 Redis 有什么缺点？ 1、由于 Redis 是内存数据库，所以单台机器存储的数据量跟机器本身的内存大小有关 2、如果进行完整重同步，由于需要生成 RDB 文件，并进行传输，会占用主机的 CPU ，并会消耗现网的带宽。不过 Redis2.8 版本，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如，新上线的备机。 3、修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，Redis 不能提供服务。 Redis 使用场景 随着数据量的增长，MySQL 已经满足不了大型互联网类应用的需求。因此，Redis 基于内存存储数据，可以极大的提高查询性能，对产品在架构上很好的补充。 在某些场景下，可以充分的利用 Redis 的特性，大大提高效率。 0、缓存 对于热点数据，缓存以后可能读取数十万次，因此，对于热点数据，缓存的价值非常大。例如，分类栏目更新频率不高，但是绝大多数的页面都需要访问这个数据，因此读取频率相当高，可以考虑基于 Redis 实现缓存。 1、会话缓存 此外，还可以考虑使用 Redis 进行会话缓存。例如，将 web session 存放在 Redis 中。 2、时效性 例如验证码只有60秒有效期，超过时间无法使用，或者基于 Oauth2 的 Token 只能在 5 分钟内使用一次，超过时间也无法使用。 3、访问频率 出于减轻服务器的压力或防止恶意的洪水攻击的考虑，需要控制访问频率，例如限制 IP 在一段时间的最大访问量。 4、计数器 数据统计的需求非常普遍，通过原子递增保持计数。例如，应用数、资源数、点赞数、收藏数、分享数等。 5、社交列表 社交属性相关的列表信息，例如，用户点赞列表、用户分享列表、用户收藏列表、用户关注列表、用户粉丝列表等，使用 Hash 类型数据结构是个不错的选择。 6、记录用户判定信息 记录用户判定信息的需求也非常普遍，可以知道一个用户是否进行了某个操作。例如，用户是否点赞、用户是否收藏、用户是否分享等。 7、交集、并集和差集 在某些场景中，例如社交场景，通过交集、并集和差集运算，可以非常方便地实现共同好友，共同关注，共同偏好等社交关系。 8、热门列表与排行榜 按照得分进行排序，例如，展示最热、点击率最高、活跃度最高等条件的排名列表。 9、最新动态 按照时间顺序排列的最新动态，也是一个很好的应用，可以使用 Sorted Set 类型的分数权重存储 Unix 时间戳进行排序。 10、消息队列 Redis 能作为一个很好的消息队列来使用，依赖 List 类型利用 LPUSH 命令将数据添加到链表头部，通过 BRPOP 命令将元素从链表尾部取出。同时，市面上成熟的消息队列产品有很多，例如 RabbitMQ。因此，更加建议使用 RabbitMQ 作为消息中间件。 参考 http://www.iocoder.cn https://www.runoob.com/redis http://blog.720ui.com/2017/redis_core_use/","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"},{"name":"Redis","slug":"Redis","permalink":"http://www.songshuiyang.com/tags/Redis/"}]},{"title":"缓存-缓存穿透-布隆过滤器","slug":"backend/cache/basic/缓存-缓存穿透-布隆过滤器","date":"2018-01-31T16:00:02.000Z","updated":"2020-01-04T12:21:51.986Z","comments":true,"path":"2018/02/01/backend/cache/basic/缓存-缓存穿透-布隆过滤器/","link":"","permalink":"http://www.songshuiyang.com/2018/02/01/backend/cache/basic/缓存-缓存穿透-布隆过滤器/","excerpt":"","text":"前言什么是布隆过滤器？ 首先，我们需要了解布隆过滤器的概念，抄自百度百科： 布隆过滤器（Bloom Filter）是一个叫做 Bloom 的老哥于1970年提出的。我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。 基本概念 如果想要判断一个元素是不是在一个集合里，一般想到的是将所有元素保存起来，然后通过比较确定。链表，树等等数据结构都是这种思路. 但是随着集合中元素的增加，我们需要的存储空间越来越大，检索速度也越来越慢(O(n),O(logn))。不过世界上还有一种叫作散列表（又叫哈希表，Hash table）的数据结构。它可以通过一个Hash函数将一个元素映射成一个位阵列（Bit array）中的一个点。这样一来，我们只要看看这个点是不是1就可以知道集合中有没有它了。这就是布隆过滤器的基本思想。 Hash面临的问题就是冲突。假设Hash函数是良好的，如果我们的位阵列长度为m个点，那么如果我们想将冲突率降低到例如 1%, 这个散列表就只能容纳m / 100个元素。显然这就不叫空间效率了（Space-efficient）了。解决方法也简单，就是使用多个Hash，如果它们有一个说元素不在集合中，那肯定就不在。如果它们都说在，虽然也有一定可能性它们在说谎，不过直觉上判断这种事情的概率是比较低的。 优缺点 优点 一个字解释快 相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势，。 布隆过滤器存储空间和插入/查询时间都是常数。 Hash函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。 布隆过滤器可以表示全集，其它任何数据结构都不能。 缺点 误判：布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率随之增加。常见的补救办法是建立一个小的白名单，存储那些可能被误判的元素。但是如果元素数量太少，则使用散列表足矣。 另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位列阵变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全的删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面. 这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。 使用场景 那什么场景可以使用布隆过滤器呢 判断给定数据是否存在：比如判断一个数字是否在于包含大量数字的数字集中（数字集很大，5亿以上！）、 防止缓存穿透（判断请求的数据是否有效避免直接绕过缓存请求数据库） 邮箱的垃圾邮件过滤、黑名单功能等等。 去重：比如爬给定网址的时候对已经爬取过的 URL 去重。 解析布隆过滤器的原理介绍 当一个元素加入布隆过滤器中的时候，会进行如下操作： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作： 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 这不和HashMap差不多原理吗 上图可以看到布隆过滤器使用了多个Hash来计算存放，这样做是为了解决hash冲突问题 实际示例Java 编程手动实现布隆过滤器 我们上面已经说了布隆过滤器的原理，知道了布隆过滤器的原理之后就可以通过例子来理解它，这样理解起来更形象 下面这个例子很简单就是判断给定数据是否存在 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class MyBloomFilter &#123; /** * 位数组的大小 */ private static final int DEFAULT_SIZE = 2 &lt;&lt; 24; /** * 通过这个数组可以创建 6 个不同的哈希函数 */ private static final int[] SEEDS = new int[]&#123;3, 13, 46, 71, 91, 134&#125;; /** * 位数组。数组中的元素只能是 0 或者 1 */ private BitSet bits = new BitSet(DEFAULT_SIZE); /** * 存放包含 hash 函数的类的数组 */ private SimpleHash[] func = new SimpleHash[SEEDS.length]; /** * 初始化多个包含 hash 函数的类的数组，每个类中的 hash 函数都不一样 */ public MyBloomFilter() &#123; // 初始化多个不同的 Hash 函数 for (int i = 0; i &lt; SEEDS.length; i++) &#123; func[i] = new SimpleHash(DEFAULT_SIZE, SEEDS[i]); &#125; &#125; /** * 添加元素到位数组 */ public void add(Object value) &#123; for (SimpleHash f : func) &#123; bits.set(f.hash(value), true); &#125; &#125; /** * 判断指定元素是否存在于位数组 */ public boolean contains(Object value) &#123; boolean ret = true; for (SimpleHash f : func) &#123; ret = ret &amp;&amp; bits.get(f.hash(value)); &#125; return ret; &#125; /** * 静态内部类。用于 hash 操作！ */ public static class SimpleHash &#123; private int cap; private int seed; public SimpleHash(int cap, int seed) &#123; this.cap = cap; this.seed = seed; &#125; /** * 计算 hash 值 */ public int hash(Object value) &#123; int h; return (value == null) ? 0 : Math.abs(seed * (cap - 1) &amp; ((h = value.hashCode()) ^ (h &gt;&gt;&gt; 16))); &#125; &#125; public static void main(String[] args) &#123; String value1 = \"https://javaguide.cn/\"; String value2 = \"https://github.com/Snailclimb\"; MyBloomFilter filter = new MyBloomFilter(); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); filter.add(value1); filter.add(value2); System.out.println(filter.contains(value1)); System.out.println(filter.contains(value2)); &#125;&#125; 如果你想要手动实现一个的话，你需要： 一个合适大小的位数组保存数据 几个不同的哈希函数 添加元素到位数组（布隆过滤器）的方法实现 判断给定元素是否存在于位数组（布隆过滤器）的方法实现。 Guava中自带的布隆过滤器 自己实现的目的主要是为了让自己搞懂布隆过滤器的原理，Guava 中布隆过滤器的实现算是比较权威的，所以实际项目中我们不需要手动实现一个布隆过滤器。 首先我们需要在项目中引入 Guava 的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;28.0-jre&lt;/version&gt;&lt;/dependency&gt; 实际使用如下： 我们创建了一个最多存放 最多 1500个整数的布隆过滤器，并且我们可以容忍误判的概率为百分之（0.01） 12345678910111213// 创建布隆过滤器对象BloomFilter&lt;Integer&gt; filter = BloomFilter.create( Funnels.integerFunnel(), 1500, 0.01);// 判断指定元素是否存在System.out.println(filter.mightContain(1));System.out.println(filter.mightContain(2));// 将元素添加进布隆过滤器filter.put(1);filter.put(2);System.out.println(filter.mightContain(1));System.out.println(filter.mightContain(2)); 在我们的示例中，当mightContain（） 方法返回true时，我们可以99％确定该元素在过滤器中，当过滤器返回false时，我们可以100％确定该元素不存在于过滤器中。 Redis 中的布隆过滤器介绍 Guava中自带的布隆过滤器它有一个重大的缺陷就是只能单机使用（另外，容量扩展也不容易），而现在互联网一般都是分布式的场景。为了解决这个问题，我们就需要用到 Redis 中的布隆过滤器了。 Redis v4.0 之后有了 Module（模块/插件） 功能，Redis Modules 让 Redis 可以使用外部模块扩展其功能 。布隆过滤器就是其中的 Module。详情可以查看 Redis 官方对 Redis Modules 的介绍 ：https://redis.io/modules。 另外，官网推荐了一个 RedisBloom 作为 Redis 布隆过滤器的 Module，RedisBloom 提供了多种语言的客户端支持，包括：Python、Java、JavaScript 和 PHP。 使用Docker安装 如果我们需要体验 Redis 中的布隆过滤器非常简单，通过 Docker 就可以了！我们直接在 Google 搜索docker redis bloomfilter 然后在排除广告的第一条搜素结果就找到了我们想要的答案（这是我平常解决问题的一种方式，分享一下），具体地址：https://hub.docker.com/r/redislabs/rebloom/ （介绍的很详细 ）。 具体操作如下： 1234➜ ~ docker run -p 6379:6379 --name redis-redisbloom redislabs/rebloom:latest➜ ~ docker exec -it redis-redisbloom bashroot@21396d02c252:/data# redis-cli127.0.0.1:6379&gt; 常用命令一览（注意： key:布隆过滤器的名称，item : 添加的元素。）: BF.ADD ：将元素添加到布隆过滤器中，如果该过滤器尚不存在，则创建该过滤器。格式：BF.ADD {key} {item}。 BF.MADD : 将一个或多个元素添加到“布隆过滤器”中，并创建一个尚不存在的过滤器。该命令的操作方式BF.ADD与之相同，只不过它允许多个输入并返回多个值。格式：BF.MADD {key} {item} [item …] 。 BF.EXISTS : 确定元素是否在布隆过滤器中存在。格式：BF.EXISTS {key} {item}。 BF.MEXISTS ： 确定一个或者多个元素是否在布隆过滤器中存在格式：BF.MEXISTS {key} {item} [item …]。 使用 12345678910127.0.0.1:6379&gt; BF.ADD myFilter java(integer) 1127.0.0.1:6379&gt; BF.ADD myFilter javaguide(integer) 1127.0.0.1:6379&gt; BF.EXISTS myFilter java(integer) 1127.0.0.1:6379&gt; BF.EXISTS myFilter javaguide(integer) 1127.0.0.1:6379&gt; BF.EXISTS myFilter github(integer) 0 总结 使用 BloomFilter 布隆过滤器可以快速判断给定数据是否存在，为什么不用其他数据结构呢，一个字解释就是快 比如下面这个问题：“如何确定一个数字是否在于包含大量数字的数字集中（数字集很大，5 亿以上！）?”解决这道题目就要用到布隆过滤器。 使用 BloomFilter 布隆过滤器的话，需要提前将已存在的 KEY ，初始化存储到【BloomFilter 缓存】中，BloomFilter 不存储 KEY 是不存在的情况 BloomFilter 存在误判。简单来说，存在的不一定存在，不存在的一定不存在。这样就会导致，一个存在的 KEY 被误判成不存在。 同时，BloomFilter 不允许删除。例如说，一个 KEY 一开始是不存在的，后来数据新增了，但是 BloomFilter 不允许删除的特点，就会导致一直会被判断成不存在。 参考 https://baike.baidu.com/item/布隆过滤器/5384697?fr=aladdin http://www.iocoder.cn https://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVug https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"}]},{"title":"缓存-缓存与DB的一致性处理","slug":"backend/cache/basic/缓存-缓存与DB的一致性处理","date":"2018-01-31T16:00:01.000Z","updated":"2020-01-04T12:21:51.983Z","comments":true,"path":"2018/02/01/backend/cache/basic/缓存-缓存与DB的一致性处理/","link":"","permalink":"http://www.songshuiyang.com/2018/02/01/backend/cache/basic/缓存-缓存与DB的一致性处理/","excerpt":"","text":"前言 主要有两种情况，会导致缓存和 DB 的一致性问题： 并发的场景下，导致读取老的 DB 数据，更新到缓存中。 这里，主要指的是，更新 DB 数据之前，先删除 Cache 的数据。在低并发量下没什么问题，但是在高并发下，就会存在问题。在(删除 Cache 的数据, 和更新 DB 数据)时间之间，恰好有一个请求 我们如果使用被动读，因为此时 DB 数据还是老的，又会将老的数据写入到 Cache 中。 缓存和 DB 的操作，不在一个事务中，可能只有一个 DB 操作成功，而另一个 Cache 操作失败，导致不一致。 当然，有一点我们要注意，缓存和 DB 的一致性，我们指的更多的是最终一致性。我们使用缓存只要是提高读操作的性能，真正在写操作的业务逻辑，还是以数据库为准。 例如说，我们可能缓存用户钱包的余额在缓存中，在前端查询钱包余额时，读取缓存，在使用钱包余额时，读取数据库。 解析解决方案 要解决这个问题，目标是 1、将缓存可能存在的并行写，实现串行写。 2、实现数据的最终一致性。 1）先淘汰缓存，再写数据库 及 先写数据库，再更新缓存 我们要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。 2）基于定时任务来实现 首先，写入数据库。 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。 【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。 3）基于消息队列来实现 首先，写入数据库。 然后，发送带有缓存 KEY 和 VALUE 的事务消息。此时，需要有支持事务消息特性的消息队列，或者我们自己封装消息队列，支持事务消息。 【异步】最后，消费者消费该消息，更新到缓存中。 其他总结 一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。 串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。 参考 http://www.iocoder.cn https://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVug https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"}]},{"title":"缓存-缓存三连-缓存穿透及缓存击穿及缓存雪崩","slug":"backend/cache/basic/缓存-缓存三连-缓存穿透及缓存击穿及缓存雪崩","date":"2018-01-31T16:00:01.000Z","updated":"2020-03-16T11:43:55.371Z","comments":true,"path":"2018/02/01/backend/cache/basic/缓存-缓存三连-缓存穿透及缓存击穿及缓存雪崩/","link":"","permalink":"http://www.songshuiyang.com/2018/02/01/backend/cache/basic/缓存-缓存三连-缓存穿透及缓存击穿及缓存雪崩/","excerpt":"","text":"前言 用了缓存之后，有哪些常见问题？ 常见的问题，可列举如下： 写入问题 缓存何时写入？并且写时如何避免并发重复写入？ 缓存如何失效？ 缓存和 DB 的一致性如何保证？ 经典三连问 如何避免缓存穿透的问题？ 如何避免缓存击穿的问题？ 如果避免缓存雪崩的问题？ 解析1、缓存穿透什么是缓存穿透 缓存穿透，是指查询一个一定不存在的数据，由于缓存是不命中时被动写，并且处于容错考虑，如果从 DB 查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，失去了缓存的意义。 在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。如下图： 上一章节我们已经看到，MySQL 的性能是远不如 Redis 的，如果大量的请求直接打到 MySQL ，则会直接打挂 MySQL 。 当然，缓存穿透不一定是攻击，也可能是我们自己程序写的问题，疯狂读取不存在的数据，又或者“无脑”的爬虫，顺序爬取数据。 另外，一定要注意，缓存穿透，指的是查询一个不存在的数据，很容易和我们要讲到的缓存击穿搞混淆。 如何避免缓存穿透的问题 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。 1）方案一，缓存空对象。 当从 DB 查询数据为空，我们仍然将这个空结果进行缓存，具体的值需要使用特殊的标识，能和真正缓存的数据区分开。 空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 ( 如果是攻击，问题更严重 )，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。 2）方案二，使用BloomFilter 布隆过滤器。 在缓存服务的基础上，构建 BloomFilter 数据结构，在 BloomFilter 中存储对应的 KEY 是否存在，如果存在，说明该 KEY 对应的值不为空。那么整个逻辑的如下： 1、根据 KEY 查询【BloomFilter 缓存】。如果不存在对应的值，直接返回；如果存在，继续向下执行。【后续的流程，就是标准的流程】 2、根据 KEY 查询在【数据缓存】的值。如果存在值，直接返回；如果不存在值，继续向下执行。 3、查询 DB 对应的值，如果存在，则更新到缓存，并返回该值。 原理介绍 当一个元素加入布隆过滤器中的时候，会进行如下操作： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作： 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 这不和HashMap差不多原理吗 BloomFilter 布隆过滤器特性 使用 BloomFilter 布隆过滤器的话，需要提前将已存在的 KEY ，初始化存储到【BloomFilter 缓存】中，BloomFilter 不存储 KEY 是不存在的情况 BloomFilter 存在误判。简单来说，存在的不一定存在，不存在的一定不存在。这样就会导致，一个存在的 KEY 被误判成不存在。 同时，BloomFilter 不允许删除。例如说，一个 KEY 一开始是不存在的，后来数据新增了，但是 BloomFilter 不允许删除的特点，就会导致一直会被判断成不存在。 2、缓存雪崩什么是缓存雪崩 缓存雪崩，是指缓存由于某些原因无法提供服务( 例如，缓存挂掉了 )，所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。 如何避免缓存雪崩的问题 预防和解决缓存雪崩的问题，可以从以下多个方面进行共同着手。 1）缓存高可用 通过搭建缓存的高可用，避免缓存挂掉导致无法提供服务的情况，从而降低出现缓存雪崩的情况。 假设我们使用 Redis 作为缓存，则可以使用 Redis Sentinel 或 Redis Cluster 实现高可用。 2）本地缓存 如果使用本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。 3）请求 DB 限流 通过限制 DB 的每秒请求数，避免把 DB 也打挂了。这样至少能有两个好处： 1、可能有一部分用户，还可以使用，系统还没死透。 2、未来缓存服务恢复后，系统立即就已经恢复，无需再处理 DB 也挂掉的情况。 当然，被限流的请求，我们最好也要有相应的处理，走【服务降级】，提供一些默认的值，或者友情提示，甚至空白的值也行。 如果我们使用 Java ，则可以使用 Guava RateLimiter、Sentinel、Hystrix 实现限流的功能。 3、缓存击穿什么是缓存击穿 缓存击穿，是指某个极度、热点数据在某个时间点过期时，恰好在这个时间点对这个 KEY 有大量的并发请求过来，这些请求发现缓存过期一般都会从 DB 加载数据并回设到缓存，但是这个时候大并发的请求可能会瞬间 DB 压垮。 开发人员使用缓存 + 过期时间的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。但是有两个问题如果同时出现，可能就会对应用造成致命的危害： 当前 key 是一个热点 key( 例如一个热门的娱乐新闻），并发量非常大。 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等。 在缓存失效的瞬间，有大量线程来重建缓存 ( 如下图)，造成后端负载加大，甚至可能会让应用崩溃。 击穿就是冲拳出击，雪崩的话是直接摧毁了 如何避免缓存击穿的问题 要解决这个问题最大的目标就是减少重建缓存的次数 1）方案一，使用互斥锁。 请求发现缓存不存在后，去查询 DB 前，使用分布式锁，保证有且只有一个线程去查询 DB ，并更新到缓存。流程如下： 1、获取分布式锁，直到成功或超时。如果超时，则抛出异常，返回。如果成功，继续向下执行。 2、获取缓存。如果存在值，则直接返回；如果不存在，则继续往下执行。获得到锁，可能已经被“那个”线程去查询过 DB ，并更新到缓存中了。 3、查询 DB ，并更新到缓存中，返回值。 2）方案二，手动过期。 缓存上从不设置过期时间，功能上将过期时间存在 KEY 对应的 VALUE 里。流程如下： 1、获取缓存。通过 VALUE 的过期时间，判断是否过期。如果未过期，则直接返回；如果已过期，继续往下执行。 2、通过一个后台的异步线程进行缓存的构建，也就是“手动”过期。通过后台的异步线程，保证有且只有一个线程去查询 DB。 3、同时，虽然 VALUE 已经过期，还是直接返回。通过这样的方式，保证服务的可用性，虽然损失了一定的时效性。 参考 http://www.iocoder.cn https://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVug","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"}]},{"title":"数据结构-二叉树","slug":"backend/dataStructure/数据结构-二叉树","date":"2018-01-31T16:00:00.000Z","updated":"2019-11-10T02:08:41.584Z","comments":true,"path":"2018/02/01/backend/dataStructure/数据结构-二叉树/","link":"","permalink":"http://www.songshuiyang.com/2018/02/01/backend/dataStructure/数据结构-二叉树/","excerpt":"","text":"","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://www.songshuiyang.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://www.songshuiyang.com/tags/数据结构/"}]},{"title":"缓存-基础概念","slug":"backend/cache/basic/缓存-基础概念","date":"2018-01-31T16:00:00.000Z","updated":"2019-11-10T02:08:41.441Z","comments":true,"path":"2018/02/01/backend/cache/basic/缓存-基础概念/","link":"","permalink":"http://www.songshuiyang.com/2018/02/01/backend/cache/basic/缓存-基础概念/","excerpt":"","text":"前言什么是缓存？ 缓存，就是数据交换的缓冲区，针对服务对象的不同（本质就是不同的硬件）都可以构建缓存。 目的是，把读写速度【慢】的介质的数据保存在读写速度【快】的介质中，从而提高读写速度，减少时间消耗。例如： CPU 高速缓存 ：高速缓存的读写速度远高于内存。 CPU 读数据时，如果在高速缓存中找到所需数据，就不需要读内存 CPU 写数据时，先写到高速缓存，再回写到内存。 磁盘缓存：磁盘缓存其实就把常用的磁盘数据保存在内存中，内存读写速度也是远高于磁盘的。 读数据，时从内存读取。 写数据时，可先写到内存，定时或定量回写到磁盘，或者是同步回写。 为什么要用缓存？ 使用缓存的目的，就是提升读写性能。而实际业务场景下，更多的是为了提升读性能，带来更好的性能，更高的并发量。 日常业务中，我们使用比较多的数据库是 MySQL ，缓存是 Redis 。一起来看看，阿里云提供的性能规格： Redis 性能规格，https://help.aliyun.com/document_detail/26350.html 。打底 8W QPS ，最高可达千万 QPS 。 MySQL 性能规格 https://help.aliyun.com/document_detail/53637.html 。打底 1.4K QPS ，最高 7W QPS 。 如此一比较，Redis 比 MySQL 的读写性能好很多。那么，我们将 MySQL 的热点数据，缓存到 Redis 中，提升读取性能，也减小 MySQL 的读取压力。例如说： 论坛帖子的访问频率比较高，且要实时更新阅读量，使用 Redis 记录帖子的阅读量，可以提升性能和并发。 商品信息，数据更新的频率不高，但是读取的频率很高，特别是热门商品。 解析缓存算法FIFO（first in first out ) 先进先出 FIFO 算法是一种比较容易实现的算法。它的思想是先进先出（FIFO，队列），这是最简单、最公平的一种思想，即如果一个数据是最先进入的，那么可以认为在将来它被访问的可能性很小。空间满的时候，最先进入的数据会被最早置换（淘汰）掉。 FIFO 算法的描述：设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能： set(key,value)：将记录(key,value)插入该结构。当缓存满时，将最先进入缓存的数据置换掉。 get(key)：返回key对应的value值。 实现： 维护一个FIFO队列，按照时间顺序将各数据（已分配页面）链接起来组成队列，并将置换指针指向队列的队首。 再进行置换时，只需把置换指针所指的数据（页面）顺次换出，并把新加入的数据插到队尾即可。 LRU（least recently used) 最近最少使用 是一种常见的缓存算法，在很多分布式缓存系统（如Redis, Memcached）中都有广泛使用。 LRU算法的思想是： 不断将最近使用的对象放到列表的顶部，这样最近最少使用的对象就会慢慢沉到底部 当容量不足的时候，可以将底部的对象去除，以留出空间给新的对象 LRU算法的描述： 设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能： set(key,value)：将记录(key,value)插入该结构。当缓存满时，将最久未使用的数据置换掉。 get(key)：返回key对应的value值。 实现： 最朴素的思想就是用数组+时间戳的方式，不过这样做效率较低。因此，我们可以用双向链表（LinkedList）+哈希表（HashMap）实现（链表用来表示位置，哈希表用来存储和查找） 在Java里有对应的数据结构LinkedHashMap。 手写 LRU 代码的实现，有多种方式。其中，最简单的是基于 LinkedHashMap 来实现，代码如下： 123456789101112131415161718192021class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) &#123; // true 表示让 LinkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; // 当 map 中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; &#125;&#125; LFU（Least Frequently used ) 最不经常使用 也是一种常见的缓存算法。 顾名思义，LFU算法的思想是：如果一个数据在最近一段时间很少被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最小频率访问的数据最先被淘汰。 设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能： set(key,value)：将记录(key,value)插入该结构。当缓存满时，将访问频率最低的数据置换掉。 get(key)：返回key对应的value值。 算法实现策略： 考虑到 LFU 会淘汰访问频率最小的数据，我们需要一种合适的方法按大小顺序维护数据访问的频率。 LFU 算法本质上可以看做是一个 top K 问题(K = 1)，即选出频率最小的元素，因此我们很容易想到可以用二项堆来选择频率最小的元素，这样的实现比较高效。最终实现策略为小顶堆+哈希表。 OPT（Bélády’s Algorithm）最佳页面置换算法 是一种理论上最佳的页面置换算法，唯一的缺点是无法实现。 它的思想是，试图淘汰掉以后永远也用不到的页面，如果没有则淘汰最久以后再用到的页面。因为这种算法必须知道进程访问页面的序列，而这是无法实现的，因此仅有理论意义。 常见的常见的缓存工具和框架有哪些？ 在 Java 后端开发中，常见的缓存工具和框架列举如下： 本地缓存：Guava LocalCache、Ehcache、Caffeine 。 Ehcache 的功能更加丰富，Caffeine 的性能要比 Guava LocalCache 好 分布式缓存：Redis、MemCache、Tair 。 Redis 最为主流和常用 总结 LRU和LFU的区别 LFU算法是根据在一段时间里数据项被使用的次数选择出最少使用的数据项，即根据使用次数的差异来决定 而LRU是根据使用时间的差异来决定的 参考 http://www.iocoder.cn https://www.sczyh30.com/posts/Algorithm/algorithm-cache/","categories":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://www.songshuiyang.com/tags/缓存/"}]},{"title":"生成二维码图片(base64格式)","slug":"backend/other/生成二维码图片(base64格式)","date":"2018-01-29T13:00:12.000Z","updated":"2020-03-16T11:43:55.552Z","comments":true,"path":"2018/01/29/backend/other/生成二维码图片(base64格式)/","link":"","permalink":"http://www.songshuiyang.com/2018/01/29/backend/other/生成二维码图片(base64格式)/","excerpt":"生成二维码图片(base64格式)","text":"生成二维码图片(base64格式) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.guangeryi.mall.payment.weixin;import com.google.zxing.BarcodeFormat;import com.google.zxing.EncodeHintType;import com.google.zxing.MultiFormatWriter;import com.google.zxing.client.j2se.MatrixToImageWriter;import com.google.zxing.common.BitMatrix;import org.apache.commons.codec.binary.Base64;import javax.imageio.ImageIO;import java.awt.image.BufferedImage;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.util.Hashtable;import java.util.Map;public class QRCodeUtils &#123; /** * 生成二维码 Base64编码后字符串 * * @param contents 内容 */ public static String encodeQRCodeBase64(String contents) &#123; return encodeQRCodeToBase64Str(contents); &#125; /** * 生成二维码 Base64编码后字符串 &lt;img src=''&gt; src填入该字符串显示图片 * （高度:300 , 宽度:300） * @param contents 内容 */ private static String encodeQRCodeToBase64Str(String contents) &#123; int width = WxPcPayConfigImpl.QR_IMG_WIDTH; int height = WxPcPayConfigImpl.QR_IMG_HEIGHT; Map&lt;EncodeHintType, Object&gt; hints = new Hashtable&lt;&gt;(); String base64Img = \"data:image/png;base64,\"; // 指定编码格式 hints.put(EncodeHintType.CHARACTER_SET, \"UTF-8\"); try &#123; // 生成输出流 BitMatrix bitMatrix1 = new MultiFormatWriter().encode(contents, BarcodeFormat.QR_CODE, width, height, hints); BufferedImage image = MatrixToImageWriter.toBufferedImage(bitMatrix1); base64Img = base64Img + encodeToString(\"png\", image); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return base64Img; &#125; /** * 将图片转换成base64格式进行存储 * * @param formatName 文件格式 * @param image 图片流 * @return base64字符串 */ private static String encodeToString(String formatName, BufferedImage image) &#123; String imageString = null; try (ByteArrayOutputStream bos = new ByteArrayOutputStream()) &#123; ImageIO.write(image, formatName, bos); byte[] imageBytes = bos.toByteArray(); imageString = new String(Base64.encodeBase64(imageBytes)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return imageString; &#125; public static void main(String[] args) &#123; // 输出在img标签中img属性中 System.out.println(encodeQRCodeBase64(\"你好\")); &#125;&#125;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"根据手机区号获取城市地理位置","slug":"backend/other/根据手机区号获取城市地理位置","date":"2018-01-29T12:55:12.000Z","updated":"2020-03-16T11:43:55.549Z","comments":true,"path":"2018/01/29/backend/other/根据手机区号获取城市地理位置/","link":"","permalink":"http://www.songshuiyang.com/2018/01/29/backend/other/根据手机区号获取城市地理位置/","excerpt":"根据手机区号获取城市地理位置httpAPI: http://www.ip138.com:8080/search.asp?action=mobile&amp;mobile=%s","text":"根据手机区号获取城市地理位置httpAPI: http://www.ip138.com:8080/search.asp?action=mobile&amp;mobile=%s 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.guangeryi.mall.third.common;import org.jsoup.Jsoup;import org.jsoup.nodes.Document;import org.jsoup.select.Elements;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.HashMap;import java.util.Map;public class MobileLocationUtils &#123; private final static Logger logger = LoggerFactory.getLogger(MobileLocationUtils.class); /** * 根据手机号获取所在地信息 * @param mobile 手机号码 * @return 返回map */ public static Map&lt;String,Object&gt; getMobileAddress (String mobile) &#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); String returnStr= getMobileAddressUtils(mobile); // 将160号的空格转化成32号的空格 returnStr = returnStr.replaceAll(\"[\\\\u00A0]+\", \" \"); // 去空格 returnStr = returnStr.trim(); String [] address = returnStr.split(\"\\\\s+\"); String province = \"\";// 省 String city = \"\"; // 市 // 直辖市 if (address.length == 1) &#123; province = address[0]; city = address[0]; &#125; if (address.length == 2) &#123; province = address[0]; city = address[1]; &#125; map.put(\"province\", province); map.put(\"city\", city); logger.info(mobile + \" 手机号所在信息:\" + map); return map; &#125; public static String getMobileAddressUtils(String mobile)&#123; try &#123; String url = \"http://www.ip138.com:8080/search.asp?action=mobile&amp;mobile=%s\"; url = String.format(url, mobile); Document doc = Jsoup.connect(url).get(); Elements els = doc.getElementsByClass(\"tdc2\"); if(els.get(1).text().equals(\"mobile 不是数字! 验证手机号有误\") || els.get(1).text().equals(\"验证手机号有误\")) &#123; return \"未知\"; &#125; return els.get(1).text(); &#125; catch (Exception e) &#123; return \"未知\"; &#125; &#125; public static void main(String[] args) &#123; System.out.println(getMobileAddress(\"13117975845\")); &#125;&#125;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"根据IP获取城市地理位置","slug":"backend/other/根据IP获取城市地理位置","date":"2018-01-29T12:54:12.000Z","updated":"2020-03-16T11:43:55.545Z","comments":true,"path":"2018/01/29/backend/other/根据IP获取城市地理位置/","link":"","permalink":"http://www.songshuiyang.com/2018/01/29/backend/other/根据IP获取城市地理位置/","excerpt":"根据IP获取城市地理位置使用的是百度查询的api，试过到淘宝的API, 但是淘宝做了访问次数限制，如果批量查询的话直接timeout","text":"根据IP获取城市地理位置使用的是百度查询的api，试过到淘宝的API, 但是淘宝做了访问次数限制，如果批量查询的话直接timeout 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168package com.guangeryi.mall.third.common;import net.sf.json.JSONObject;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.*;import java.net.URL;import java.nio.charset.Charset;import java.util.HashMap;import java.util.Map;/** * 根据IP获取城市地理位置 * 调用百度api：http://api.map.baidu.com/location/ip */public class IpUtils &#123; private final static Logger logger = LoggerFactory.getLogger(AddressUtils.class); /** * 根据ip获取城市信息 * @param ip * @return */ public static Map&lt;String, Object&gt; getCityInfoByIp(String ip)&#123; Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(); result.put(\"status\",\"success\"); String jsonInfo = null; try &#123; jsonInfo = getCityInfoByUrlAPI(ip); logger.info(\"jsonInfo:\" + jsonInfo); &#125; catch (IOException e) &#123; logger.error(\"调用 api.map.baidu.com/location/ip 获取城市信息异常, ip:\" + ip, e); result.put(\"status\",\"failed\"); return result; &#125; String province = \"\"; String city = \"\"; String district =\"\"; String street = \"\"; try &#123; JSONObject jsonObject = JSONObject.fromObject(jsonInfo); if (jsonObject != null) &#123; if (jsonObject.getJSONObject(\"content\") != null) &#123; JSONObject addressDetail = jsonObject.getJSONObject(\"content\").getJSONObject(\"address_detail\"); province = (String)addressDetail.get(\"province\"); // 省 city = (String)addressDetail.get(\"city\"); // 市 district = (String)addressDetail.get(\"district\"); // 区 street = (String)addressDetail.get(\"street\"); // 街道 &#125; &#125; &#125; catch (Exception e) &#123; logger.error(\"调用 api.map.baidu.com/location/ip 获取城市信息异常,解析JSON异常 ip:\" + ip, e); result.put(\"status\",\"failed\"); return result; &#125; result.put(\"province\",province); result.put(\"city\",city); result.put(\"district\",district); result.put(\"street\",street); return result; &#125; /** * 调用 api.map.baidu.com/location/ip 获取城市信息 * @param ip * @return * @throws IOException */ private static String getCityInfoByUrlAPI(String ip) throws IOException &#123; String url = \"http://api.map.baidu.com/location/ip?ak=F454f8a5efe5e577997931cc01de3974&amp;ip=\" + ip; try (InputStream is = new URL(url).openStream()) &#123; BufferedReader rd = new BufferedReader(new InputStreamReader(is, Charset.forName(\"UTF-8\"))); String jsonText = getStrByReader(rd); jsonText = decodeUnicode(jsonText); return jsonText; &#125; &#125; /** * 获取流数据 * @param rd * @return * @throws IOException */ private static String getStrByReader(Reader rd) throws IOException &#123; StringBuilder sb = new StringBuilder(); int cp; while ((cp = rd.read()) != -1) &#123; sb.append((char) cp); &#125; return sb.toString(); &#125; /** * unicode 转换成 中文 * * @author fanhui 2007-3-15 * @param theString 字符串 * @return String */ private static String decodeUnicode(String theString) &#123; char aChar; int len = theString.length(); StringBuilder outBuilder = new StringBuilder(len); for (int x = 0; x &lt; len;) &#123; aChar = theString.charAt(x++); if (aChar == '\\\\') &#123; aChar = theString.charAt(x++); if (aChar == 'u') &#123; int value = 0; for (int i = 0; i &lt; 4; i++) &#123; aChar = theString.charAt(x++); switch (aChar) &#123; case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': value = (value &lt;&lt; 4) + aChar - '0'; break; case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': value = (value &lt;&lt; 4) + 10 + aChar - 'a'; break; case 'A': case 'B': case 'C': case 'D': case 'E': case 'F': value = (value &lt;&lt; 4) + 10 + aChar - 'A'; break; default: throw new IllegalArgumentException(\"Malformed encoding.\"); &#125; &#125; outBuilder.append((char) value); &#125; else &#123; if (aChar == 't') &#123; aChar = '\\t'; &#125; else if (aChar == 'r') &#123; aChar = '\\r'; &#125; else if (aChar == 'n') &#123; aChar = '\\n'; &#125; else if (aChar == 'f') &#123; aChar = '\\f'; &#125; outBuilder.append(aChar); &#125; &#125; else &#123; outBuilder.append(aChar); &#125; &#125; return outBuilder.toString(); &#125; public static void main(String[] args) &#123; System.out.println(getCityInfoByIp(\"118.212.211.23\")); &#125;&#125; 获取用户真实IP地址123456789101112131415161718192021222324252627282930313233343536/** * 获取用户真实IP地址，不使用request.getRemoteAddr()的原因是有可能用户使用了代理软件方式避免真实IP地址, * 可是，如果通过了多级反向代理的话，X-Forwarded-For的值并不止一个，而是一串IP值 */public static String getRemoteIp(HttpServletRequest request) &#123; String ip = request.getHeader(\"x-forwarded-for\"); if (ip != null &amp;&amp; ip.length() != 0 &amp;&amp; !\"unknown\".equalsIgnoreCase(ip)) &#123; // 多次反向代理后会有多个ip值，第一个ip才是真实ip if(ip.contains(\",\"))&#123; ip = ip.split(\",\")[0]; &#125; &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"Proxy-Client-IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"WL-Proxy-Client-IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"HTTP_CLIENT_IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"HTTP_X_FORWARDED_FOR\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getHeader(\"X-Real-IP\"); &#125; if (ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); &#125; // TODO 本地测试使用 if (!isIpv4(ip)) &#123; ip= \"120.27.129.177\"; // 服务器ip &#125; return ip;&#125; 校验IP地址12345678910111213141516/** * 校验IP地址 * @param ipAddress IP 地址 * @return true or false */public static boolean isIpv4(String ipAddress) &#123; String ip = \"^(1\\\\d&#123;2&#125;|2[0-4]\\\\d|25[0-5]|[1-9]\\\\d|[1-9])\\\\.\" +\"(00?\\\\d|1\\\\d&#123;2&#125;|2[0-4]\\\\d|25[0-5]|[1-9]\\\\d|\\\\d)\\\\.\" +\"(00?\\\\d|1\\\\d&#123;2&#125;|2[0-4]\\\\d|25[0-5]|[1-9]\\\\d|\\\\d)\\\\.\" +\"(00?\\\\d|1\\\\d&#123;2&#125;|2[0-4]\\\\d|25[0-5]|[1-9]\\\\d|\\\\d)$\"; Pattern pattern = Pattern.compile(ip); Matcher matcher = pattern.matcher(ipAddress); return matcher.matches();&#125;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"阿里云服务器搭建Javaweb运行环境","slug":"backend/server/JavaEE服务器/阿里云服务器搭建Javaweb运行环境","date":"2018-01-20T07:07:12.000Z","updated":"2019-11-10T02:08:42.051Z","comments":true,"path":"2018/01/20/backend/server/JavaEE服务器/阿里云服务器搭建Javaweb运行环境/","link":"","permalink":"http://www.songshuiyang.com/2018/01/20/backend/server/JavaEE服务器/阿里云服务器搭建Javaweb运行环境/","excerpt":"","text":"一：前言借助阿里云的云翼计划的梯子买了个 阿里的ESC云服务器，学生专享优惠10块钱/月，原价一百多一个月，超级划算，当然服务器配置对于我们这些学生捣鼓捣鼓还是满足的。 配置： 配置 参数 CPU Intel Xeon E5-2682 v4 1核 内存 2G 最新一代DDR4 内存 带宽 1M带宽 VPC专有网络, I/O 优化 系统盘 40G系统盘高效云盘 系统：CentOS 7.3 64位(可选ubuntu, windows service) ESC: 云服务器 ECS（Elastic Compute Service）是一种弹性可伸缩的计算服务，助您降低 IT 成本，提升运维效率，使您更专注于核心业务创新 二：搭建步骤2.1 购买 ESC云服务器购买链接:https://www.aliyun.com/product/ecs?spm=5176.8499797.765261.239.9Uf4pK, 当然如果是学生的话可以使用上面的云翼计划(https://promotion.aliyun.com/ntms/campus2017.html?spm=5176.8789780.765430.4.246c0fa5bHX2oK)优惠的方式购买，当时购买还送了(CDN流量包)和(OSS资源包) , 良心企业!!! 2.2 查看系统参数，及配置参数下单完成之后在 控制台-&gt; 云服务器 ECS -&gt; 实例 可看到系统自动为我们创建的 服务器实例, 里面提供了一些系统参数，还展示了系统的一些运行状态参数。 我们需要的参数 1.公网ip 访问实例需要用 2.远程连接密码 这个在第一次使用浏览器远程连接主机的时候，阿里云会提供，记住只出现一次，可以用笔记本记录下来，以后每次用浏览器远程控制访问主机的时候需要提供 3.登入系统的密码 在实例信息面板中有一个重置密码的功能，第一次需要自己设置，这个是主机系统的登入密码。 一开始用浏览器远程连接主机的时候，进入到了命令行界面, 要求输入密码的时候一直输入的是远程连接密码，导致一直登不进，查了一下资料发现系统登入密码需要自己创建, 登入用户 root 4.安全组配置 安全组配置是阿里云在系统做了一次网关过滤，外网访问主机，主机访问外网都需要配置这个参数，否则访问不到, 安全组配置分为入口和出口 入口配置: 把一些常用端口打开:80 22(ssh, sftp) 23(telnet) , 使用xshell和ftp都是使用的是22端口 添加 全部 ICMP 协议类型, 端口范围为-1/-1, 没有这条规则则ping 不通主机 2.3 连接主机进行配置有了上面的配置就可以通过远程连接主机了, 我是使用xshell 进行远程连接, 使用fileZilla进行传输文件 2.3.1 配置 Java环境方式一：使用yum安装JDK 参考：https://www.cnblogs.com/sxdcgaq8080/p/7492426.html12345678910111213141516171819201.查看yum库中都有哪些jdk版本(暂时只发现了openjdk): [root@localhost ~]# yum search java|grep jdk2.选择版本,进行安装[root@localhost ~]# yum install java-1.8.0-openjdk//安装完之后，默认的安装目录是在: /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.75.x86_643.设置环境变量[root@localhost ~]# vi /etc/profile在profile文件中添加如下内容#set java environmentJAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH4.让修改生效[root@localhost java]# source /etc/profile 注: 如果出现export =&#39; not a valid identifier12345678910111213原因就是你修改的 /etc/profile 文件里你加过空格我的代码如下：export JAVA_HOME = /usr/java/jdk1.7.0_75export PATH = $JAVA_HOME/bin:$PATHexport CLASSPATH = .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar修改为如下：export JAVA_HOME=/usr/java/jdk1.7.0_75export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar将等号两边的空格去掉就可以了 ，大家要注意 2.3.2 配置 Tomcat环境参考： http://www.linuxidc.com/Linux/2015-09/123118.htm12# tar -zxvf apache-tomcat-8.0.26.tar.gz // 解压压缩包 # mv apache-tomcat-8.0.26 tomcat // 改名 注:1.在ECS上启动tomcat后，第一次访问时间特别长1234567892017-04-25 10:16:04 INFO com.world.socket.ServerSocketListener 25-Apr-2017 10:18:48.171 INFO [localhost-startStop-1] org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom CreaecureRandom instance for session ID generation using [SHA1PRNG] took [163,521] milliseconds. 这个session ID引起的 解决办法：在JVM环境中解决 打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容：securerandom.source=file:/dev/urandom 替换成securerandom.source=file:/dev/./urandom 2.Centos打开、关闭、结束tomcat，及查看tomcat运行日志1234567891011启动：一般是执行sh tomcat/bin/startup.sh 停止：一般是执行sh tomcat/bin/shutdown.sh脚本命令 查看：执行ps -ef |grep tomcat 输出如下 *** 5144 。。。等等.Bootstrap start 说明tomcat已经正常启动， 5144 就为进程号 pid = 5144 杀死：kill -9 5144------------------------linux下实时查看tomcat运行日志-------------------------1、先切换到：cd tomcat/logs2、tail -f catalina.out3、这样运行时就可以实时查看运行日志了Ctrl+c 是退出tail命令。 2.3.3 配置 Mysql环境参考： http://www.linuxidc.com/Linux/2016-09/134992.htm 2.4 投放项目文件使用fileZilla进行传输文件1234Tomcat中部署web项目的三种方式：1.部署解包的webapp目录2.打包的war文件3.Manager Web应用程序","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/tags/Linux/"}]},{"title":"npm scripts","slug":"frontend/npm/npm scripts","date":"2018-01-14T03:48:12.000Z","updated":"2019-09-16T13:11:07.292Z","comments":true,"path":"2018/01/14/frontend/npm/npm scripts/","link":"","permalink":"http://www.songshuiyang.com/2018/01/14/frontend/npm/npm scripts/","excerpt":"","text":"一、什么是 npm 脚本npm 允许在package.json文件里面，使用scripts字段定义脚本命令。123456&#123; // ... \"scripts\": &#123; \"build\": \"node build.js\" &#125;&#125; 上面代码是package.json文件的一个片段，里面的scripts字段是一个对象。它的每一个属性，对应一段脚本。比如，build命令对应的脚本是node build.js。命令行下使用npm run命令，就可以执行这段脚本。123$ npm run build# 等同于执行$ node build.js 这些定义在package.json里面的脚本，就称为 npm 脚本。它的优点很多 项目的相关脚本，可以集中在一个地方。 不同项目的脚本命令，只要功能相同，就可以有同样的对外接口。用户不需要知道怎么测试你的项目，只要运行npm run test即可。 可以利用 npm 提供的很多辅助功能。 查看当前项目的所有 npm 脚本命令，可以使用不带任何参数的npm run命令。1$ npm run 二：执行顺序如果 npm 脚本里面需要执行多个任务，那么需要明确它们的执行顺序。如果是并行执行（即同时的平行执行），可以使用&amp;符号。1$ npm run script1.js &amp; npm run script2.js 如果是继发执行（即只有前一个任务成功，才执行下一个任务），可以使用&amp;&amp;符号1$ npm run script1.js &amp;&amp; npm run script2.js 应用在 package.json 添加以下代码执行npm run gg 可以连续执行（hexo g）（hexo d）俩个命令，这样就不用每次执行俩个命令123\"scripts\": &#123; \"gg\": \"hexo g &amp;&amp; hexo d\" &#125; 详见:http://www.ruanyifeng.com/blog/2016/10/npm_scripts.html","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"node","slug":"node","permalink":"http://www.songshuiyang.com/tags/node/"},{"name":"npm","slug":"npm","permalink":"http://www.songshuiyang.com/tags/npm/"}]},{"title":"接入银联支付接口","slug":"backend/business/payment/接入银联支付接口","date":"2018-01-11T14:24:12.000Z","updated":"2020-03-16T11:43:55.367Z","comments":true,"path":"2018/01/11/backend/business/payment/接入银联支付接口/","link":"","permalink":"http://www.songshuiyang.com/2018/01/11/backend/business/payment/接入银联支付接口/","excerpt":"吐槽一下： 1.银联支付SDK是没有提供独立的jar包的，高大上的银联把示例demo和sdk整合在一起了，支付流程和支付宝支付相似，支付需要到银联的支付页面 2.证书说明：其实我们只需要一个邮件上的签名证书文件，官网上文档说的开发者调用接口前需要的其他证书在开发包中目录assets下都有，每个人都一样，没错，每个人都一样 3.银联开发平台常常在下午6点发版本，遇到过俩次，第一次感到惊讶:银联网站挂了？不可能呀，过了十多分钟又恢复正常，晕 4.代码不够规范，用代码检测工具一片黄色123456/** * @ClassName AcpService * @Description acpsdk接口服务类，接入商户集成请可以直接参考使用本类中的方法 * @date 2016-7-22 下午2:44:37 * 声明：以下代码只是为了方便接入方测试而提供的样例代码，商户可以根据自己需要，按照技术文档编写。该代码仅供参考，不提供编码，性能，规范性等方面的保障 */","text":"吐槽一下： 1.银联支付SDK是没有提供独立的jar包的，高大上的银联把示例demo和sdk整合在一起了，支付流程和支付宝支付相似，支付需要到银联的支付页面 2.证书说明：其实我们只需要一个邮件上的签名证书文件，官网上文档说的开发者调用接口前需要的其他证书在开发包中目录assets下都有，每个人都一样，没错，每个人都一样 3.银联开发平台常常在下午6点发版本，遇到过俩次，第一次感到惊讶:银联网站挂了？不可能呀，过了十多分钟又恢复正常，晕 4.代码不够规范，用代码检测工具一片黄色123456/** * @ClassName AcpService * @Description acpsdk接口服务类，接入商户集成请可以直接参考使用本类中的方法 * @date 2016-7-22 下午2:44:37 * 声明：以下代码只是为了方便接入方测试而提供的样例代码，商户可以根据自己需要，按照技术文档编写。该代码仅供参考，不提供编码，性能，规范性等方面的保障 */ 大致步骤一：下载demo及sdkhttps://open.unionpay.com/ajweb/product/newProDetail?proId=1&amp;cataId=14 二：配置参数：接入银联支付审核 听头说好像是挺繁琐的，费时费力，接入银联支付设及到下面几个参数，其他的参数银联都帮我们配置好了 1.商户号: 在银联商家技术服务中心可以看到 https://open.unionpay.com/ajweb/index，注意：在测试环境的商户号一致，刚开始我还不相信，通过客服才知道俩个是一样的，在测试账号信息里面可以看到 2.后台通知地址：填写接收银联后台通知的地址，必须外网能访问 3.前台通知地址：填写处理银联前台通知的地址，必须外网能访问 4.签名证书: 在审核成功发送的邮件里面 5.签名证书密码： 在审核成功发送的邮件里面有 三：调用支付接口protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.setContentType(\"text/html; charset=\"+ DemoBase.encoding); //前台页面传过来的 String merId = req.getParameter(\"merId\"); String txnAmt = req.getParameter(\"txnAmt\"); Map&lt;String, String&gt; requestData = new HashMap&lt;String, String&gt;(); /***银联全渠道系统，产品参数，除了encoding自行选择外其他不需修改***/ requestData.put(\"version\", DemoBase.version); //版本号，全渠道默认值 requestData.put(\"encoding\", DemoBase.encoding); //字符集编码，可以使用UTF-8,GBK两种方式 requestData.put(\"signMethod\", SDKConfig.getConfig().getSignMethod()); //签名方法 requestData.put(\"txnType\", \"01\"); //交易类型 ，01：消费 requestData.put(\"txnSubType\", \"01\"); //交易子类型， 01：自助消费 requestData.put(\"bizType\", \"000201\"); //业务类型，B2C网关支付，手机wap支付 requestData.put(\"channelType\", \"07\"); //渠道类型，这个字段区分B2C网关支付和手机wap支付；07：PC,平板 08：手机 /***商户接入参数***/ requestData.put(\"merId\", merId); //商户号码，请改成自己申请的正式商户号或者open上注册得来的777测试商户号 requestData.put(\"accessType\", \"0\"); //接入类型，0：直连商户 requestData.put(\"orderId\",DemoBase.getOrderId()); //商户订单号，8-40位数字字母，不能含“-”或“_”，可以自行定制规则 requestData.put(\"txnTime\", DemoBase.getCurrentTime()); //订单发送时间，取系统时间，格式为YYYYMMDDhhmmss，必须取当前时间，否则会报txnTime无效 requestData.put(\"currencyCode\", \"156\"); //交易币种（境内商户一般是156 人民币） requestData.put(\"txnAmt\", txnAmt); //交易金额，单位分，不要带小数点 //requestData.put(\"reqReserved\", \"透传字段\"); //请求方保留域，如需使用请启用即可；透传字段（可以实现商户自定义参数的追踪）本交易的后台通知,对本交易的交易状态查询交易、对账文件中均会原样返回，商户可以按需上传，长度为1-1024个字节。出现&amp;={}[]符号时可能导致查询接口应答报文解析失败，建议尽量只传字母数字并使用|分割，或者可以最外层做一次base64编码(base64编码之后出现的等号不会导致解析失败可以不用管)。 //前台通知地址 （需设置为外网能访问 http https均可），支付成功后的页面 点击“返回商户”按钮的时候将异步通知报文post到该地址 //如果想要实现过几秒中自动跳转回商户页面权限，需联系银联业务申请开通自动返回商户权限 //异步通知参数详见open.unionpay.com帮助中心 下载 产品接口规范 网关支付产品接口规范 消费交易 商户通知 requestData.put(\"frontUrl\", DemoBase.frontUrl); //后台通知地址（需设置为【外网】能访问 http https均可），支付成功后银联会自动将异步通知报文post到商户上送的该地址，失败的交易银联不会发送后台通知 //后台通知参数详见open.unionpay.com帮助中心 下载 产品接口规范 网关支付产品接口规范 消费交易 商户通知 //注意:1.需设置为外网能访问，否则收不到通知 2.http https均可 3.收单后台通知后需要10秒内返回http200或302状态码 // 4.如果银联通知服务器发送通知后10秒内未收到返回状态码或者应答码非http200，那么银联会间隔一段时间再次发送。总共发送5次，每次的间隔时间为0,1,2,4分钟。 // 5.后台通知地址如果上送了带有？的参数，例如：http://abc/web?a=b&amp;c=d 在后台通知处理程序验证签名之前需要编写逻辑将这些字段去掉再验签，否则将会验签失败 requestData.put(\"backUrl\", DemoBase.backUrl); // 订单超时时间。 // 超过此时间后，除网银交易外，其他交易银联系统会拒绝受理，提示超时。 跳转银行网银交易如果超时后交易成功，会自动退款，大约5个工作日金额返还到持卡人账户。 // 此时间建议取支付时的北京时间加15分钟。 // 超过超时时间调查询接口应答origRespCode不是A6或者00的就可以判断为失败。 requestData.put(\"payTimeout\", new SimpleDateFormat(\"yyyyMMddHHmmss\").format(new Date().getTime() + 15 * 60 * 1000)); ////////////////////////////////////////////////// // // 报文中特殊用法请查看 PCwap网关跳转支付特殊用法.txt // ////////////////////////////////////////////////// /**请求参数设置完毕，以下对请求参数进行签名并生成html表单，将表单写入浏览器跳转打开银联页面**/ Map&lt;String, String&gt; submitFromData = AcpService.sign(requestData,DemoBase.encoding); //报文中certId,signature的值是在signData方法中获取并自动赋值的，只要证书配置正确即可。 String requestFrontUrl = SDKConfig.getConfig().getFrontRequestUrl(); //获取请求银联的前台地址：对应属性文件acp_sdk.properties文件中的acpsdk.frontTransUrl String html = AcpService.createAutoFormHtml(requestFrontUrl, submitFromData,DemoBase.encoding); //生成自动跳转的Html表单 LogUtil.writeLog(\"打印请求HTML，此为请求报文，为联调排查问题的依据：\"+html); //将生成的html写到浏览器中完成自动跳转打开银联支付页面；这里调用signData之后，将html写到浏览器跳转到银联页面之前均不能对html中的表单项的名称和值进行修改，如果修改会导致验签不通过 resp.getWriter().write(html); } 异步通知：与支付宝微信异步通知处理相同参考于：https://open.unionpay.com/ajweb/product/newProDetail?proId=1&amp;cataId=14","categories":[{"name":"业务","slug":"业务","permalink":"http://www.songshuiyang.com/categories/业务/"}],"tags":[{"name":"支付","slug":"支付","permalink":"http://www.songshuiyang.com/tags/支付/"}]},{"title":"接入微信扫码支付接口","slug":"backend/business/payment/接入微信支付接口","date":"2018-01-11T13:24:12.000Z","updated":"2020-03-16T11:43:55.333Z","comments":true,"path":"2018/01/11/backend/business/payment/接入微信支付接口/","link":"","permalink":"http://www.songshuiyang.com/2018/01/11/backend/business/payment/接入微信支付接口/","excerpt":"准备条件开始之前先看一下微信的几个平台: 微信公众平台:是微信公众账号申请入口和管理后台。商户可以在公众平台提交基本资料、业务资料、财务资料申请开通微信支付功能。平台入口：http://mp.weixin.qq.com。 微信开放平台:微信开放平台是商户APP接入微信支付开放接口的申请入口，通过此平台可申请微信APP支付。平台入口：http://open.weixin.qq.com。 微信商户平台:微信商户平台是微信支付相关的商户功能集合，包括参数配置、支付数据查询与统计、在线退款、代金券或立减优惠运营等功能。平台入口：http://pay.weixin.qq.com 刚开始接入的时候有点昏，各种参数需要到不同的平台找, 不像支付宝一样只有一个开发平台，如果是接入微信扫码支付设及到微信公众平台和微信商户平台，如果是手机app微信支付，设及到微信开放平台和微信商户平台 开通支付功能:有了平台账号之后，然后就是开通支付功能，等待审核通过，当然审核过程有可能被退回，大多是描述信息或者经营类别与营业执照描述不一致","text":"准备条件开始之前先看一下微信的几个平台: 微信公众平台:是微信公众账号申请入口和管理后台。商户可以在公众平台提交基本资料、业务资料、财务资料申请开通微信支付功能。平台入口：http://mp.weixin.qq.com。 微信开放平台:微信开放平台是商户APP接入微信支付开放接口的申请入口，通过此平台可申请微信APP支付。平台入口：http://open.weixin.qq.com。 微信商户平台:微信商户平台是微信支付相关的商户功能集合，包括参数配置、支付数据查询与统计、在线退款、代金券或立减优惠运营等功能。平台入口：http://pay.weixin.qq.com 刚开始接入的时候有点昏，各种参数需要到不同的平台找, 不像支付宝一样只有一个开发平台，如果是接入微信扫码支付设及到微信公众平台和微信商户平台，如果是手机app微信支付，设及到微信开放平台和微信商户平台 开通支付功能:有了平台账号之后，然后就是开通支付功能，等待审核通过，当然审核过程有可能被退回，大多是描述信息或者经营类别与营业执照描述不一致 微信支付开发: 下面是微信支付的业务流程时序图, 可以看到与支付宝的支付流程主要流程是差不多的，只不过微信扫码可以在本系统完成支付，没有发生页面跳转，可以自己DIY支付页面，只要将支付链接生成二维码图片即可完成支付 logo 接入微信支付步骤1. 获取支付SDK gradle:地址 compile(&quot;com.github.wxpay:wxpay-sdk:0.0.3&quot;) 2. 配置参数主要是如下参数, 可以配置在一个属性文件中方面配置 1、APP ID ，应用ID（在公众平台–基本配置模块中） 2、APP Sercret ，应用秘钥（在公众平台–基本配置模块中）32位数字大小写字母 3、API Key，API的秘钥（在商户平台–API安全中设置） 4、mchID , 商户号（在公众平台—微信支付—商户信息） 5、order_api ， 统一下单API的接口 6、notify_url 交易成功回调的接口的URL 3. 新建一个参数配置类 WxPcPayConfigImpl.java 继承 WXPayConfig.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163/** * 微信支付PC端 基础属性配置 */public class WxPcPayConfigImpl implements WXPayConfig &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); // 配置文件地址 private static final String FILE_NAME = \"weixin_pc_pay.properties\"; // 服务号的应用ID public static String APP_ID; // 服务号的应用密钥 public static String APP_SECRET; // 服务号的配置token public static String TOKEN; // 商户号 public static String MCH_ID; // API密钥 public static String API_KEY; // 签名加密方式 public static String SIGN_TYPE; // 微信支付证书 public static String CERT_PATH; // 异步回调地址 public static String NOTIFY_URL; // 是否使用沙箱环境 public static boolean IS_USE_SANDBOX; // 证书 private static byte[] certData; // INSTANCE private static WxPcPayConfigImpl INSTANCE; // 配置对象 private static Configuration configs; // 文件分隔符 public final static String SF_FILE_SEPARATOR = System.getProperty(\"file.separator\");//文件分隔符 // 二维码图片宽度 public final static int QR_IMG_WIDTH = 300; // 二维码图片高度 public final static int QR_IMG_HEIGHT = 300; /** * 返回配置文件实例 * * @return * @throws Exception */ public static WxPcPayConfigImpl getInstance() throws Exception &#123; if (INSTANCE == null) &#123; synchronized (WxPcPayConfigImpl.class) &#123; if (INSTANCE == null) &#123; INSTANCE = new WxPcPayConfigImpl(); &#125; &#125; &#125; return INSTANCE; &#125; /** * 加载微信配置文件 */ public static synchronized void init() &#123; if (configs != null) &#123; return; &#125; try &#123; configs = new PropertiesConfiguration(FILE_NAME); &#125; catch (ConfigurationException e) &#123; e.printStackTrace(); &#125; if (configs == null) &#123; throw new IllegalStateException(\"读取配置文件错误\" + FILE_NAME); &#125; APP_ID = configs.getString(\"appId\"); APP_SECRET = configs.getString(\"appSecret\"); TOKEN = configs.getString(\"token\"); MCH_ID = configs.getString(\"mchId\"); API_KEY = configs.getString(\"apiKey\"); SIGN_TYPE = configs.getString(\"signType\"); CERT_PATH = configs.getString(\"certPath\"); IS_USE_SANDBOX = configs.getBoolean(\"isUseSandbox\"); NOTIFY_URL = configs.getString(\"notifyUrl\"); // 加载证书 File file; try &#123; // file = new File(CERT_PATH); Resource resource = new ClassPathResource(CERT_PATH); file = resource.getFile(); InputStream certStream = new FileInputStream(file); certData = new byte[(int) file.length()]; certStream.read(certData); certStream.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取 App ID * * @return App ID */ @Override public String getAppID() &#123; return APP_ID; &#125; /** * 获取 Mch ID * * @return Mch ID */ @Override public String getMchID() &#123; return MCH_ID; &#125; /** * 获取 API 密钥 * * @return API密钥 */ @Override public String getKey() &#123; return API_KEY; &#125; /** * 获取商户证书内容 * * @return 商户证书内容 */ @Override public InputStream getCertStream() &#123; ByteArrayInputStream certBis; certBis = new ByteArrayInputStream(this.certData); return certBis; &#125; /** * HTTP(S) 连接超时时间，单位毫秒 * * @return */ @Override public int getHttpConnectTimeoutMs() &#123; return 8000; &#125; /** * HTTP(S) 读数据超时时间，单位毫秒 * * @return */ @Override public int getHttpReadTimeoutMs() &#123; return 10000; &#125; public byte[] getCertData() &#123; return certData; &#125; public void setCertData(byte[] certData) &#123; this.certData = certData; &#125;&#125; 4. new 一个WXPay对象123WXPay wxAppPay;WxPcPayConfigImpl pcConfig = WxPcPayConfigImpl.getInstance();wxpay = new WXPay(pcConfig, WXPayConstants.SignType.MD5, WxPcPayConfigImpl.IS_USE_SANDBOX); 5. 有了”对象”之后就可以发送支付请求了123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * PC端微信支付请求 * * @param domainId 商户订单号取实体类id * @param amount 充值金额 * @return 处理结果数据 */public Map&lt;String, Object&gt; weixinPay(String domainId, BigDecimal amount, HttpServletRequest request) &#123; Map&lt;String, Object&gt; resultMaps = new HashMap&lt;&gt;(); resultMaps.put(\"status\", \"success\"); HashMap&lt;String, String&gt; data = new HashMap&lt;&gt;(); String currentUserName = \"\"; if (AccountUtils.getCurrentUser() != null) &#123; if (StringUtils.isNotBlank(AccountUtils.getCurrentUser().getFdNickName())) &#123; currentUserName = AccountUtils.getCurrentUser().getFdNickName(); &#125; &#125; String description = currentUserName + \" 账户充值\"; data.put(\"body\", description); // 商品描述 data.put(\"out_trade_no\", domainId); // 商户订单号 data.put(\"total_fee\", AmountUtils.transAmountToCent(amount)); // 总金额,单位为分 data.put(\"spbill_create_ip\", WxUtils.getRemoteIp(request)); // 发起人IP地址 data.put(\"notify_url\", WxPcPayConfigImpl.NOTIFY_URL); // 异步通知地址 data.put(\"trade_type\", \"NATIVE\"); // 此处指定为扫码支付 data.put(\"product_id\", domainId); // 商品ID,trade_type=NATIVE时（即扫码支付），此参数必传 Map&lt;String, String&gt; resultMap; try &#123; resultMap = wxpay.unifiedOrder(data); logger.info(\"微信生成二维码返回xml 转成Json\" + JsonFormatUtil.formatJson(resultMap.toString())); System.out.println(resultMap); &#125; catch (Exception e) &#123; e.printStackTrace(); logger.error(\"微信支付处理异常\"); resultMaps.put(\"status\", \"failed\"); return resultMaps; &#125; String returnCode = resultMap.get(\"return_code\"); // 返回结果 if (\"SUCCESS\".equals(returnCode)) &#123; String resultCode = resultMap.get(\"result_code\"); // 处理结果 if (\"SUCCESS\".equals(resultCode)) &#123; logger.info(\"订单号：&#123;&#125;生成微信支付码成功\", domainId); String urlCode = resultMap.get(\"code_url\"); // 生成二维码 logger.info(\"\"); // WxUtils.encodeQRCode(urlCode,imgPath); String imgBase64Str = WxUtils.encodeQRCodeBase64(urlCode); // 是否是微信支付 resultMaps.put(\"id\", domainId); resultMaps.put(\"isWxPay\", true); resultMaps.put(\"img\", imgBase64Str); &#125; else &#123; String errCodeDes = resultMap.get(\"err_code_des\"); logger.info(\"订单号：&#123;&#125;生成微信支付码(系统)失败:&#123;&#125;\", domainId, errCodeDes); resultMaps.put(\"status\", \"failed\"); return resultMaps; &#125; &#125; else &#123; String returnMsg = resultMap.get(\"return_msg\"); logger.info(\"(订单号：&#123;&#125;生成微信支付码(通信)失败:&#123;&#125;\", domainId, returnMsg); resultMaps.put(\"status\", \"failed\"); return resultMaps; &#125; return resultMaps;&#125; 微信支付统一下单接口:12345678910/** * 作用：统一下单&lt;br&gt; * 场景：公共号支付、扫码支付、APP支付 * @param reqData 向wxpay post的请求数据 * @return API返回数据 * @throws Exception */public Map&lt;String, String&gt; unifiedOrder(Map&lt;String, String&gt; reqData) throws Exception &#123; return this.unifiedOrder(reqData, config.getHttpConnectTimeoutMs(), this.config.getHttpReadTimeoutMs());&#125; 6. 生成支付二维码这里我是将二维码链接字符串转成字符流 然后生成Base64位的图片字符, 只要在 设置src属性值，就可以完成图片展示，不用考虑生成的图片放在那里 7. 支付完成, 处理异步回调备注： 微信支付是使用的xml进行传输数据，需要将xml转成map，当然微信SDK中也提供了工具类，提供了一些十分用的方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257package com.github.wxpay.sdk;import java.io.ByteArrayInputStream;import java.io.InputStream;import java.io.StringWriter;import java.util.*;import java.security.MessageDigest;import org.w3c.dom.Node;import org.w3c.dom.NodeList;import javax.crypto.Mac;import javax.crypto.spec.SecretKeySpec;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import javax.xml.transform.OutputKeys;import javax.xml.transform.Transformer;import javax.xml.transform.TransformerFactory;import javax.xml.transform.dom.DOMSource;import javax.xml.transform.stream.StreamResult;import com.github.wxpay.sdk.WXPayConstants.SignType;public class WXPayUtil &#123; /** * XML格式字符串转换为Map * * @param strXML XML字符串 * @return XML数据转换后的Map * @throws Exception */ public static Map&lt;String, String&gt; xmlToMap(String strXML) throws Exception &#123; Map&lt;String, String&gt; data = new HashMap&lt;String, String&gt;(); DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder documentBuilder= documentBuilderFactory.newDocumentBuilder(); InputStream stream = new ByteArrayInputStream(strXML.getBytes(\"UTF-8\")); org.w3c.dom.Document doc = documentBuilder.parse(stream); doc.getDocumentElement().normalize(); NodeList nodeList = doc.getDocumentElement().getChildNodes(); for (int idx=0; idx&lt;nodeList.getLength(); ++idx) &#123; Node node = nodeList.item(idx); if (node.getNodeType() == Node.ELEMENT_NODE) &#123; org.w3c.dom.Element element = (org.w3c.dom.Element) node; data.put(element.getNodeName(), element.getTextContent()); &#125; &#125; try &#123; stream.close(); &#125; catch (Exception ex) &#123; &#125; return data; &#125; /** * 将Map转换为XML格式的字符串 * * @param data Map类型数据 * @return XML格式的字符串 * @throws Exception */ public static String mapToXml(Map&lt;String, String&gt; data) throws Exception &#123; DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder documentBuilder= documentBuilderFactory.newDocumentBuilder(); org.w3c.dom.Document document = documentBuilder.newDocument(); org.w3c.dom.Element root = document.createElement(\"xml\"); document.appendChild(root); for (String key: data.keySet()) &#123; String value = data.get(key); if (value == null) &#123; value = \"\"; &#125; value = value.trim(); org.w3c.dom.Element filed = document.createElement(key); filed.appendChild(document.createTextNode(value)); root.appendChild(filed); &#125; TransformerFactory tf = TransformerFactory.newInstance(); Transformer transformer = tf.newTransformer(); DOMSource source = new DOMSource(document); transformer.setOutputProperty(OutputKeys.ENCODING, \"UTF-8\"); transformer.setOutputProperty(OutputKeys.INDENT, \"yes\"); StringWriter writer = new StringWriter(); StreamResult result = new StreamResult(writer); transformer.transform(source, result); String output = writer.getBuffer().toString(); //.replaceAll(\"\\n|\\r\", \"\"); try &#123; writer.close(); &#125; catch (Exception ex) &#123; &#125; return output; &#125; /** * 生成带有 sign 的 XML 格式字符串 * * @param data Map类型数据 * @param key API密钥 * @return 含有sign字段的XML */ public static String generateSignedXml(final Map&lt;String, String&gt; data, String key) throws Exception &#123; return generateSignedXml(data, key, SignType.MD5); &#125; /** * 生成带有 sign 的 XML 格式字符串 * * @param data Map类型数据 * @param key API密钥 * @param signType 签名类型 * @return 含有sign字段的XML */ public static String generateSignedXml(final Map&lt;String, String&gt; data, String key, SignType signType) throws Exception &#123; String sign = generateSignature(data, key, signType); data.put(WXPayConstants.FIELD_SIGN, sign); return mapToXml(data); &#125; /** * 判断签名是否正确 * * @param xmlStr XML格式数据 * @param key API密钥 * @return 签名是否正确 * @throws Exception */ public static boolean isSignatureValid(String xmlStr, String key) throws Exception &#123; Map&lt;String, String&gt; data = xmlToMap(xmlStr); if (!data.containsKey(WXPayConstants.FIELD_SIGN) ) &#123; return false; &#125; String sign = data.get(WXPayConstants.FIELD_SIGN); return generateSignature(data, key).equals(sign); &#125; /** * 判断签名是否正确，必须包含sign字段，否则返回false。使用MD5签名。 * * @param data Map类型数据 * @param key API密钥 * @return 签名是否正确 * @throws Exception */ public static boolean isSignatureValid(Map&lt;String, String&gt; data, String key) throws Exception &#123; return isSignatureValid(data, key, SignType.MD5); &#125; /** * 判断签名是否正确，必须包含sign字段，否则返回false。 * * @param data Map类型数据 * @param key API密钥 * @param signType 签名方式 * @return 签名是否正确 * @throws Exception */ public static boolean isSignatureValid(Map&lt;String, String&gt; data, String key, SignType signType) throws Exception &#123; if (!data.containsKey(WXPayConstants.FIELD_SIGN) ) &#123; return false; &#125; String sign = data.get(WXPayConstants.FIELD_SIGN); return generateSignature(data, key, signType).equals(sign); &#125; /** * 生成签名 * * @param data 待签名数据 * @param key API密钥 * @return 签名 */ public static String generateSignature(final Map&lt;String, String&gt; data, String key) throws Exception &#123; return generateSignature(data, key, SignType.MD5); &#125; /** * 生成签名. 注意，若含有sign_type字段，必须和signType参数保持一致。 * * @param data 待签名数据 * @param key API密钥 * @param signType 签名方式 * @return 签名 */ public static String generateSignature(final Map&lt;String, String&gt; data, String key, SignType signType) throws Exception &#123; Set&lt;String&gt; keySet = data.keySet(); String[] keyArray = keySet.toArray(new String[keySet.size()]); Arrays.sort(keyArray); StringBuilder sb = new StringBuilder(); for (String k : keyArray) &#123; if (k.equals(WXPayConstants.FIELD_SIGN)) &#123; continue; &#125; if (data.get(k).trim().length() &gt; 0) // 参数值为空，则不参与签名 sb.append(k).append(\"=\").append(data.get(k).trim()).append(\"&amp;\"); &#125; sb.append(\"key=\").append(key); if (SignType.MD5.equals(signType)) &#123; return MD5(sb.toString()).toUpperCase(); &#125; else if (SignType.HMACSHA256.equals(signType)) &#123; return HMACSHA256(sb.toString(), key); &#125; else &#123; throw new Exception(String.format(\"Invalid sign_type: %s\", signType)); &#125; &#125; /** * 获取随机字符串 Nonce Str * * @return String 随机字符串 */ public static String generateNonceStr() &#123; return UUID.randomUUID().toString().replaceAll(\"-\", \"\").substring(0, 32); &#125; /** * 生成 MD5 * * @param data 待处理数据 * @return MD5结果 */ public static String MD5(String data) throws Exception &#123; java.security.MessageDigest md = MessageDigest.getInstance(\"MD5\"); byte[] array = md.digest(data.getBytes(\"UTF-8\")); StringBuilder sb = new StringBuilder(); for (byte item : array) &#123; sb.append(Integer.toHexString((item &amp; 0xFF) | 0x100).substring(1, 3)); &#125; return sb.toString().toUpperCase(); &#125; /** * 生成 HMACSHA256 * @param data 待处理数据 * @param key 密钥 * @return 加密结果 * @throws Exception */ public static String HMACSHA256(String data, String key) throws Exception &#123; Mac sha256_HMAC = Mac.getInstance(\"HmacSHA256\"); SecretKeySpec secret_key = new SecretKeySpec(key.getBytes(\"UTF-8\"), \"HmacSHA256\"); sha256_HMAC.init(secret_key); byte[] array = sha256_HMAC.doFinal(data.getBytes(\"UTF-8\")); StringBuilder sb = new StringBuilder(); for (byte item : array) &#123; sb.append(Integer.toHexString((item &amp; 0xFF) | 0x100).substring(1, 3)); &#125; return sb.toString().toUpperCase(); &#125;&#125; 参考于:http://mp.weixin.qq.com http://open.weixin.qq.com http://pay.weixin.qq.com","categories":[{"name":"业务","slug":"业务","permalink":"http://www.songshuiyang.com/categories/业务/"}],"tags":[{"name":"支付","slug":"支付","permalink":"http://www.songshuiyang.com/tags/支付/"}]},{"title":"接入支付宝支付接口","slug":"backend/business/payment/接入支付宝支付接口","date":"2018-01-10T02:24:12.000Z","updated":"2020-03-16T11:43:55.364Z","comments":true,"path":"2018/01/10/backend/business/payment/接入支付宝支付接口/","link":"","permalink":"http://www.songshuiyang.com/2018/01/10/backend/business/payment/接入支付宝支付接口/","excerpt":"一: 应用场景 主要应用于一些交易平台商品订单支付，账户充值，线上收费这些有支付需求的交易 用户通过支付宝PC收银台完成支付，交易款项即时给到商户支付宝账户 logo logo","text":"一: 应用场景 主要应用于一些交易平台商品订单支付，账户充值，线上收费这些有支付需求的交易 用户通过支付宝PC收银台完成支付，交易款项即时给到商户支付宝账户 logo logo 二: 准备条件 一个公司, 不是公司的话是不能接入商户支付宝网关支付的, 当然支付宝是分个人用户和商户用户的, 如果是个人网站的话可以贴个自己收款二维码上去进行收款, 如果是正在运营的商户企业收取费用的话是要接入支付宝网关支付功能进行收费, 这样的话可以看起来bigger更高 企业或个体工商户，具有真实有效的营业执照，且支付宝账户名称需与营业执照主体一致 网站通过ICP备案，能正常访问，页面显示完整，有明确的运营内容与完整的商品信息。 三：接入支付宝支付功能步骤第一步：创建应用要在应用中使用支付宝开放产品的接口能力： 需要先去蚂蚁金服开放平台，在开发者中心创建登记您的应用，此时将获得应用唯一标识（APPID） 请在【功能信息】中点击【添加功能】，选择【电脑网站支付】 提交审核（需要上传公司营业执照,填写法人身份信息等等），等待审核通过，该应用正式可以使用 TIPS：电脑网站支付接口需签约后才能调用 第二步：配置密钥开发者调用接口前需要先生成RSA密钥，RSA密钥包含应用私钥(APP_PRIVATE_KEY)、应用公钥(APP_PUBLIC_KEY）。生成密钥后在开放平台管理中心进行密钥配置，配置完成后可以获取支付宝公钥(ALIPAY_PUBLIC_KEY)。 用途：支付宝发送信息给商户系统时，使用支付宝私钥对数据进行加签，商户获取到支付宝加签的信息后使用支付宝公钥对数据进行验签，得到正确的数据。商户系统给支付宝发送信息时，使用商户自己的私钥对数据加签，支付宝获取到数据后使用商家上传的公钥进行验签。 加签步骤: 1.筛选 获取所有请求参数，不包括字节类型参数，如文件、字节流，剔除sign与sign_type参数。 2.排序 将筛选的参数按照第一个字符的键值ASCII码递增排序（字母升序排序），如果遇到相同字符则按照第二个字符的键值ASCII码递增排序，以此类推。拼接 将排序后的参数与其对应值，组合成“参数=参数值”的格式，并且把这些参数用&amp;字符连接起来，此时生成的字符串为待签名字符串。商户将待签名字符串和商户私钥带入加签算法中得出sign。然后将sign值加入到请求参数中，发送给支付宝 3.拼接 将排序后的参数与其对应值，组合成“参数=参数值”的格式，并且把这些参数用&amp;字符连接起来，此时生成的字符串为待签名字符串。 4.加签 商户将待签名字符串和商户私钥带入加签算法中得出sign。然后将sign值加入到请求参数中，发送给支付宝 验签步骤： 与加签步骤一致，只不过是延签是使用公钥算出sign值，两方算出的sign值都一致的话则延签成功 第三步：搭建和配置开发环境 需要到支付宝开发平台下载服务端SDK,打包即用, 十分方便 配置参数 123456789AlipayClient alipayClient = new DefaultAlipayClient(URL,APP_ID,APP_PRIVATE_KEY,FORMAT,CHARSET,ALIPAY_PUBLIC_KEY,SIGN_TYPE);// URL:支付宝网关（固定） https://openapi.alipay.com/gateway.do, 如果是沙箱环境的话: https://openapi.alipaydev.com/gateway.do// APP_ID:创建应用时获取, 支付宝提供// APP_PRIVATE_KEY: 应用私钥, 运用支付宝提供的工具进行生成// FORMAT: json（固定）// CHARSET: 编码格式// ALIPAY_PUBLIC_KEY: 支付宝公钥, 由支付宝提供// SIGN_TYPE： 加签类型，商户生成签名字符串所使用的签名算法类型，目前支持RSA2和RSA，推荐使用RSA2 配置完参数之后就可以调用支付宝的支付接口了, 十分方便, 阿里阿里 !!! 配置完参数之后先来看一下支付的调用流程： logo 接下来就是发起支付请求了12345678910111213141516171819202122232425262728import com.alipay.api.*;import com.alipay.api.request.*; public void doPost(HttpServletRequest httpRequest, HttpServletResponse httpResponse) throws ServletException,IOException &#123; //获得初始化的AlipayClient AlipayClient alipayClient = new DefaultAlipayClient(\"https://openapi.alipay.com/gateway.do\", APP_ID, APP_PRIVATE_KEY, FORMAT, CHARSET, ALIPAY_PUBLIC_KEY, SIGN_TYPE);//创建支付请求的对应requestAlipayTradePagePayRequest alipayRequest = new AlipayTradePagePayRequest();//设置请求参数及回跳地址和通知地址 alipayRequest.setBizContent(\"&#123;\" + \" \\\"out_trade_no\\\":\\\"20150320010101001\\\",\" + \" \\\"total_amount\":88.88,\" + \" \\\"subject\\\":title\\\",\" + \" \\\"body\\\":\\\"Iphone6 16G\\\",\" + &#125;\");//跳转地址就是支付完成之后，支付宝自动执行页面重定向,就是跳转到我们设置的页面alipayRequest.setReturnUrl(\"http://www.songshuiyang.site/return_url\"); //通知地址就是支付宝会根据API中商户传入的notify_url，通过POST请求的形式将支付结果作为参数通知到商户系统。alipayRequest.setNotifyUrl(\"http://www.songshuiyang.site/notify_url\");String form=\"\";try &#123; //调用SDK生成html表单 form = alipayClient.pageExecute(alipayRequest).getBody(); &#125; catch (AlipayApiException e) &#123; e.printStackTrace(); &#125; //直接将完整的表单html输出到页面httpResponse.setContentType(\"text/html;charset=\" + CHARSET); httpResponse.getWriter().write(form); httpResponse.getWriter().flush(); httpResponse.getWriter().close(); &#125; 支付接口生成的html代码12345&lt;form name=\"punchout_form\" method=\"post\" action=\"https://openapi.alipay.com/gateway.do?charset=utf-8&amp;method=alipay.trade.page.pay&amp;sign=jsgXRru7b%2FHLO76SMPoj6lIuCnKJ9lkLo%2BTPIKfetqMOd8kyp2zYBZ456Dvf0eb4SyYgUrOjAgTkNW2AkgJh%2BbLJDu3eAtQVAUEEzFGy2Ix3uE3j3lPLHZDs1cF7g8vw7hwfmEqe8CE8OCJ%2B79J0Hp6YFOH8vnJEDUPvjla2AsCO0mhAsnYxm30rmqgDqJPfZLytOvRD5FF%2BoBd4UPH%2Budk7vCn9lEX%2BkEe7YBa3E7l6vWxXz%2BJDKGL9ZMHNtUzYUaid%2F%2BIugVLqtECybldd8YDZUFnz92Iq%2BOwIL09MzNtb6iC9AypfQxlTseFezDihBn%2Fey5itIovqntbLLdxt2g%3D%3D&amp;return_url=http%3A%2F%2Fwww.songshuiyang.com%2Fbuyer2%2Fpayment%2Findex&amp;notify_url=http%3A%2F%2Fwww.songshuiyang.com%2Fbuyer2%2Fpayment2%2Falipay_notify&amp;version=1.0&amp;app_id=123456789101554&amp;sign_type=RSA2&amp;timestamp=2018-01-01+14%3A27%3A50&amp;alipay_sdk=alipay-sdk-java-dynamicVersionNo&amp;format=json\"&gt; &lt;input type=\"hidden\" name=\"biz_content\" value=\"&#123;&amp;quot;out_trade_no&amp;quot;:&amp;quot;160b06765224a9aee66a6654541b947f&amp;quot;,&amp;quot;total_amount&amp;quot;:&amp;quot;0.01&amp;quot;,&amp;quot;subject&amp;quot;:&amp;quot;江西广而易科技有限公司 账户充值&amp;quot;,&amp;quot;body&amp;quot;:&amp;quot;充值金额: 0.01&amp;quot;,&amp;quot;product_code&amp;quot;:&amp;quot;FAST_INSTANT_TRADE_PAY&amp;quot;&#125;\"&gt; &lt;input type=\"submit\" value=\"立即支付\" style=\"display:none\" &gt;&lt;/form&gt;&lt;script&gt;document.forms[0].submit();&lt;/script&gt; 注意 action 链接后面的sign值就是签名字符串, 用于校验数据的来源还有数据有没有被修改 biz_content 是业务参数 html输出到页面后会跳转到支付的支付页面 第四步：扫码支付进行的步骤1.支付 logo 2.支付成功会自动跳转到商户页面(同步通知) 就是前面设置的 alipayRequest.setReturnUrl(“http://www.songshuiyang.site/return_url&quot;);,这部是支付完成之后支付宝的处理程序进行了页面重定向, 不是支付宝主动触发的。 logo 3.系统后台收到异步通知 对于PC网站支付的交易，在用户支付完成之后，支付宝会根据API中商户传入的alipayRequest.setNotifyUrl(“http://www.songshuiyang.site/notify_url&quot;);，通过POST请求的形式将支付结果作为参数通知到商户系统，该方式的作用是页面跳转同步通知没有处理订单更新，需要通过异步通知的方式去通知系统后台更新流水 4.进行异步通知处理 程序执行完后必须打印输出“success”。如果商户反馈给支付宝的字符不是success这7个字符，支付宝服务器会不断重发通知，直到超过24小时22分钟。一般情况下，25小时以内完成8次通知（通知的间隔频率一般是：4m,10m,10m,1h,2h,6h,15h）； 处理代码:123456789101112131415//将异步通知中收到的所有参数都存放到map中Map&lt;String, String&gt; paramsMap = ...;//调用SDK验证签名boolean signVerified = AlipaySignature.rsaCheckV1(paramsMap, ALIPAY_PUBLIC_KEY, CHARSET, SIGN_TYPE) if(signVerfied)&#123; // TODO 验签成功后，按照支付结果异步通知中的描述，对支付结果中的业务内容进行二次校验1、商户需要验证该通知数据中的out_trade_no是否为商户系统中创建的订单号，2、判断total_amount是否确实为该订单的实际金额（即商户订单创建时的金额），3、校验通知中的seller_id（或者seller_email) 是否为out_trade_no这笔单据的对应的操作方4、验证app_id是否为该商户本身。// 二次校验成功，继续商户自身业务处理，处理完成之后返回success&#125; else &#123; // TODO 验签失败则记录异常日志，并在response中返回failure. &#125; 注意： 这里延签公钥是支付宝公钥, 不是应用公钥, 如果是按照支付宝的示例代码的话很容易填成应用公钥, 导致延签失败 如果是异步通知处理失败 当商户后台、网络、服务器等出现异常，商户系统最终未接收到支付异步通知；需要自己手动向支付宝发送查询请求，根据查询出来的结果确定该交易是否成功 12345678910111213AlipayClient alipayClient = new DefaultAlipayClient(\"https://openapi.alipay.com/gateway.do\",\"app_id\",\"your private_key\",\"json\",\"GBK\",\"alipay_public_key\",\"RSA2\"); //创建查询请求的对应requestAlipayTradeQueryRequest request = new AlipayTradeQueryRequest();request.setBizContent(\"&#123;\" + \"\\\"out_trade_no\\\":\\\"20150320010101001\\\",\" + \"\\\"trade_no\\\":\\\"2014112611001004680073956707\\\"\" + \"&#125;\"); AlipayTradeQueryResponse response = alipayClient.execute(request); if(response.isSuccess())&#123; //交易状态：WAIT_BUYER_PAY（交易创建，等待买家付款）、TRADE_CLOSED（未付款交易超时关闭，或支付完成后全额退款）、TRADE_SUCCESS（交易支付成功）、TRADE_FINISHED（交易结束，不可退款） System.out.println(\"调用成功\"); &#125; else &#123; System.out.println(\"调用失败\"); 注意： 这里延签公钥是支付宝公钥, 不是应用公钥, 如果是按照支付宝的示例代码的话很容易填成应用公钥, 导致签名失败 五：支付宝网关支付API 接口英文名 接口中文 alipay.trade.page.pay 统一收单下单并支付页面接口 alipay.trade.refund 统一收单交易退款接口 alipay.trade.fastpay.refund.query 统一收单交易退款查询接口 alipay.trade.query 统一收单线下交易查询接口 alipay.trade.close 统一收单交易关闭接口 alipay.data.dataservice.bill.downloadurl.query 查询对账单下载地址 六： 使用沙箱环境进行测试 蚂蚁沙箱环境(Beta)是协助开发者进行接口功能开发及主要功能联调的辅助环境。沙箱环境模拟了开放平台部分产品的主要功能和主要逻辑（当前沙箱支持产品请参考“沙箱支持产品列表”）。 在开发者应用上线审核前，开发者可以根据自身需求，先在沙箱环境中了解、组合和调试各种开放接口，进行开发调通工作，从而帮助开发者在应用上线审核完成后，能更快速、更顺利的进行线上调试和验收工作。 可以体验一把土豪的感觉, 不用在真实环境下使用一分钱测试联调大法了 七：总结 支付宝的支付接口进行了高度封装，可以拿过来直接使用，不必关心怎样签名&amp;验签、HTTP接口请求这些处理 在进行数据传输通信的同时，需要校验传输数据的来源，数据有没有进行修改，防止恶意数据攻击 注:本文内容参考支付宝开放平台文档内容, 一切以官方文档为准, 链接地址: https://open.alipay.com/platform/home.htm","categories":[{"name":"业务","slug":"业务","permalink":"http://www.songshuiyang.com/categories/业务/"}],"tags":[{"name":"支付","slug":"支付","permalink":"http://www.songshuiyang.com/tags/支付/"}]},{"title":"Maven 41种骨架","slug":"backend/buildTool/Maven/maven 骨架","date":"2017-11-18T13:58:45.000Z","updated":"2020-03-16T11:43:55.313Z","comments":true,"path":"2017/11/18/backend/buildTool/Maven/maven 骨架/","link":"","permalink":"http://www.songshuiyang.com/2017/11/18/backend/buildTool/Maven/maven 骨架/","excerpt":"","text":"Maven 的41种骨架功能介绍 …&gt;mvn archetype:generate12345678910111213141516171819202122232425262728293031323334353637383940411: internal -&gt; appfuse-basic-jsf (创建一个基于Hibernate，Spring和JSF的Web应用程序的原型) 2: internal -&gt; appfuse-basic-spring (创建一个基于Hibernate，Spring和Spring MVC的Web应用程序的原型) 3: internal -&gt; appfuse-basic-struts (创建一个基于Hibernate，Spring和Struts 2的Web应用程序的原型) 4: internal -&gt; appfuse-basic-tapestry (创建一个基于Hibernate, Spring 和 Tapestry 4的Web应用程序的原型) 5: internal -&gt; appfuse-core (创建一个基于 Hibernate and Spring 和 XFire的jar应用程序的原型) 6: internal -&gt; appfuse-modular-jsf (创建一个基于 Hibernate，Spring和JSF的模块化应用原型) 7: internal -&gt; appfuse-modular-spring (创建一个基于 Hibernate, Spring 和 Spring MVC 的模块化应用原型) 8: internal -&gt; appfuse-modular-struts (创建一个基于 Hibernate, Spring 和 Struts 2 的模块化应用原型) 9: internal -&gt; appfuse-modular-tapestry (创建一个基于 Hibernate, Spring 和 Tapestry 4 的模块化应用原型) 10: internal -&gt; maven-archetype-j2ee-simple (一个简单的J2EE的Java应用程序) 11: internal -&gt; maven-archetype-marmalade-mojo (一个Maven的 插件开发项目 using marmalade) 12: internal -&gt; maven-archetype-mojo (一个Maven的Java插件开发项目) 13: internal -&gt; maven-archetype-portlet (一个简单的portlet应用程序) 14: internal -&gt; maven-archetype-profiles () 15: internal -&gt; maven-archetype-quickstart () 16: internal -&gt; maven-archetype-site-simple (简单的网站生成项目) 17: internal -&gt; maven-archetype-site (更复杂的网站项目) 18: internal -&gt; maven-archetype-webapp (一个简单的Java Web应用程序) 19: internal -&gt; jini-service-archetype (Archetype for Jini service project creation) 20: internal -&gt; softeu-archetype-seam (JSF+Facelets+Seam Archetype) 21: internal -&gt; softeu-archetype-seam-simple (JSF+Facelets+Seam (无残留) 原型) 22: internal -&gt; softeu-archetype-jsf (JSF+Facelets 原型) 23: internal -&gt; jpa-maven-archetype (JPA 应用程序) 24: internal -&gt; spring-osgi-bundle-archetype (Spring-OSGi 原型) 25: internal -&gt; confluence-plugin-archetype (Atlassian 聚合插件原型) 26: internal -&gt; jira-plugin-archetype (Atlassian JIRA 插件原型) 27: internal -&gt; maven-archetype-har (Hibernate 存档) 28: internal -&gt; maven-archetype-sar (JBoss 服务存档) 29: internal -&gt; wicket-archetype-quickstart (一个简单的Apache Wicket的项目) 30: internal -&gt; scala-archetype-simple (一个简单的scala的项目) 31: internal -&gt; lift-archetype-blank (一个 blank/empty liftweb 项目) 32: internal -&gt; lift-archetype-basic (基本（liftweb）项目) 33: internal -&gt; cocoon-22-archetype-block-plain ([http://cocoapacorg2/maven-plugins/]) 34: internal -&gt; cocoon-22-archetype-block ([http://cocoapacorg2/maven-plugins/]) 35: internal -&gt; cocoon-22-archetype-webapp ([http://cocoapacorg2/maven-plugins/]) 36: internal -&gt; myfaces-archetype-helloworld (使用MyFaces的一个简单的原型) 37: internal -&gt; myfaces-archetype-helloworld-facelets (一个使用MyFaces和Facelets的简单原型) 38: internal -&gt; myfaces-archetype-trinidad (一个使用MyFaces和Trinidad的简单原型) 39: internal -&gt; myfaces-archetype-jsfcomponents (一种使用MyFaces创建定制JSF组件的简单的原型) 40: internal -&gt; gmaven-archetype-basic (Groovy的基本原型) 41: internal -&gt; gmaven-archetype-mojo (Groovy mojo 原型) 原文: https://www.cnblogs.com/iusmile/archive/2012/11/14/2770118.html","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://www.songshuiyang.com/tags/maven/"}]},{"title":"Git初始配置","slug":"backend/buildTool/git/git初始配置","date":"2017-10-22T02:45:12.000Z","updated":"2020-03-16T11:43:55.316Z","comments":true,"path":"2017/10/22/backend/buildTool/git/git初始配置/","link":"","permalink":"http://www.songshuiyang.com/2017/10/22/backend/buildTool/git/git初始配置/","excerpt":"","text":"使用Git的前的初始配置1. 配置提交时的用户名与邮件名称(注:只是标识本次commit是谁提交的)1.1 通过命令的方式1234$ git config --global user.name \"songshuiyang\"$ git config --global user.email songshiuyang@foxmail.com注: global 全局配置,在此电脑上的所有项目的git提交都会用这个用户名和邮件 1.2 通过修改配置文件的方式 12345文件路径: 用户目录/.gitconfig 文件把name email改成(新增)自己的配置即可[user] name = songshuiyang email = songshiuyang@foxmail.com 2. 配置 短命令2.1 通过命令的方式1234$ git config --global alias.st status$ git config --global alias.ci commit$ git congig --global alias.co checkout$ git congig --global alias.br branch 2.2 通过修改配置文件的方式123456789101112131415[alias] co = checkout ci = commit st = status cm = commit -m br = branch bm = branch -m bd = branch -D cb = checkout -b df = diff ls = log --stat lp = log -p plo = pull origin plode = pull origin develop pho = push origin 3. 配置文件 Git的三个配置文件 版本库级别的配置文件,文件路径: 项目路径/.git/config 全局配置文件, 文件路径: 用户目录/.gitconfig 系统级配置文件,文件路径: 安装目录/etc目录下 优先级: 版本库级别的配置文件 &gt; 全局配置文件 &gt; 系统级配置文件 4. 文件 .git/index实际上就是一个包括文件索引的目录树,像是一个虚拟的工作区,记录了文件名和文件的状态信息(时间戳和文件长度),文件的内容保存在.git/objects目录下,文件索引建立了文件和对象库中对象实体之间的对应 工作区,版本区,暂存区原理图 git","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://www.songshuiyang.com/tags/git/"}]},{"title":"Android-SDK-配置","slug":"android/Android-SDK-配置","date":"2017-10-21T16:00:00.000Z","updated":"2020-03-16T11:43:55.294Z","comments":true,"path":"2017/10/22/android/Android-SDK-配置/","link":"","permalink":"http://www.songshuiyang.com/2017/10/22/android/Android-SDK-配置/","excerpt":"","text":"https://www.androiddevtools.cn","categories":[{"name":"Android","slug":"Android","permalink":"http://www.songshuiyang.com/categories/Android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://www.songshuiyang.com/tags/android/"}]},{"title":"编译构建部署版本工具","slug":"backend/buildTool/git/如何修改Git commit的信息","date":"2017-10-14T08:38:12.000Z","updated":"2020-03-16T11:43:55.321Z","comments":true,"path":"2017/10/14/backend/buildTool/git/如何修改Git commit的信息/","link":"","permalink":"http://www.songshuiyang.com/2017/10/14/backend/buildTool/git/如何修改Git commit的信息/","excerpt":"","text":"转自：http://www.cnblogs.com/shenh062326/p/git.html","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://www.songshuiyang.com/tags/git/"}]},{"title":"Hibernate Validator","slug":"backend/framework/hibernate/Hibernate Validator","date":"2017-10-14T04:28:12.000Z","updated":"2020-03-16T11:43:55.387Z","comments":true,"path":"2017/10/14/backend/framework/hibernate/Hibernate Validator/","link":"","permalink":"http://www.songshuiyang.com/2017/10/14/backend/framework/hibernate/Hibernate Validator/","excerpt":"","text":"Hibernate ValidatorHibernate Validator 是 Bean Validation 的参考实现 。Hibernate Validator 提供了 JSR 303 规范中所有内置 constraint 的实现，除此之外还有一些附加的 constraint。在日常开发中，Hibernate Validator经常用来验证bean的字段，基于注解，方便快捷高效。 1. Bean Validation 中内置的 constraint 注解 作用 @Valid 被注释的元素是一个对象，需要检查此对象的所有字段值 @Valid 被注释的元素是一个对象，需要检查此对象的所有字段值 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max, min) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(value) 被注释的元素必须符合指定的正则表达式 2. Hibernate Validator 附加的 constraint 注解 作用 @Email 被注释的元素必须是电子邮箱地址 @Length(min=, max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=, max=) 被注释的元素必须在合适的范围内 @NotBlank 被注释的字符串的必须非空 @URL(protocol=,host=, port=, regexp=, flags=) 被注释的字符串必须是一个有效的url @CreditCardNumber 被注释的字符串必须通过Luhn校验算法， 银行卡，信用卡等号码一般都用Luhn 计算合法性 @ScriptAssert (lang=, script=, alias=) 要有Java Scripting API 即JSR 223 (“Scripting for the JavaTM Platform”)的实现 @SafeHtml(whitelistType=, additionalTags=) classpath中要有jsoup包 举个栗子123456789101112131415161718192021222324252627282930public class User &#123; @NotBlank private String name; //年龄要大于18岁 @Min(18) private int age; @Email private String email; //嵌套验证 @Valid private Product products; ... //省略getter，setter &#125; public class Product &#123; @NotBlank private String name; //价格在10元-50元之间 @Range(min=10,max=50) private int price; ... //省略getter，setter &#125; 转自:http://blog.csdn.net/u011851478/article/details/51842157","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Hibernate","slug":"Hibernate","permalink":"http://www.songshuiyang.com/tags/Hibernate/"}]},{"title":"编译构建部署版本工具","slug":"backend/buildTool/grandle","date":"2017-10-13T17:07:12.000Z","updated":"2020-03-16T11:43:55.324Z","comments":true,"path":"2017/10/14/backend/buildTool/grandle/","link":"","permalink":"http://www.songshuiyang.com/2017/10/14/backend/buildTool/grandle/","excerpt":"","text":"Grandle gradle 易百教程http://www.yiibai.com/gradle/ Gradle学习系列之一——Gradle快速入门http://www.cnblogs.com/CloudTeng/p/3417762.html android grandlehttp://www.jianshu.com/p/9df3c3b6067a","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.songshuiyang.com/tags/java/"}]},{"title":"github","slug":"technology/github","date":"2017-10-08T14:10:12.000Z","updated":"2020-03-16T11:43:55.625Z","comments":true,"path":"2017/10/08/technology/github/","link":"","permalink":"http://www.songshuiyang.com/2017/10/08/technology/github/","excerpt":"","text":"watch、star、fork 的使用watch 对于别人的项目，默认自己都处于 Not watching 的状态，当你选择 Watching，表示你以后会关注这个项目的所有动态，这个项目以后只要发生变动，如被别人提交了 pull request、被别人发起了issue等等情况，你都会在自己的个人通知中心，收到一条通知消息，如果你设置了个人邮箱，那么你的邮箱也可能收到相应的邮件。 star 当你点击 star，表示你喜欢这个项目或者通俗点，可以把他理解成朋友圈的点赞吧，表示对这个项目的支持 fork 当选择 fork，相当于你自己有了一份原项目的拷贝，当然这个拷贝只是针对当时的项目文件，如果后续原项目文件发生改变，你必须通过其他的方式去同步（注意）。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"web","slug":"web","permalink":"http://www.songshuiyang.com/tags/web/"}]},{"title":"计算属性","slug":"frontend/计算属性","date":"2017-10-05T02:52:12.000Z","updated":"2019-09-16T13:11:07.315Z","comments":true,"path":"2017/10/05/frontend/计算属性/","link":"","permalink":"http://www.songshuiyang.com/2017/10/05/frontend/计算属性/","excerpt":"","text":"计算属性是基于它们的依赖进行缓存的。计算属性只有在它的相关依赖发生改变时才会重新求值。这就意味着只要 message 还没有发生改变，多次访问 reversedMessage 计算属性会立即返回之前的计算结果，而不必再次执行函数。 这也同样意味着下面的计算属性将不再更新，因为 Date.now() 不是响应式依赖：12345computed: &#123; now: function () &#123; return Date.now() &#125;&#125; 12345computed: &#123; now: function () &#123; return Date.now() &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.songshuiyang.com/tags/vue/"}]},{"title":"v-model v-bind","slug":"frontend/v-model和v-bind的区别","date":"2017-10-05T02:12:12.000Z","updated":"2019-09-16T13:11:07.299Z","comments":true,"path":"2017/10/05/frontend/v-model和v-bind的区别/","link":"","permalink":"http://www.songshuiyang.com/2017/10/05/frontend/v-model和v-bind的区别/","excerpt":"","text":"Mustache (双大括号写法)不能在 HTML 属性中使用，应使用 v-bind 指令：1&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 这对布尔值的属性也有效 —— 如果条件被求值为 false 的话该属性会被移除：1&lt;button v-bind:disabled=&quot;someDynamicCondition&quot;&gt;Button&lt;/button&gt; v-bind动态绑定指令，默认情况下标签自带属性的值是固定的，在为了能够动态的给这些属性添加值，可以使用v-bind:你要动态变化的值=”表达式” v-bind用于绑定属性和数据 ，其缩写为“ : ” 也就是v-bind:id === :id v-model用在表单控件上的，用于实现双向数据绑定，所以如果你用在除了表单控件以外的标签是没有任何效果的。 v-bind1234567891011121314151617181920212223&lt;!-- 绑定一个属性 --&gt;&lt;img v-bind:src=&quot;imageSrc&quot;&gt;&lt;!-- 缩写 --&gt;&lt;img :src=&quot;imageSrc&quot;&gt;&lt;!-- 内联字符串拼接 --&gt;&lt;img :src=&quot;&apos;/path/to/images/&apos; + fileName&quot;&gt;&lt;!-- class 绑定 --&gt;&lt;div :class=&quot;&#123; red: isRed &#125;&quot;&gt;&lt;/div&gt;&lt;div :class=&quot;[classA, classB]&quot;&gt;&lt;/div&gt;&lt;div :class=&quot;[classA, &#123; classB: isB, classC: isC &#125;]&quot;&gt;&lt;!-- style 绑定 --&gt;&lt;div :style=&quot;&#123; fontSize: size + &apos;px&apos; &#125;&quot;&gt;&lt;/div&gt;&lt;div :style=&quot;[styleObjectA, styleObjectB]&quot;&gt;&lt;/div&gt;&lt;!-- 绑定一个有属性的对象 --&gt;&lt;div v-bind=&quot;&#123; id: someProp, &apos;other-attr&apos;: otherProp &#125;&quot;&gt;&lt;/div&gt;&lt;!-- 通过 prop 修饰符绑定 DOM 属性 --&gt;&lt;div v-bind:text-content.prop=&quot;text&quot;&gt;&lt;/div&gt;&lt;!-- prop 绑定。“prop”必须在 my-component 中声明。--&gt;&lt;my-component :prop=&quot;someThing&quot;&gt;&lt;/my-component&gt;&lt;!-- 通过 $props 将父组件的 props 一起传给子组件 --&gt;&lt;child-component v-bind=&quot;$props&quot;&gt;&lt;/child-component&gt;&lt;!-- XLink --&gt;&lt;svg&gt;&lt;a :xlink:special=&quot;foo&quot;&gt;&lt;/a&gt;&lt;/svg&gt;","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.songshuiyang.com/tags/vue/"}]},{"title":"Vue.js","slug":"frontend/Vue","date":"2017-10-03T14:40:12.000Z","updated":"2019-09-16T13:11:07.261Z","comments":true,"path":"2017/10/03/frontend/Vue/","link":"","permalink":"http://www.songshuiyang.com/2017/10/03/frontend/Vue/","excerpt":"前缀 $，实例属性与方法这些只是Vue的命名规则，为了缺分普通变量属性，避免我们自己声明或者添加自定义属性导致覆 生命周期beforecreated：el 和 data 并未初始化 created:完成了 data 数据的初始化，el没有 beforeMount：完成了 el 和 data 初始化 mounted ：完成挂载","text":"前缀 $，实例属性与方法这些只是Vue的命名规则，为了缺分普通变量属性，避免我们自己声明或者添加自定义属性导致覆 生命周期beforecreated：el 和 data 并未初始化 created:完成了 data 数据的初始化，el没有 beforeMount：完成了 el 和 data 初始化 mounted ：完成挂载 生命周期 lifecyc 生命周期钩子 Lifecycle 钩子函数 钩子函数就是指再所有函数执行前，我先执行了的函数，即 钩住 我感兴趣的函数，只要它执行，我就先执行,这个解释666 双向绑定v-model 指令，它能轻松实现表单输入和应用状态之间的双向绑定。 在底层的实现上，Vue 将模板编译成虚拟 DOM 渲染函数。结合响应系统，在应用状态改变时，Vue 能够智能地计算出重新渲染组件的最小代价并应用到 DOM 操作上。 数据如果你知道你会在晚些时候需要一个属性，但是一开始它为空或不存在，那么你仅需要设置一些初始值。比如： 1234567data: &#123; newTodoText: '', visitCount: 0, hideCompletedTodos: false, todos: [], error: null&#125; 一个对象的 v-for123&lt;div v-for=\"(value, key, index) in object\"&gt; &#123;&#123; index &#125;&#125;. &#123;&#123; key &#125;&#125;: &#123;&#123; value &#125;&#125;&lt;/div&gt; 12345678910new Vue(&#123; el: &apos;#v-for-object&apos;, data: &#123; object: &#123; firstName: &apos;John&apos;, lastName: &apos;Doe&apos;, age: 30 &#125; &#125;&#125;) 索引 key value 123&lt;div v-for=\"(value, key, index) in object\"&gt; &#123;&#123; index &#125;&#125;. &#123;&#123; key &#125;&#125;: &#123;&#123; value &#125;&#125;&lt;/div&gt; 123456789101112&lt;!-- 阻止单击事件冒泡 --&gt;&lt;a v-on:click.stop=\"doThis\"&gt;&lt;/a&gt;&lt;!-- 提交事件不再重载页面 --&gt;&lt;form v-on:submit.prevent=\"onSubmit\"&gt;&lt;/form&gt;&lt;!-- 修饰符可以串联 --&gt;&lt;a v-on:click.stop.prevent=\"doThat\"&gt;&lt;/a&gt;&lt;!-- 只有修饰符 --&gt;&lt;form v-on:submit.prevent&gt;&lt;/form&gt;&lt;!-- 添加事件侦听器时使用事件捕获模式 --&gt;&lt;div v-on:click.capture=\"doThis\"&gt;...&lt;/div&gt;&lt;!-- 只当事件在该元素本身 (比如不是子元素) 触发时触发回调 --&gt;&lt;div v-on:click.self=\"doThat\"&gt;...&lt;/div&gt; vue模板只能有一个根对象1234&lt;template&gt; &lt;h2&gt;底部&lt;/h2&gt; &lt;span v-text=\"msgFromFather\"&gt;&lt;/span&gt;&lt;/template&gt; 报错1Component template should contain exactly one root element. If you are using v-if on multiple elements, use v-else-if to chain them instead. 原来vue模板只能有一个根对象所以你想要出现正常的效果，你的用一个div来或是别的标签来包裹全部的元素123456&lt;template&gt; &lt;div&gt; &lt;h2&gt;底部&lt;/h2&gt; &lt;span v-text=\"msgFromFather\"&gt;&lt;/span&gt; &lt;/div&gt;&lt;/template&gt;","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.songshuiyang.com/tags/vue/"}]},{"title":"其他插件","slug":"technology/其他插件","date":"2017-10-01T06:31:12.000Z","updated":"2020-03-16T11:43:55.635Z","comments":true,"path":"2017/10/01/technology/其他插件/","link":"","permalink":"http://www.songshuiyang.com/2017/10/01/technology/其他插件/","excerpt":"","text":"","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"web","slug":"web","permalink":"http://www.songshuiyang.com/tags/web/"}]},{"title":"嵌入网易云插件","slug":"essay/网易云","date":"2017-10-01T06:31:12.000Z","updated":"2020-03-16T11:43:55.619Z","comments":true,"path":"2017/10/01/essay/网易云/","link":"","permalink":"http://www.songshuiyang.com/2017/10/01/essay/网易云/","excerpt":"","text":"","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"web","slug":"web","permalink":"http://www.songshuiyang.com/tags/web/"}]},{"title":"增加畅言功能","slug":"technology/增加畅言功能","date":"2017-10-01T05:31:12.000Z","updated":"2020-03-16T11:43:55.640Z","comments":true,"path":"2017/10/01/technology/增加畅言功能/","link":"","permalink":"http://www.songshuiyang.com/2017/10/01/technology/增加畅言功能/","excerpt":"","text":"畅言- 专业的社会化评论系统 网址:https://changyan.kuaizhan.com/ 添加功能: 根据上面的网址注册 复制 畅言秘钥(SourceID) 复制以下代码，并粘贴到您网页源代码的123456789```aidl&lt;div id=&quot;SOHUCS&quot; sid=&quot;请将此处替换为配置SourceID的语句&quot;&gt;&lt;/div&gt;&lt;script charset=&quot;utf-8&quot; type=&quot;text/javascript&quot; src=&quot;https://changyan.sohu.com/upload/changyan.js&quot; &gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt;window.changyan.api.config(&#123;appid: &apos;cytf5fPKF&apos;,conf: &apos;prod_ee3a22e2c13174e193691fbc93e3cbc8&apos;&#125;);&lt;/script&gt; 效果: view 网站需要备案,不然只有15天的试用期: ICP备案： 只要网站在国内不管网站大小都需要在工信部网站在线申请备案号，但提供的审核资料可能就是不真实的，因为工信部不会去实际的核实。工信部要求的仅仅是有备案号即视为合法网站","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"web","slug":"web","permalink":"http://www.songshuiyang.com/tags/web/"}]},{"title":"nodeJs","slug":"frontend/nodeJs","date":"2017-10-01T03:48:12.000Z","updated":"2019-09-16T13:11:07.285Z","comments":true,"path":"2017/10/01/frontend/nodeJs/","link":"","permalink":"http://www.songshuiyang.com/2017/10/01/frontend/nodeJs/","excerpt":"","text":"Node.jsNode.js 让 JavaScript 编写服务器端应用程序成为可能。它建立在 JavaScript V8（C++ 编写的） 运行时之上，所以它很快。最初，它旨在为应用程序提供服务器环境，但是开发人员开始利用它来创建工具，帮助他们本地的任务自动化。此后，一个全新基于 Node 工具（如 Grunt 和 Gulp）的生态系统，使得前端开发改头换面。 要使用 Node.js 中的这些工具（或包），我们需要一种有效的方式来安装和管理它们。这就要用到node 包管理器： npm 了。它能够安装你想要的包，而且提供一个强大接口来使用它们。在使用 npm 之前，首先得在系统上安装 Node.js。 NPM（node package manager）node包管理器 将开发者从繁琐的包管理工作（版本、依赖等）中解放出来，更加专注于功能的开发。 package.json包描述信息如果我们的项目依赖了很多package，一个一个地安装那将是个体力活。我们可以将项目依赖的包都在package.json这个文件里声明，然后一行命令搞定 1npm install 安装方式本地安装：package会被下载到当前所在目录，也只能在当前目录下使用。 全局安装：package会被下载到到特定的系统目录下，安装的package能够在所有目录下使用。’ devDependencies和dependencies的区别使用npm install 安装模块或插件的时候，有两种命令把他们写入到 package.json 文件里面去，比如： –save-dev –save 但是当安装新包的时候如何让它保持最新呢？我们可以使用 –save 标识。 在 package.json 文件里面提现出来的区别就是，使用 –save-dev 安装的 插件，被写入到 devDependencies 对象里面去，而使用 –save 安装的插件，责被写入到 dependencies 对象里面去。 那 package.json 文件里面的 devDependencies 和 dependencies 对象有什么区别呢？ devDependencies 里面的插件只用于开发环境，不用于生产环境，而 dependencies 是需要发布到生产环境的。","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"node","slug":"node","permalink":"http://www.songshuiyang.com/tags/node/"},{"name":"npm","slug":"npm","permalink":"http://www.songshuiyang.com/tags/npm/"}]},{"title":"Hibernate 问题记录","slug":"backend/framework/hibernate/hibernate问题集合","date":"2017-09-24T08:54:12.000Z","updated":"2020-03-16T11:43:55.396Z","comments":true,"path":"2017/09/24/backend/framework/hibernate/hibernate问题集合/","link":"","permalink":"http://www.songshuiyang.com/2017/09/24/backend/framework/hibernate/hibernate问题集合/","excerpt":"","text":"org.hibernate.MappingException: Unknown entity常见问题 可能原因一 检查实体类是否导入的是 javax.persistence 下的包 可能原因二 没有在cfg文件中加入 *.hbm.xml造成的 hibernate版本问题,一代版本一代神 4.5 版本 1ServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySettings(conf.getProperties()).build(); 5.2 版本 1ServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySettings(conf.getProperties()).configure().build();","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Hibernate","slug":"Hibernate","permalink":"http://www.songshuiyang.com/tags/Hibernate/"}]},{"title":"Hibernate笔记","slug":"backend/framework/hibernate/Hibernate笔记","date":"2017-09-23T15:28:12.000Z","updated":"2020-03-16T11:43:55.393Z","comments":true,"path":"2017/09/23/backend/framework/hibernate/Hibernate笔记/","link":"","permalink":"http://www.songshuiyang.com/2017/09/23/backend/framework/hibernate/Hibernate笔记/","excerpt":"","text":"hibernate.properties 使用 hibernate.properties 文件配置Hibernate 需要在代码里面手动添加持久化类,所以在实际开发中不使用hibernate.property 文件作为配置文件的原因","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Hibernate","slug":"Hibernate","permalink":"http://www.songshuiyang.com/tags/Hibernate/"}]},{"title":"Hibernate 例子","slug":"backend/framework/hibernate/Hibernate","date":"2017-09-23T15:28:12.000Z","updated":"2020-03-16T11:43:55.390Z","comments":true,"path":"2017/09/23/backend/framework/hibernate/Hibernate/","link":"","permalink":"http://www.songshuiyang.com/2017/09/23/backend/framework/hibernate/Hibernate/","excerpt":"概述: 面向Java环境的对象/关系数据库映射工具,用于将面向对象模型表示的对象映射到基于SQL的关系模型的数据结构中,消除那些针对特定数据库厂商的SQL代码,并把结果集从表格式的形式转换成值对象的形式","text":"概述: 面向Java环境的对象/关系数据库映射工具,用于将面向对象模型表示的对象映射到基于SQL的关系模型的数据结构中,消除那些针对特定数据库厂商的SQL代码,并把结果集从表格式的形式转换成值对象的形式 Hibernate的数据库操作直接采用了POJO(普通的传统的Java对象)作为持久化类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.hibernate.entity;import javax.persistence.*;/** * @author songshuiyang * @title: * @description: * @date 2017/9/23 23:41 */@Entity /*标明持久化类*/@Table(name = &quot;user&quot;)public class User &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) // 主键生成策略 private String id; private String name; private int sex; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getSex() &#123; return sex; &#125; public void setSex(int sex) &#123; this.sex = sex; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&apos;&quot; + id + &apos;\\&apos;&apos; + &quot;, name=&apos;&quot; + name + &apos;\\&apos;&apos; + &quot;, sex=&quot; + sex + &apos;&#125;&apos;; &#125;&#125; Hibernate基本上是使用了JPA的标准注解(javax.persistence) JPA JPA是Java Persistence API的简称，中文名Java持久层API，是JDK 5.0注解或XML描述对象－关系表的映射关系，并将运行期的实体对象持久化到数据库中。Sun引入新的JPA ORM规范出于两个原因：其一，简化现有Java EE和Java SE应用开发工作；其二，Sun希望整合ORM技术，实现天下归一。 JPA是一种规范，而Hibernate是它的一种实现。除了Hibernate，还有EclipseLink(曾经的toplink)，OpenJPA等可供选择，所以使用Jpa的一个好处是，可以更换实现而不必改动太多代码。 配置文件 (#.properties , XML配置文件的形式)1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;GBK&quot;?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC &quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot;&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 指定连接数据库所用的驱动 --&gt; &lt;property name=&quot;connection.driver_class&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;!-- 指定连接数据库的url，其中hibernate是本应用连接的数据库名 --&gt; &lt;property name=&quot;connection.url&quot;&gt;jdbc:mysql://localhost/ecut&lt;/property&gt; &lt;!-- 指定连接数据库的用户名 --&gt; &lt;property name=&quot;connection.username&quot;&gt;root&lt;/property&gt; &lt;!-- 指定连接数据库的密码 --&gt; &lt;property name=&quot;connection.password&quot;&gt;root&lt;/property&gt; &lt;!-- 指定连接池里最大连接数 --&gt; &lt;property name=&quot;hibernate.c3p0.max_size&quot;&gt;20&lt;/property&gt; &lt;!-- 指定连接池里最小连接数 --&gt; &lt;property name=&quot;hibernate.c3p0.min_size&quot;&gt;1&lt;/property&gt; &lt;!-- 指定连接池里连接的超时时长 --&gt; &lt;property name=&quot;hibernate.c3p0.timeout&quot;&gt;5000&lt;/property&gt; &lt;!-- 指定连接池里最大缓存多少个Statement对象 --&gt; &lt;property name=&quot;hibernate.c3p0.max_statements&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;hibernate.c3p0.idle_test_period&quot;&gt;3000&lt;/property&gt; &lt;property name=&quot;hibernate.c3p0.acquire_increment&quot;&gt;2&lt;/property&gt; &lt;property name=&quot;hibernate.c3p0.validate&quot;&gt;true&lt;/property&gt; &lt;!-- 指定数据库方言 --&gt; &lt;property name=&quot;dialect&quot;&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/property&gt; &lt;!-- 根据需要自动创建数据表 --&gt; &lt;property name=&quot;hbm2ddl.auto&quot;&gt;update&lt;/property&gt;&lt;!--①--&gt; &lt;!-- 显示Hibernate持久化操作所生成的SQL --&gt; &lt;property name=&quot;show_sql&quot;&gt;true&lt;/property&gt; &lt;!-- 将SQL脚本进行格式化后再输出 --&gt; &lt;property name=&quot;hibernate.format_sql&quot;&gt;true&lt;/property&gt; &lt;mapping class=&quot;com.hibernate.entity.User&quot;/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 测试方法1234567891011121314151617181920212223242526public class UserManagerTest &#123; @Test public void test1()&#123; // 实例化Configuration， Configuration conf = new Configuration().configure(); ServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySettings(conf.getProperties()).configure().build(); // 以Configuration实例创建SessionFactory实例 SessionFactory sf = conf.buildSessionFactory(serviceRegistry); // 创建Session Session sess = sf.openSession(); // 开始事务 Transaction tx = sess.beginTransaction(); // 创建消息对象 User user = new User(); // 设置消息标题和消息内容 user.setName(&quot;hibernate&quot;); user.setSex(12); sess.save(user); // 提交事务 tx.commit(); // 关闭Session sess.close(); sf.close(); &#125;&#125;","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Hibernate","slug":"Hibernate","permalink":"http://www.songshuiyang.com/tags/Hibernate/"}]},{"title":"常见的编码方式","slug":"backend/other/常见的编码方式","date":"2017-09-21T12:54:12.000Z","updated":"2020-03-16T11:43:55.543Z","comments":true,"path":"2017/09/21/backend/other/常见的编码方式/","link":"","permalink":"http://www.songshuiyang.com/2017/09/21/backend/other/常见的编码方式/","excerpt":"计算机为什么要编码在计算机中所有的数据都是以0,1来存储的,那字符是怎样在计算机存储的呢,美国的科学家把一个特定的数字对应一个特定的字母进行存储和传输，比如我需要存储字母a，那么我存入一个数字97(即在计算机中存入二进制(01100001)，这个过程叫做编码(encode)，而我们在读取数据的时候，当遇到97时，我们就让计算机显示字母a，这个过程叫做解码(decode)。 编码发展历史简介","text":"计算机为什么要编码在计算机中所有的数据都是以0,1来存储的,那字符是怎样在计算机存储的呢,美国的科学家把一个特定的数字对应一个特定的字母进行存储和传输，比如我需要存储字母a，那么我存入一个数字97(即在计算机中存入二进制(01100001)，这个过程叫做编码(encode)，而我们在读取数据的时候，当遇到97时，我们就让计算机显示字母a，这个过程叫做解码(decode)。 编码发展历史简介 第一阶段ASCII规则: 所有的控制字符(比如CR回车、DEL删除等)编码在0-31范围以及127中。 把所有的标点符号，英文大小写全部放在32-126范围中。 防止以后出现需要补充的情况，把128-255位这么多位置留出来，应该足够用了吧！所以设置一个字节8位二进制，把这个标准叫American Standard Code for Information Interchange(美国标准信息交换代码，简写为ASCII)，标准制定结束。 实现方式: 第一位始终未0，后面7位表示0-127的范围，一个数字对应一个字母或者标点符号，亦或者控制符号，即所有的ASCII码的统一形式为0xxxx xxxx。 第二阶段 GB2312,GBK, BIG5 Latin1, ISO-8859-1, JIS, ANSI… 计算机技术到了欧洲，欧洲人发现怎么我们的那么多符号没有编进去啊！所以欧洲”砖家”坐到了一起，开始讨论。发现既然美国人把第一位流出来了，那么我们就用128-255的位置好了。 规则: 128-159之间为控制字符，160-255位文字符号，其中包括了西欧语言、希腊语、泰语、阿拉伯语、希伯来语。 刚好把美国人给的空间全部用完，世界真美好，谢谢美利坚预留的每一个位置。 砖家们决定把他们的编码名称叫做Latin1，后面由于欧洲统一制定ISO标准，所以又有了一个ISO的名称，即ISO-8859-1。 实现方式: 0-127的所有位置不动，那么可以兼容ASCII，二进制位0xxx xxxx 128-255位置全部用完，二进制位1xxx xxxx由于所有的位置全部用完，而欧元符号实在指定标准之后才出现的，所以在这个码表中连欧洲人自己的货币符号都没有办法放进去。 计算机技术当然也传到了亚洲大地，比如中国。中国砖家们坐在一起发现，美国人搞的这个东西真的有问题，预留才128-255的空间，可是我们的汉字个数远远超出了这个数目啊，怎么办？？后面聪明的中国砖家们发现，只能使用2个字节了，否则真的搞不定。由于必须和美国原来制定的ASCII不冲突，所以指定了如下规则 规则: 如果一个字节中第一位为0，那么这就是一个ASCII字符。 如果一个字节中第一位为1，那么这个是汉字，认定需要2个字节才表示一个编码的文字。把这个码表叫GB2312这个码表中包含汉字6763个和非汉字图形字符682个。还有很多的空间没有用到，索性全部预留了吧。 实现方式: 0xxxxxxx：表示为ASCII字符 -1xxxxxxx 1xxxxxxx：表示为汉字 后面再次添加更多的字符进去，再次命名为GB18030，兼容GBK。由于汉字很多，2个字节并不能完全包括进去，所以GB18030采用2\\4位混编的形式。 当然计算机也传到了日本(JIS)、韩国、台湾(BIG5)等等地方，大家全部发挥自己的聪明才智，各自实现了自己的编码。这些编码都与ASCII兼容，但是相互之间不兼容。 使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码，又称为”MBCS（Muilti-Bytes Charecter Set，多字节字符集）”。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码，所以在中文 windows下要转码成gb2312,gbk只需要把文本保存为ANSI编码即可。 不同ANSI编码之间互不兼容 第三阶段 随着通讯越来越多，而老美发现在自己公司需要国际化的时候，自己原来埋的这个雷真的害了自己。于是乎，开始研讨把世界上几乎所有文字全部放在一个码表中，而这个包罗万象的码表就叫做Unicode，即万国码。Unicode是国际组织制定的可以容纳世界上所有文字和符号的字符编码方案。Unicode用数字0-0x10FFFF来映射这些字符，最多可以容纳1114112个字符，或者说有1114112个码位。码位就是可以分配给字符的数字。实际上，在软件制造商的协会（unicode.org）在做这个工作时，国际标准化组织（ISO）在做同样的事情，最后大家都意识到世界上并不需要两个不同的万国码，于是大家坐在一起合并研究的成果，最后的结果就是现在的Unicode。 各个编码及其范围ASCII编码范围00-7F，其中00-1F、FF为控制字符。其它为英文字母、数字、标点符号。 Latin1编码范围00-FF，其中00-7F同ASCII，80-9F为控制符、9F-FF为字母和标点符号. CP1252微软的企业标准，补充了一些符号和欧元符号，为Latin1的超集。 GB2312编码范围为A1A1-F7FE(剔除xx7F)，共23940个码位。其中很多区间没有用到，而汉字使用的区间为B0A1-F7FE，其他为标点符号和特殊字符。除常用简体汉字字符外还包括希腊字母、日文平假名及片假名字母、俄语西里尔字母等字符，未收录繁体中文汉字和一些生僻字。对汉字进行了分区管理，其中第一个字节为区位码，包括下面区位。01-09区为特殊符号。16-55区为一级汉字，按拼音排序。56-87区为二级汉字，按部首/笔画排序。10-15区及88-94区则未有编码。第二个字节为位字节，01-94总计94个。为什么实际选择不是01-5E，而是选择A1-F7的位置呢？因为英文可见字符区间为20-7F，加上128(也就是最高位为1)后得到的取件即是A1-FE区位码使用了0xA1-0xF7(把01-87区的区号加上0xA0)，位字节使用了0xA1-0xFE(把01-94加上 0xA0) GBK编码范围为8140-FEFE,兼容GB2312，仍然有部分区间没有用到。GBK也支持希腊字母、日文假名字母、俄语字母等字符，但不支持韩语中的表音字符（非汉字字符）。GBK还收录了GB2312不包含的 汉字部首符号、竖排标点符号等字符。GBK对GB2312就是，你有的，我也有，你没得的，我还有！ CP936CP936是微软指定的标准，属于企业标准，和GBK的有些许差别，绝大多数情况下可以把CP936当作GBK的别名。 BIG5Big5是双字节编码，高字节编码范围是0x81-0xFE，低字节编码范围是0x40-0x7E和0xA1-0xFE。和GBK相比，少了低字节是0x80-0xA0的组合。0x8140-0xA0FE是保留区域，用于用户造字区。Big5收录的汉字只包括繁体汉字，不包括简体汉字，一些生僻的汉字也没有收录。 CP950微软的企业标准，可以理解为是对 Big5的扩展。 GB18030编码范围同GBK，补充了更多的字符，由于Unicode开始流行且GB18030补充的字符都比较生僻，所以实际使用上基本是GBK。GB18030编码是变长编码，有单字节、双字节和四字节三种方式。GB18030的单字节编码范围是0x00-0x7F，完全等同与ASCII；双字节编码的范围和GBK相同，高字节是0x81-0xFE，低字节的编 码范围是0x40-0x7E和0x80-FE；四字节编码中第一、三字节的编码范围是0x81-0xFE，二、四字节是0x30-0x39。 Unicode中文的编码范围为4E00-9FCF，其中9FC4-9FCF之间的区间没有使用。一个蛋疼的问题就是这个区间全部都是文字，中文标点没有包含在其中，中文标点散落在各个位置。详细请看http://blog.chinaunix.net/uid-12348673-id-3335307.html。一些特殊的文字和中文部首以及一些特殊符号也不在此范围内，详细情况可以参考网址：http://www.cnblogs.com/sosoft/p/3456631.html Unicode的实现方式 Unicode只是进行了编码，也就是说只是一个码表，至于具体怎么实现，并没有规定。下面是Unicode的几种实现方法。 Unicode UTF-8之间的关系简单来说：Unicode 是「字符集」 UTF-8 是「编码规则」 其中： 字符集：为每一个「字符」分配一个唯一的 ID（学名为码位 / 码点 / Code Point） 编码规则：将「码位」转换为字节序列的规则（编码/解码 可以理解为 加密/解密 的过程） Unicode定义了所有可以用来表示字符的数值集合（称之为Code Point）。UTF-8和UTF-16等UTF标准定义了这些数值和字符的映射关系。 正如名字所示，在UTF－8中，字符是以8位序列来编码的，用一个或几个字节来表示一个字符。这种方式的最大好处，是UTF－8保留了ASCII字符的编码做为它的一部分，例如，在UTF－8和ASCII中，“A”的编码都是0x41.UTF－16和UTF－32分别是Unicode的16位和32位编码方式。考虑到最初的目的，通常说的Unicode就是指UTF-16。 UTF-8 (UCS Transfer Format:Unicode转做某种格式)UTF-8以字节为单位对Unicode进行编码。 从Unicode到UTF-8的编码方式如下： Unicode编码(16进制) ║ UTF-8 字节流(二进制) 000000 - 00007F ║ 0xxxxxxx 000080 - 0007FF ║ 110xxxxx 10xxxxxx 000800 - 00FFFF ║ 1110xxxx 10xxxxxx 10xxxxxx 010000 - 10FFFF ║ 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 特点:UTF-8的特点是对不同范围的字符使用不同长度的编码 UTF-16在Unicode基本多文种平面定义的字符（无论是拉丁字母、汉字或其他文字或符号），一律使用2字节储存。而在辅助平面定义的字符，会以代理对（surrogate pair）的形式，以两个2字节的值来储存。UTF-16比起UTF-8，好处在于大部分字符都以固定长度的字节 (2字节) 储存，但UTF-16却无法兼容于ASCII编码。可以认为UTF-16是下面介绍的UCS-2的父集。在没有辅助平面字符（surrogate code points）前，UTF-16与UCS-2所指的是同一的意思。但当引入辅助平面字符后，就称为UTF-16了。现在若有软件声称自己支援UCS-2编码，那其实是暗指它不能支援在UTF-16中超过2bytes的字集。对于小于0x10000的UCS码，UTF-16编码就等于UCS码。如果一个UTF-16文件没有指定BOM，默认应该是UTF-16BE，但是在Intel x86中却是UTF-16LE。所以在现实世界中有很多的没有指定大小尾的UTF-16却是UTF-16LE。 UTF-32每一个Unicode码位使用恰好32位元。可以粗暴的认为UTF-32和下面要介绍的UCS-4是等同的。 UCS-2采用2个字节，定长的表示每一个字符，所以总计可以表示2^16个字符。 UCS-4UCS-4根据最高位为0的最高字节分成2^7=128个group。每个group再根据次高字节分为256个plane。每个plane根据第3个字节分为256行(rows)，每行包含256个cells。当然同一行的cells只是最后一个字节不同，其余都相同。group 0的plane 0被称作Basic Multilingual Plane, 即BMP。或者说UCS-4中，高两个字节为0的码位被称作BMP。将UCS-4的BMP去掉前面的两个零字节就得到了UCS-2。在UCS-2的两个字节前加上两个零字节，就得到了UCS-4的BMP。而目前的UCS-4规范中还没有任何字符被分配在BMP之外。 转自:http://www.cnblogs.com/jessonluo/p/4800331.html 编码检测到底采用什么编码，如果能检测就好了。专家们也是这么想的，所以专家给每种格式和字节序规定了一些特殊的编码， 这些编码在unicode 中是没有使用的，所以不用担心会冲突。 这个叫做BOM（Byte Order Mark）头。意思是字节序标志头。通过它基本能确定编码格式和字节序。 UTF编码 ║ Byte Order Mark UTF-8 ║ EF BB BF UTF-16LE ║ FF FE UTF-16BE ║ FE FF UTF-32LE ║ FF FE 00 00 UTF-32BE ║ 00 00 FE FF所以通过检测文件前面的BOM头，基本能确定编码格式和字节序。但是这个BOM头只是建议添加，不是强制的，所以不少软件和系统没有添加这个BOM头（所以有些软件格式中有带BOM头 和NoBOM头的选择），这个时候要检测什么格式，就比较麻烦了当然可以检测，但是不能保证100%准确，只能通过编码范围从概率上来检查，虽然准确度还是比较高，但是不能保证 100%。所以，时常看到检测错误的软件，也不奇怪了。 UTF-8 与UTF-16的区别 UTF-16比较好理解,就是任何字符对应的数字都用两个字节来保存.我们通常对Unicode的误解就是把Unicode与UTF-16等同了.但是很显然如果都是英文字母这做有点浪费.明明用一个字节能表示一个字符为啥整两个啊. 于是又有个UTF-8,这里的8非常容易误导人,8不是指一个字节,难道一个字节表示一个字符?实际上不是.当用UTF-8时表示一个字符是可变的,有可能是用一个字节表示一个字符,也可能是两个,三个.当然最多不能超过3个字节了.反正是根据字符对应的数字大小来确定. 于是UTF-8和UTF-16的优劣很容易就看出来了.如果全部英文或英文与其他文字混合,但英文占绝大部分,用UTF-8就比UTF-16节省了很多空间.而如果全部是中文这样类似的字符或者混合字符中中文占绝大多数.UTF-16就占优势了,可以节省很多空间.另外还有个容错问题,等会再讲","categories":[{"name":"笔记","slug":"笔记","permalink":"http://www.songshuiyang.com/categories/笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"}]},{"title":"Struts2 问题总结","slug":"backend/framework/struts2/Struts2 问题总结","date":"2017-09-19T08:12:44.000Z","updated":"2020-03-16T11:43:55.405Z","comments":true,"path":"2017/09/19/backend/framework/struts2/Struts2 问题总结/","link":"","permalink":"http://www.songshuiyang.com/2017/09/19/backend/framework/struts2/Struts2 问题总结/","excerpt":"","text":"上传图片出现错误但是，明明上传的文件格式是正确，还是出现： Content-Type not allowed: file &quot;09poC_wallpapers.jpg&quot; &quot;upload_1ea6fe4e_13611ac7d7c__8000_00000012.tmp&quot; image/pjpeg firefox 和 ie 的文件类型区别 Firefox： image/jpeg, image/bmp, image/gif, image/png ie 6： image/pjpeg ,image/bmp, image/gif, image/x-png ie 7： image/pjpeg, image/bmp, image/gif, image/x-png ie 8： image/pjpeg, image/bmp, image/gif, image/x-png Ie 9： image/jpeg, image/bmp, image/gif, image/png 解决方法 &lt;param name=&quot;allowedTypes&quot;&gt; image/bmp,image/png,image/gif,image/jpeg,image/jpg, image/pjpeg ,image/bmp, image/gif, image/x-png, &lt;/param&gt;","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.songshuiyang.com/tags/java/"},{"name":"struts2","slug":"struts2","permalink":"http://www.songshuiyang.com/tags/struts2/"}]},{"title":"Struts2 的简单实例","slug":"backend/framework/struts2/Struts2 的简单实例","date":"2017-09-16T13:30:44.000Z","updated":"2020-03-16T11:43:55.402Z","comments":true,"path":"2017/09/16/backend/framework/struts2/Struts2 的简单实例/","link":"","permalink":"http://www.songshuiyang.com/2017/09/16/backend/framework/struts2/Struts2 的简单实例/","excerpt":"","text":"Struts2 实现流程 浏览器发送请求 到达 StrutsPrepareAndExecuteFilter ( 核心控制器 ) 分发到指定 XXXAction ( 业务控制器 ) 调用业务方法 返回逻辑视图名 StrutsPrepareAndExecuteFilter forward到物理视图,生成响应内容，输出响应","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.songshuiyang.com/tags/java/"},{"name":"struts2","slug":"struts2","permalink":"http://www.songshuiyang.com/tags/struts2/"}]},{"title":"Servlet-web.xml中配置JSP属性","slug":"backend/java/servlet/Servlet-web.xml中配置JSP属性","date":"2017-09-15T08:19:45.000Z","updated":"2020-03-16T11:43:55.515Z","comments":true,"path":"2017/09/15/backend/java/servlet/Servlet-web.xml中配置JSP属性/","link":"","permalink":"http://www.songshuiyang.com/2017/09/15/backend/java/servlet/Servlet-web.xml中配置JSP属性/","excerpt":"","text":"web.xml中配置JSP属性 为什么要在web.xml配置JSP属性 如果许多JSP有着相似的属性，那么在每个JSP文件的顶部重复添加page指令是非常麻烦的工作。幸运的是，在部署描述符中可以配置通用的JSP属性。 web.xml中添加JSP属性样例 &lt;jsp-config&gt; &lt;jsp-property-group&gt; &lt;url-pattern&gt;*.jsp&lt;/url-pattern&gt; &lt;url-pattern&gt;*.jspf&lt;/url-pattern&gt; &lt;page-encoding&gt;UTF-8&lt;/page-encoding&gt; &lt;scripting-invalid&gt;false&lt;/scripting-invalid&gt; &lt;include-prelude&gt;/WEB-INF/jsp/base.jspf&lt;/include-prelude&gt; &lt;trim-directive-whitespaces&gt;true&lt;/trim-directive-whitespaces&gt; &lt;default-content-type&gt;text/html&lt;/default-content-type&gt; &lt;/jsp-property-group&gt; &lt;/jsp-config&gt; 中可以包含任意数目的标签。通过为定义不同的标签来区分不同的属性组。 标签，将告诉容器在所有属于改该属性组的JSP的头部添加文件/WEB-INF/jsp/base.jspf。 标签定义了包含在组中所有JSP尾部的文件。 在一个JSP组中可以同时使用这些标签多次。 与page指令的pageEncoding特性一致。 标签可以定义内容类型，默认为text/html 也是一个特别有用的属性，该属性告诉JSP转换器删除响应输出中的空白，只保留指令、声明、脚本和其他JSP标签创建的文本。 标签可以实现完全禁止JSP中的Java 的作用类似，不过它对应的是page指令中的isELIgnored特性。除了，中所有标签都是可选的，但在使用它们时必须按照下面的顺序添加到中(忽略掉部希望使用的标签)：、、、、、、、、、、、。","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Server","slug":"Server","permalink":"http://www.songshuiyang.com/tags/Server/"},{"name":"Jsp","slug":"Jsp","permalink":"http://www.songshuiyang.com/tags/Jsp/"}]},{"title":"Servlet","slug":"backend/java/servlet/Servlet-概述","date":"2017-09-14T15:36:44.000Z","updated":"2020-03-16T11:43:55.518Z","comments":true,"path":"2017/09/14/backend/java/servlet/Servlet-概述/","link":"","permalink":"http://www.songshuiyang.com/2017/09/14/backend/java/servlet/Servlet-概述/","excerpt":"Servlet服务器端小程序,运行在服务器端的程序，用于处理及响应客户端的请求,自MVC规范出现之后,Servlet仅仅只作为控制器 Servlet和Jsp的区别 Servlet中没有内置对象,原来JSP中的内置对象都必须有程序显式创建 Servlet对于HTML标签只能使用页面输出流逐行输出，所以自MVC规范出现之后,Servlet仅仅只作为控制器","text":"Servlet服务器端小程序,运行在服务器端的程序，用于处理及响应客户端的请求,自MVC规范出现之后,Servlet仅仅只作为控制器 Servlet和Jsp的区别 Servlet中没有内置对象,原来JSP中的内置对象都必须有程序显式创建 Servlet对于HTML标签只能使用页面输出流逐行输出，所以自MVC规范出现之后,Servlet仅仅只作为控制器 @WebServlet从3.0开始配置Servlet可以使用注解的形式 有些人可能会遇到这种种情况，在采用注解WebServlet配置Servlet的时候，明明在配置了urlPatterns属性，部署应用程序的时候也没有出错。但是就是在浏览器发请求的时候访问不到资源，报404错误request resource is not available。捣腾了半天也不知道，到底是哪而出错了？ Servlet3.0之后新增了注解，用于简化Servlet、Filter及Listener的声明，这样就在配置Servlet的时候多了一个选择。Servlet3.0的部署描述文件web.xml的顶层标签有一个metadata-complete属性，该属性为true，则容器在部署时只依赖部署描述文件，忽略所有标注，如果不配置该属性，或者将其设置为false，则表示启动标注支持。当metadata-complete=”false”时，web.xml和注解对于Servlet的影响同时起作用，两种方法定义的url-partten都可以访问到该Servlet，但是当通过web.xml定义的url-partten访问时，注解定义的属性（初始化参数等）将失效。 属性值name String 指定Servlet 的 name 属性，等价于 。如果没有显式指定，则该 Servlet 的取值即为类的全限定名。 value String[] 该属性等价于 urlPatterns 属性。两个属性不能同时使用。 urlPatterns String[] 指定一组 Servlet 的 URL 匹配模式。等价于标签。 loadOnStartup int 指定 Servlet 的加载顺序，等价于 标签。 initParams WebInitParam[] 指定一组 Servlet 初始化参数，等价于标签。 asyncSupported boolean 声明 Servlet 是否支持异步操作模式，等价于 标签。 description String 该 Servlet 的描述信息，等价于 标签。 displayName String 该 Servlet 的显示名，通常配合工具使用，等价于 标签。 创建Servlet有俩个时机 用户请求某个Servlet，系统创建该Servlet的实例,所以Servlet第一次访问的时间是较长的，因为要初始化Servlet Web应用启动立即创建Servlet实例,即load-on-startup Servlet Servlet 生命周期 创建实例 Web容器调用Servlet的init方法，对Servlet进行初始化。 初始化后将一直存在于容器中，用于响应客户端请求,get post service用于响应用户请求 通常在Web应用关闭之时销毁Servlet，先调用Servlet的destory()方法 使用Servlet作为表现层如有以下几个劣势 所有的Html标签都需要页面输出流完成 前端人员无法参与到页面的编写 可维护性差，页面代码不好调试","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Server","slug":"Server","permalink":"http://www.songshuiyang.com/tags/Server/"}]},{"title":"Servlet-JSP脚本中的九个内置对象","slug":"backend/java/servlet/Servlet-JSP脚本中的九个内置对象","date":"2017-09-14T07:25:44.000Z","updated":"2020-03-16T11:43:55.511Z","comments":true,"path":"2017/09/14/backend/java/servlet/Servlet-JSP脚本中的九个内置对象/","link":"","permalink":"http://www.songshuiyang.com/2017/09/14/backend/java/servlet/Servlet-JSP脚本中的九个内置对象/","excerpt":"JSP脚本中包含九个内置对象，这九个内置对象都是Servlet API接口的实例，只是JSP规范对它们进行了默认初始化（由JSP页面对应的Servlet的_jspService()方法来创建这些实例),也就是说它们已经是对象，可以直接使用 1 pageContext javax.servlet.jsp.PageContext 2 request javax.servlet.http.HttpServletRequest 3 response javax.servlet.http.HttpServletResponse 4 session javax.servlet.http.HttpSession 5 application javax.servlet.ServletContext 6 config javax.servlet.ServletConfig 7 out javax.servlet.jsp.JspWriter 8 page java.lang.Object 9 exception java.lang.Throwable","text":"JSP脚本中包含九个内置对象，这九个内置对象都是Servlet API接口的实例，只是JSP规范对它们进行了默认初始化（由JSP页面对应的Servlet的_jspService()方法来创建这些实例),也就是说它们已经是对象，可以直接使用 1 pageContext javax.servlet.jsp.PageContext 2 request javax.servlet.http.HttpServletRequest 3 response javax.servlet.http.HttpServletResponse 4 session javax.servlet.http.HttpSession 5 application javax.servlet.ServletContext 6 config javax.servlet.ServletConfig 7 out javax.servlet.jsp.JspWriter 8 page java.lang.Object 9 exception java.lang.Throwable page对象page对象表示当前一个JSP页面，可以理解为一个对象本身，即：把一个JSP当作一个对象来看待。page对象在开发中几乎不用，了解一下即可 out对象out对象代表一个页面输出流，通常用于在页面上输出变量值及常量。一般在使用输出表达式的地方都可以使用out对象达到同样的效果。out是个页面输出流，负责输出页面的内容，但是用out需要编写更多的代码。&lt;%= %&gt;表达式的本质就是out.write(…);对于页面上的某个html标签来讲 如果使用了out即 &lt;% out.println(“&lt;table&gt;”); out.println(“&lt;tr&gt;”); out.println(“&lt;/tr&gt;”); out.println(“&lt;/table&gt;”); %&gt; pageContext对象pageContext对象是JSP技术中最重要的一个对象，它代表JSP页面的运行环境，这个对象不仅封装了对其它8大隐式对象的引用，它自身还是一个域对象(容器)，可以用来保存数据。并且，这个对象还封装了web开发中经常涉及到的一些常用操作，例如引入和跳转其它资源、检索其它域对象中的属性等。 getException方法 返回exception隐式对象 getPage方法 返回page隐式对象 getRequest方法 返回request隐式对象 getResponse方法 返回response隐式对象 getServletConfig方法 返回config隐式对象 getServletContext方法返回application隐式对象 getSession方法 返回session隐式对象 getOut方法 返回out隐式对象 pageContext 封装其它8大内置对象的意义 如果在编程过程中，把pageContext对象传递给一个普通java对象，那么这个java对象将可以获取8大隐式对象，此时这个java对象就可以和浏览器交互了，此时这个java对象就成为了一个动态web资源了，这就是pageContext封装其它8大内置对象的意义，把pageContext传递给谁，谁就能成为一个动态web资源，那么什么情况下需要把pageContext传递给另外一个java类呢，什么情况下需要使用这种技术呢，在比较正规的开发中，jsp页面是不允许出现java代码的，如果jsp页面出现了java代码，那么就应该想办法把java代码移除掉，我们可以开发一个自定义标签来移除jsp页面上的java代码，首先围绕自定义标签写一个java类，jsp引擎在执行自定义标签的时候就会调用围绕自定义标签写的那个java类，在调用java类的时候就会把pageContext对象传递给这个java类，由于pageContext对象封装了对其它8大隐式对象的引用，因此在这个java类中就可以使用jsp页面中的8大隐式对象(request，response，config，application，exception，Session，page，out)了，pageContext对象在jsp自定义标签开发中特别重要。 pageContext 作为域对象 pageContext对象可以作为容器来使用，因此可以将一些数据存储在pageContext对象中。 pageContext对象的常用方法 1 public void setAttribute(java.lang.String name,java.lang.Object value) 2 public java.lang.Object getAttribute(java.lang.String name) 3 public void removeAttribute(java.lang.String name) 4 public java.lang.Object findAttribute(java.lang.String name) application 对象 在整个Web应用的多个JSP、Servlet之间的共享数据。通常被定义为数据字典来使用。通常在一处实现application.setAttribute(“name”,value);来定义一个变量，在JSP中使用application.getAttribute(“name”);获取值；在Servlet中使用一个实例的ServletContext对象sc.getAttribute(“name”);获取值。我们可以把application理解成一个Map对象，任何JSP、Servlet都可以把某个变量放入application中保存，并指出一个属性名；而该应用的其他JSP、Servlet就可以根据该属性名来得到这个变量。由于application对象代表整个Web应用，所以只应该把Web应用的状态数据放入到application中。 访问Web应用的配置参数，在web.xml中配置类似的参数，该标签是下的子标签。即 &lt;context-param&gt; &lt;param-name&gt;name&lt;/param-name&gt; &lt;param-value&gt;value&lt;/param-value&gt; &lt;/context-param&gt; 在JSP中可以通过 application.getInitParameter(“name”);取得配置的参数，在Servlet中可以先实例个ServletContext对象即： final javax.servlet.ServletContext application;然后就可以取值了，即： application = pageContext.getServletContext(); application.getInitParameter(&quot;name&quot;); 这里通常被用作普通java Web开发中数据库用户名，密码的获取时使用，因为在项目开发用的密码不一定和部署在服务器上的密码一致，但是把它写到这里便于修改这些有关项目的参数。 config 对象config对象代表当前的JSP配置信息，但JSP页面通常无需配置，因此也就不存在配置信息，该对象在JSP页面用的比较少，但在Servlet中用处则相对较大，因为Servlet需要在web.xml文件中进行配置，可以指定配置参数。但是如果说要为某个JSP配置一些参数的话，也是跟配置Servlet一样需要在web.xml中配置，也就说吧JSP当成Servlet配置 &lt;servlet&gt; &lt;servlet-name&gt;Configure&lt;/servlet-name&gt; &lt;jsp-file&gt;/getcontextparam.jsp&lt;/jsp-file&gt; &lt;init-param&gt; &lt;param-name&gt;conn&lt;/param-name&gt; &lt;param-value&gt;connnn&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;Configure&lt;/servlet-name&gt; &lt;url-pattern&gt;/configure&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 其中这里“/getcontextparam.jsp”是表明把某个JSP配置成Servlet。在地址栏中访问时要输入http://localhost:8080/test/configure（url-pattern中内容）在JSP中获取参数时使用config.getInitParameter(“conn”)即可。 exception 对象该实例代表其他页面的异常和错误,只有当页面是错误处理页面，即编译指令page的isErrorPage属性为true时,该对象才可以使用","categories":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.songshuiyang.com/tags/Java/"},{"name":"Server","slug":"Server","permalink":"http://www.songshuiyang.com/tags/Server/"},{"name":"Jsp","slug":"Jsp","permalink":"http://www.songshuiyang.com/tags/Jsp/"}]},{"title":"Spring mvc整合velocity","slug":"backend/framework/velocity/Spring mvc整合velocity","date":"2017-09-11T08:12:12.000Z","updated":"2020-03-16T11:43:55.409Z","comments":true,"path":"2017/09/11/backend/framework/velocity/Spring mvc整合velocity/","link":"","permalink":"http://www.songshuiyang.com/2017/09/11/backend/framework/velocity/Spring mvc整合velocity/","excerpt":"添加Maven依赖:&lt;!--springmvc集成 velocity--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-tools&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt;","text":"添加Maven依赖:&lt;!--springmvc集成 velocity--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-tools&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; applicationContext-mvc配置文件:&lt;!--》》》》》》》》》》》》》》》 添加velocity显示技术 》》》》》》》》》》》》》》》》》--&gt; &lt;!-- velocity环境配置 --&gt; &lt;bean id=&quot;velocityConfig&quot; class=&quot;org.springframework.web.servlet.view.velocity.VelocityConfigurer&quot;&gt; &lt;!-- velocity配置文件路径 或者直接用velocityProperties属性 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:velocity.properties&quot;/&gt; &lt;!-- velocity模板路径 --&gt; &lt;property name=&quot;resourceLoaderPath&quot; value=&quot;/WEB-INF/templates/&quot;/&gt; &lt;/bean&gt; &lt;!-- velocity视图解析器 --&gt; &lt;bean id=&quot;velocityViewResolver&quot; class=&quot;org.springframework.web.servlet.view.velocity.VelocityLayoutViewResolver&quot;&gt; &lt;property name=&quot;order&quot; value=&quot;0&quot;/&gt; &lt;property name=&quot;contentType&quot; value=&quot;text/html;charset=UTF-8&quot;/&gt; &lt;property name=&quot;cache&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.vm&quot;/&gt; &lt;property name=&quot;layoutUrl&quot; value=&quot;layout/layout.vm&quot;/&gt; &lt;property name=&quot;exposeSpringMacroHelpers&quot; value=&quot;true&quot; /&gt;&lt;!--是否使用spring对宏定义的支持--&gt; &lt;property name=&quot;exposeSessionAttributes&quot; value=&quot;true&quot; /&gt;&lt;!--是否开放request属性--&gt; &lt;property name=&quot;requestContextAttribute&quot; value=&quot;request&quot;/&gt;&lt;!--request属性引用名称--&gt; &lt;property name=&quot;dateToolAttribute&quot; value=&quot;dateTool&quot;/&gt; &lt;property name=&quot;numberToolAttribute&quot; value=&quot;numberTool&quot;/&gt; &lt;/bean&gt; velocity.properties 配置文件该文件velocity.properties 在下面的包路径可以找到 org.apache.velocity.runtime.defaults.velocity.properties #设置字符集 #encoding input.encoding =UTF-8 output.encoding=UTF-8 contentType=text/html;charset=UTF-8 #autoreload when vm changed file.resource.loader.cache=false file.resource.loader.modificationCheckInterval =1 velocimacro.library.autoreload=false 显示文件目录结构 header.mv&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=UTF-8&quot;&gt; &lt;meta http-equiv=&quot;Cache-Control&quot; content=&quot;no-store&quot;/&gt; &lt;meta http-equiv=&quot;Pragma&quot; content=&quot;no-cache&quot;/&gt; &lt;meta http-equiv=&quot;Expires&quot; content=&quot;3600&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt; &lt;meta content=&quot;width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no&quot; name=&quot;viewport&quot;&gt; layout.mv&lt;html&gt; &lt;head&gt; &lt;title&gt;$!page_title&lt;/title&gt; #parse(&quot;default/header.vm&quot;) &lt;/head&gt; &lt;body&gt; &lt;div&gt; $screen_content &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; velocity.mv&lt;html&gt; &lt;head&gt; &lt;title&gt;Spring MVC and Velocity&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Spring MVC and Velocity&lt;/h1&gt; Hello ${hello} &lt;hr /&gt; Copyright &amp;copy 2014 lm &lt;/body&gt; &lt;/html&gt; velocity 基本语法Velocity的基本语法：1、”#”用来标识Velocity的脚本语句，包括#set、#if 、#else、#end、#foreach、#end、#iinclude、#parse、#macro等；如: #if($info.imgs) #else #end 2、”$”用来标识一个对象(或理解为变量)；如如：$i、$msg、$TagUtil.options(…)等。 3、”{}”用来明确标识Velocity变量；比如在页面中，页面中有一个$someonename，此时，Velocity将把someonename作为变量名，若我们程序是想在someone这 个变量的后面紧接着显示name字符，则上面的标签应该改成${someone}name。 4、”!”用来强制把不存在的变量显示为空白。如当页面中包含$msg，如果msg对象有值，将显示msg的值，如果不存在msg对象同，则在页面中将显示$msg字符。这是我们不希望的，为了把不存 在的变量或变量值为null的对象显示为空白，则只需要在变量名前加一个“!”号即可。如：$!msg 5、循#foreach( $info in $list) $info.someList #end，环读取集合list中的对象 #foreach( $info in $hotL包含文件#inclue(“模板文件名”)或#parse(“模板文件名”)st1)$!info.title #end上面的脚本表示循环遍历hotList1集合中的对象，并输出对象的相关内容。 6、包含文件#inclue(“模板文件名”)或#parse(“模板文件名”)主要用于处理具有相同内容的页面，比如每个网站的顶部或尾部内容。使用方法，可以参考EasyJF开源Blog及EasyJF开源论坛中的应用！如：#parse(“/blog/top.html”)或#include(“/blog/top.html”)parse与include的区别在于，若包含的文件中有Velocity脚本标签，将会进一步解析，而include将原样显示。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://www.songshuiyang.com/tags/Spring/"},{"name":"velocity","slug":"velocity","permalink":"http://www.songshuiyang.com/tags/velocity/"},{"name":"Spring Mvc","slug":"Spring-Mvc","permalink":"http://www.songshuiyang.com/tags/Spring-Mvc/"}]},{"title":"常用的JavaEE服务器","slug":"backend/server/JavaEE服务器/常用的JavaEE服务器","date":"2017-09-10T15:30:44.000Z","updated":"2020-03-16T11:43:55.558Z","comments":true,"path":"2017/09/10/backend/server/JavaEE服务器/常用的JavaEE服务器/","link":"","permalink":"http://www.songshuiyang.com/2017/09/10/backend/server/JavaEE服务器/常用的JavaEE服务器/","excerpt":"","text":"Web服务器1：Tomcat与Java结合的最好、开源、Oracle官方推荐的JSP服务器 2：Jetty嵌入式服务器：在应用中加入Jetty的Jar文件,即可提供Web服务，最好搭配Maven使用，采用maven jetty插件，即可通过简单的配置，执行命令即可启动web服务 3：Resin目前最快的Jsp，Servlet运行平台，支持EJB,个人免费，商业交钱 Java EE服务器1：JBoss开源，全面支持各种最新的Java EE规范 2：GlassFishOracle官方提供的JavaEE服务器 3：WebLogic收费所以牛逼 4：WebSphereIBM收费也是牛逼,WebSphere 是 IBM 的软件平台。它包含了编写、运行和监视全天候的工业强度的随需应变 Web 应用程序和跨平台、跨产品解决方案所需要的整个中间件基础设施，如服务器、服务和工具。WebSphere 提供了可靠、灵活和健壮的软件。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.songshuiyang.com/categories/Linux/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.songshuiyang.com/tags/java/"},{"name":"server","slug":"server","permalink":"http://www.songshuiyang.com/tags/server/"}]},{"title":"新建博客方法","slug":"essay/新建博客方法","date":"2017-09-09T17:07:12.000Z","updated":"2020-03-16T11:43:55.608Z","comments":true,"path":"2017/09/10/essay/新建博客方法/","link":"","permalink":"http://www.songshuiyang.com/2017/09/10/essay/新建博客方法/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.songshuiyang.com/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://www.songshuiyang.com/tags/github/"}]},{"title":"Markdown语法","slug":"backend/Markdown语法","date":"2017-09-09T17:07:12.000Z","updated":"2020-03-16T11:43:55.297Z","comments":true,"path":"2017/09/10/backend/Markdown语法/","link":"","permalink":"http://www.songshuiyang.com/2017/09/10/backend/Markdown语法/","excerpt":"","text":"图片1![logo](/images/server/mybatis/mybatis-framework.png) logo 表格:123| a | b | c ||:-------:|:------------- | ----------:|| 居中 | 左对齐 | 右对齐 | a b c 居中 左对齐 右对齐 全部左对齐 123| a | b | c ||:-------|:------------- | :----------|| 左对齐 | 左对齐 | 左对齐 | a b c 左对齐 左对齐 左对齐 第二行 链接http://www.songshuiyang.com","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://www.songshuiyang.com/tags/markdown/"}]},{"title":"前端学习技术","slug":"frontend/前端学习技术","date":"2017-09-09T17:00:12.000Z","updated":"2019-09-16T13:11:07.307Z","comments":true,"path":"2017/09/10/frontend/前端学习技术/","link":"","permalink":"http://www.songshuiyang.com/2017/09/10/frontend/前端学习技术/","excerpt":"技术架构图:","text":"技术架构图: logo","categories":[{"name":"前端","slug":"前端","permalink":"http://www.songshuiyang.com/categories/前端/"}],"tags":[{"name":"web","slug":"web","permalink":"http://www.songshuiyang.com/tags/web/"}]},{"title":"Hexo问题总结","slug":"essay/hexo问题总结","date":"2017-09-09T07:07:12.000Z","updated":"2020-03-16T11:43:55.604Z","comments":true,"path":"2017/09/09/essay/hexo问题总结/","link":"","permalink":"http://www.songshuiyang.com/2017/09/09/essay/hexo问题总结/","excerpt":"","text":"Hexo问题总结 hexo部署后，CNAME会被自动删除，怎么办？ &nbsp;&nbsp;&nbsp;&nbsp;准确来说 CNAME 文件是放在 hexo 项目下的 source 目录，你再运行下hexo generade然后你再去 public 目录中看看就明白了BTW，为了达到更有说服力的验证，最好在开始前先运行下hexo clean这样会先删除 public 目录 HEXO发布到Github上，README.md文件正常显示的解决 &nbsp;&nbsp;&nbsp;&nbsp;使用hexo d 发布本地编译过的代码到github上的时候，发现这个README.md文件也被解析的乱七八糟的，不是一般的github项目里面的README.md文件的显示样式，查了下，在最外层的_config.yml里面把skip_render: README.md添加这个配置，就OK啦。 指定端口启动 hexo server -p 4001 如何在markdowm中添加本地图片 建议将图片统一放在 source/images 文件夹中。然后通过绝对路径![](/images/image.jpg) 引用 卸载hexo npm uninstall hexo -g hexo版本12hexo: 3.7.0hexo-cli: 1.0.3","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.songshuiyang.com/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://www.songshuiyang.com/tags/github/"}]},{"title":"第一篇博客","slug":"essay/第一篇博客","date":"2017-09-09T03:02:12.000Z","updated":"2020-03-16T11:43:55.614Z","comments":true,"path":"2017/09/09/essay/第一篇博客/","link":"","permalink":"http://www.songshuiyang.com/2017/09/09/essay/第一篇博客/","excerpt":"使用hexo+github搭建免费个人博客优势: 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台；","text":"使用hexo+github搭建免费个人博客优势: 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台； hexo简介Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。 官网： http://hexo.io github: https://github.com/hexojs/hexo 原理由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。 注意事项 很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行 hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导 hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的 使用Hexo搭建博客时，需要区分『博客源代码』和『博客生成代码』 『博客源代码』: Hexo的源码，包括themes目录（博客模板），source目录(使用MarkDown写的博客)等 『博客生成代码』： 执行hexo generate或者hexo server命令生成的代码，是Hexo自动生成的，再public目录 常用命令hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server） hexo deploy #部署到GitHub hexo help #查看帮助 hexo version #查看Hexo的版本 ### hexo的文件结构├── _config.yml ├── db.json ├── node_modules ├── package.json ├── public ├── scaffolds ├── source #所有文章文件放在这里 └── themes #主题文件夹 _config.yml 站点的配置文件。 db.json 缓存文件 node_modules 安装的插件以及hexo所需的一些node.js模块。 package.json 应用程序信息，配置hexo运行需要的js包。 public 最终所见网页的所有内容 scaffolds 模板文件夹。当新建一个文章时，会默认包含对应模板的内容。 source 资源文件夹是存放用户资源的地方。所有的源文件都会被保存在_post文件夹中。除 posts 文件夹之外，开头命名为 (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes 存放主题文件，hexo会根据主题来生成静态页面。 图片测试 logo","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.songshuiyang.com/categories/开发工具/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.songshuiyang.com/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://www.songshuiyang.com/tags/github/"},{"name":"nodejs","slug":"nodejs","permalink":"http://www.songshuiyang.com/tags/nodejs/"}]}]}